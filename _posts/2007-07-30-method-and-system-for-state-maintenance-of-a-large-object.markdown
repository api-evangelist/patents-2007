---

title: Method and system for state maintenance of a large object
abstract: In one approach, a system performs state maintenance of a large object with a cache that associates one or more buffers with a transaction involving a large object, the large object data may be accessed using the one or more buffers during the transaction, and the cache stores large object data from the one or more buffers in one or more sets of contiguous blocks in storage.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08775479&OS=08775479&RS=08775479
owner: Oracle International Corporation
number: 08775479
owner_city: Redwood Shores
owner_country: US
publication_date: 20070730
---
The invention relates to computer systems and more particularly to a method and system for implementing state maintenance of a large object in a database management system.

Database management systems DBMS have traditionally dealt with structured data that is stored in rows and columns. A row or a tuple of column pieces is also called relational data. Relational data is typically hundreds of bytes per row and is much smaller than unstructured or file data that has traditionally been managed in file systems. A single file or LOB datatype object can be anywhere from tens of kilobytes to hundreds and thousands of megabytes and as a result passing such enormous amounts of bulk data between the network and the disk differs from how a row is transferred between the network and the disk.

In a DBMS relational data may be passed from the network to underlying storage subsystem of the DBMS without any loss of performance. Optionally storage of relational data in a database may involve reading in the data values from the network writing the data values to a cache and storing the relational data values to the disk. A cache is a collection of data that is a duplication of original values stored elsewhere or computed earlier when the original data is expensive to fetch or to compute relative to retrieval from the cache.

In a database management system a large object may be streamed into the database management system as a collection of a large number of small network packets. If each network packet of a large object is passed from the network to storage one at a time then the performance of the database management system may suffer because each network packet would require space allocation a storage layer update and multiple Input Output I O calls for a small amount of data. The piecemeal space allocation for the large object may leave the disk fragmented and subsequent reads of the data may suffer due to the fragmentation. The small and frequent storage layer updates and I O calls result in suboptimal performance for a large object write. Furthermore the small disk I Os waste disk bandwidth with the disk head seek and rotate involved in writing the large object data.

As shown in embodiments of this approach place a strain on the Database Server resources with the streaming of data for the large object from a Network . For example the approach in requires frequent expensive memory copy calls to stream a large object with the copy of data from the Network Component Buffer to the Database Buffer Cache and from the Database Buffer Cache to the Disk for each network packet received which may place a strain on the Processor . As discussed above the small space allocation small storage layer updates and small I Os to disk affect the DBMS loss of performance. As shown in streaming the data from a Network for the large object results in fragmentation on Disk because the disk space is allocated upon receipt of each network packet and therefore the space allocation does not result in contiguous blocks on disk. Thus there is a need to reduce both the fragmentation and the expense on the DBMS that result from the storage of a large object on a disk.

Although embodiments are described in reference to a database server it should be noted that the state maintenance in the access of a large object can also be used with other types of servers that store large objects.

A method system and computer program product are described for state maintenance of a large object. According to some embodiments the method system and computer program product perform by associating one or more buffers with a transaction involving a large object the large object data may be accessed with the one or more buffers during the transaction and storing data for the large object from the one or more buffers in one or more sets of contiguous blocks.

In one or more embodiments a system performs state maintenance of a large object with a cache that associates one or more buffers with a transaction involving a large object the large object data may be accessed using the one or more buffers during the transaction and the cache stores large object data from the one or more buffers in the one or more sets of contiguous blocks in storage.

Embodiments of the present invention provide state maintenance for the access of a large objects. Access of a large object encompasses reading and writing a large object and hereinafter access will be used to refer to all types of access of a large object.

The Database Management System may be implemented as a server running database management software. A Database Management System server has one or more Processors for executing the instructions for the database management system. In one or more embodiments database management systems may be implemented as a cluster with multiple instances of the database management software running simultaneously on multiple computers to handle database requests while accessing a single database. A cluster is a group of computers that work together so that in many respects they can be viewed as though they are a single computer.

Optionally the Database Management System may employ the use of a Database Buffer Cache . With a clustered database the database buffer caches on each computer may operate as a single global cache to ensure that all instances of the database management system software have access to the cached data to handle database requests. The Database Buffer Cache stores data to be written to or from the database a collection of data stored on one or more disks in order to service database requests without the I O read and write costs. The underlying storage used by a Database Management System may take on many forms including but not limited to one or more Disks on a network.

The Database Management System uses a Write Gather Cache Layer to implement state maintenance for transactions . . . N involving the access of one or more large objects by a Remote Node . In one or more embodiments the Write Gather Cache Layer may have state information associated with each transaction and or file for the Remote Node involving the access of a large object. An implementation of a Write Gather Cache Layer will be described in further detail below with . By maintaining state in buffers for each transaction the Write Gather Cache Layer ensures that the transaction is isolated not visible to other transactions because the gathered data is dirty not written to storage and will remain dirty until the transaction is committed. In one or more embodiments the Write Gather Cache Layer may request buffers from the Database Buffer Cache to enable access of a large object by a Remote Node . The Write Gather Cache Layer posts the buffers to the Network to allow the Network Component to write the Network Packets to buffers in the Write Gather Cache Layer instead of the proprietary network buffers of the Network Component allowing for a decrease in the cost associated with copying data between the Network Component and the Database Cache Buffers .

The Write Gather Cache Layer is associated with a Locator Mapping to assist in tracking the state of an access of the large object by the Remote Node . The Write Gather Cache Layer buffers for the large object accessed by the Remote Node in the transaction may have been flushed written to Disk since the last access of the large object by the Remote Node . In order to ensure that the Remote Node is able to have access to the data expected in the Write Gather Cache Layer buffers the Locator Mapping indicates whether the Write Gather Cache Layer buffers contain the data of the large object that the Remote Node expects. In one or more embodiments the Locator Mapping indicates whether the large object has been written to Disk since the last access by the Remote Node . To ensure consistent access of the large object the Locator Mapping may have a snapshot of the database at a point in time after the large object has been written to Disk .

In one or more embodiments the Database Management System has a De duplication Layer a Compression Layer or both layers to reduce the amount of data written to Disk . Compression has been described in U.S. application Ser. No. 11 584 415 entitled System and method for data compression having the disclosure of which are hereby expressly incorporated by reference in their entirety. De duplication has been described in U.S. application Ser. No. 11 584 782. entitled System and method for data de duplication having the disclosure of which are hereby expressly incorporated by reference in their entirety.

In one or more embodiments the Database Management System has an Inode Layer to provide an interface for an Inode Chunk Map a data structure with a mapping of the logical blocks used for the large object to the physical block location of the large object on Disk . An implementation of an Inode Chunk Map will be described in detail with below.

After the data from the large object to be written to Disk has been determined one or more embodiments of a Database Management System use a Space Layer that keeps track of the space that is available on the Disk for the large object to be written. In one or more embodiments the Space Layer indicates both the used and unused space on Disk . After the space available has been determined with the Space Layer the large object is written to Disk in Block of Large Object Block of Large Object and Block of Large Object . By delaying the write of the large object to Disk with the use of the state maintenance the Space Layer is able to allocate contiguous blocks on Disk to the large object.

In one or more embodiments the Write Gather Cache Layer may request the Buffer Block . . . N from the Database Buffer Cache . The Database Management System may determine the appropriate block size to enable writing the large object data to Disk . Embodiments may employ the use of vector of buffers e.g. an iovec data structure to keep track of the Buffer Blocks . . . N in order to allow the Network Component to write to buffers that may not be contiguous in memory. Buffer Blocks . . . N may be implemented to store both metadata for the large object that may be used by the Database Management System and the large object data itself. For example a Buffer Block may be implemented to have a Block Header to store metadata on the large object and a Data portion to store the data for the large object itself.

Continuing with a Write Gather Cache Layer may have a Locator Mapping to identify the point in time as of which the data of a large object the Remote Node expects to access for a transaction. The Write Gather Cache Layer may need to flush the buffers of a File State Object write the contents of one or more Write State Objects . . . N of the File State Object to Disk and the Write Gather Cache Layer may need to provide data that the Remote Node expects to access in a transaction in buffers of the Write Gather Cache Layer . For example if a threshold for the amount of unwritten data beneficial for the Write Gather Cache Layer to keep in the buffers has been reached the Write Gather Cache Layer must be flushed the data in the File State Object written to Disk .

The Locator Mapping may provide information to reconcile the differences between the data expected to be accessed by the Remote Node and the data for the large object on Disk . In one or more embodiments the Locator for a Remote Node will store a snapshot a record of the state of the database for the last interaction the Remote Node had with the Database Management System and the Locator Mapping will store a snapshot after the data from the Write Gather Cache Layer buffers for a large object were flushed. The Locator Mapping may map the snapshot in the Locator to a different snapshot of the database after a flush of the large object to account for the delayed write of the data to Disk .The Write Gather Cache Layer may use the information from the Locator and the Locator Mapping to retrieve the data from Disk and put the data in the buffers that the Remote Node expects to access in a transaction. A mapping of the contents of the Disk may be used to retrieve the data from the Disk required by the Remote Node .

Alternatively in if the Remote Node is not creating a new large object then the Remote Node needs to access an existing large object in the Database Management System . To access an existing large object the Write Gather Cache Layer buffer e.g. Buffer Blocks . . . N of the Write State Objects . . . N of the File State Object for the large object contents will be determined with the existing Locator which will be described in more detail with .

Continuing with after the Write Gather Cache Layer buffers are either requested from the Database Buffer Cache for a new large object or the Write Gather Cache Layer buffers are determined with a Locator the Write Gather Cache Layer posts the buffers to the Network Component . The Network Component may access the data e.g. writes the network data for the Remote Node by writing the Network Packet to the Write Gather Cache Layer buffer . Next the Write Gather Cache Layer determines if the buffer needs to be flushed . If the Write Gather Cache Layer buffer does not need to be flushed then the process will repeat if the Remote Node has more data to write to the large object .

Alternatively if the Write Gather Cache Layer requires a flush of the Write Gather Cache buffers then the Write Gather Cache Layer will write the buffer contents to Disk . The storage of the large object data accessed by the Remote Node in the Write Gather Cache Layer buffers allows the Database Management System to write the buffers in contiguous blocks on Disk . In one or more embodiments data de duplication and compression may be performed on the Write Gather Cache Layer buffers prior to writing the data to Disk with the De duplication and Compression Layer .

The storage of the large object in the Write Gather Cache Layer buffers allows the Database Management System to compress and perform de duplication for the large object. Because the large object is stored in the Write Gather Cache Layer buffers compression can be performed upon the entire or a portion of the large object that is larger than the Network Packet instead of performing compression on a Network Packet available with prior approaches. De duplication allows for the storage of one large object and a pointer to the large object by another large object with the same data. Because the large object is not being written to Disk upon receipt of each Network Packet candidates for de duplication can be identified prior to a write to Disk .

After the large object data has optionally been compressed and gone through de duplication the availability of disk space must be determined and locked for the large object . In one or more embodiments the Space Layer determines what space is available on Disk . In one or more embodiments the Write Gather Cache Layer will lock all disk space on the Disk for the large object instead of locking memory on Disk on a block by block basis upon receipt a Network Packet .

Continuing with after the space available for the Write Gather Cache buffer has been determined and locked then the Write Gather Cache Layer writes the Write Gather Cache buffer to Disk . The process may repeat if the Remote Node has more data to access in the large object . If the Remote Node has no more data to access then the process ends.

Continuing with alternatively if the Locator Mapping indicates that a flush has occurred since the last access by the Remote Node then the Locator is updated with the snapshot of the flush of the buffers for the large object in the transaction and the Write Gather Cache Layer will request buffers from the Database Buffer Cache . Next the Write Gather Cache Layer requests that the Database Management System fill the buffers with the content requested from the large object data by the Remote Node . In one or more embodiments the Database Management System may rely on the Locator Mapping snapshot to bring the requested data for the large object into the Write Gather Cache Layer buffer as of a desired point in time. Embodiments may allow the Remote Node to request specific content from a large object with a logical offset e.g. a chapter in a movie that may be mapped to a specific address on Disk and the corresponding length of the large object logical division with the Inode Chunk Map .

Next the Database Management System may determine if the large object data placed in the buffers of the Write Gather Cache Layer from Disk is consistent with the last access by the Remote Node in the transaction . If the data of the large object placed in the buffer of the Write Gather Cache Layer for the transaction of the Remote Node is consistent then the Write Gather Cache Layer posts the buffers to the Network Component and the process ends

Continuing with alternatively if the data for the large object on Disk is inconsistent with the last access by the Remote Node then the changes that have occurred between the last access of the large object and the flush of the Write Gather Cache Layer buffers may be rolled back by the Database Management System to ensure that the buffer data is consistent with the data in the large object that the Remote Node expects from the last access of the large object in the transaction . Next the Write Gather Cache Layer posts the buffers to the Network Component for use by the Remote Node in the transaction and the process ends.

Continuing with the Remote Node may now read the data of the Write Gather Cache Layer Buffer to access the large object .

The execution of the sequences of instructions required to practice the embodiments may be performed by a computer system as shown in . In an embodiment execution of the sequences of instructions is performed by a single computer system . According to other embodiments two or more computer systems coupled by a communication link may perform the sequence of instructions in coordination with one another. Although a description of only one computer system will be presented below however it should be understood that any number of computer systems may be employed to practice the embodiments.

A computer system according to an embodiment will now be described with reference to which is a block diagram of the functional components of a computer system . As used herein the term computer system is broadly used to describe any computing device that can store and independently run one or more programs.

Each computer system may include a communication interface coupled to the bus . The communication interface provides two way communication between computer systems . The communication interface of a respective computer system transmits and receives electrical electromagnetic or optical signals that include data streams representing various types of signal information e.g. instructions messages and data. A communication link links one computer system with another computer system . For example the communication link may be a LAN in which case the communication interface may be a LAN card or the communication link may be a PSTN in which case the communication interface may be an integrated services digital network ISDN card or a modem or the communication link may be the Internet in which case the communication interface may be a dial up cable or wireless modem.

A computer system may transmit and receive messages data and instructions including program i.e. application code through its respective communication link and communication interface . Received program code may be executed by the respective processor s as it is received and or stored in the storage device or other associated non volatile media for later execution.

In an embodiment the computer system operates in conjunction with a data storage system e.g. a data storage system that contains a database that is readily accessible by the computer system . The computer system communicates with the data storage system through a data interface . A data interface which is coupled to the bus transmits and receives electrical electromagnetic or optical signals that include data streams representing various types of signal information e.g. instructions messages and data. In embodiments the functions of the data interface may be performed by the communication interface .

Computer system includes a bus or other communication mechanism for communicating instructions messages and data collectively information and one or more processors coupled with the bus for processing information. Computer system also includes a main memory such as a random access memory RAM or other dynamic storage device coupled to the bus for storing dynamic data and instructions to be executed by the processor s . The main memory also may be used for storing temporary data i.e. variables or other intermediate information during execution of instructions by the processor s .

The computer system may further include a read only memory ROM or other static storage device coupled to the bus for storing static data and instructions for the processor s . A storage device such as a magnetic disk or optical disk may also be provided and coupled to the bus for storing data and instructions for the processor s .

A computer system may be coupled via the bus to a display device such as but not limited to a cathode ray tube CRT for displaying information to a user. An input device e.g. alphanumeric and other keys is coupled to the bus for communicating information and command selections to the processor s .

According to one embodiment an individual computer system performs specific operations by their respective processor s executing one or more sequences of one or more instructions contained in the main memory . Such instructions may be read into the main memory from another computer usable medium such as the ROM or the storage device . Execution of the sequences of instructions contained in the main memory causes the processor s to perform the processes described herein. In alternative embodiments hard wired circuitry may be used in place of or in combination with software instructions. Thus embodiments are not limited to any specific combination of hardware circuitry and or software.

The term computer usable medium as used herein refers to any medium that provides information or is usable by the processor s . Such a medium may take many forms including but not limited to non volatile volatile and transmission media. Non volatile media i.e. media that can retain information in the absence of power includes the ROM CD ROM magnetic tape and magnetic discs. Volatile media i.e. media that can not retain information in the absence of power includes the main memory . Transmission media includes coaxial cables copper wire and fiber optics including the wires that comprise the bus . Logic refers to software hardware or any combination of software and hardware.

In the foregoing specification the embodiments have been described with reference to specific elements thereof. It will however be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the embodiments. For example the reader is to understand that the specific ordering and combination of process actions shown in the process flow diagrams described herein is merely illustrative and that using different or additional process actions or a different combination or ordering of process actions can be used to enact the embodiments. The specification and drawings are accordingly to be regarded in an illustrative rather than restrictive sense.

