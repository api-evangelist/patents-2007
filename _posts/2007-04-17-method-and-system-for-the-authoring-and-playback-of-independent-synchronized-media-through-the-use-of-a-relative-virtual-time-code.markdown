---

title: Method and system for the authoring and playback of independent, synchronized media through the use of a relative virtual time code
abstract: A method and system is provided for the creation and playback of multiple independently produced and distributed media intended for synchronized playback. One embodiment of the invention overcomes variances in independently produced and distributed media that make accurate synchronization impossible today. The system utilizes both authoring and playback processes. During authoring, a relative virtual time code profile is generated based on the original source media in a defined associated media set. The system employs an extensible framework of multiple synchronization recognizers that analyze the source media to generate a relative virtual time code profile for the associated media set. During playback, the system's client can access the relative virtual time code profile to coordinate the synchronized playback of an associated media set. The system generates an absolute time code using the available associated media and the original relative virtual time code profile. The system can overcome significant variances between the available associated media and the original associated media such as missing content, added content, resolution differences, format differences, etc.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07913157&OS=07913157&RS=07913157
owner: Overcast Media Incorporated
number: 07913157
owner_city: Seattle
owner_country: US
publication_date: 20070417
---
This application claims priority under 35 U.S.C. 119 e to U.S. Provisional Patent Application Ser. No. 60 793 300 entitled METHOD AND SYSTEM FOR THE AUTHORING AND PLAYBACK OF INDEPENDENT SYNCHRONIZED MEDIA THROUGH THE USE OF A RELATIVE VIRTUAL TIME CODE filed Apr. 18 2006 with inventors Richard Wales Stoakley Laura Janet Butler and Joseph H. Matthews III and also claims priority under 35 U.S.C. 119 e to U.S. Provisional Patent Application Ser. No. 60 793 110 entitled RELATIVE VIRTUAL TIME CODE AND SYNCHRONIZATION FILE FORMAT filed Apr. 18 2006 with inventors Laura Janet Butler Richard Wales Stoakley and Joseph H. Matthews III both of which are assigned to the same assignee as the present application and are incorporated herein by reference in their entireties.

This application also incorporates herein by reference in their entireties all of the following applications owned by the same assignee as the present application U.S. patent application Ser. No. 11 690 389 entitled SYSTEMS AND METHODS FOR USER INTERFACES FOR CONTROLLING INDEPENDENT SYNCHRONIZED MEDIA filed Mar. 23 2007 with inventors Joseph H. Matthews III Richard Wales Stoakley and Laura Janet Butler which in turn claims priority under 35 U.S.C. 119 e to U.S. Provisional Patent Application Ser. No. 60 785 789 entitled SYSTEMS AND METHODS FOR USER INTERFACES FOR CONTROLLING INDEPENDENT SYNCHRONIZED MEDIA filed Mar. 24 2006 with inventors Joseph H. Matthews III Richard Wales Stoakley and Laura Janet Butler U.S. patent application Ser. No. 11 690 399 entitled METHOD AND SYSTEM FOR MONETIZATION OF MULTIPLE INDEPENDENT SYNCHRONIZED MEDIA filed Mar. 23 2007 with inventors Joseph H. Matthews III and Richard Wales Stoakley which in turn claims priority under 35 U.S.C. 119 e to U.S. Provisional Patent Application Ser. No. 60 785 791 entitled METHOD AND SYSTEM FOR MONETIZATION OF MULTIPLE INDEPENDENT SYNCHRONIZED MEDIA filed Mar. 24 2006 with inventors Joseph H. Matthews III and Richard Wales Stoakley.

This disclosure generally relates to interactive entertainment systems such as interactive television systems network connected personal computers or mobile devices such as video iPods or media capable cell phones. More particularly but not exclusively this disclosure relates to a computer method and system for authoring and playing multiple independent synchronized media.

Video content in all of its various forms of distribution is delivered to a viewer as a continuous data stream. Movies distributed on digital video discs DVDs are one example of video content distributed as a continuous data stream. Television video content such as broadcast television shows and pay per view movies is delivered to a viewer as a continuous data stream. Today television programming is distributed and received at homes via antenna cable or increasingly via other means such as digital cable satellite digital download or Internet Protocol IP based streaming.

In each of the prior art methods for delivering and receiving video content there is no seamless opportunity to view supplemental content that has been designed produced and distributed independently but with the intent for simultaneous viewing with the video content. Such supplemental content can be created containing audio video animation graphics text interactive links or other metadata.

Similarly prior art methods of video based content distributed by other means such as internet video files and internet video streaming do not offer the opportunity to view supplemental content that has been designed and produced independently but with the intent for simultaneous viewing with the video content. This collection of video content and supplemental content designed for simultaneous viewing is referred to as a synchronous media set. Individual items in the synchronous media set are referred to as synchronous media elements. 

Viewers of DVD movies are familiar with supplemental content that is produced and made available on the DVD and thru DVD players. This capability however is limited to the content on the DVD and is controlled by the copyright holder. Because the supplemental content distributed on DVDs is produced with the knowledge of the content on the DVD dynamic synchronization capability is not required by the DVD player.

As media distribution moves from closed and restricted distribution networks to open distribution networks and as digital media tools move from expensive proprietary systems to inexpensive and widely available tools the amount of media content that is developed with the purpose of being played with independently created and distributed content will increase dramatically.

For media content developed with the purpose of being played with independently created and distributed content no system exists which 1 allows an author to select and composite independent media files for the future playback over similar but different independent media files 2 utilizes a framework for the coordinated application of multiple media recognizers to analyze and understand the media elements in the synchronous media set 3 develops a relative virtual time code profile for the synchronous media set and the desired authored playback experience 4 utilizes the relative virtual time code profile at playback to generate an absolute time code for the available media elements in the synchronous media set and 5 allows the author to establish how the supplemental content will be composited with other media in the synchronous media set.

Accordingly a system and method that overcomes the problems and disadvantages that exist in the prior art is needed to allow viewers to easily enjoy the playback of associated independent synchronized media. In particular the inventors have designed a method and system for overcoming these disadvantages in the prior art so that the playback of the independent media in a synchronous media set is possible and can be played synchronously despite the variances that exist between the media elements which exist at the point of playback and the media elements which existed at the time the synchronous media set was originally authored.

One embodiment provided by the present inventors is directed towards a method. The method includes enabling authoring of a media set enabling selection of a first independent media element associated with a first entity enabling selection of at least a second independent media element associated with a second entity and enabling presenting of the first and second media elements together as the media set in a synchronous manner using a relative virtual time code wherein said relative virtual time code includes an intermediary data structure containing a collection of patterns and time based relationships used to generate an absolute time code for variations of the media elements in the synchronous media set and wherein said absolute time code includes a fixed time code for specific instances of the media elements in the synchronous media set.

Other embodiments are directed towards an article of manufacture that includes a machine readable medium having instructions stored thereon a system and an apparatus.

In one embodiment the article of manufacture includes a machine readable medium having instructions stored thereon that are executable by a processor to 

select a first independent media element associated with a first entity as a principal media element 

select or create a second independent media element associated with a second entity as a supplemental media element 

perform media compositing to relate presentation of the principal and supplemental media elements to each other 

publish the portable media compositing file the portable media compositing file being usable to allow presentation of the media set in a synchronous manner using a relative virtual time code wherein said relative virtual time code includes an intermediary data structure containing a collection of patterns and time based relationships used to generate an absolute time code for variations of the media elements in the synchronous media set and wherein said absolute time code includes a fixed time code for specific instances of the media elements in the synchronous media set.

In one embodiment the article of manufacture includes a machine readable medium having instructions stored thereon that are executable by a processor to 

select a playback principal media element the playback principal media element being an independent media element associated with a first entity 

select at least one supplemental media element the supplemental media element being an independent media element associated with a second entity 

perform media compositing to relate the selected principal media element and the selected supplemental media element to each other using the portable media compositing file and

control playback of the media set having the composited principal media supplemental media elements in a synchronous manner using a relative virtual time code wherein said relative virtual time code includes an intermediary data structure containing a collection of patterns and time based relationships used to generate an absolute time code for variations of the media elements in the synchronous media set and wherein said absolute time code includes a fixed time code for specific instances of the media elements in the synchronous media set

In one embodiment the system includes means for authoring a media set means for providing a first independent media element associated with a first entity means for providing at least a second independent media element associated with a second entity and means for presenting the first and second media elements together as the media set in a synchronous manner using a relative virtual time code wherein said relative virtual time code includes an intermediary data structure containing a collection of patterns and time based relationships used to generate an absolute time code for variations of the media elements in the synchronous media set and wherein said absolute time code includes a fixed time code for specific instances of the media elements in the synchronous media set.

a first tool to select a first independent media element associated with a first entity as a principal media element 

a second tool to select or create a second independent media element associated with a second entity as a supplemental media element 

a third tool to perform media compositing to relate presentation of the principal and supplemental media elements to each other 

a fourth tool to generate a portable media project file that contains results of the media compositing 

a sixth tool to publish the portable media compositing file the portable media compositing file being usable to allow presentation of the media set in a synchronous manner using a relative virtual time code wherein said relative virtual time code includes an intermediary data structure containing a collection of patterns and time based relationships used to generate an absolute time code for variations of the media elements in the synchronous media set and wherein said absolute time code includes a fixed time code for specific instances of the media elements in the synchronous media set.

a first tool to select a playback principal media element the playback principal media element being an independent media element associated with a first entity 

a second tool to select at least one supplemental media element the supplemental media element being an independent media element associated with a second entity 

a fourth tool to perform media compositing to relate the selected principal media element and the selected supplemental media element to each other using the portable media compositing file and

a fifth tool to control playback of the media set having the composited principal media supplemental media elements in a synchronous manner using a relative virtual time code wherein said relative virtual time code includes an intermediary data structure containing a collection of patterns and time based relationships used to generate an absolute time code for variations of the media elements in the synchronous media set and wherein said absolute time code includes a fixed time code for specific instances of the media elements in the synchronous media set.

In the following description numerous specific details are given to provide a thorough understanding of embodiments. One skilled in the relevant art will recognize however that the invention can be practiced without one or more of the specific details or with other methods components materials etc. In other instances well known structures materials or operations are not shown or described in detail to avoid obscuring aspects of the invention.

Reference throughout this specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. Thus the appearances of the phrases in one embodiment or in an embodiment in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics may be combined in any suitable manner in one or more embodiments.

One or more embodiments of the present invention provides a method and system to be utilized by interactive entertainment systems to at least substantially guarantee the simultaneous playback of two or more independent synchronized media files or streams. The media files or streams in a synchronous media set can be files streaming media or cached partial files or other types of content.

According to one embodiment authoring and playback of synchronized media files is provided through the use of a relative virtual time code which in one embodiment comprises an intermediary data structure containing a collection of patterns and time based relationships used to generate absolute time codes for variations of a set of media elements in a synchronous media set. An absolute time code of one embodiment comprises a fixed time code for known and specific instances of a set of media elements in a synchronous media set.

An embodiment of an interactive entertainment system or interactive media player exists to provide access and playback control for a library of media content. This media content includes but is not limited to audio video animation graphics text interactive links or other metadata and the content itself may reside within a media device such as a computer or a portable player or it may reside on a server that is coupled to the media device. For the purposes of this description an interactive entertainment system or interactive media player includes all variations of systems such as but not limited to media software that is run on a computer media software that is part of a computer operating system or any dedicated interactive device which is capable of playing local or network delivered digital media such as an cable set top box or digital video recorder.

In the networked environment embodiment of media content such as principal content and or supplemental content can be communicated between the various servers and client devices. Alternatively or additionally the media content such as principal content and or supplemental content can be provided via other mechanisms. For example the principal content may be available online while the supplemental content may be available on a portable storage device such as a DVD or vice versa. In yet another example both principal and supplemental content may be available on portable storage devices or otherwise made available to the client devices without necessarily being required to be downloaded and or streamed from a network location.

An embodiment of a client side interactive entertainment system is shown in which can be present at the client device . Specifically shows a block diagram of an embodiment of a representative interactive entertainment system at the client side that includes an interactive media system a client service a portable media compositing file that may have been downloaded or otherwise obtained and stored and one or more media elements . One example of an interactive entertainment system is a web browser displaying a web page containing a video file. Another example of an interactive entertainment system is a dedicated set top box connected to an IP based network. The embodiments can be applied to the broadest definitions of interactive entertainment systems.

The embodiment of the client side interactive entertainment system of includes the interactive media system which can perform the above mentioned tasks of displaying a web page containing a video file communicating with an IP based network and various other operations related to playback of synchronous media sets as will be described in further detail below. The client side interactive entertainment system can also include one or more client services that cooperate with the interactive media system to communicate with external components or to otherwise manage operation of the client side interactive entertainment system . The client side interactive entertainment system of can also be configured to store the portable media compositing file which will be described in further detail below and also described in the priority application identified above entitled RELATIVE VIRTUAL TIME CODE AND SYNCHRONIZATION FILE FORMAT and at least one media element shown at .

 Independent synchronized media refers to a set of media wherein at least one of the media in the set has been selected with the intent that at least two of the entire set of media should be played at the same time in a synchronous manner. One media in the set is referred to as the principal media element . The additional media elements in the set are referred to as supplemental media elements. The supplemental media elements are created to augment a principal media element. This collection of principal content and supplemental content designed for simultaneous viewing is referred to as a synchronous media set. Individual items in the synchronous media set are referred to as synchronous media elements. 

Further each synchronous media element in a synchronous media set is truly independent. For each synchronous media element the following characteristics are involved each synchronous media element may be authored by a different author each synchronous media element may be distributed in different digital or physical methods each synchronous media element may have been acquired by the viewer at different times each synchronous media element may have different digital rights management rules or each synchronous media element may have a unique licensing agreement or no licenses agreement at all or other characteristics. These differences serve as examples to help describe what is meant by synchronous media elements that are independent from one another. The number of differences which distinguish synchronous media elements should be considered unlimited.

There are many methods for adding principal media elements to a library of media content that is accessible by an interactive entertainment system such as the client side interactive entertainment system of . A digital file of a television show can be created from a broadcast television signal using a digital video recorder. Alternatively or additionally a digital file of a television show can be purchased from an internet based video service such as iTunes or Google Video. Alternatively or additionally a digital file of a television show may have been purchased and accessed on a DVD disc via a retail DVD set purchase. Alternatively or additionally a digital file of a television show may be streamed to the viewer s interactive entertainment system from an internet based video service. These examples for a television program are presented for illustration and do not represent the complete range of methods that can be used for acquiring digital content.

The many different methods for acquiring principal media elements can result in principal media element files which may represent the same program but which have different characteristics and variances. These variances increase the challenge of synchronizing one or more synchronous media elements to a particular synchronous media element. Suppose an audio commentary has been generated for an episode of Survivor. Viewer A may have recorded the target Survivor episode using a digital video recorder. Viewer A s digital recording of the Survivor episode contains the commercials that were broadcasted and the file is 60 minutes in length. Viewer B also has a digital file of the same target Survivor episode but Viewer B has purchased this digital file from Apples iTunes service. Viewer B s digital file of the same target Survivor episode does not contain commercials and is 45 minutes in length. Variances in digital files is not limited to total time or presence of commercials and can result from a multitude of issues involved with file creation transmission and storage. Examples of other variances are file format bit rate of recorded media frames per second video aspect ratio and number of audio channels or other parameters.

In one embodiment the media elements principal and or supplemental media elements are not stored in the system server of but rather stored at some other network location such as at one or more third party servers . Thus rather than storing the media elements themselves in the media set database the media set database can store pointers links or other information identifying the location of the media elements.

In one embodiment the system s server may also have a customer database for tracking customers and customer viewing history. The system s server may also have a transaction database for recording financial transaction information associated with the playback of synchronous media sets. Alternatively or additionally such databases may be present at a third party server . Further details of the operation associated with such databases are provided in the prior filed applications entitled METHOD AND SYSTEM FOR MONETIZATION OF MULTIPLE INDEPENDENT SYNCHRONIZED MEDIA that are identified above.

A server engine controls operation of the server including interaction between each of the elements contained in the server and or interaction between such elements and external elements.

A synchronous media set is created or composed by an individual who defines the synchronous media set through the use of a computing system and client authoring software. One embodiment of the invention s authoring related processes can be for example incorporated into a unique tool incorporated within an existing tool or added to existing tools without code changes to the existing tool by using plug in code. The authoring tool may be a software tool installed on a PC of the author. In another embodiment the authoring tool can comprise an online tool available on a web site. Other methods for proving and operating the authoring tool can be used

The author may select media elements from online sources local storage portable storage media such as DVDs or from other sources. The author may create media elements using any appropriate method including video capture assembling together of individual media elements into a single media element and so forth.

After the media elements have been identified or created the author s next step is media compositing at which involves relating the presentation of the individual media elements to each other. For example the author can determine a point in time when a supplemental media element can begin and end with relation to a point in the playback of the principal media element. In another example the author can set the playback volume level relationships between the principal media element and the supplemental media elements. As an additional example if the supplemental media element is visual the author can also determine at what location in the video display e.g. at which specific location within a video frame the visual media element is to be displayed.

When the author finishes compositing the synchronous media set at the author instructs the client authoring program to save the project file which represents media and the compositing that the author has completed. This information is saved in the portable media project file by the client authoring program at . An embodiment of the authoring process further involves generating saving at and publishing at a portable media compositing file which will be described in further detail below.

A second routine referred to as the principal media timeline analyzer is responsible for analyzing and extracting an understanding of elements and characteristics about the actual media content data in the principal media itself. The principal media timeline analyzer uses the principal media file as input. All available aspects of the principal media are analyzed including if available its audio video text metadata like VBI based text data and graphics. Examples of extracted characteristics include but are not limited to periods of silence dramatic volume changes wave patterns etc. for the audio in the principal media. For video characteristics such as periods of blackness dramatic visual scene shifts or cuts discernable image patterns etc. are detected and saved. For text such as closed caption information keywords triggers blank spaces etc. are detected and saved. For graphics characteristics such as blank field regions discernable image patterns etc. are detected and saved. The extracted elements and characteristics of the principal media file are fed to the principal media timeline analyzer routine and can also be saved to a principal media timeline file for later use by other processes in one embodiment of the invention.

The principal media timeline analyzer also uses the principal media profile generated by the principal media analyzer . An additional input utilized by the principal media timeline analyzer is the compositing information that contains the presentation relationship between the principal media file and supplemental media file s as determined by the author. The principal media timeline analyzer of one embodiment accepts input from additional input mechanisms in a pluggable manner. Each input provides direct and indirect information that assists the principal media timeline analyzer in determining what key elements and characteristics are contained in the principal media .

The principal media timeline analyzer generates a principal media timeline file which is an outline description of the principal media source that represents layout of segments and time at a higher semantic level than simple absolute time references. The description represents the principal media in terms of segments segment order length of segments advertisement segments scenes within segments and other breaks or interruptions. Because the principal media timeline of one embodiment is an outline description it is capable of describing segments that are contained or nested within other segments. The principal media timeline also contains information that describes the relationships between visual elements in the synchronous media set. These descriptions are stored in relative terms to that alignment can work with differently sized and formatted media files in future playback events.

When the principal media timeline analyzer has completed its analysis of the principal media file together with all additional input the analyzer saves the final principal media timeline file . The principal media timeline analyzer also creates and saves the portable media project file including analysis of the supplemental media to extract supplemental media metadata and placing the metadata into the portable media project file .

With the portable media project file fully defined and saved the system has completed its analysis and understanding of the principal and supplemental media files and . The system also understands the intent of the author regarding how the principal and supplemental media files and are to be presented in the future. The next step for the system is to develop the information that will be usable to allow for the proper playback of the supplemental media content when applied to a future playback principal media file. This information is referred to as a relative virtual time code. 

The system processes described in which generate the portable media compositing file utilize a virtual time code generator routine which uses the principal media file and the portable media project file as input. The virtual time code generator s responsibility is to generate a series of landmark definitions which correspond to the synchronous events and relationships which exist between the primary principal and supplemental media files as determined by the authored presentation. The virtual time code generator uses a landmark identification analyzer process which in one embodiment is a pluggable framework for employing and coordinating multiple landmark identification routines. Landmark identification routines can include but are not limited to scene detection voice recognition audio level analysis etc. The landmark identification analyzer employs information about each landmark identification routine to weight and rank the results from all of the available landmark identification routines. For example the landmark identification analyzer would rank audio based landmark routines lower than video based landmark routines when the principal media file comprises of a video without sound. Similarly the landmark identification analyzer would favor luminance based identification routines over hue based routines when the principal media contains a black and white video.

The virtual time code generator receives information from the landmark identification routine and determines if it has enough information to create a relative virtual time code that could be used to successfully play a synchronous media set in the future. If the virtual time code generator does not have enough information it may instruct the landmark identification analyzer to either 1 utilize additional available landmark identification routines or 2 process again previously process segments with information that was not available at the time the segments were originally processed.

When the virtual time code generator has determined it has enough information to create a portable media compositing file it first saves a relative virtual time code file belonging to the synchronous media set. The relative virtual time code contains information used to translate the absolute time codes from the original principal media file into relative time codes that will work with future playback principal media files guaranteeing that the system understands all corresponding points which exist between the original principal media file and the future playback media file. The relative virtual time code stores small instances of data and patterns from one or more streams from the principal media file . These data and patterns serve as landmarks within the principal media file and can be used in the future by embodiments of the invention s playback routines. shows a block diagram of example components saved in one embodiment of a relative virtual time code file including the principal media timeline and landmark definitions shown at .

The next step for the system is to generate a file that can be published transmitted and used by any consumer to playback the synchronous media set in the manner intended by the author. This file is referred to as the portable media compositing file. The virtual time code generator creates and saves the portable media compositing file .

The final step in the authoring process of synchronous media sets is to make the portable media compositing file available to consumers. See e.g. in the flowchart of . The author utilizes the client authoring system to publish the portable media compositing file to the system s server . As a result consumers with interactive media systems can locate and consume the portable media compositing file such as by downloading the portable media compositing file into their client devices for storage as shown in . The portable media compositing file may also be transferred directly by one of many possible methods. For example the author could send the portable media compositing file to another individual as an attachment in email or as a file saved to electronic media. At this point all appropriate steps in the authoring and creation process for synchronous media sets have been completed.

In the viewer first selects the supplemental media at . The viewer also selects the playback principal media at which can come from any one of a number of sources. For example the playback principal media may be on a DVD owned by the viewer. Alternatively the playback principal media may have been recorded by the viewer using a digital recording program.

A viewer can use an interactive media system such as shown in which communicates with the system s server . Whenever the viewer requests a synchronous media element from the interactive media system the interactive media system sends a request to the system s server to identify which if any media sets the selected media element may belong to. With this information the client device can display the media set and its synchronous media elements to the viewer. The viewer can review the media set and make a decision to play none some or all of the synchronous media elements in a synchronous manner.

Once the consumer has identified two or more media elements to play synchronously the system next determines if the viewer has access to the individual synchronous media elements that make up the media set. The synchronous media elements may be owned by the viewer and may exist as digital files on the viewer s computer hard drive. Alternatively or additionally the viewer may have access to one or more of the synchronous media elements through a streaming media service where the media is resident on a third party server . Other techniques may be used to provide media elements to the viewer.

If the viewer does not have access to one or more of the individual synchronous media elements in the set then the system is capable of referring the viewer to third party services that can provide the transaction and distribution for the viewer to attain the appropriate synchronous media element s . The information used by the system s server to identify the third party services is contained in the metadata for the media set stored on the system server . The third party service may charge the viewer for the right to access and or own the synchronous media element. This charge and transaction is handled by the third party service. The third party service is responsible for delivering the content or granting access to the content that the viewer has selected.

In one embodiment because the system does not store the principal media file and because the playback principal media file can come from many sources the playback media file may be different in some way from the original playback media file that was used by the author to define the synchronous media set. The client device communicates to the system server to retrieve the portable media compositing file at . The client device composites the synchronous media set as instructed by the information contained in the portable media compositing file at . Finally the client device plays the playback principal media and the supplemental media in a synchronous manner matching the intent of the author at .

In the viewer first selects the principal media for playback at . The client device communicating with the system s server can retrieve and present the list of available supplemental media sets for the chosen principal media at . If the viewer selects a particular supplemental media set at the client device downloads the appropriate supplemental media files and the portable media compositing file at . The client composites the synchronous media set at as instructed by the information contained in the portable media compositing file . Finally the client plays the playback principal media and the supplemental media in a synchronous manner matching the intent of the author at .

In various tools can be provided at the client device to perform the various selection retrieval compositing and playback operations. These tools for instance can be part of the interactive client side interactive entertainment system embodied as software hardware and or combination of both.

The playback process for a synchronous media set begins with an analysis of the playback principal media file selected by the either the viewer or the system. shows a flowchart of the steps involved in the analysis of the playback principal media file according to an embodiment. The playback principal media file selected by the viewer is evaluated by a principal media analyzer routine that extracts metadata information and properties about the playback principal media file . This metadata information may contain information such as title description author copyright information duration and key markers or indices or other information. The principal media analyzer routine also determines the type and properties of the principal media file . For example if the principal media file is a video file information such as frame rate display dimensions input format e.g. MPED2 WMV etc. and output format e.g. interlaced RGB24 non interlaced YUV9 etc . The principal media file can be any type of media and the media analysis routine is capable of recognizing and understanding all types of digital media. The principal media file metadata information is fed to other processes in the system and is also saved to a principal media profile file for later use by other processes in one embodiment of the invention.

A second routine referred to as the principal media timeline analyzer is responsible for analyzing and extracting an understanding of elements and characteristics about the actual media content data in the playback principal media itself. The principal media timeline analyzer uses the playback principal media file as input. All available aspects of the principal media are analyzed including if available its audio video text and graphics. Examples of extracted characteristics include but are not limited to periods of silence dramatic volume changes wave patterns etc. for the audio in the principal media. For video characteristics such as periods of blackness dramatic visual scene shifts or cuts discernable image patterns etc. are detected and saved. For text such as closed caption information keywords triggers blank spaces etc. are detected and saved. For graphics characteristics such as blank field regions discernable image patterns etc. are detected and saved.

In an embodiment the principal media analyzer and or principal media timeline analyzer form part of the interactive media system installed in the client device of . The principal media analyzer and principal media timeline analyzer may be plug ins software modules or other types of tools that can be installed in the client device such as via download from a network location or installed from a CD. In another embodiment the principal media analyzer and or principal media timeline analyzer are present in a device external to the client device such as remotely at a network location accessible to the client device .

The client device retrieves the original principal media metadata stored in the portable media compositing file which has been downloaded or otherwise obtained by the client device . The original principal media metadata information is sent to the principal media timeline analyzer routine .

The principal media timeline analyzer also uses the principal media profile generated by the principal media analyzer . The principal media timeline analyzer accepts input from additional input mechanisms in a pluggable manner in an embodiment. Each input provides direct and indirect information that assists the principal media timeline analyzer in determining what elements and characteristics are contained in the playback principal media .

The playback principal media timeline analyzer generates a playback principal media timeline file which is an outline description of the playback principal media source that represents layout of segments and time at a higher semantic level than simple timeline references. The description represents the playback principal media in terms of segments segment order length of segments advertisement segments scenes within segments and other breaks or interruptions. Because the playback principal media timeline is an outline description in one embodiment it is capable of describing segments that are contained or nested within other segments. These descriptions are stored in relative terms so that alignment can work with differently sized and formatted media files in future playback events.

When the principal media timeline analyzer has completed its analysis of the playback principal media file the analyzer saves the final playback principal media timeline file . The system has completed its analysis and understanding of the playback principal media file . The next step for the system is to generate the information that will be used to allow for the proper playback of the supplemental media content when applied to the playback principal media file . This information for proper playback is referred to as an absolute time code reference.

The system utilizes an absolute time code generator routine that uses the playback principal media file the playback principal media profile and the playback principal media timeline as input. The absolute time code generator also retrieves the relative virtual time code from the portable media compositing file for the synchronous media set.

The absolute time code generator s responsibility is to generate references to the playback principal media s internal time code by using the landmark definitions in the relative virtual time code . These definitions correspond to the synchronous events and relationships between the playback principal media and supplemental media files as determined by the original authored presentation. The absolute time code generator uses a landmark identification analyzer process shown in further detail in that in one embodiment is a pluggable framework for employing and coordinating multiple landmark identification routines. Landmark identification routines can include but are not limited to audio analysis video analysis video frame analysis compression stream analysis closed captioning analysis timecode analysis etc. The landmark identification analyzer process of one embodiment employs information about each landmark identification routine to weight and rank the results from all of the available landmark identification routines. This ranking can be used to increase the likeliness of recognition and or to minimize computational impact on the playback machine.

The landmark identification analyzer makes analysis passes through the media input to resolve and tally the number of resolved landmarks at . If the landmark identification analyzer does not get any resolved landmarks at it is assumed the input media is wrong or too different and the process exits at unable to create a new absolute time code.

If the landmark identification analyzer resolves all of the landmarks e.g. using the same exact video at then the process ends with the generation of the absolute time code . If the landmark identification analyzer is not in an all or none state then the landmark identification analyzer makes continuous passes using A data from the newly resolved landmarks and B relaxed reduced recognition thresholds at and . Eventually the landmark identification analyzer arrives at a point where no new landmarks are resolved but enough exist to build a reasonable absolute time code and exits the recursive process. If there are still some unresolved landmarks the landmark identification analyzer applies a best guess algorithm at to place any unresolved landmarks and the process exits at to generate the absolute time code reference .

The absolute time code generator receives information from the landmark identification analyzer routine and determines if it has enough information to create an absolute time code that could be used to successfully play the playback principal media together with the supplemental media . If the absolute time code generator of one embodiment does not have enough information it may instruct the landmark identification analyzer process to either 1 utilize additional available landmark identification routines or 2 process again previously process segments with information that was not available at the time the segments were originally processed.

The absolute time code generator compares the profiles of the original principal media and the playback principal media in order to produce a new master timeline and presentation space. This process involves matching up segments and scenes determining if segments are missing or have been added and determining if display elements have been altered.

Next segments from the synchronous media are placed into the new timeline. The absolute time code generator matches patterns resolves landmarks and handles degenerate cases such as clipping or time difference resolution. Any visual aspects of the synchronous media elements are fitted into the presentation space for the playback media file. The absolute time code generator matches patterns resolves landmarks and handles degenerate cases such as stretching or clipping the supplemental content or location for the visual content.

Finally the absolute time code generator compiles a new timeline for the synchronous media elements that fit into the new presentation of the playback principal media .

When the absolute time code generator has determined it has enough information to create an absolute time code reference it ends the analysis and saves the absolute time code reference file belonging to the synchronous media set. The absolute time code reference contains timelines and mixing information for the playback principal and supplemental media files and . The absolute time code reference also contains information that describes the relationships between visual elements in the synchronous media set.

With the absolute time code reference generated a media composite engine of can now assemble the instructions to successfully play the playback principal and supplemental media files and as originally intended by the author using one or more tools to perform the assembly and playback. illustrates the flowchart for compositing the synchronous media set according to an embodiment. The media composite engine composites the playback principal media with the supplemental media based on the instructions contained in the absolute time code reference . The media composite engine may also introduce additional media files into the composition. An example of an additional media file could be an advertisement video that is played before after or at any point in the timeline of the playback principal media .

When finished with compositing the media composite engine can output and or save the composition in any number of ways including saved as a single file saved as multiple files streamed to a device or sent to an interactive media player. Playback does not require a specific interactive media player nor does it require changes to the code of an interactive media player. Playback could be accomplished through file formats or plug ins supported by an interactive media player.

Regardless of the final mechanism for delivering the presentation the result is a composite multimedia presentation that behaves like one synchronized unit even though original principal media file and the playback principal media file were created independently and unrelated to each other. The supplemental media elements synchronize perfectly with the playback principal media visually and in time.

While the various flowcharts provided herein show certain operations performed in a certain order other embodiments can provide different implementations. For example with other embodiments certain operations can be added removed modified or combined. Moreover the operations need not necessarily occur in the exact order shown.

In at least one embodiment the operations can be embodied by software or other machine readable instruction stored on a machine readable medium and executable by one or more processors. For example the machine readable instructions and machine readable medium can be located at a server and or at a client device.

While specific embodiments and applications of the present invention have been described and illustrated it is to be understood that the invention is not limited to the precise description configuration and elements disclosed. While specific embodiments and examples are described herein for illustrative purposes various equivalent modifications are possible within the scope of the invention and can be made without deviating from the spirit and scope of the invention.

For example while this description utilizes a network connected client and server the embodiment s can also be applied to scenarios that involve portable devices which can be connected to a network but which are not always connected to the network. Variations and modifications apparent to those skilled in the art may be made in the arrangement application and details of the methods and systems of the present invention disclosed herein without changing the spirit and scope of the invention.

In the various embodiments described above certain elements have been referred to as files that are generated such as a portable media project file a portable media compositing file a timeline file and so forth. It is appreciated that the files and various other elements such as profiles metadata time codes etc. described above can comprise data structures that are newly generated data structures that can be stored for later use during authoring playback or other types of data structures.

These and other modifications can be made to the invention in light of the above detailed description. The terms used in the following claims should not be construed to limit the invention to the specific embodiments disclosed in the specification and the claims.

All of the above U.S. patents U.S. patent application publications U.S. patent applications foreign patents foreign patent applications and non patent publications referred to in this specification and or listed in the Application Data Sheet are incorporated herein by reference in their entirety.

