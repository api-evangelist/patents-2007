---

title: Crawlable applications
abstract: Systems and methods in accordance with various embodiments of the present invention provide for a computer based method for crawling application data from an application data store. The applications data store has business objects of an application stored thereon. The method may include identifying a first request for application data received from a search engine as a seed universal resource locator (URL). A crawlable definition for the identified business object is accessed, the crawlable definition including a query selecting one or more attributes of the business object. Moreover, the method can include sending the query to the application data store and receiving query results in response thereto. Additionally, the method can include forming a crawlable document which includes the retrieved results of the business object.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07752207&OS=07752207&RS=07752207
owner: Oracle International Corporation
number: 07752207
owner_city: Redwood Shores
owner_country: US
publication_date: 20070501
---
A portion of the disclosure of this patent document contains material that is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever.

The present invention relates generally to searching application data. More particularly the present invention relates to an interface for crawling structured application data.

As the use of networks expands the use of enterprise applications is becoming more prevalent. An enterprise application is generally a software application hosted on a server which has the capability of simultaneously providing services to a large number of users on a network. Often an enterprise application is suitable for performing business related functions. Business related functions may include but are not limited to tracking customer information accounting and production scheduling.

It is desirable to search for information that may be stored in or otherwise associated with applications or enterprise applications. The current methods of searching data require a search engine to first collect the content from diverse sources and then to text index the content. The process of collecting the content is known as crawling. The structure of application data poses numerous challenges for crawling and indexing and later searching the data. Application data is often times highly structured for example a single business object may span multiple tables in a database. Current methods of sourcing structured data include a search engine crawler plug in. The crawler plug in is designed to fetch documents of a data source type that is not supported by any of the search engine defined data source types. To create a plug in the user must become familiar with the architecture of the search engine crawler and the crawler plug in and decide upon an appropriate data source model which sets out the attributes that are to be extracted. The user then programs the crawler plug in to implement the data source model.

However the plug in framework is not a satisfactory solution for enabling the search of highly structured data. The plug in framework is business object dependent. Essentially the plug in code is confined to extract the attributes of a particular data source model associated with a business object. As such there is a significant amount of overhead in the individual implementation of each business object. Where the number of business objects to be crawled indexed and searched is large individual implementation may not be a viable solution. Hence although information is likely to be successfully crawled using the plug in framework the steps associated with creating the plug in may be complicated and time consuming. Additionally the crawler is fixed to the business object structure defined at the time of creation of the crawler. When there are subsequent changes to the structure of the business object and the crawler is not aware of the modification the crawler is inoperable to crawl the business object.

Moreover each plug in is search engine dependent. The crawler plug in code must conform to the APIs application programming interfaces of the particular search engine. In order to implement the search capabilities using different search engines for an applications suite the user must become familiar with the architecture of each search engine crawler and each search engine plug in and must write the plug in code to comply with the APIs of each respective search engine.

Current solutions are not accessible for all types of applications. For example plug ins are dependent upon the applications for which they are targeted to access. Every application or suite of applications requires a plug in to rely on the particular library files for the application. If a plug in relies on the library of one application the same plug in may not be operable to crawl another application without experiencing significant deployment difficulty in merging the disparate applications.

Furthermore the plug in framework requires the internal structure of the business object and the execution context to be exposed to the search engine. The internal structure of enterprise applications may be proprietary. Accessing the highly structured application data where the application data is proprietary normally occurs through the Java Data Base Connectivity JDBC Application Programming Interface API . A JDBC API is a standard Structured Query Language SQL database access interface on which crawlers may be based. Under this methodology the crawler plug in includes an SQL query or form based query to retrieve the required data from the database. When the SQL statement is executed the proprietary application data is exposed. Accordingly through the JDBC connection all of the proprietary data is available to be retrieved. This type of exposure could have serious implications on the application architecture with regard to deployments dependency performance and usability. Although enterprise search engines have implemented various security policies there are no solutions which control the exposure of application data on the applications side.

Systems and methods in accordance with various embodiments of the present invention provide for a computer based method for crawling application data from an application data store. The applications data store has a plurality of business objects of an application stored thereon. Such a method can include identifying a first request for application data received from a search engine as a seed universal resource locator URL sourcing a business object of the plurality of business objects of the application. The method also can include accessing a crawlable definition for the identified business object the crawlable definition including a way of extracting information from a complex structure of related business objects such as a query selecting one or more attributes of the business object. Moreover the method can include sending the query to the application data store and receiving query results in response thereto. Additionally the method can include forming a crawlable document including the retrieved results of the business object to generate a data feed. The method can also include generating a control feed by dividing the data feed into transferrable batches and creating batch URLs for the batches and returning a feed document to the search engine the feed document comprising the control feed.

In another embodiment the feed document further includes the data feed. In yet another embodiment the method includes identifying a second request for application data received from a search engine as a re entry URL. The method also includes returning a batch from the data feed where the batch requested in the re entry URL returning a related document where the related document is requested in the re entry URL and returning a dependent document where the dependent document is requested in the re entry URL.

A method in accordance with various embodiments of the present invention provides for a computer based method for enabling structured application data to be crawled via a user interface for the development of a crawlable business object definition. The user interface includes providing a data source field for user input within a display window to set a data source definition for a business object of a plurality of business objects of an application where the data source definition includes a way of extracting information from a complex structure of related business objects such as a query selecting one or more attributes of the business object to be exposed to a search engine. The user interface also includes providing a plurality of user input fields corresponding to a first set of metadata tags to specify how each attribute of the one or more selected attributes of the business object is to be crawled by the search engine where the first set of metadata tags include a mapping metadata tag to identify an attribute of the one or more selected attributes to be mapped to a document structure persisted in the search engine.

A further understanding of the nature and the advantages of the inventions disclosed herein may be realized by reference of the remaining portions of the specification and the attached drawings.

In the description that follows the present invention will be described in reference to embodiments of subsystems on a platform for a software application such as a database application. However embodiments are not limited to any particular architecture environment application or implementation. For example although embodiments will be described in reference to network database applications the invention may be advantageously applied to any software application. Therefore the description of the embodiments that follows is for purposes of illustration and not limitation.

Searches for highly structured data associated with enterprise applications are generally not readily crawlable by search engines. Although some search engines provide customizable plug in programs those search engines generally require significant developmental efforts on the part of the end user before specific enterprise application data may be crawled and indexed. A framework which provides exposure of business objects to a full text generic search engine in an uniformed manner while maintaining security functions and which allows the generic search engine to crawl applications with highly structured data without requiring the use of plug ins is provided.

Creating the framework for searching structured application data includes creating an interface between the application data and existing search engines alleviating the need to augment the search engine itself. In one embodiment an applications developer is provided with a user interface environment that is used to develop crawlable definitions which are needed to integrate a particular application with a crawlable applications interface which in turn incorporates existing search engines. The crawlable definitions may be used by the crawlable applications interface to develop documents which are crawlable e.g. can be grabbed by the search engine. The use of such crawlable definitions and crawlable applications interface leverages the existing functionality of high performance search engines such as crawling indexing and searching any number of enterprise applications without requiring significant development efforts on the part of a search engine developer.

Crawlable Applications Interface is arranged between search engine and application and produces a document representing the application data which is crawlable by the search engine . That is Crawlable Applications interface effectively serves as a two way translator between search engine and application such that search engine may crawl and index and later search information associated with application . The application data may be stored in applications tables or views such as in an application data store e.g. applications database management system DBMS .

The application data can be made to be crawlable by providing a crawlable definition of a business object of the application . In one embodiment each business object is associated with its own crawlable definition . Alternatively multiple business objects may be associated with a single crawlable definition or a single business object may be associated with multiple crawlable definitions . In one embodiment an applications developer is provided with a user interface that may be used to develop the crawlable definition of the business object thus deciding how and to what degree the business object will be exposed to the search engine . An Integrated Development Environment IDE such as JDeveloper is an exemplary platform for developing the crawlable definitions. In one embodiment Oracle Application Framework OAF is used as the foundation for building such definitions. Complex data mapping and transformation for business objects may be created using OAF.

In step a data source definition is set by forming a query to access the application data in the application DBMS . In one embodiment the query is written in SQL. The user such as the applications developer is acquainted with the structure of the business object. The user may selectively decide which elements of the business object to expose to the search engine by writing a query to retrieve those specific elements. For example referring back to the Purchase Order Requisition business object includes the Requisition table and the Employee table. The Employee table includes a Social Security Number SSN attribute. are XML code of an exemplary structure of a crawlable definition in accordance with one embodiment. Within the metadata tags an exemplary SQL statement is provided. The user selects a number of attributes from the Employee table in to expose to the search engine . However the Employee.SSN attribute is not selected and will not be retrieved. Accordingly the search engine will not have access to the Employee.SSN attribute with regard to the Purchase Order Requisition business object. By controlling the business object on the applications side the applications developer through the crawlable definitions can also manage any changes to the structure of the business object.

In step of indexing rules are set using the provided metadata tag. The indexing rules specify whether the textual body of an attribute will be crawlable by the search engine. Referring back to properties are defined for the selected attributes of the business object. The property CRAWL IS INDEXED for the RequisitionHeaderId attribute is defined as true. Accordingly the body of the text of the RequisitionHeaderId attribute will be made to be crawlable by the search engine. However the property CRAWL IS INDEXED for the PreparerId attribute is defined as false. Accordingly this attribute will not be crawlable by the search engine.

In step of the user sets security rules using the provided metadata tag. An attribute for which the security tag is set is deemed to be a security attribute. Referring back to the property CRAWL IS SECURE for the PersonId attribute is defined as true. Accordingly the security attribute for the RequisitionsSVO business object is the PersonId attribute. In an alternative embodiment the security attribute is set using an Access Control List ACL any other known security means or combinations thereof.

In step of display URL rules are set using the provided metadata tag. A display URL is a URL string used for search result display. This is the URL used when an end user of the search engine clicks a search result link provided by the search engine after the end user supplies a query. Referring back to the property CRAWL IS DISPLAYED for the RequisitionHeaderId attribute is defined as true. Accordingly this attribute value will be included in the display URL. The property CRAWL IS DISPLAYED for the PreparerId attribute is defined as false. Accordingly this attribute will not be displayed in the display URL.

In step of the rules for mapping to a document structure pertained by the search engines are set. As previously stated the application data may be highly structured. This rule maps attributes of the search engine index to the source attributes or properties of the application data. The attributes of the business object may be set to be stored in the search engine index. Referring back to the property CRAWL IS STORED for the RequisitionHeaderId attribute is defined as true. Accordingly this attribute will be mapped to the search engine.

Referring back to the crawlable definitions described above are stored within the crawlable applications interface . In alternative embodiments the crawlable definitions may be stored elsewhere as would be apparent to one of ordinary skill in the art. After the crawlable definitions have been determined the search engine may begin the process of crawling the application data. The application in this example is a search source for the crawler. In one embodiment application is sourced by a crawler plug in. Rather than designing the plug in around a single business object which is highly time consuming to implement for many business objects the entire application may be sourced with a crawlable entry point such as a seed URL. Prior art methods of creating a plug in to source applications required additional information such as repository access data. For a database prior art methods required the database connect string and the schema name and password. In alternative embodiments the application may be sourced by a plug in targeted for a subset of the all the business objects comprising the application . For example a single business object may be sourced through the plug in.

After application has been sourced the search engine sends a seed URL request to the crawlable applications interface . A virtual network between the search engine and the crawlable applications interface allows the application to be crawled over existing Hyper Text Transfer Protocol HTTP or Hyper Text Transfer Protocol Secure HTTPS . As previously described accessing application data normally occurs through JDBC thus exposing the proprietary application data to the search engine. By allowing the search engine crawler to access the application data through the provided HTTP or HTTPS endpoints or URLs the application data is exposed to the degree the applications developer dictates in the crawlable definition. In this way the protection of the application data is accomplished on the applications side.

A crawlable application endpoint of crawlable applications interface receives the seed URL request from the search engine . The crawlable endpoint is a web service that performs two functions. First when the crawlable endpoint receives the seed URL request the crawlable endpoint sends a request to crawlable factory to generate control feed and data feed . Second the crawlable endpoint provides a web accessible secure end point or URL that is crawlable to external search engines through a defined messaging protocol such as HTTP S . This web service provides crawlable data sets to the search engine crawlers for indexing and later for searching.

Crawlable factory is a software module that performs three functions. The first is to create data feed . Once the crawlable factory receives the request to create the data feed the crawlable factory accesses the crawlable business objects specified in the crawlable definition . In one embodiment the factory accesses the definitions of the business objects that were specifically sourced. As previously described the crawlable definition includes all or a subset of the business objects of the application . For each of the crawlable business objects defined or sourced the factory queries the data source as defined in the business object crawlable definition for example as a SQL query and retrieves the records of the business object from the data source. Each record is an instance of the business object. In one embodiment the business object data can be read directly from application tables and or views. Alternatively the business object data can be staged in interface tables as needed using SQL such as application content staging table .

The crawlable factory forms a crawlable document for each retrieved record of the business object. The crawlable document includes the data for each record. In another embodiment the crawlable document is comprised of one or more records. The crawlable factory makes use of the search related application metadata to create the documents. Recall the metadata which may reside within the crawlable definition includes metadata tags for the attributes of the business object. In one embodiment the documents are written in XML. The crawlable factory compiles the data feed by numbering the documents into a larger document that contains those records instances. Each instance of the business object may contain any of the following sections metadata including security rights searchable objects to be indexed dependent document URLs and related searchable object URLs. These sections will be discussed with regard to .

Referring back to the second function of the crawlable factory is to generate control feed . The factory creates the control feed by splitting the large volume of the data feed into batches where each batch represents a re entry URL of a data feed. In one embodiment the crawlable data in the data feed is split into transferable batches. Each batch can be transferred over the defined messaging protocol such as HTTP S . In most cases the crawlable data will be very large in volume including instances of crawlable business objects. The defined messaging protocol may place limits on the size of crawlable application data that is made available through the crawlable endpoint . It is not practical to send a large volume of data in one request over HTTP S for example. Accordingly the application data is split into batches.

The crawlable factory creates batch URLs for each batch. is XML code of an exemplary structure of a control feed in accordance with one embodiment. The control feed URL is identified with the metadata tag with the value RequisitionsSVO ControlFeed. The batch URLs may be identified by a feed identifier. The batch URL for the feed is provided with the metadata tag following the feed identifier. Accordingly the control feed is similar to a queue or a list of links where each link represents a batch of documents.

Referring back to the third function of the crawlable factory is to return a feed document to the crawlable endpoint . In one embodiment the feed document is made up of the control feed . Accordingly the feed document represents the batches of all or a subset of the business objects within the application . The crawlable endpoint returns the feed document to the search engine . In an alternative embodiment the feed document is made up of a combination of the data feed and the control feed in whole or in part and is returned to the search engine in response to the seed URL request. A feed document has two sections a data feed section and a control feed section. The control feed section contains a list of re entryable URLs for more data feeds. The data feed section contains data that are instances of the business object. These two sections do not have to be related although they may be. For example if a re entry URL requests a data set and the crawlable factory decides that the volume is too large for the request a document would be formed that has a data feed section that contain the first 100 records and the rest may be broken down into small data feed URLs in the control feed section. The feed document may be an Extensible Markup Language XML document.

On the search engine side the feed document is crawled through generic methods. In one embodiment the search engine determines if the feed document has content to be indexed or has further links to other documents. If the search engine finds links the search engine pushes those links into a job queue such as URL queue . Where the feed document includes the control feed the search engine pushes the list of batch links onto the URL queue . Where the feed document includes the data feed the search engine may determine there is content to be indexed and push the content to a document queue . The data feed may also includes further links such as related searchable object links and or dependent links. These further links are pushed onto the URL queue . It should be appreciated that processing of links such as those found in the feed document may vary widely according to the implementation of the search engine . Further it should be appreciated that processing of content such as that found in the batch URL dependent document URL related URL etc. may vary widely according to the implementation of the search engine .

At this point the search engine crawler manager spawns multiple threads or crawlers to crawl the sites listed in the URL queue . The crawler can send a request for a re entry URL which is a URL other than a seed URL. For example a re entry URL may include a batch URL related URL or a dependent document URL. The crawlable application endpoint receives the re entry URL request from the search engine crawler . The requested batch is returned to the search engine where the re entry URL is a batch URL. The requested related document is returned where the re entry URL is a related URL. The requested dependent document is returned where the re entry URL is a dependent document URL.

Further the contents of the document queue may be indexed at indexer . Following indexing the application data is stored in indexed form in the index storage . In alternative embodiments the entire document within the document queue is stored in the document full text storage . The application data has been successfully crawled and is available for searching by an end user.

At block the crawlable applications interface sends a request to the crawlable factory to generate a control feed and data feed. At block the crawlable applications interface begins to generate the data feed by accessing the crawlable definitions of business objects for the application. In one embodiment a subset of all the crawlable definitions is accessed such as when specific business objects are sourced. The data feed provides crawlable data representing business object instances. At block the data source defined in the crawlable definition is queried. The crawlable definition includes a data source for the searchable object. In one embodiment a query specified in the crawlable definition accesses the data source. The query may be an SQL query. The business object data is retrieved from the data source at block . At block the crawlable factory generates the data feed. In one embodiment the factory forms a document for each instance of the business object and numbers the documents into a larger document that contains all of the instances of the business object. This process is repeated for each crawlable business object of the application. In another embodiment the process is repeated for the sourced business objects.

At block the crawlable applications interface determines transferable batches. In order to accomplish this the data feed is split into smaller sized batches. Each batch is of a size that would permit the batch to be transferred to a requesting entity such as a search engine. The batch sizes may be identical however uniformity is not required. In one embodiment the batch sizes may be optimized during transmission. At block the control feed is generated by creating batch URLs for each batch of application data. In one embodiment the total number of documents which represent the instances of the business objects of an application is large for example one million. The crawlable applications interface may determine that a batch size of 500 documents is transferable. Accordingly 2 000 batch URLs are created one URL for each batch. At block a feed document is returned to the requestor such as the search engine. As previously discussed the feed document may be made up of any combination of the control feed and the data feed. In one embodiment the feed document includes the control feed only. In another embodiment the feed document includes both the control feed and the data feed.

Processing loops back to block where the crawlable applications interface receives a URL request. In one embodiment the feed document was made up of the control feed. As previously discussed the control feed contains batch URLs. As such the search engine pushed the batch URLs on the job queue and spawned multiple crawlers to grab the documents in the job queue. Each crawler grabs a job from the queue and makes a request for the batch URL. The crawlable applications interface determines if the request is one for a seed URL or for any other URL for example a batch URL dependent document URL or related URL. If the URL requested is not a seed URL processing continues to block where the information that was requested is returned to the search engine. For a batch URL request for example an XML document corresponding to the batch of application data is returned. For a dependent document URL request an XML document corresponding to a dependent document is returned. A dependent document may include an attachment. For a related searchable object URL request an XML document corresponding to a related business object instance is returned. In an alternative embodiment the preceding URLs provide any type of document which is crawlable by the search engine. The process terminates if the crawlable applications interface no longer receives URL requests from the search engine.

Prior methods of providing secure search services require the enterprise application to make their proprietary data available to the search engine. The enterprise application is entirely dependent on the search engine s security policies. Weak policies introduce a weaker link in the security chain. In one embodiment application data which has been previously crawled and indexed into the search engine cannot be served out to an end user without security permissions from an applications security service on the applications side. is a diagrammatic representation of a system in which an interface between a search engine and applications allows the application data to be securely indexed and searched. System includes applications security service which in this embodiment is a web service that pairs with crawlable applications interface to provide authorization and authentication services. This web service ensures that the search engine serves search results to end user with proper security measures. In one embodiment the security service communicates through a defined messaging protocol such as HTTP S . The implementation of the security service is not limited to any particular search engine.

The secure search begins by authentication of an end user . Authentication is enforced when the end user requests a protected application area. The search engine authenticates the end user through the applications security service if the end user has not previously been authenticated. The search engine provides a login dialog for end user identification. In one embodiment authentication is accomplished by using a browser login dialog for the end user to enter a username and password. The search engine sends a request to the applications security service to authenticate the end user by providing the end user login information. In one embodiment this is performed over HTTP as a web service call by sending an XML document including the login information. The applications security service returns an acceptance or denial of the end user as a valid user of the application.

After authentication the end user may enter a search query. The user interface may provide a list of searchable business objects. In one embodiment the list of searchable business objects is limited based on the security rights of the end user . The end user queries on one or more selected business objects. The user interface passes the search query to the search engine for authorization. The search engine connects to the applications security service to perform authorization. The process of authorization limits end user s access to the application data. The applications security service sends to the search engine a key or a set of keys based on the end user and or the business object to be queried. The keys are determined by the attributes that have been set in the crawlable definition or through other designated security means. In the search engine the indexed application data may be locked and can be viewed with an authorized key. The search engine rewrites the query to include the security predicates such as the key or set of keys obtained by the application security service . The search engine issues the query to the secured application content index . As previously described the applications developer may dictate the security requirements of the business object within the crawlable definition using the security metadata tags. These security requirements are indexed along with each document in the search engine index after the documents have been crawled. The query is set to retrieve the records with attribute values which match the key. The index returns the search results to the search user interface . The search results are displayed to the end user .

In most embodiments the system includes some type of network . The network may can be any type of network familiar to those skilled in the art that can support data communications using any of a variety of commercially available protocols including without limitation TCP IP SNA IPX AppleTalk and the like. Merely by way of example the network can be a local area network LAN such as an Ethernet network a Token Ring network and or the like a wide area network a virtual network including without limitation a virtual private network VPN the Internet an intranet an extranet a public switched telephone network PSTN an infra red network a wireless network e.g. a network operating under any of the IEEE 802.11 suite of protocols the Bluetooth protocol known in the art and or any other wireless protocol and or any combination of these and or other networks.

The system may also include one or more server computers which can be general purpose computers specialized server computers including merely by way of example PC servers UNIX servers mid range servers mainframe computers rack mounted servers etc. server farms server clusters or any other appropriate arrangement and or combination. One or more of the servers e.g. may be dedicated to running applications such as a business application a Web server application server etc. Such servers may be used to process requests from user computers . The applications can also include any number of applications for controlling access to resources of the servers .

The Web server can be running an operating system including any of those discussed above as well as any commercially available server operating systems. The Web server can also run any of a variety of server applications and or mid tier applications including HTTP servers FTP servers CGI servers database servers Java servers business applications and the like. The server s also may be one or more computers which can be capable of executing programs or scripts in response to the user computers . As one example a server may execute one or more Web applications. The Web application may be implemented as one or more scripts or programs written in any programming language such as Java C C or C and or any scripting language such as Perl Python or TCL as well as combinations of any programming scripting languages. The server s may also include database servers including without limitation those commercially available from Oracle Microsoft Sybase IBM and the like which can process requests from database clients running on a user computer .

The system may also include one or more databases . The database s may reside in a variety of locations. By way of example a database may reside on a storage medium local to and or resident in one or more of the computers . Alternatively it may be remote from any or all of the computers and or in communication e.g. via the network with one or more of these. In a particular set of embodiments the database may reside in a storage area network SAN familiar to those skilled in the art. Similarly any necessary files for performing the functions attributed to the computers may be stored locally on the respective computer and or remotely as appropriate. In one set of embodiments the database may be a relational database such as Oracle 10g that is adapted to store update and retrieve data in response to SQL formatted commands.

The computer system may additionally include a computer readable storage media reader a communications system e.g. a modem a network card wireless or wired an infra red communication device etc. and working memory which may include RAM and ROM devices as described above. In some embodiments the computer system may also include a processing acceleration unit which can include a digital signal processor DSP a special purpose processor and or the like.

The computer readable storage media reader can further be connected to a computer readable storage medium together and optionally in combination with storage device s comprehensively representing remote local fixed and or removable storage devices plus storage media for temporarily and or more permanently containing computer readable information. The communications system may permit data to be exchanged with the network and or any other computer described above with respect to the system .

The computer system may also comprise software elements shown as being currently located within a working memory including an operating system and or other code such as an application program which may be a client application Web browser mid tier application RDBMS etc. . It should be appreciated that alternate embodiments of a computer system may have numerous variations from that described above. For example customized hardware might also be used and or particular elements might be implemented in hardware software including portable software such as applets or both. Further connection to other computing devices such as network input output devices may be employed.

Storage media and computer readable media for containing code or portions of code can include any appropriate media known or used in the art including storage media and communication media such as but not limited to volatile and non volatile removable and non removable media implemented in any method or technology for storage and or transmission of information such as computer readable instructions data structures program modules or other data including RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disk DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices data signals data transmissions or any other medium which can be used to store or transmit the desired information and which can be accessed by the computer. Based on the disclosure and teachings provided herein a person of ordinary skill in the art will appreciate other ways and or methods to implement the various embodiments.

The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense. It will however be evident that various modifications and changes may be made thereunto without departing from the broader spirit and scope of the invention as set forth in the claims.

The above description is illustrative but not restrictive. Many variations of the invention will become apparent to those skilled in the art upon review of the disclosure. While enterprise applications have generally been described as suitable for being crawlable using the crawlable applications interface applications that are made to be crawlable are not limited to being enterprise applications. For example an application that is not an enterprise application may be crawlable using the crawlable applications interface. The scope of the invention should therefore be determined not with reference to the above description but instead should be determined with reference to the pending claims along with their full scope or equivalents.

