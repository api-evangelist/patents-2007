---

title: Creating and editing web 2.0 entries including voice enabled ones using a voice only interface
abstract: The present invention discloses a method for creating Web 2.0 entries, such as WIKI entries. In the method, a voice communication channel can be established between a user and an automated response system. User speech input can be received over the voice communication channel. A Web 2.0 entry can be created based upon the speech input. The Web 2.0 entry can be saved in a data store accessible by a Web 2.0 server. The Web 2.0 server can serve the saved Web 2.0 entry to Web 2.0 clients. The Web 2.0 clients can include a graphical and/or a voice interface through which the Web 2.0 entry can be presented to users of the clients. The created Web 2.0 entries (e.g. Web 2.0 application) can be formatted in an ATOM PUBLISHING PROTOCOL compliant manner.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08032379&OS=08032379&RS=08032379
owner: International Business Machines Corporation
number: 08032379
owner_city: Armonk
owner_country: US
publication_date: 20070621
---
This continuation in part application claims the benefit of U.S. patent application Ser. No. 11 765 900 filed Jun. 20 2007 the benefit of U.S. patent application Ser. No. 11 765 928 filed Jun. 20 2007 and the benefit of U.S. patent application Ser. No. 11 765 962 filed Jun. 20 2007 which are incorporated by reference herein.

The present invention relates to the field of Web 2.0 software development tools and more particularly to creating and editing Web 2.0 entries using a voice only interface.

Web 2.0 refers to a cooperative Web in which end users add value by providing content as opposed to Web systems that unidirectionally provide information from an information provider to an information consumer. In other words Web 2.0 refers to a readable writable and updateable Web. While a myriad of types of Web 2.0 applications exists some currently popular ones include WIKIs BLOGs MASHUPs FOLKSONOMIEs social networking sites and the like.

Currently Web 2.0 users are restricted to using Graphical User Interface GUI based editors to create and edit content. For example WIKI content providers can utilize a WIKI editor from a Web browser to add WIKI entries written in a WIKI syntax. The visual modality restriction makes it difficult if not impossible for visually impaired individuals to create and modify Web 2.0 content without assistance. It also restricts interactive options of sighted users such as a BLOG creator who could desire to update create BLOG entries via a telephone interface.

In general Web 2.0 applications do not incorporate speech processing technologies. Such technologies can require a Web 2.0 server to be integrated with a server side speech processing system. Traditional interface mechanisms to these speech processing systems rely upon specialized voice toolkits such as IBM s WEBSPHERE VOICE SERVER WVS voice toolkit. Use of these toolkits requires some knowledge of speech processing technologies that is beyond a proficiency of most end users and even many programmers. Since end users are content providers of Web 2.0 applications this effectively prevents Web 2.0 applications from utilizing speech processing technologies. It further prevents voice only interfaces which are typically more restricted than graphical ones from being used to create speech enabled applications.

The present invention discloses a software development tool that allows users to create and edit Web 2.0 entries such as WIKI entries utilizing a voice only interface. The Web 2.0 entries can be speech enabled entries written to conform to an ATOM PUBLISHING PROTOCOL APP format. In one configuration of the invention users can be permitted to create and edit voice applications over a telephone. Appreciably an end user of the inventive software development tool is not required to establish a complex client side interface with a server side speech processing system. Instead a new speech processing system interface is created that utilizes a set of constrained commands using Representational State Transfer architecture REST commands e.g. GET PUT POST and DELETE commands to interface with speech engines using standard Web 2.0 protocols.

In one embodiment of the invention the software development tool accessible via a voice response interface can prompt a user in a well defined manner by asking a finite set of questions. For example the tool can prompt a user to speak a text to speech TTS prompt that is desired a name of a grammar to be used to process prompt responses actions to take depending upon recognition results and any other desired parameters. The user input can be converted into Web 2.0 entries which are executable by a Web 2.0 server. The created Web 2.0 entries can be served to clients having a Voice User Interface VUI as well as clients having a Graphical User Interface GUI .

The present invention can be implemented in accordance with numerous aspects consistent with the material presented herein. For example one aspect of the present invention can include a method for creating Web 2.0 entries such as WIKI entries. In the method a voice communication channel can be established between a user and an automated response system. User speech input can be received over the voice communication channel. A Web 2.0 entry can be created based upon the speech input. The Web 2.0 entry can be saved in a data store accessible by a Web 2.0 server. The Web 2.0 server can serve the saved Web 2.0 entry to Web 2.0 clients. The Web 20 clients can include a graphical and or a voice interface through which the Web 2.0 entry can be presented to users of the clients.

Another aspect of the present invention can include a system for creating Web 2.0 applications via a voice only interface that includes a Web 2.0 server an automated response system and an application development component. The Web 2.0 server which can be a WIKI server can serve applications to remotely located clients. Each of the applications can include an introspection document an entry collection of linked entries and a resource collection of resources. The automated response can interact with remotely located users over a voice communication channel. The application development component can be communicatively linked to the automated response system and configured to receive speech input from users over the voice communication channel. The application development component can create content contained within entries of the entry collection based upon the received speech input. That is the entries created via the application development component can be served by the Web 2.0 server.

Still another aspect of the present invention can include a method for creating and editing Web 2.0 applications using a voice user interface. In the method a user can connect to a voice response system over a voice communication channel. The voice response system can be linked to a data store containing a set of speech enabled Web 2.0 applications. Each of the speech enabled Web 2.0 applications can include an introspection document a collection of entries and a collection of resources. A Web 2.0 server can serve the speech enabled Web 2.0 applications to remotely located clients. Speech input can be received over the voice communication channel which can be speech recognized. The speech recognized input can be processed to create and or edit one of the entries in the collection of entries. In one configuration end users can be able to introspect customize replace add re order and remove entries and resources in the collections through either a GUI editor or through the voice user interface of the method.

It should be noted that various aspects of the invention can be implemented as a program for controlling computing equipment to implement the functions described herein or a program for enabling computing equipment to perform processes corresponding to the steps disclosed herein. This program may be provided by storing the program in a magnetic disk an optical disk a semiconductor memory or any other recording medium. The program can also be provided as a digitally encoded signal conveyed via a carrier wave. The described program can be a single program or can be implemented as multiple subprograms each of which interact within a single computing device or interact in a distributed fashion across a network space.

It should also be noted that the methods detailed herein can also be methods performed at least in part by a service agent and or a machine manipulated by a service agent in response to a service request.

Each application can be associated with an introspection document and a collection of entries and resources. The resources can link a Web 2.0 server to speech processing engines of speech system . End users of environment can be permitted to introspect customize add re order and remove entries and resources of the collections via the voice only interface . In one embodiment applications and resources can also be created modified by a graphical editor not shown of the Web 2.0 server . In one embodiment the application can be written in accordance with Representational State Transfer architecture REST principles. For example the application can conform to the ATOM PUBLISHING PROTOCOL APP .

The voice response system can be an automated system that permits users to interact with applications through a voice communication channel. The voice response system can incorporate telephone technologies to permit callers to receive speech output and to present speech and or Dual Tone Multi Frequency DTMF dial pad input. The voice response system can provide dialog prompts each associated with a constrained grammar or a set of acceptable responses. These responses can in turn be mapped to programmatic actions which are selectively triggered based upon user responses to the prompts. In one embodiment the applications can be written in VoiceXML or other voice markup language which is interpreted by a VoiceXML interpreter included within or accessed by the voice response system .

The voice editor can utilize a set of well defined commands to create application using a finite set of questions. For example the voice editor can prompt a user to speak a desired TTS prompt a name of a grammar for the TTS prompt and actions to be taken with the recognition results. This prompting can repeat for each turn in the application . In one embodiment end users can customize behavior of the voice editor to use different user specific defaults and or different types of prompting.

In another embodiment the editor can utilize sets of generic templates for different types of applications. These templates can be customized and extended. For example a template for a survey can be used to quickly generate a speech enabled telephone survey application by having a user e.g. application developer fill in details of a partially filled survey application template. In another example a customer service template can include a previously configured set of dialog templates which a user e.g. application developer edits using editor to create a customized customer service application.

The Web 2.0 server can be a WIKI server a BLOG server MASHUP server a FOLKSONOMY server a social networking server and the like. A speech system can include speech processing engines which can be accessed by the server through use of a set of RESTful commands. Further the speech system can be part of a turn based network system such as the WEBSPHERE VOICE SERVER. The RESTful commands can include GET PUT POST and or DELETE commands. There are no assumptions regarding the Web 2.0 clients to which the applications are served other than an ability to communicate with a Web 2.0 server .

The speech system can be a network accessible system of speech processing resources. The system can be a turn based speech system which provides speech recognition speech synthesis speaker identification and verification and other speech processing services. In one embodiment the speech system can be an implementation of IBM s WEBSPHERE VOICE SERVER although the invention is not limited in this regard.

The method of which includes steps can be performed in the context of environment . The method can begin in step where a user establishes a voice communication channel with a voice response system. In step an application creation editing tool of a voice editor can be initiated. In step the tool can prompt the user for a dialog start. In step the user can speak input that defines an initial dialog prompt. This input can be speech to text converted by the voice editor and added to markup code for the application entry being created by the user. This markup code can include VoiceXML markup. In step a user can then speak grammar to be used for the dialog prompt. An existing grammar can be specified by the user at this stage or the user can enumerate a set of valid entries for a new grammar. A speech recognition grammar that corresponds to the new dialog prompt can be established by processing user provided input from step .

In step the user can specify a back end server that is to process responses provided to the dialog prompt . In step a Web 2.0 entry can be automatically created based upon the processed speech input. This Web 2.0 entry can include VoiceXML written code and can be formatted to conform to an APP compliant protocol. In step the new Web 2.0 entry can be optionally linked to other Web 2.0 entries which together form a Web 2.0 application. In step speech processing parameters can be optionally specified for the Web 2.0 entries. When no speech processing parameters are specified in step defaults can be utilized. In step the newly created Web 2.0 entry and associated parameters can be stored in a memory space accessible by a Web 2.0 server. A determination as to whether additional Web 2.0 entries are to be manipulated and or created can be made in step . If new entries are to be created the method can loop from step to step where a user can be prompted for new dialog specifying input. When no other entries are to be created the method can proceed from step to step where the application development tool can be exited and where the voice connection with the voice response system can be terminated.

To illustrate a use of a user can access the voice editor to create a WIKI entry. Upon establishing a communication connection the user can be initially informed that they are building their first WIKI page. When prompted the user can speak a welcome authentication prompt such as Welcome to Acme banking . . . . Please enter your account number and PIN. The user can then be prompted for a grammar to use for the welcome authentication prompt. The user can specify a pre built grammar which corresponds to a properly formatted account number and PIN input. The user can then specify a link to a back end server for handling a properly entered account number and PIN. A format of input output to the back end server can be provided at this time. Speech processing for this interaction can be handled by speech system which also handles speech processing operations for completed applications . The process can be repeated for additional WIKI pages until the WIKI application is finished. Links can be established between different WIKI pages and data values such as account number can be conveyed across these links. A user i.e. application developer can be permitted to configure speech system specific parameters such as TTS voice speaking rate ASR thresholds and the like for the new application using the voice editor . A finished WIKI application can be stored and thereafter served to WIKI clients by server .

In system Web 2.0 clients can communicate with Web 2.0 servers utilizing a REST ATOM protocol. The Web 2.0 servers can serve one or more speech enabled applications where speech resources are provided by a Web 2.0 for Voice system . One or more of the applications can include AJAX or other JavaScript code. In one embodiment the AJAX code can be automatically converted from WIKI or other syntax by a transformer of a server .

Communications between the Web 2.0 servers and system can be in accordance with REST ATOM protocols. Each speech enabled application can be associated with an ATOM container which specifies Web 2.0 items resources and media . One or more resource can correspond to a speech engine .

The Web 2.0 clients can be any client capable of interfacing with a Web 2.0 server . For example the clients can include a Web or voice browser as well as any other type of interface which executes upon a computing device. The computing device can include a mobile telephone a mobile computer a laptop a media player a desktop computer a two way radio a line based phone and the like. Unlike conventional speech clients the clients need not have a speech specific interface and instead only require a standard Web 2.0 interface. That is there are no assumptions regarding the client other than an ability to communicate with a Web 2.0 server using Web 2.0 conventions.

The Web 2.0 servers can be any server that provides Web 2.0 content to clients and that provides speech processing capabilities through the Web 2.0 for voice system . The Web 2.0 servers can include a WIKI server a BLOG server a MASHUP server a FOLKSONOMY server a social networking server and any other Web 2.0 server .

The Web 2.0 for voice system can utilize Web 2.0 concepts to provide speech capabilities. A server side interface is established between the voice system and a set of Web 2.0 servers . Available speech resources can be introspected and discovered via introspection documents which are one of the Web 2.0 items . Introspection can be in accordance with the APP specification or a similar protocol. The ability for dynamic configuration and installation is exposed to the servers via the introspection document.

That is access to Web 2.0 for voice system can be through a Web 2.0 server that lets users e.g. clients provide their own customizations personalizations. Appreciably use of the APP opens up the application interface to speech resources using Web 2.0 JAVA 2 ENTERPRISE EDITION J2EE WEBSPHERE APPLICATION SERVER WAS and other conventions rather than being restricted to protocols such as media resource control protocol MRCP real time streaming protocol RTSP or real time protocol RTP .

A constrained set of RESTful commands can be used to interface with the Web 2.0 for voice system . RESTful commands can include a GET command a POST command a PUT command and a DELETE command each of which is able to be implemented as an HTTP command. As applied to speech GET e.g. HTTP GET can return capabilities and elements that are modifiable. The GET command can also be used for submitting simplistic speech queries and for receiving query results.

The POST command can create media related resources using speech engines . For example the POST command can create an audio file from input text using a text to speech TTS resource which is linked to a TTS engine . The POST command can create a text representation given an audio input using an automatic speech recognition ASR resource which is linked to an ASR engine . The POST command can create a score given an audio input using a Speaker Identification and Verification SIV resource which is linked to a SIV engine . Any type of speech processing resource can be similarly accessed using the POST command.

The PUT command can be used to update configuration of speech resources e.g. default voice name ASR or TTS language TTS voice media destination media delivery type etc. The PUT command can also be used to add a resource or capability to a Web 2.0 server e.g. installing an SIV component . The DELETE command can remove a speech resource from a configuration. For example the DELETE command can be used to uninstall a previously installed speech component.

The Web 2.0 for Voice system is an extremely flexible solution that permits users of clients to customize numerous speech processing elements. Customizable speech processing elements can include speech resource availability request characteristics result characteristics media characteristics and the like. Speech resource availability can indicate whether a specific type of resource e.g. ASR TTS SIV Voice XML interpreter is available. Request characteristics can refer to characteristics such as language grammar voice attributes gender rate of speech and the like. The result characteristics can specify whether results are to be delivered synchronously or asynchronously. Result characteristics can alternatively indicate whether a listener for callback is to be supplied with results. Media characteristics can include input and output characteristics which can vary from a URI reference to an RTP stream. The media characteristics can specify a codec e.g. G711 a sample rate e.g. 8 KHz to 22 KHz and the like. In one configuration the speech engines can be provided from a J2EE environment such as a WAS environment. This environment can conform to a J2EE Connector Architecture JCA .

In one embodiment a set of additional facades can be utilized on top of Web 2.0 protocols to provide additional interface and protocol options e.g. MRCP RTSP RTP Session Initiation Protocol SIP etc. to the Web 2.0 for voice system . Use of facades can enable legacy access use of the Web 2.0 for voice system . The facades can be designed to segment the protocol from underlying details so that characteristics of the facade do not bleed through to speech implementation details. Functions such as the WAS 6.1 channel framework or a JCA container can be used to plug in a protocol which is not native to the J2EE environment . The media component of the container can be used to handle media storage delivery and format conversions as necessary. Facades can be used for asynchronous or synchronous protocols .

In system a browser can communicate with Web 2.0 server via Representational State Transfer REST architecture ATOM based protocol. The Web 2.0 server can communicate with a speech for Web 2.0 system via a REST ATOM based protocol. Protocols can include HTTP and similar protocols that are RESTful by nature as well as an Atom Publishing Protocol APP or other protocol that is specifically designed to conform to REST principles.

The Web 2.0 server can include a data store in which applications which can be speech enabled are stored. In one embodiment the applications can be written in a WIKI or other Web 2.0 syntax and can be stored in an APP format.

The contents of the application can be accessed and modified using editor . The editor can be a standard WIKI or other Web 2.0 editor having a voice plug in or extensions . In one implementation user specific modifications made to the speech enabled application via the editor can be stored in customization data store as a customization profile and or a state definition. The customization profile and state definition can contain customization settings that can override entries contained within the original application . Customizations can be related to a particular user or set of users.

The transformer can convert WIKI or other Web 2.0 syntax into standard markup for browsers. In one embodiment the transformer can be an extension of a conventional transformer that supports HTML and XML. The extended transformer can be enhanced to handle JAVA SCRIPT such as AJAX. For example resource links of application can be converted into AJAX functions by the transformer having an AJAX plug in . The transformer can also include a VoiceXML plug in which generates VoiceXML markup for voice only clients.

The present invention may be realized in hardware software or a combination of hardware and software. The present invention may be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software may be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention also may be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program in the present context means any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation b reproduction in a different material form.

This invention may be embodied in other forms without departing from the spirit or essential attributes thereof. Accordingly reference should be made to the following claims rather than to the foregoing specification as indicating the scope of the invention.

