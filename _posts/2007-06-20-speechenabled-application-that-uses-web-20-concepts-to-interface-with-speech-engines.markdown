---

title: Speech-enabled application that uses web 2.0 concepts to interface with speech engines
abstract: The present invention discloses a speech-enabled application that includes two or more linked markup documents that together form a speech-enabled application served by a Web 2.0 server. The linked markup documents can conform to an ATOM PUBLISHING PROTOCOL (APP) based protocol. Additionally, the linked markup documents can include an entry collection of documents and a resource collection of documents. The resource collection can include at least one speech resource associated with a speech engine disposed in a speech processing system remotely located from the Web 2.0 server. The speech resource can add a speech processing capability to the speech-enabled application. In one embodiment, end-users of the speech-enabled application can be permitted to introspect, customize, replace, add, re-order, and remove at least a portion of the linked markup documents.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08086460&OS=08086460&RS=08086460
owner: International Business Machines Corporation
number: 08086460
owner_city: Armonk
owner_country: US
publication_date: 20070620
---
This application is related to and the teachings of which are incorporated herein by reference in their entirety the following United States Applications for Patent entitled SPEECH PROCESSING SYSTEM BASED UPON A REPRESENTATIONAL STATE TRANSFER REST ARCHITECTURE THAT USES WEB 2.0 CONCEPTS FOR SPEECH RESOURCE INTERFACES filed Jun. 20 2007 assigned U.S. application Ser. No. 11 765 900 and identified internally by and SPEECH PROCESSING METHOD BASED UPON A REPRESENTATIONAL STATE TRANSFER REST ARCHITECTURE THAT USES WEB 2.0 CONCEPTS FOR SPEECH RESOURCE INTERFACES filed Jun. 20 2007 assigned U.S. application Ser. No. 11 765 928 and identified internally by both of which are assigned to the assignee of the present application.

The present invention relates to the field of speech processing technologies and more particularly to a speech enabled application that uses Web 2.0 concepts to interface with speech engines.

In the past companies having a Web presence thrived by providing as many people broad access to as much information as possible. Information flow was unidirectional from a company to information consumers. As time has progressed users have become inundated with too much information from too many sources. Successful Web sites began to provide user facing information management and information filtration mechanisms designed to aid users in identifying information of interest. Even these Web sites were somewhat flawed in a sense that information still flowed in a unidirectional manner. A user was limited to information gathered and groomed by a particular information provider.

A new type of Web application began to emerge which emphasized user interactions and two way information exchange. These new Web applications operated more as information marketplaces were people shared information and not as information depots where users accessed a semi static reservoir of information. This new Web and set of Web applications can be referred to as Web 2.0 where Web 2.0 signifies a second generation of Web based services and applications that emphasize online collaboration and information sharing among users. In other words a Web 1.0 application would be one that was effectively read only from a user perspective whereas a Web 2.0 application would provide read write and update access to end users. Web 2.0 users can fundamentally change a Web 2.0 application.

Specific examples of Web 2.0 instances include WIKIs BLOGs social networking sites FOLKSONOMIEs MASHUPs and the like. All of these Web 2.0 instances allow end users to add content which other users are able to access. A value of a Web 2.0 Web site is enhanced by the user provided content and may even be completely dependent upon it.

For example WIKIPEDIA e.g. one Web 2.0 application is a WIKI based encyclopedia where each end user is able to view add and edit content. No content would exist without end user contributions. Information accuracy results from an end user population constantly updating erroneous entries which other users provide. As new innovations emerge customers update and add WIKIPEDIA entries that describe these new innovations. Other examples of Web 2.0 applications include MYSPACE.com YOUTUBE.com DEL.ICIO.US.com CRAIGSLIST.com and the like.

Currently a schism exists between speech processing technologies and Web 2.0 applications meaning that Web 2.0 instances do not generally incorporate speech processing technologies. One reason for this is that conventional interfaces to speech resources are too complex for an average end user to utilize. For this reason speech technologies are typically only available from Web sites services that provide a unidirectional flow of information. For example speech technologies are commonly used by enterprises to handle routine customer interactions via a telephone interface such as providing bank balances and the like.

One problem contributing to the schism is that speech processing technologies are currently implemented using a non uniform interface and the Web 2.0 is generally based upon a uniform interface. That is speech processing operations are accessed via function calls method invocations remote procedure calls RPC and other messages that are only understood by a specific server or a small subset of components. A specific invocation mechanism and required parameters must be known by a client and must be integrated into an interface. A non uniform interface is characteristic of RPC based techniques which includes Simple Object Access Protocol SOAP Common Object Request Broker Architecture CORBA Distributed Component Object Model DCOM JINI and the like. Without deliberate integration efforts however the chances that two software objects designed from an unconstrained architecture are near nil. At best an ad hoc collection of software objects having vastly different interface requirements result from the RPC style architecture. The lack of uniform interfaces makes integrating speech processing capabilities for each RPC based application a unique endeavor fraught with application specific challenges which usually require significant speech processing design skills to overcome.

In contrast a uniform interface exists that includes a few basic primitive commands e.g. GET PUT POST DELETE that act upon targets which in a Web 2.0 context are generally able to be referenced by Uniform Resource Identifiers URIs . A term used for this type of architecture is Representational State Transfer REST . REST based solutions simplify component implementation reduce the complexity of connector semantics improve the effectiveness of performance tuning and increase the scalability of pure server components. The Web e.g. hypertext technologies in general is founded upon REST principles. Web 2.0 expands these REST principles to permit end users to add HTTP PUT update HTTP POST and remove HTTP DELETE content. Thus WIKIs BLOGs FOLKSONOMIEs MASHUPs and the like are all considered RESTful since each generally follows REST principles.

What is needed to bridge the gap between speech processing resources and conventional Web 2.0 applications is a new paradigm for interfacing with speech processing resources which makes speech processing resources more available to end users. In this contemplated paradigm end users would optimally be able to cooperatively and dynamically develop speech enabled solutions which the end users would then be able to integrate into Web 2.0 content. Thus a more robust Web 2.0 environment that incorporates speech processing technologies will be allowed to evolve. This is a stark contrast with a conventional paradigm for interfacing with speech processing resources which is decisively non RESTful in nature.

The present invention discloses speech enabled applications that use Web 2.0 concepts for interfacing with server side speech resources. The speech enabled applications can each be any variety of Web 2.0 application such as WIKIs BLOGs social networking sites FOLKSONOMIEs MASHUPs and the like. Each speech enabled application can contain a collection of entries and resources. The entries can include Web 2.0 entries such as WIKI entries and the resources can include speech resources such as speech recognition speech synthesis speech identification and voice interpreter resources. Each entry and resource can be further decomposed into sub components specified at a lower granularity level. Each application resource entry can be introspected customized replaced added re ordered and or removed by end users.

The present invention can be implemented in accordance with numerous aspects consistent with the material presented herein. For example one aspect of the present invention can include a speech enabled application for a Web 2.0 for voice system. The application can include at least one root entry that includes an introspection entry and links to an entry collection and a resource collection. At least one of the resources in the resource collection can be a speech resource associated with a speech engine which adds a speech processing capability to a speech enabled application associated with the root entry. Entries of the entry collection can be markup documents served to browsers by a Web 2.0 server.

Another aspect of the present invention can include a speech enabled application that includes two or more linked markup documents that together form a speech enabled application served by a Web 2.0 server. The linked markup documents can conform to an Atom Publication Protocol APP based protocol. Additionally the linked markup documents can include an entry collection of documents and a resource collection of documents. The resource collection can include at least one speech resource associated with a speech engine disposed in a speech processing system remotely located from the Web 2.0 server. The speech resource can add a speech processing capability to the speech enabled application.

Still another aspect of the present invention can include a speech enabled application that includes multiple linked markup documents served by a Web 2.0 server to standard browsers. At least one of the linked markup documents can be a resource document for a speech resource associated with a speech engine. The resource document can add a speech processing capability to the speech enabled application. The speech resource can be an automatic speech recognition ASR resource a text to speech TTS resource a speaker identification and verification SIV resource a voice interpreter resource and or any other type of speech processing resource. The Web 2.0 server can be configured so that end users are able to introspect customize replace add re order and remove at least a portion of the linked markup documents.

It should be noted that various aspects of the invention can be implemented as a program for controlling computing equipment to implement the functions described herein or a program for enabling computing equipment to perform processes corresponding to the steps disclosed herein. This program may be provided by storing the program in a magnetic disk an optical disk a semiconductor memory or any other recording medium. The program can also be provided as a digitally encoded signal conveyed via a carrier wave. The described program can be a single program or can be implemented as multiple subprograms each of which interact within a single computing device or interact in a distributed fashion across a network space.

It should also be noted that the methods detailed herein can also be methods performed at least in part by a service agent and or a machine manipulated by a service agent in response to a service request.

The Web 2.0 server can be a WIKI server a BLOG server MASHUP server a FOLKSONOMY server a social networking server and the like. A speech system can include speech processing engines which can be accessed by the server through use of a set of RESTful commands . Further the speech system can be part of a turn based network system such as the WEBSPHERE VOICE SERVER. The RESTful commands can include GET PUT POST and or DELETE commands. There are no assumptions regarding the client upon which the interface executes other than an ability to communicate with a Web 2.0 server .

Details for the speech enabled application are shown which illustrates a RESTful application having an introspection document an entries link to the entry collection and a resources link to the resource collection . The RESTful application is one adhering to Representational State Transfer architecture REST principles such as an application conforming to the ATOM PUBLISHING PROTOCOL APP .

An initial entry collection can refer to various pages of a Web 2.0 site such as pages of a WIKI site. Each page can have an associated entry. Additionally each page can link to other collections and . When the collection is a collection of entries further decomposition of the corresponding Web 2.0 page can be specified. For example Collection can specify one or more sections of a Web 2.0 page. Additionally each entry of collection or any other collection can specify entity specific resources. These resources can be activated when the corresponding entity is active. When lower level entries are active all parent entries and their resources can also be active.

The resource collection can include an entries link used to configure the associated resource and can include links to other resources collections and . Resources can include any of a variety of computing resources including but not limited to speech processing resources media delivery resources and the like. Speech processing resources can include automatic speech recognition resources ASR text to speech resources speaker identification and verification SIV resources voice interpreter resources and the like. Media delivery resources can include Real Time Protocol RTP Real Time Streaming Protocol RTSP Media Resource Control Protocol MRCP resources and the like.

The ASR resource is further decomposed in to illustrate a manner in which entries can be used to configure resources. More specifically the ASR resource can link to ASR entries which include grammars delivery protocols and the like. The grammar entry can link to ASR grammars which include a grammar a grammar . . . grammar n. Grammars of the ASR grammars can include context dependent grammars which are linked to specific Web 2.0 pages or sections. The grammars can also include one or more speaker dependent grammars that are specific to a user of the application .

It should be re emphasized that end users can be permitted to edit add delete and or otherwise configure or personalize the entries or resources items of the speech enabled application . Thus the application provides a personalized experience tailored to an end user . Additionally the end user can create and publish a speech enabled application using standard Web 2.0 server creation mechanisms and are not required to create manipulate a speech processing client interface specific to the speech system .

As used herein Web 2.0 is a concept that refers to a cooperative Web in which end users add value by providing content as opposed to Web systems that unidirectionally provide information from an information provider to an information consumer. In other words Web 2.0 refers to a readable writable and updateable Web. While a myriad of types of Web 2.0 applications exist some currently popular ones include WIKIs BLOGs MASHUPs FOLKSONOMIEs social networking sites and the like.

A REST approach focuses on utilizing a constrained operation set e.g. commands such as GET PUT POST and DELETE to act against a set of structured targets which can be URL addressable. A REST architecture is a client server architecture which is stateless cacheable and layered by nature. REST replaces a paradigm of do something with a make something so concept. That is instead of attempting to execute a kind of state transition for a software object the REST concept changes a state of a software object to a user designated state. A RESTful object is one which primarily conforms to REST concepts. A RESTful interface e.g. interface can be a simple interface that transmits domain specific data using a HyperText Transfer Protocol HTTP based protocol without utilizing an additional messaging layer such as SOAP and without reliance upon session tracking HTTP cookies.

The WIKI banking application includes a collection of WIKI pages that include an authenticate entry a banking services entry and an account balance entry . The entries can be linked to back end systems and and to a collection of resources. The collection can include speech processing resources such as an ASR resource TTS resource SIV resource and voice interpreter resource . Resources of collection can be utilized by associated entries as needed.

The authenticate entry can be a WIKI that performs authentication of the user with a back end server . For example a user accessing entry can enter an account number and PIN to authenticate themselves responsive to being prompted. The basic WIKI markup of entry can contain links to a back end server for authentication a link to the next WIKI in the application a link to a help Wiki not shown and links to ASR and TTS resources. Entry can include voice input and output TTS or pre recorded audio welcome prompt . The markup of WIKI can include a welcome prompt prompts for authentication information confirmation prompts and the like. In one embodiment speech identification and verification can be performed by WIKI which can utilize SIV resource .

The banking services entry can be a WIKI that queries a user for a banking service of interest such as savings services checking services account balance services and the like. The WIKI can then direct a user to a selected service. A user s account number can be obtained from entry via the link between entries and . Entry can include links to ASR and TTS resources as well as a link to a voice interpreter resource . Entry does not include links to back end servers but does include a link to account balance entry and other service entries not shown .

The account balance entry can be a WIKI that finds an account balance for a user by connecting to a bank end banking services server . The user s account number used by WIKI can be obtained from entry or entry . Entry can utilize a TTS resource when speech output is desired. An amount of money in a user s account can be conveyed from the server and presented to a user through a WIKI interface. The WIKI can also link back to the banking services WIKI so that a user can perform other banking services after hearing their account balance.

In system Web 2.0 clients can communicate with Web 2.0 servers utilizing a REST ATOM protocol. The Web 2.0 servers can serve one or more speech enabled applications where speech resources are provided by a Web 2.0 for Voice system . One or more of the applications can include AJAX or other JavaScript code. In one embodiment the AJAX code can be automatically converted from WIKI or other syntax by a transformer of a server .

Communications between the Web 2.0 servers and system can be in accordance with REST ATOM protocols. Each speech enabled application can be associated with an ATOM container which specifies Web 2.0 items resources and media . One or more resource can correspond to a speech engine .

The Web 2.0 clients can be any client capable of interfacing with a Web 2.0 server . For example the clients can include a Web or voice browser as well as any other type of interface which executes upon a computing device. The computing device can include a mobile telephone a mobile computer a laptop a media player a desktop computer a two way radio a line based phone and the like. Unlike conventional speech clients the clients need not have a speech specific interface and instead only require a standard Web 2.0 interface. That is there are no assumptions regarding the client other than an ability to communicate with a Web 2.0 server using Web 2.0 conventions.

The Web 2.0 servers can be any server that provides Web 2.0 content to clients and that provides speech processing capabilities through the Web 2.0 for voice system . The Web 2.0 servers can include a WIKI server a BLOG server a MASHUP server a FOLKSONOMY server a social networking server and any other Web 2.0 server .

The Web 2.0 for voice system can utilize Web 2.0 concepts to provide speech capabilities. A server side interface is established between the voice system and a set of Web 2.0 servers . Available speech resources can be introspected and discovered via introspection documents which are one of the Web 2.0 items . Introspection can be in accordance with the APP specification or a similar protocol. The ability for dynamic configuration and installation is exposed to the servers via the introspection document.

That is access to Web 2.0 for voice system can be through a Web 2.0 server that lets users e.g. clients provide their own customizations personalizations. Appreciably use of the APP opens up the application interface to speech resources using Web 2.0 JAVA 2 ENTERPRISE EDITION J2EE WEBSPHERE APPLICATION SERVER WAS and other conventions rather than being restricted to protocols such as media resource control protocol MRCP real time streaming protocol RTSP or real time protocol RTP .

A constrained set of RESTful commands can be used to interface with the Web 2.0 for voice system . RESTful commands can include a GET command a POST command a PUT command and a DELETE command each of which is able to be implemented as an HTTP command. As applied to speech GET e.g. HTTP GET can return capabilities and elements that are modifiable. The GET command can also be used for submitting simplistic speech queries and for receiving query results.

The POST command can create media related resources using speech engines . For example the POST command can create an audio file from input text using a text to speech TTS resource which is linked to a TTS engine . The POST command can create a text representation given an audio input using an automatic speech recognition ASR resource which is linked to an ASR engine . The POST command can create a score given an audio input using a Speaker Identification and Verification SIV resource which is linked to a SIV engine . Any type of speech processing resource can be similarly accessed using the POST command.

The PUT command can be used to update configuration of speech resources e.g. default voice name ASR or TTS language TTS voice media destination media delivery type etc. The PUT command can also be used to add a resource or capability to a Web 2.0 server e.g. installing an SIV component . The DELETE command can remove a speech resource from a configuration. For example the DELETE command can be used to uninstall a previously installed speech component.

The Web 2.0 for Voice system is an extremely flexible solution that permits users of clients to customize numerous speech processing elements. Customizable speech processing elements can include speech resource availability request characteristics result characteristics media characteristics and the like. Speech resource availability can indicate whether a specific type of resource e.g. ASR TTS SIV Voice XML interpreter is available. Request characteristics can refer to characteristics such as language grammar voice attributes gender rate of speech and the like. The result characteristics can specify whether results are to be delivered synchronously or asynchronously. Result characteristics can alternatively indicate whether a listener for callback is to be supplied with results. Media characteristics can include input and output characteristics which can vary from a URI reference to an RTP stream. The media characteristics can specify a codec e.g. G711 a sample rate e.g. 8 KHz to 22 KHz and the like. In one configuration the speech engines can be provided from a J2EE environment such as a WAS environment. This environment can conform to a J2EE Connector Architecture JCA .

In one embodiment a set of additional facades can be utilized on top of Web 2.0 protocols to provide additional interface and protocol options e.g. MRCP RTSP RTP Session Initiation Protocol SIP etc. to the Web 2.0 for voice system . Use of facades can enable legacy access use of the Web 2.0 for voice system . The facades can be designed to segment the protocol from underlying details so that characteristics of the facade do not bleed through to speech implementation details. Functions such as the WAS 6.1 channel framework or a JCA container can be used to plug in a protocol which is not native to the J2EE environment . The media component of the container can be used to handle media storage delivery and format conversions as necessary. Facades can be used for asynchronous or synchronous protocols .

In system a browser can communicate with Web 2.0 server via Representational State Transfer REST architecture ATOM based protocol. The Web 2.0 server can communicate with a speech for Web 2.0 system via a REST ATOM based protocol. Protocols can include HTTP and similar protocols that are RESTful by nature as well as an Atom Publishing Protocol APP or other protocol that is specifically designed to conform to REST principles.

The Web 2.0 server can include a data store in which applications which can be speech enabled are stored. In one embodiment the applications can be written in a WIKI or other Web 2.0 syntax and can be stored in an APP format.

The contents of the application can be accessed and modified using editor . The editor can be a standard WIKI or other Web 2.0 editor having a voice plug in or extensions . In one implementation user specific modifications made to the speech enabled application via the editor can be stored in customization data store as a customization profile and or a state definition. The customization profile and state definition can contain customization settings that can override entries contained within the original application . Customizations can be related to a particular user or set of users.

The transformer can convert WIKI or other Web 2.0 syntax into standard markup for browsers. In one embodiment the transformer can be an extension of a conventional transformer that supports HTML and XML. The extended transformer can be enhanced to handle JAVA SCRIPT such as AJAX. For example resource links of application can be converted into AJAX functions by the transformer having an AJAX plug in . The transformer can also include a VoiceXML plug in which generates VoiceXML markup for voice only clients.

As shown in system a user can create a WIKI using the editor . Once created the WIKI can be processed by the transformer which generates an XML version of the WIKI which is stored in data store . In one embodiment links to speech resources added to the WIKI can be transformed into suitable VoiceXML code that is included in the generated WIKI . In another example specific WIKI speech extensions can be entered by a user into WIKI which are converted into appropriate format in WIKI for server to implement the speech capabilities.

In entry HTML is used for content. Additionally an AJAX protocol which can be implemented as any JAVASCRIPT based protocol can provide a seamless interface to a speech server within the HTML as shown by code item . Entry can be usable for both GUI and VUI applications as can sample application of . Appreciably the content of entry can be written in any type of markup language including but not limited to XML and VoiceXML.

The present invention may be realized in hardware software or a combination of hardware and software. The present invention may be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software may be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention also may be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program in the present context means any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation b reproduction in a different material form.

This invention may be embodied in other forms without departing from the spirit or essential attributes thereof. Accordingly reference should be made to the following claims rather than to the foregoing specification as indicating the scope of the invention.

