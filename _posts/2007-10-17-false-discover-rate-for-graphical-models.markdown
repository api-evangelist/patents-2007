---

title: False discover rate for graphical models
abstract: The claimed subject matter provides systems and/or methods that determines a number of non-spurious arcs associated with a learned graphical model. The system can include devices and mechanisms that utilize learning algorithms and datasets to generate learned graphical models and graphical models associated with null permutations of the datasets, ascertaining the average number of arcs associated with the graphical models associated with null permutations of the datasets, enumerating the total number of arcs affiliated with the learned graphical model, and presenting a ratio of the average number of arcs to the total number of arcs, the ratio indicative of the number of non-spurious arcs associated the learned graphical model.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07885905&OS=07885905&RS=07885905
owner: Microsoft Corporation
number: 07885905
owner_city: Redmond
owner_country: US
publication_date: 20071017
---
In many application areas where graphical models are used and where their structure is learned from data the end goal is neither prediction nor density estimation. Rather it is the uncovering of discrete relationships between entities. For example in computational biology one can be interested in discovering which proteins within a large set of proteins interact with one another or which miRNA e.g. micro ribonucleic acid single stranded ribonucleic acid molecules that regulate gene expression molecules target which mRNA e.g. messenger ribonucleic acid a molecule of ribonucleic acid encoding a chemical blueprint for a protein product molecules. In these problems relationships can be represented by arcs in a graphical model. Consequently given a learned model it can be beneficial to determine how many of the arcs are real or non spurious.

Previous attempts to address the problem of uncovering discrete relationships between entities have involved computing confidence measures on arcs and other features of induced Bayesian networks by using a bootstrap or parametric bootstrap . By re modeling data and using a Bayesian network for each sampled data set such attempts have enumerated the number of times a given arc has occurred and estimated a probability of that arc circumflex over p as the proportion of times it is found across all bootstrap samples. Nevertheless such confidence measures typically do not estimate the number of non spurious arcs. For example applying a pathological search algorithm which systematically adds all arcs yields the estimate circumflex over p 1 for every arc.

Other attempts to provide solutions to the foregoing problem of identifying discrete relationships between entities have included using MCMC samples over variable orderings to compute marginal probabilities of arc hypotheses. Although such approaches have characterized the performance of the MCMC method they typically have not determined whether the exact or approximated posterior probabilities have been accurate of calibrated in the sense that hypothesis labeled for example 0.4 are true 40 of the time.

Other more recent attempts to reveal discrete relationships between entities have utilized stochastic greedy structure search algorithms running such algorithms numerous e.g. in excess of 1000 times to local optimums and scoring each arc according to the proportion of times the arc appeared across all local optima found. Although such an approach can provide asymptotic guarantees the approach nevertheless fails to yield accurate estimates on finite data.

In yet a further attempt to uncover discrete relationships between entities a frequentist test for edge inclusion in graphical Gaussian models GGMs has been developed the technique provides a reasonable model for null distributions of this test wherein a score is assigned to each edge based on how much it hurts the model when each edge is independently removed this is assessed in the presence of all other possible edges being included in the model one backward step search for each edge . These scores can then be employed to compute a false discovery rate for a given set of edges. However in application such an approach has been found to associate low scores to a vast quantity of real arc hypotheses resulting in inaccurate estimates of the false discovery rate.

The following presents a simplified summary in order to provide a basic understanding of some aspects of the disclosed subject matter. This summary is not an extensive overview and it is not intended to identify key critical elements or to delineate the scope thereof. Its sole purpose is to present some concepts in a simplified form as a prelude to the more detailed description that is presented later.

In many application domains such as computational biology the goal of graphical model structure learning is to uncover discrete relationships between entities. For example in one problem of interest concerning HIV e.g. Human Immunodeficiency Virus vaccine design researches can want to infer which HIV peptides e.g. polymers formed from the linking in a defined order of various amino acids interact with which immune system molecules e.g. Human Leukocyte Antigen HLA molecule groups of genes that reside on chromosome 6 and that encode cell surface antigen presenting proteins and many other genes . For problems of this nature there can be an interest in determining the number of non spurious arcs in a learned graphical model. One approach utilized by the claimed subject matter to uncover the number of non spurious arcs in a learned graphical model e.g. directed acyclic graphs undirected graphs chain graphs or factor graphs known as a frequentist approach employs a method based on the concept of the false discovery rate. On synthetic data sets generated from models similar to the ones learned it has been found that such a frequentist approach yields accurate estimates of the number of spurious arcs. Additionally the frequentist approach which is non parametric can out perform parametric approaches e.g. Bayesian approaches in situations where the models learned are less representative of the data.

The claimed subject matter in accordance with an illustrative aspect provides a system that determines a number of non spurious arcs associated with a learned graphical model. The system can include components and devices that utilize datasets and learning algorithms to generate learned graphical models and graphical models associated with null distribution datasets enumerate an average number of arcs confederated with each of the graphical models associated with the null distribution datasets determines a total number of arcs associated with the learned graphical model and distributes the average number of arcs associated with the null distribution datasets and the total number of arcs associated with the learned graphical model as a result that indicates the number of non spurious arcs associated with the learned graphical model.

To the accomplishment of the foregoing and related ends certain illustrative aspects of the disclosed and claimed subject matter are described herein in connection with the following description and the annexed drawings. These aspects are indicative however of but a few of the various ways in which the principles disclosed herein can be employed and is intended to include all such aspects and their equivalents. Other advantages and novel features will become apparent from the following detailed description when considered in conjunction with the drawings.

The subject matter as claimed is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding thereof. It may be evident however that the claimed subject matter can be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form in order to facilitate a description thereof.

For ease and clarity of exposition the claimed subject matter has been explicated in terms of the rational design of HIV e.g. Human Immunodeficiency Virus vaccines. Nevertheless as will be appreciated by those conversant in the art the subject matter as claimed is not so limited and can find applicability and utility in other contexts and fields of endeavor.

Typically there are two arms of the adaptive immune system the humoral arm that manufactures antibodies and the cellular arm that recognizes cells that are infected and kills them. The illustrative HIV vaccine design under consideration for purposes of elucidation of the claimed subject matter concentrates on the cellular arm. The cellular arm kills infected cells by recognizing short e.g. 8 11 amino acid long bits of proteins known as epitopes that are can be presented on the surface of most human cells. The epitopes typically are the result of digestion of proteins e.g. both normal and foreign with the cell and are presented on HLA e.g. Human Leukocyte Antigen molecules than can form a complex with the epitope before it is presented. Special cells of the immune system known as T cells e.g. a group of white blood cells known as lymphocytes that can play a central role in cell mediated immunity can recognize the epitope HLA complexes and kill the cell if the epitopes correspond to foreign or non self proteins.

There can be hundreds of types of HLA molecules across the human population each person has from three to six different types for example. Further epitopes presented by one HLA type are typically different from those presented by another type. This diversity is thought to be useful in preventing a single virus or other pathogen from destroying the human race. One possible design of a cellular vaccine can then be to identify a set of peptides that are epitopes for a large number of people and assemble them in a delivery mechanism that can train T cells to recognize and kill cells infected by HIV.

To identify peptide HLA pairs that are epitopes one can take a peptide and mix it with the blood which can include T cells of an individual and watch for the release of gamma interferon which can indicate that the T cell killing mechanism has been activated an ELIspot assay. If the reaction occurs it is likely that the peptide is an epitope for one of the HLA types of the patient. Although it is impossible to discern the HLA type or types that are responsible for a reaction from a single patient with data from many patients one can infer e.g. probabilistically which of the patients HLA types are causing the observed immune reactions.

To perform this inference the claimed subject matter can be employed to model data through utilization of bi partite graphs with noisy OR distributions. Noisy OR distributions are typically based on the assumption of independence of causal influence and can take the form 

Accordingly given a learned set of arcs representing peptide HLA interactions the claimed subject matter can determine how many of these arcs are real so that an assessment can be made as whether any of them merit further confirmatory testing. In general given a single model structure learned by any method the claimed subject matter can determine its expected number or non spurious arcs. This determination can allow researchers to generate specific testable hypotheses and gauge confidence in them before considering whether to pursue them further.

As employed herein without limitation disclaimer or prejudice the term arc hypothesis can connote the event that an arc is present in an underlying distribution of the data. Accordingly the claimed subject matter in accordance with an illustrative aspect overcomes the problem of estimating the number of true arc hypotheses in a given learned model.

Interface can provide various adapters connectors channels communication pathways etc. to integrate the various components included in system into virtually any operating system and or database system and or with one another. Additionally interface can provide various adapters connectors channels communication modalities and the like that can provide for interaction with various components that can comprise system and or any other component external and or internal data and the like associated with system .

Discovery component can estimate and control a false discovery rate FDR of a set of arc hypotheses e.g. known as a frequentist approach . The false discovery rate FDR can be defined as the expected proportion of all hypotheses e.g. arc hypotheses which can be labeled as true but which are actually false e.g. the number of false positives divided by the number of total hypotheses called true . This approach typically addresses only the number of true arc hypotheses within a given set and generally does not place a probability distribution jointly or marginally on the arc hypotheses in the set. On application of the approach by discovery component to synthetic datasets generated from models similar to ones learned indicates that the technique yields accurate estimates of the number of non spurious arcs. Furthermore indications are that the approach utilized herein is far more computationally efficient than other approaches e.g. Bayesian employed to date. Moreover as a matter of interest the frequentist approach employed by the claimed subject matter and in particular discovery component is a non parametric technique that can outperform other parametric approaches e.g. Bayesian in situations where the models learned are less representative of the data.

As stated supra discovery component estimates and controls a false discovery rate FDR of a set of arc hypotheses e.g. known as a frequentist approach . In order to effectuate such estimation and control discovery component can solicit obtain or retrieve input such as for example learning algorithms and datasets from multiple sources e.g. users associated databases disparate affiliated components etc. . Upon receipt of input discovery component can apply the received learning algorithms against the received datasets to produce a graphical model e.g. a graphical model derived from the received datasets that can be represented as a bi partite graph comprising nodes connected by arcs for example. An example of such a bi partite graph is provided in .

Once discovery component has constructed a graphical model through utilization of received datasets and in conjunction with obtained leaning algorithms discovery component can utilize the received datasets to generate null datasets which can be applied against the learning algorithm utilized in the construction of the original graphical model to provide other graphical models e.g. bi partite graph representative of each and every null dataset produced. Discovery component can then locate and aggregate arcs in the graphical models generated utilizing null datasets and thereafter ascertain an average number present with respect to graphical models produced through use of null datasets. Further discovery component can also perform a similar identification and aggregation facility with respect to arcs associated with the original model e.g. the model built using the original non null datasets. Discovery component can thereafter produce a false discovery rate FDR metric defined as the expected proportion of all hypotheses labeled as true but which are actually false e.g. the average number of arcs present with respect to graphical models produced through use of null dataset divided by the number of total arcs associated with the model built using the initially input non null dataset . This false discovery rate can then be applied to uncover relationships between entities and to discern a relative authoritativeness with which such uncovered relationships should be treated.

When inferring whether a single hypothesis e.g. arc is true of not statisticians have traditionally relied a p value which can control the number of false positives e.g. type I errors . However when testing hundreds or thousands of hypotheses e.g. hundreds or thousands of arcs simultaneously the p value can need to be corrected to help avoid making conclusions based on chance alone e.g. known as the problem of multiple hypothesis testing . A widely used though conservative correction is the Bonferroni correction that can control Family Wise Error Rates FWER . The FWER can be considered a compound measure of error generally defined as the probability of seeing at least one false positive among all hypotheses tested. In light of the conservative nature of methods which control the FWER the statistics community has recently placed great emphasis on estimating and controlling a different compound measure of error the false discovery rate FDR .

In a typical computation of false discovery rate FDR discovery component can be provided a set of hypotheses e.g. arcs in a constructed graphical model where each hypothesis e.g. an arc connecting nodes included in the constructed graphical model i can be assigned a score si traditionally a test statistic or the p value resulting from such a test statistic . These scores can often be assumed to be independent and identically distributed although there has nevertheless been much work to relax the assumption of independence. Discovery component can thus compute the false discovery rate FDR as a function of a threshold t on these scores FDR FDR t . For threshold t all hypotheses with S t can be said to be significant e.g. assuming without loss of generality that the higher a score the more a hypothesis is believed . The false discovery rate FDR at threshold t can then be provided by 

Applying this approach to estimating the number of non spurious arcs e.g. hypotheses in a given graphical model discovery component can receive or obtain as input a particular structure search algorithm e.g. which may have hyperparameters such as K that can control the number of arcs learned and can generalize S and F to be functions of algorithm . In particular S can be the number or arcs found by algorithm and F the number of arcs whose corresponding hypotheses can be classified as false. Accordingly discovery component can utilize the approximation E S N D where N D typifies the number of arcs found by applying to the real data D. In addition discovery component can estimate E F to be N D averaged over multiple data sets D q 1 . . . Q drawn from a null distribution. That is 

In one aspect of the claimed subject matter it can be assumed that algorithm has the property that it can be decomposed by discovery component into independent searches for the parents of each node. Given this assumption when discovery component learns the parent set of a given node it can create a null distribution for that node by permuting the real data for the corresponding variable. This permutation can guarantee that all arc hypotheses are generally false in the null distribution. The generation of these null distributions is typically computationally efficient as well as non parametric making them generally applicable to situations where the models learned are less representative of the data.

In a further aspect and in recognition that the frequentist estimation of false discovery rate FDR as utilized by discovery component can occasionally be overly conservative for larger values of the false discovery rate FDR e.g. smaller values of expected positive predictive value PPV discovery component can use a sequential approximation to E F where instead of simply permuting the data and applying a search algorithm discovery component can recursively estimate E F K . Specifically discovery component can start with a relatively low value of K Kso that only a few arcs are generated using the real data and then estimate E F K . Then to estimate E F K for larger values of K K K discovery component can initialize structure search using the Kstructure and continue structure search using null data generated from this same structure e.g. using a parametric bootstrap when necessary . Discovery component can then utilize the estimate E F K E F K n where nrepresents the number of arcs added to the Kstructure. This recursive procedure can then be continued increasing K on each iteration.

It is to be appreciated that store can be for example volatile memory or non volatile memory or can include both volatile and non volatile memory. By way of illustration and not limitation non volatile memory can include read only memory ROM programmable read only memory PROM electrically programmable read only memory EPROM electrically erasable programmable read only memory EEPROM or flash memory. Volatile memory can include random access memory RAM which can act as external cache memory. By way of illustration rather than limitation RAM is available in many forms such as static RAM SRAM dynamic RAM DRAM synchronous DRAM SDRAM double data rate SDRAM DDR SDRAM enhanced SDRAM ESDRAM Synchlink DRAM SLDRAM Rambus direct RAM RDRAM direct Rambus dynamic RAM DRDRAM and Rambus dynamic RAM RDRAM . Store of the subject systems and methods is intended to comprise without being limited to these and any other suitable types of memory. In addition it is to be appreciated that store can be a server a database a hard drive and the like.

The independent components may be used to further fill out or span an information space and the dependent components may be employed in combination to improve quality of common information recognizing that all sensor input data may be subject to error and or noise. In this context data fusion techniques employed by data fusion component may include algorithmic processing of sensor input data to compensate for inherent fragmentation of information because particular phenomena may not be observed directly using a single sensing input modality. Thus data fusion provides a suitable framework to facilitate condensing combining evaluating and or interpreting available sensed or received information in the context of a particular application.

In view of the foregoing it is readily apparent that utilization of the context component to consider and analyze extrinsic information can substantially facilitate determining meaning of sets of inputs.

Users can also interact with regions to select and provide information via various devices such as a mouse roller ball keypad keyboard and or voice activation for example. Typically the mechanism such as a push button or the enter key on the keyboard can be employed subsequent to entering the information in order to initiate for example a query. However it is to be appreciated that the claimed subject matter is not so limited. For example nearly highlighting a checkbox can initiate information conveyance. In another example a command line interface can be employed. For example the command line interface can prompt e.g. via text message on a display and an audio tone the user for information via a text message. The user can then provide suitable information such as alphanumeric input corresponding to an option provided in the interface prompt or an answer to a question posed in the prompt. It is to be appreciated that the command line interface can be employed in connection with a graphical user interface and or application programming interface API . In addition the command line interface can be employed in connection with hardware e.g. video cards and or displays e.g. black and white and EGA with limited graphic support and or low bandwidth communication channels.

In view of the exemplary systems shown and described supra methodologies that may be implemented in accordance with the disclosed subject matter will be better appreciated with reference to the flow chart of . While for purposes of simplicity of explanation the methodologies are shown and described as a series of blocks it is to be understood and appreciated that the claimed subject matter is not limited by the order of the blocks as some blocks may occur in different orders and or concurrently with other blocks from what is depicted and described herein. Moreover not all illustrated blocks may be required to implement the methodologies described hereinafter. Additionally it should be further appreciated that the methodologies disclosed hereinafter and throughout this specification are capable of being stored on an article of manufacture to facilitate transporting and transferring such methodologies to computers.

The claimed subject matter can be described in the general context of computer executable instructions such as program modules executed by one or more components. Generally program modules can include routines programs objects data structures etc. that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined and or distributed as desired in various aspects.

The claimed subject matter can be implemented via object oriented programming techniques. For example each component of the system can be an object in a software routine or a component within an object. Object oriented programming shifts the emphasis of software development away from function decomposition and towards the recognition of units of software called objects which encapsulate both data and functions. Object Oriented Programming OOP objects are software entities comprising data structures and operations on data. Together these elements enable objects to model virtually any real world entity in terms of its characteristics represented by its data elements and its behavior represented by its data manipulation functions. In this way objects can model concrete things like people and computers and they can model abstract concepts like numbers or geometrical concepts.

The benefit of object technology arises out of three basic principles encapsulation polymorphism and inheritance. Objects hide or encapsulate the internal structure of their data and the algorithms by which their functions work. Instead of exposing these implementation details objects present interfaces that represent their abstractions cleanly with no extraneous information. Polymorphism takes encapsulation one step further the idea being many shapes one interface. A software component can make a request of another component without knowing exactly what that component is. The component that receives the request interprets it and figures out according to its variables and data how to execute the request. The third principle is inheritance which allows developers to reuse pre existing design and code. This capability allows developers to avoid creating software from scratch. Rather through inheritance developers derive subclasses that inherit behaviors that the developer then customizes to meet particular needs.

In particular an object includes and is characterized by a set of data e.g. attributes and a set of operations e.g. methods that can operate on the data. Generally an object s data is ideally changed only through the operation of the object s methods. Methods in an object are invoked by passing a message to the object e.g. message passing . The message specifies a method name and an argument list. When the object receives the message code associated with the named method is executed with the formal parameters of the method bound to the corresponding values in the argument list. Methods and message passing in OOP are analogous to procedures and procedure calls in procedure oriented software environments.

However while procedures operate to modify and return passed parameters methods operate to modify the internal state of the associated objects by modifying the data contained therein . The combination of data and methods in objects is called encapsulation. Encapsulation provides for the state of an object to only be changed by well defined methods associated with the object. When the behavior of an object is confined to such well defined locations and interfaces changes e.g. code modifications in the object will have minimal impact on the other objects and elements in the system.

Each object is an instance of some class. A class includes a set of data attributes plus a set of allowable operations e.g. methods on the data attributes. As mentioned above OOP supports inheritance a class called a subclass may be derived from another class called a base class parent class etc. where the subclass inherits the data attributes and methods of the base class. The subclass may specialize the base class by adding code which overrides the data and or methods of the base class or which adds new data attributes and methods. Thus inheritance represents a mechanism by which abstractions are made increasingly concrete as subclasses are created for greater levels of specialization.

As used in this application the terms component and system are intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component can be but is not limited to being a process running on a processor a processor a hard disk drive multiple storage drives of optical and or magnetic storage medium an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a server and the server can be a component. One or more components can reside within a process and or thread of execution and a component can be localized on one computer and or distributed between two or more computers.

Artificial intelligence based systems e.g. explicitly and or implicitly trained classifiers can be employed in connection with performing inference and or probabilistic determinations and or statistical based determinations as in accordance with one or more aspects of the claimed subject matter as described hereinafter. As used herein the term inference infer or variations in form thereof refers generally to the process of reasoning about or inferring states of the system environment and or user from a set of observations as captured via events and or data. Inference can be employed to identify a specific context or action or can generate a probability distribution over states for example. The inference can be probabilistic that is the computation of a probability distribution over states of interest based on a consideration of data and events. Inference can also refer to techniques employed for composing higher level events from a set of events and or data. Such inference results in the construction of new events or actions from a set of observed events and or stored event data whether or not the events are correlated in close temporal proximity and whether the events and data come from one or several event and data sources. Various classification schemes and or systems e.g. support vector machines neural networks expert systems Bayesian belief networks fuzzy logic data fusion engines . . . can be employed in connection with performing automatic and or inferred action in connection with the claimed subject matter.

Furthermore all or portions of the claimed subject matter may be implemented as a system method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device or media. For example computer readable media can include but are not limited to magnetic storage devices e.g. hard disk floppy disk magnetic strips . . . optical disks e.g. compact disk CD digital versatile disk DVD . . . smart cards and flash memory devices e.g. card stick key drive . . . . Additionally it should be appreciated that a carrier wave can be employed to carry computer readable electronic data such as those used in transmitting and receiving electronic mail or in accessing a network such as the Internet or a local area network LAN . Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Some portions of the detailed description have been presented in terms of algorithms and or symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and or representations are the means employed by those cognizant in the art to most effectively convey the substance of their work to others equally skilled. An algorithm is here generally conceived to be a self consistent sequence of acts leading to a desired result. The acts are those requiring physical manipulations of physical quantities. Typically though not necessarily these quantities take the form of electrical and or magnetic signals capable of being stored transferred combined compared and or otherwise manipulated.

It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like. It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the foregoing discussion it is appreciated that throughout the disclosed subject matter discussions utilizing terms such as processing computing calculating determining and or displaying and the like refer to the action and processes of computer systems and or similar consumer and or industrial electronic devices and or machines that manipulate and or transform data represented as physical electrical and or electronic quantities within the computer s and or machine s registers and memories into other data similarly represented as physical quantities within the machine and or computer system memories or registers or other such information storage transmission and or display devices.

Referring now to there is illustrated a block diagram of a computer operable to execute the disclosed system. In order to provide additional context for various aspects thereof and the following discussion are intended to provide a brief general description of a suitable computing environment in which the various aspects of the claimed subject matter can be implemented. While the description above is in the general context of computer executable instructions that may run on one or more computers those skilled in the art will recognize that the subject matter as claimed also can be implemented in combination with other program modules and or as a combination of hardware and software.

Generally program modules include routines programs components data structures etc. that perform particular tasks or implement particular abstract data types. Moreover those skilled in the art will appreciate that the inventive methods can be practiced with other computer system configurations including single processor or multiprocessor computer systems minicomputers mainframe computers as well as personal computers hand held computing devices microprocessor based or programmable consumer electronics and the like each of which can be operatively coupled to one or more associated devices.

The illustrated aspects of the claimed subject matter may also be practiced in distributed computing environments where certain tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules can be located in both local and remote memory storage devices.

A computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by the computer and includes both volatile and non volatile media removable and non removable media. By way of example and not limitation computer readable media can comprise computer storage media and communication media. Computer storage media includes both volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital video disk DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the computer.

With reference again to the exemplary environment for implementing various aspects includes a computer the computer including a processing unit a system memory and a system bus . The system bus couples system components including but not limited to the system memory to the processing unit . The processing unit can be any of various commercially available processors. Dual microprocessors and other multi processor architectures may also be employed as the processing unit .

The system bus can be any of several types of bus structure that may further interconnect to a memory bus with or without a memory controller a peripheral bus and a local bus using any of a variety of commercially available bus architectures. The system memory includes read only memory ROM and random access memory RAM . A basic input output system BIOS is stored in a non volatile memory such as ROM EPROM EEPROM which BIOS contains the basic routines that help to transfer information between elements within the computer such as during start up. The RAM can also include a high speed RAM such as static RAM for caching data.

The computer further includes an internal hard disk drive HDD e.g. EIDE SATA which internal hard disk drive may also be configured for external use in a suitable chassis not shown a magnetic floppy disk drive FDD e.g. to read from or write to a removable diskette and an optical disk drive e.g. reading a CD ROM disk or to read from or write to other high capacity optical media such as the DVD . The hard disk drive magnetic disk drive and optical disk drive can be connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical drive interface respectively. The interface for external drive implementations includes at least one or both of Universal Serial Bus USB and IEEE 1294 interface technologies. Other external drive connection technologies are within contemplation of the claimed subject matter.

The drives and their associated computer readable media provide nonvolatile storage of data data structures computer executable instructions and so forth. For the computer the drives and media accommodate the storage of any data in a suitable digital format. Although the description of computer readable media above refers to a HDD a removable magnetic diskette and a removable optical media such as a CD or DVD it should be appreciated by those skilled in the art that other types of media which are readable by a computer such as zip drives magnetic cassettes flash memory cards cartridges and the like may also be used in the exemplary operating environment and further that any such media may contain computer executable instructions for performing the methods of the disclosed and claimed subject matter.

A number of program modules can be stored in the drives and RAM including an operating system one or more application programs other program modules and program data . All or portions of the operating system applications modules and or data can also be cached in the RAM . It is to be appreciated that the claimed subject matter can be implemented with various commercially available operating systems or combinations of operating systems.

A user can enter commands and information into the computer through one or more wired wireless input devices e.g. a keyboard and a pointing device such as a mouse . Other input devices not shown may include a microphone an IR remote control a joystick a game pad a stylus pen touch screen or the like. These and other input devices are often connected to the processing unit through an input device interface that is coupled to the system bus but can be connected by other interfaces such as a parallel port an IEEE 1294 serial port a game port a USB port an IR interface etc.

A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor a computer typically includes other peripheral output devices not shown such as speakers printers etc.

The computer may operate in a networked environment using logical connections via wired and or wireless communications to one or more remote computers such as a remote computer s . The remote computer s can be a workstation a server computer a router a personal computer portable computer microprocessor based entertainment appliance a peer device or other common network node and typically includes many or all of the elements described relative to the computer although for purposes of brevity only a memory storage device is illustrated. The logical connections depicted include wired wireless connectivity to a local area network LAN and or larger networks e.g. a wide area network WAN . Such LAN and WAN networking environments are commonplace in offices and companies and facilitate enterprise wide computer networks such as intranets all of which may connect to a global communications network e.g. the Internet.

When used in a LAN networking environment the computer is connected to the local network through a wired and or wireless communication network interface or adapter . The adaptor may facilitate wired or wireless communication to the LAN which may also include a wireless access point disposed thereon for communicating with the wireless adaptor .

When used in a WAN networking environment the computer can include a modem or is connected to a communications server on the WAN or has other means for establishing communications over the WAN such as by way of the Internet. The modem which can be internal or external and a wired or wireless device is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the computer or portions thereof can be stored in the remote memory storage device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers can be used.

The computer is operable to communicate with any wireless devices or entities operatively disposed in wireless communication e.g. a printer scanner desktop and or portable computer portable data assistant communications satellite any piece of equipment or location associated with a wirelessly detectable tag e.g. a kiosk news stand restroom and telephone. This includes at least Wi Fi and Bluetooth wireless technologies. Thus the communication can be a predefined structure as with a conventional network or simply an ad hoc communication between at least two devices.

Wi Fi or Wireless Fidelity allows connection to the Internet from a couch at home a bed in a hotel room or a conference room at work without wires. Wi Fi is a wireless technology similar to that used in a cell phone that enables such devices e.g. computers to send and receive data indoors and out anywhere within the range of a base station. Wi Fi networks use radio technologies called IEEE 802.11x a b g etc. to provide secure reliable fast wireless connectivity. A Wi Fi network can be used to connect computers to each other to the Internet and to wired networks which use IEEE 802.3 or Ethernet .

Wi Fi networks can operate in the unlicensed 2.4 and 5 GHz radio bands. IEEE 802.11 applies to generally to wireless LANs and provides 1 or 2 Mbps transmission in the 2.4 GHz band using either frequency hopping spread spectrum FHSS or direct sequence spread spectrum DSSS . IEEE 802.11a is an extension to IEEE 802.11 that applies to wireless LANs and provides up to 54 Mbps in the 5 GHz band. IEEE 802.11a uses an orthogonal frequency division multiplexing OFDM encoding scheme rather than FHSS or DSSS. IEEE 802.11b also referred to as 802.11 High Rate DSSS or Wi Fi is an extension to 802.11 that applies to wireless LANs and provides 11 Mbps transmission with a fallback to 5.5 2 and 1 Mbps in the 2.4 GHz band. IEEE 802.11 g applies to wireless LANs and provides 20 Mbps in the 2.4 GHz band. Products can contain more than one band e.g. dual band so the networks can provide real world performance similar to the basic 10BaseT wired Ethernet networks used in many offices.

Referring now to there is illustrated a schematic block diagram of an exemplary computing environment for processing the disclosed architecture in accordance with another aspect. The system includes one or more client s . The client s can be hardware and or software e.g. threads processes computing devices . The client s can house cookie s and or associated contextual information by employing the claimed subject matter for example.

The system also includes one or more server s . The server s can also be hardware and or software e.g. threads processes computing devices . The servers can house threads to perform transformations by employing the claimed subject matter for example. One possible communication between a client and a server can be in the form of a data packet adapted to be transmitted between two or more computer processes. The data packet may include a cookie and or associated contextual information for example. The system includes a communication framework e.g. a global communication network such as the Internet that can be employed to facilitate communications between the client s and the server s .

Communications can be facilitated via a wired including optical fiber and or wireless technology. The client s are operatively connected to one or more client data store s that can be employed to store information local to the client s e.g. cookie s and or associated contextual information . Similarly the server s are operatively connected to one or more server data store s that can be employed to store information local to the servers .

What has been described above includes examples of the disclosed and claimed subject matter. It is of course not possible to describe every conceivable combination of components and or methodologies but one of ordinary skill in the art may recognize that many further combinations and permutations are possible. Accordingly the claimed subject matter is intended to embrace all such alterations modifications and variations that fall within the spirit and scope of the appended claims. Furthermore to the extent that the term includes is used in either the detailed description or the claims such term is intended to be inclusive in a manner similar to the term comprising as comprising is interpreted when employed as a transitional word in a claim.

