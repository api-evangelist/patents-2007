---

title: Credential caching for clustered storage systems
abstract: A technique efficiently transmits credentials between network elements and disk elements in a clustered storage system. According to the novel technique, in response to a user request to access data served by a data element, a network element inserts (adds) a credential associated with the user to a network element credential cache and creates a corresponding credential handle that indexes the credential in that cache. The network element relays the credential and credential handle to the disk element, which adds the credential to a corresponding disk element credential cache at a location indexed by the corresponding credential handle. Requests may then be sent between the elements using the credential handle. In addition, the network element may further send a series of chained requests to the disk element for the same credential/credential handle with an indication that the requests are for the same credential without sending the credential or credential handle.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08099766&OS=08099766&RS=08099766
owner: NetApp, Inc.
number: 08099766
owner_city: Sunnyvale
owner_country: US
publication_date: 20070326
---
The present invention is directed to storage system and in particular to credentials in a clustered storage system.

A storage system typically comprises one or more storage devices into which information may be entered and from which information may be obtained as desired. The storage system includes a storage operating system that functionally organizes the system by inter alia invoking storage operations in support of a storage service implemented by the system. The storage system may be implemented in accordance with a variety of storage architectures including but not limited to a network attached storage environment a storage area network and a disk assembly directly attached to a client or host computer. The storage devices are typically disk drives organized as a disk array wherein the term disk commonly describes a self contained rotating magnetic media storage device. The term disk in this context is synonymous with hard disk drive HDD or direct access storage device DASD .

The storage operating system of the storage system may implement a high level module such as a file system to logically organize the information stored on volumes as a hierarchical structure of data containers such as files and logical units. For example each on disk file may be implemented as set of data structures i.e. disk blocks configured to store information such as the actual data for the file. These data blocks are organized within a volume block number vbn space that is maintained by the file system. The file system may also assign each data block in the file a corresponding file offset or file block number fbn . The file system typically assigns sequences of fbns on a per file basis whereas vbns are assigned over a larger volume address space. The file system organizes the data blocks within the vbn space as a logical volume each logical volume may be although is not necessarily associated with its own file system.

A known type of file system is a write anywhere file system that does not overwrite data on disks. If a data block is retrieved read from disk into a memory of the storage system and dirtied i.e. updated or modified with new data the data block is thereafter stored written to a new location on disk to optimize write performance. A write anywhere file system may initially assume an optimal layout such that the data is substantially contiguously arranged on disks. The optimal disk layout results in efficient access operations particularly for sequential read operations directed to the disks. An example of a write anywhere file system that is configured to operate on a storage system is the Write Anywhere File Layout WAFL file system available from Network Appliance Inc. Sunnyvale Calif.

The storage system may be further configured to operate according to a client server model of information delivery to thereby allow many clients to access data containers such as files and logical units stored on the system. In this model the client may comprise an application such as a database application executing on a computer that connects to the storage system over a computer network such as a point to point link shared local area network LAN wide area network WAN or virtual private network VPN implemented over a public network such as the Internet. Each client may request the services of the storage system by issuing file based and block based protocol messages in the form of packets to the system over the network.

A plurality of storage systems may be interconnected to provide a storage system cluster configured to service many clients. Each storage system or node may be configured to service one or more volumes wherein each volume stores one or more data containers. Communication among the nodes involves the exchange of information between two or more entities interconnected by communication links. These entities are typically software programs executing on the nodes. The nodes communicate by exchanging discrete packets or messages of information according to predefined protocols. In this context a protocol consists of a set of rules defining how the nodes interact with each other.

Each node generally provides its services through the execution of software modules such as processes. A process is a software program that is defined by a memory address space. For example an operating system of the node may be implemented as a single process with a large memory address space wherein pieces of code within the process provide operating system services such as process management. Yet the node s services may also be implemented as separately scheduled processes in distinct protected address spaces. These separate processes each with its own process address space execute on the node to manage resources internal to the node and in the case of a database or network protocol to interact with a variety of network elements.

Services that are part of the same process address space communicate by accessing the same memory space. That is information exchanged between services implemented in the same process address space is not transferred but rather may be accessed in a common memory. However communication among services that are implemented as separate processes is typically effected by the exchange of messages. For example information exchanged between different address spaces of processes is transferred as one or messages between different memory spaces of the processes. A known message passing mechanism provided by an operating system to transfer information between process address spaces is the Inter Process Communication IPC mechanism.

Resources internal to the node may include communication resources that enable a process on one node to communicate over the communication links or network with another process on a different node. The communication resources include the allocation of memory and data structures such as messages as well as a network protocol stack. The network protocol stack in turn comprises layers of software such as a session layer a transport layer and a network layer. The Internet protocol IP is a network layer protocol that provides network addressing between nodes whereas the transport layer provides a port service that identifies each process executing on the nodes and creates a connection between those processes that indicate a willingness to communicate. Examples of trans port layer protocols include the Transmission Control Protocol TCP and other reliable connection protocols.

Broadly stated the connection provided by the transport layer such as that provided by TCP is a reliable securable logical circuit between pairs of processes. A TCP process executing on each node establishes the TCP connection in accordance with a conventional 3 way handshake arrangement involving the exchange of TCP message or segment data structures. The resulting TCP connection is identified by port numbers and IP addresses of the nodes. The TCP transport service provides reliable delivery of a message using a TCP transport header. The TCP protocol and establishment of a TCP connection are described in Computer Networks 3rd Edition particularly at pgs. 521 542 which is hereby incorporated by reference as though fully set forth herein.

The session layer manages the establishment or binding of an association between two communicating processes in the nodes. In this context the association is a session comprising a series of interactions between the two communicating processes for a period of time e.g. during the span of a connection. Upon establishment of the one or more connections the processes take turn exchanging information such as commands and is data over the session typically through the use of request and response messages in accordance with a network protocol.

The storage system may be configured to operate with a plurality of file level protocols such as the Common Internet File System CIFS and the Network File System NFS protocols to thereby enhance the utility of the system for networking clients. As such the storage system is typically configured with a CIFS server and or an NFS server. The NFS protocol is typically utilized by Unix based clients to access data sets served by the NFS server whereas the CIFS protocol is typically associated with Microsoft Windows based clients serviced by the CIFS server. NFS and CIFS utilize one or more authentication techniques for identifying access limitations to a particular data set such as a file.

Specifically the NFS protocol utilizes a conventional network information services NIS set of attributes. As such the terms NFS attributes and NIS attributes shall be used interchangeably herein however it is understood that NIS encompasses more than just NFS. NFS utilizes a user identifier UID and a primary group identifier GID for authentication. To that end the UID and GIDs are sent from the client to the NFS server in a conventional NFS credential with every NFS operation containing a data access request. The NFS server compares the received UID and or GID with permissions associated with a particular file. The NFS server does not perform any additional authentication but simply accepts the UID GID that is asserted by the client when sending the data access request. In an exemplary NFS environment the permissions associated with a file are stored as mode bits which are divided into three fields namely the permissions associated with the owner with the group and with others. Each of the three fields contains three bits one for read access one for write access and one for execute permission. NFS mode bits for permissions are further described in 1094 by Bill Nowicki March 1989 the contents of which are hereby incorporated by reference.

Additionally one technique for improving the authentication of NFS requests is the use of NFS Kerberos. In a conventional NFS Kerberos implementation the client is transmits a conventional Kerberos ticket to the NFS server of the storage system to assert its name and the storage system constructs an appropriate file system credential from the asserted Kerberos ticket. Notably all clients communicating with the NFS server in this manner must support NFS Kerberos as a Kerberos ticket is inserted into each NFS request sent to the server. 

The CIFS protocol does not trust the client to transmit the correct credentials with a data access request. In a CIFS environment user identifiers are not UIDs as utilized by NFS but comprise security identifiers SIDs which are unique on a worldwide basis. One or more identification authorities authenticate a given SID as described further below. When a CIFS command arrives at the CIFS server the credential is compared with an access control list ACL . An ACL consists of zero or more access control entries ACE . Each ACE consists of a SID which identifies the person or group to which the ACE applies and a set of permissions which can identify access allowance or denial. Thus an ACE may identify a particular SID and denote that access is not to be granted to the person s identified by that SID.

Credentials generally are well understood by those skilled in the art. Broadly stated a credential is information that identifies an authenticated user or machine requesters . For instance an authenticating device may receive a request from a user e.g. a client device to access particular data in storage. The authenticating device authenticates the requester s identity and associates a corresponding credential with the requester. Notably the credential may be stored locally to the authenticating device or in one or more external credential databases e.g. Lightweight Director Access Protocol or LDAP servers etc. . Once the requester is authenticated the request may be passed to a data access device e.g. responsible for communicating with the data in storage along with the corresponding credential which is the authenticated requester identity used to process the request. A passed credential typically contains the identity of a single authenticated user for a single domain and domain type as will be understood by those skilled in the art. 

As noted there are different styles of credentials based on the particular operating environment s used. For instance CIFS and NFS protocols e.g. Windows and Unix respectively may each utilize a particular style of credential unique to their respective environments. Generally credentials are variable in length depending upon the relevant information stored therein. Sometimes credentials may be large and complicated e.g. especially very large CIFS credentials and as such a large amount of bandwidth may be required to inefficiently transmit the credentials between the authenticating device and the data access device. In addition it may be particularly burdensome on processing resources e.g. CPU memory etc. at both devices to marshal transfer and unmarshal the sometimes large and complicated credentials. That is to exchange the credentials between the devices the credentials may need to be generated collected and manipulated to comply with a transmission exchange protocol e.g. packets at a first device and then received and re manipulated e.g. back to an original credential form by a second device as will be appreciated by those skilled in the art.

The present invention overcomes the disadvantages of the prior art by providing a technique for efficiently transmitting credentials among nodes of a clustered storage system. In particular one or more embodiments of the present invention provide a system and method that store comparatively larger e.g. full credentials at caches of particular nodes of the storage system and create credential handles that index the larger credentials. The nodes of the storage system may then transmit the smaller credential handles as opposed to the larger credentials thus reducing traffic sent between nodes and processing performed at the nodes.

Illustratively each node is generally organized as a network element and or a disk element wherein the network element generally interfaces with a network and may be used to authenticate and direct user requests to one or more disk elements each of which generally interfaces with storage and communicates with e.g. access data in storage e.g. on one or more disks . Each element includes a cluster fabric interface module adapted to implement a network protocol which integrates a session infrastructure and an application operation set into a session layer. The session layer manages the creation and termination of sessions between a pair of elements in the cluster. Each session provides a context for the flow of request messages and the flow of corresponding response messages to those requests through the network.

In response to a user request to access data served by a data element the network element inserts adds a credential associated with the user e.g. an authenticated requester credential to a network element credential cache and creates a corresponding credential handle that indexes the credential in that cache. The network element then relays the credential and credential handle to the disk element which adds the credential to a corresponding disk element credential cache at a location indexed by the corresponding credential handle. Requests may then be sent between the network element and the disk element using the credential handle. In addition and in accordance with one or more embodiments described herein the network element may further send a series of chained requests to the disk element for the same credential credential handle with an indication that the requests are for the same credential without sending the credential or credential handle to the disk element.

Advantageously the novel technique efficiently transmits credentials between network elements and disk elements in a clustered storage system. By establishing credential caches on the network elements and disk elements traffic sent within the clustered storage system between the elements particularly credential information may be substantially reduced. Also processing of the credential information may be reduced in the network elements and disk elements e.g. particularly where large credentials are used.

One or more embodiments of the present invention provide a technique for efficiently transmitting credentials among nodes of a clustered storage system. In particular a system and method is provided that store comparatively larger e.g. full credentials at is caches of particular nodes of the storage system and create credential handles that index the larger credentials. The nodes of the storage system may then transmit the smaller credential handles as opposed to the larger credentials thus reducing traffic sent between nodes and processing performed at the nodes.

The clients may be general purpose computers configured to interact with the node in accordance with a client server model of information delivery. That is each client may request the services of the node and the node may return the results of the services requested by the client by exchanging packets over the network . The client may issue packets including file based access protocols such as the Common Internet File System CIFS protocol or Network File System NFS protocol over the Transmission Control Protocol Internet Protocol TCP IP when accessing information in the form of files and directories. Alternatively the client may issue packets including block based access protocols such as the Small Computer Systems Interface SCSI protocol encapsulated over TCP iSCSI and SCSI encapsulated over Fibre Channel FCP when accessing information in the form of blocks.

Each node is illustratively embodied as a dual processor storage system executing a storage operating system that preferably implements a high level module such as a file system to logically organize the information as a hierarchical structure of named directories files and special types of files called virtual disks hereinafter generally blocks on the disks. However it will be apparent to those of ordinary skill in the art that the node may alternatively comprise a single or more than two processor system. Illustratively one processor executes the functions of the N module on the node while the other processor executes the functions of the D module .

The memory illustratively comprises storage locations that are addressable by the processors and adapters for storing software program code and data structures associated with the present invention e.g. network element credential cache and disk element credential cache described herein . The processor and adapters may in turn comprise processing elements and or logic circuitry configured to execute the software code and manipulate the data structures. The storage operating system portions of which is typically resident in memory and executed by the processing elements functionally organizes the node by inter alia invoking storage operations in support of the storage service implemented by the node. It will be apparent to those skilled in the art that other processing and memory means including various computer readable media may be used for storing and executing program instructions pertaining to the invention described herein.

The network adapter comprises a plurality of ports adapted to couple the node to one or more users clients over point to point links wide area networks virtual private networks implemented over a public network Internet or a shared local area network. The network adapter thus may comprise the mechanical electrical and signaling circuitry needed to connect the node to the network. Illustratively the computer network may be embodied as an Ethernet network or a Fibre Channel FC network. Each client may communicate with the node over network by exchanging discrete frames or packets of data according to pre defined protocols such as TCP IP.

The storage adapter cooperates with the storage operating system executing on the node to access information requested by the clients. The information may be stored on any type of attached array of writable storage device media such as video tape optical DVD magnetic tape bubble memory electronic random access memory micro electro mechanical and any other similar media adapted to store information including data and parity information. However as illustratively described herein the information is preferably stored on the disks of array . The storage adapter comprises a plurality of ports having input output I O interface circuitry that couples to the disks over an I O interconnect arrangement such as a conventional high performance FC link topology.

Storage of information on each array is preferably implemented as one or more storage volumes that comprise a collection of physical storage disks cooperating to define an overall logical arrangement of volume block number vbn space on the volume s . Each logical volume is generally although not necessarily associated with its own file system. The disks within a logical volume file system are typically organized as one or more groups wherein each group may be operated as a Redundant Array of Independent or Inexpensive Disks RAID . Most RAID implementations such as a RAID 4 level implementation enhance the reliability integrity of data storage through the redundant writing of data stripes across a given number of physical disks in the RAID group and the appropriate storing of parity information with respect to the striped data. An illustrative example of a RAID implementation is a RAID 4 level implementation although it should be understood that other types and levels of RAID implementations may be used in accordance with the inventive principles described herein.

To facilitate access to the disks the storage operating system implements a write anywhere file system that cooperates with one or more virtualization modules to virtualize the storage space provided by disks . The file system logically organizes the information as a hierarchical structure of named data containers such as directories and files on the disks. Each on disk file may be implemented as set of disk blocks configured to store information such as data whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization module s allow the file system to further logically organize information as a hierarchical structure of data containers such as blocks on the disks that are exported as named logical unit numbers luns .

In the illustrative embodiment the storage operating system is preferably the NetApp Data ONTAP operating system available from Network Appliance Inc. Sunnyvale Calif. that implements a Write Anywhere File Layout WAFL file system. However it is expressly contemplated that any appropriate storage operating system may be enhanced for use in accordance with the inventive principles described herein. As such where the term WAFL is employed it should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.

In addition the storage operating system includes a series of software layers organized to form a storage server that provides data paths for accessing information stored on the disks of the node . To that end the storage server includes a file system module in cooperating relation with a credential management and caching function described below a RAID system module and a disk driver system module . The RAID system manages the storage and retrieval of information to and from the volumes disks in accordance with I O operations while the disk driver system implements a disk access protocol such as e.g. the SCSI protocol.

The file system implements a virtualization system of the storage operating system through the interaction with one or more virtualization modules illustratively embodied as e.g. a virtual disk vdisk module not shown and a SCSI target module . The vdisk module enables access by administrative interfaces such as a user interface of a management framework in response to a user system administrator issuing commands to the node . The SCSI target module is generally disposed between the FC and iSCSI drivers and the file system to provide a translation layer of the virtualization system between the block lun space and the file system space where luns are represented as files.

The file system is illustratively a message based system that provides logical volume management capabilities for use in access to the information stored on the storage devices such as disks. That is in addition to providing file system semantics the file system provides functions normally associated with a volume manager. These functions include i aggregation of the disks ii aggregation of storage bandwidth of the disks and iii reliability guarantees such as mirroring and or parity RAID . The file system illustratively implements the WAFL file system hereinafter generally the write anywhere file system having an on disk format representation that is block based using e.g. 4 kilobyte kB blocks and using index nodes inodes to identify files and file attributes such as creation time access permissions size and block location . The file system uses files to store meta data describing the layout of its file system these meta data files include among others an inode file. A file handle i.e. an identifier that includes an inode number is used to retrieve an inode from disk.

Broadly stated all inodes of the write anywhere file system are organized into the is inode file. A file system fs info block specifies the layout of information in the file system and includes an inode of a file that includes all other inodes of the file system. Each logical volume file system has an fsinfo block that is preferably stored at a fixed location within e.g. a RAID group. The inode of the inode file may directly reference point to data blocks of the inode file or may reference indirect blocks of the inode file that in turn reference data blocks of the inode file. Within each data block of the inode file are embedded inodes each of which may reference indirect blocks that in turn reference data blocks of a file.

Operationally a request from the client is forwarded as a packet over the computer network and onto the node where it is received at the network adapter . A network driver of layer or layer processes the packet and if appropriate passes it on to a network protocol and file access layer for additional processing prior to forwarding to the write anywhere file system . This additional processing may illustratively include inter alia user authentication and associated credential management e.g. by credential management and caching function credentials such as described herein in accordance with the present invention. Upon receiving the request packet the file system performs credential management e.g. credential management and caching function credentials in accordance with the present invention described herein and also generates operations to load retrieve the requested data from disk if it is not resident in core i.e. in memory . If the information is not in memory the file system indexes into the inode file using the inode number to access an appropriate entry and retrieve a logical vbn. The file system then passes a message structure including the logical vbn to the RAID system the logical vbn is mapped to a disk identifier and disk block number disk dbn and sent to an appropriate driver e.g. SCSI of the disk driver system . The disk driver accesses the dbn from the specified disk and loads the requested data block s in memory for processing by the node. Upon completion of the request the node and operating system returns a reply to the client over the network . Note that further description of the storage operating system particularly an illustrative message exchange protocol between the multi protocol engine and the storage server is detailed below under the heading D. CF PROTOCOL . 

It should be noted that the software path through the storage operating system layers described above needed to perform data storage access for the client request received at the node may alternatively be implemented in hardware. That is in an alternate embodiment of the invention a storage access request data path may be implemented as logic circuitry embodied within a field programmable gate array FPGA or an application specific integrated circuit ASIC . This type of hardware implementation increases the performance of the storage service provided by node in response to a request issued by client . Moreover in another alternate embodiment of the invention the processing elements of adapters may be configured to offload some or all of the packet processing and storage access operations respectively from processor to thereby increase the performance of the storage service provided by the node. It is expressly contemplated that the various processes architectures and procedures described herein can be implemented in hardware firmware or software.

As used herein the term storage operating system generally refers to the computer executable code operable on a computer to perform a storage function that manages data access and may in the case of a node implement data access semantics of a general purpose operating system. The storage operating system can also be implemented as a microkernel an application program operating over a general purpose operating system such as UNIX or Windows NT or as a general purpose operating system with configurable functionality which is configured for storage applications as described herein.

In addition it will be understood to those skilled in the art that the invention described herein may apply to any type of special purpose e.g. file server filer or storage serving appliance or general purpose computer including a standalone computer or portion thereof embodied as or including a storage system. Moreover the teachings of this invention can be adapted to a variety of storage system architectures including but not limited to a network attached storage environment a storage area network and a disk assembly directly attached to a client or host computer. The term storage system should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems. It should be noted that while this description is written in terms of a write any where file system the teachings of the present invention may be utilized with any suitable file system including a write in place file system.

In the illustrative embodiment the storage server is embodied as D module of the storage operating system to service one or more volumes of array . In addition the multi protocol engine is embodied as N module to i perform protocol termination with respect to a client issuing incoming data access request packets over the network as well as ii redirect those data access requests to any storage server of the cluster . Moreover the N module and D module cooperate to provide a highly scalable distributed storage system architecture of the cluster . To that end each module includes a cluster fabric CF interface module adapted to implement intra cluster communication among the modules including D module to D module communication for e.g. data container striping operations.

The protocol layers e.g. the NFS CIFS layers and the iSCSI FC layers of the N module function as protocol servers that translate file based and block based data access requests from clients into CF protocol messages used for communication with the D module . That is the N module servers convert the incoming data access requests into file system primitive operations commands that are embedded within CF messages by the CF interface module for transmission to the D modules of the cluster . In particular in accordance with the present invention described herein the N modules manage credentials of the requests and credentials within the CF messages sent to the D modules. For instance as mentioned above and as will be understood by those skilled in the art a credential is information that identifies an authenticated user or machine. Accordingly the CF protocol messages may be used to communicate these credentials and or credential handles described herein between the N modules and D modules i.e. to identify an authenticated user or machine. Notably the CF interface modules cooperate to provide a single file system image across all D modules in the cluster . Thus any network port of an N module that receives a client request can access any data container within the single file system image located on any D module of the cluster.

Further to the illustrative embodiment the N module and D module are implemented as separately scheduled processes of storage operating system however in an alternate embodiment the modules may be implemented as pieces of code within a single operating system process. Communication between an N module and D module is thus illustratively effected through the use of message passing between the modules although in the case of remote communication between an N module and D module of different nodes such message passing occurs over the cluster switching fabric . A known message passing mechanism provided by the storage operating system to transfer information between modules processes is the Inter Process Communication IPC mechanism.

The protocol used with the IPC mechanism is illustratively a generic file and or block based agnostic CF protocol that comprises a collection of methods functions constituting a CF application programming interface API . Examples of such an agnostic protocol are the SpinFS and SpinNP protocols available from Network Appliance Inc. The SpinFS protocol is described in the above referenced U.S. Pat. No. 6 671 773. To that end the CF protocol is illustratively a multi layered network protocol that integrates a session infrastructure and an application operation set into a session layer. The session layer manages the establishment and termination of sessions between modules in the cluster and is illustratively built upon a connection layer that defines a set of functionality or services provided by a connection oriented protocol. The connection oriented protocol may include a framing protocol layer over a network transport such as TCP or other reliable connection protocols or a memory based IPC protocol. An example of a session layer that may be advantageously used with the present invention is described in commonly owned copending U.S. patent application Ser. No. 11 118 466 entitled SYSTEM AND METHOD FOR MULTIPLEXING CHANNELS OVER MULTIPLE CONNECTIONS IN A STORAGE SYSTEM CLUSTER filed by Peter F. Corbett et al. on Apr. 29 2005 now issued as U.S. Pat. No. 7 443 872 on Oct. 28 2008 the contents of which are hereby incorporated in their entirety as though fully set forth herein.

The CF interface module implements the CF protocol for communicating file system commands among the modules of cluster . Communication is illustratively effected by the D module exposing the CF API to which an N module or another D module issues calls. To that end the CF interface module is organized as a CF encoder and CF decoder. The CF encoder of e.g. CF interface on N module encapsulates a CF message as i a local procedure call LPC when communicating a file system command to a D module residing on the same node or ii a remote procedure call RPC when communicating the command to a D module residing on a remote node of the cluster . In either case the CF decoder of CF interface on D module de encapsulates the CF message and processes the file system command.

In the illustrative embodiment a data container is represented in the write anywhere file system as an inode data structure adapted for storage on the disks . is a schematic block diagram of an inode which preferably includes a meta data section and a data section . The information stored in the meta data section of each inode describes the data container e.g. a file and as such includes the type e.g. regular directory vdisk of file its size time stamps e.g. access and or modification time and ownership i.e. user identifier UID and group ID GID of the file. The meta data section also includes a generation number and a meta data invalidation flag field . The contents of the data section of each inode may be interpreted differently depending upon the type of file inode defined within the type field . For example the data section of a directory inode contains meta data controlled by the file system whereas the data section of a regular inode contains file system data. In this latter case the data section includes a representation of the data associated with the file.

In accordance with an embodiment of the present invention a storage system architecture illustratively comprises two or more volumes distributed across a plurality of nodes of cluster . The volumes are organized as a striped volume set SVS and configured to store content of data containers such as files and luns served by the cluster in response to multi protocol data access requests issued by clients . Notably the content of each data container is apportioned among the volumes of the SVS to thereby improve the efficiency of storage service provided by the cluster. To facilitate a description and understanding of the present invention data containers are hereinafter referred to generally as files .

To determine the location of a D module to which to transmit a CF message the N module may utilize a database process e.g. a VFS location database or VLDB process not shown that tracks the locations of various storage components e.g. a VFS or Virtual File System within the cluster to thereby facilitate routing of requests throughout the cluster. In the illustrative embodiment the N module of each node has a look up table e.g. config table that maps the VFS ID of a file handle to a D module that owns is running the VFS within the cluster. The VLDB provides the contents of the look up table by among other things keeping track of the locations of the VFSs within the cluster. The VLDB has a remote procedure call RPC interface e.g. a Sun RPC interface which allows the N module to query the VLDB. When encountering a VFS ID that is not stored in its mapping table the N module sends an RPC to the VLDB process. In response the VLDB returns to the N module the appropriate mapping information including an identifier of the D module that owns the VFS. The N module stores the information in its look up table and uses the D module ID to forward the incoming request to the appropriate VFS. Determining the location of a D module to which an N module transmits a CF message is further described in commonly owned copending U.S. patent application Ser. No. 11 119 279 entitled SYSTEM AND METHOD FOR IMPLEMENTING ATOMIC CROSS STRIPE WRITE OPERATIONS IN A STRIPED VOLUME SET filed by Richard P. Jernigan IV et al. on Apr. 29 2005 now issued as U.S. Pat. No. 7 743 210 on Jun. 22 2010.

As mentioned above credentials are generally well understood by those skilled in the art as information that identifies an authenticated user or machine requesters . That is an authenticating device e.g. network element N module may receive a request from a user e.g. a client device to access particular data in storage and in response authenticates the requester s identity and associates a corresponding credential with the requester. The network element is responsible for using the correct credential for each request e.g. depending upon the client protocol e.g. CIFS NFS etc. user domain virtual interface used and any other conditions that can determine user credentials as will be understood by those skilled in the art. Notably each module node and cluster storage system may have its own credential known generally as machine credentials such as for interoperation with other modules nodes clusters through fabric . 

Details on how a node may generate credentials for received requests is described generally in commonly owned copending U.S. patent application Ser. No. 10 910 164 entitled SYSTEM AND METHOD FOR A SIDECAR AUTHENTICATION MECHANISM filed by Benjamin T. H. Cox et al. on Aug. 2 2004 now issued as U.S. Pat. No. 7 519 813 on Apr. 14 2009 and commonly owned copending U.S. patent application Ser. No. 10 858 182 entitled SYSTEM AND METHOD FOR ASSOCIATING NIS ATTRIBUTES WITH CIFS CLIENTS filed by John Eric Hoffmann et al. on Jun. 1 2004 now issued as U.S. Pat. No. 7 668 881 on Feb. 23 2010 the contents of both of which are hereby incorporated in their entirety as though fully set forth herein.

Illustratively the network element passes the request to a data access device e.g. disk element D module along with the corresponding credential which is the authenticated requester identity used by the disk elements to process the request. Generally disk elements use the received credentials from the network elements without questioning them i.e. the D modules trust the N modules to authenticate and send proper credentials . As noted sending full credentials between network elements and disk elements may require a large amount of bandwidth within the cluster fabric while marshaling transferring and unmarshaling the full credentials may be particularly burdensome on processing resources e.g. CPU memory etc. at both elements.

The present invention overcomes the disadvantages of the prior art by providing a technique for efficiently transmitting credentials among nodes of a clustered storage system e.g. between network elements N modules and disk elements D modules . According to the invention in response to a user request to access data served by a data element a network element inserts adds a credential associated with the user e.g. an authenticated requester credential to a network element credential cache and creates a corresponding credential handle that indexes the credential in that cache. The network element then relays transmits the credential and credential handle to the disk element which adds the credential to a corresponding disk element credential cache at a location indexed by the corresponding credential handle. Requests may then be sent transmitted between the network element and the disk element using the credential handle. Effectively the credential handle represents a mapping between a full credential which may be large and complicated to an illustratively smaller identifier the credential handle . Credential handles therefore reduce the need to transfer complete full credentials over is the cluster fabric network such as transmitting full NFS and or CIFS credentials over the CF protocol messages with each request as mentioned above and possibly reduce the processing of such credentials as well.

Operationally the network element N module may establish a requester credential in a conventional manner in response to a received request e.g. from a user client or in response to other events such as pre configuration by a system administrator etc. as will be understood by those skilled in the art. Notably the established credential is associated with the requester client and a session between the network element and e.g. a disk element configured to service the request. The network element then generates determines a credential handle that uniquely identifies the associated credential and is unambiguous for the lifetime of the session in which it is established. The credential handle is used to represent a requester s credential illustratively by uniquely indexing pointing to a particular entry of the cache that contains the actual credential . As shown in cache credential handles are represented 1 2 3 . . . N etc. but those skilled in the art will understand that any value e.g. a 64 bit value substantially smaller than conventional credentials may be used to index to a particular entry for a corresponding credential e.g. represented as CRED 1 CRED 2 etc. . For example the network element may establish a requester credential CRED 2 and may thus create generate an associated credential handle 2 both of which are stored in the network element credential cache i.e. at an entry indexed by the handle 2 .

Once the credential and corresponding credential handle are established and stored in cache the network element may send the credential pair full credential and credential handle to the disk element D module . For instance a CF message may be sent from the network element to the disk element that contains a message type flag indication e.g. a SET CRED indication requesting that the disk element store the credential pair e.g. in credential field in its credential cache . Alternatively the network element may utilize a replicated database RDB process to distribute the credentials and corresponding credential handles to all nodes in the cluster as will be understood by those skilled in the art. Because the network element specifies the credential handle the same credential handle may be used to represent the same credential to multiple disk elements e.g. 2 represents CRED 2 on more than one disk element thus advantageously reducing the size of the credential cache of the network element.

The disk element D module receives the request for the credential pair and upon inserting the credential and credential handle into its credential cache the disk element D module may send an acknowledgement CF message to the initiating network element N module . If for any reason the disk element does not successfully establish the credential handle in its cache the disk element may return an error to the network element. For example if a credential is an improper invalid credential a CF message type indicating ERR BAD CRED may be sent to the network element. Also the disk element may reject the addition of a new entry to its cache if the cache has no space e.g. not enough memory to store the new entry e.g. an ERR NO SPACE message .

Further if the network element attempts to set a credential for a credential handle that already exists the disk element may return an error message e.g. a CF message with an ERR CRED EXISTS indication . In the event however that the network element instructs the disk element to replace the existing credential corresponding to that particular credential handle e.g. in a CF message with an indication to REPLACE EXISTING CRED the previous credential corresponding to that handle may be replaced accordingly without error. Moreover there may exist multiple credential types for a same requester client e.g. for different client protocols CIFS NFS etc. as will be understood by those skilled in the art. As such a network element may wish to merge the previous existing credential indexed by a credential handle with a new credential. If so a CF message e.g. indicating ADD TO EXISTING CRED may be used to instruct the disk element to merge the supplied credential in the message with the existing credential in the cache for example to add new credential types e.g. allowable only when the two credentials do not contain any overlapping types .

Prior to utilizing the cached credentials in a request message the network element may await confirmation from the disk element that the credential and credential handle have been successfully stored in cache . In response to receiving an error notification from the disk element however the network element may resubmit the credential and credential handle in a new SET CRED request or may determine that requests corresponding to this rejected credential should be sent with a full credential in a conventional manner e.g. where the disk element is unable to add the credential to its cache . Alternatively to alleviate the latency associated with round trip messaging confirmation rejection of credentials the network element may optimistically send a request to the disk element using the credential handle immediately after requesting that the credential handle be set. In other words the network element thus assumes that the disk element will have successfully cached the credential and credential handle. If not the disk element may reject the request having the unsuccessful credential handle.

Once the credentials have been successfully cached in cache and and indexed by corresponding credential handles requests may then be sent between the network and disk elements using the credential handles. For instance assume the network element N module receives a request from a client requester . The network element determines the corresponding credential for the requester and performs a lookup operation into its credential cache to find the proper credential . Notably the network element should maintain a sufficient amount of the actual credential in its cache in order to properly match the credentials for the incoming requests. For instance where a certain subset of a full credential i.e. a partial credential is all that is required to uniquely identify a credential only that subset need be stored in credential field . Disk element credential cache however may illustratively require the entire credential to be used as described herein. 

The network element adds the appropriate corresponding credential handle to CF message sent to the disk element which then performs another lookup operation into its credential cache to find the original cached credential i.e. the full credential necessary to process the request . In this manner the traffic sent between the elements may be substantially reduced by providing efficient transmission of credentials i.e. sending a smaller handle than the full credential . Notably if the disk element does not have a credential corresponding to the provided credential handle in the message the disk element may reject the request accordingly e.g. an ERR NO CRED indication . At this time the network element may resubmit the credential and credential handle in a new SET CRED request as described above or may resubmit the rejected request with a full credential in a conventional manner.

Generally the credential handles are scoped established by session such that the credential caches on the disk elements are not shared among different sessions. In the event the session fails the cached credentials of the disk elements are illustratively invalidated. In such an event upon reestablishing the session the network element may create new credential handles for the corresponding credentials e.g. 4 for CRED 2 . Alternatively the network element may reuse the old handles e.g. 2 for CRED 2 if the handles remain stored in cache however because the disk element credential cache has been invalidated the network elements should resubmit the previously used credential handles to the disk elements for the new session. The disk element should further be adapted to store credentials and credential handles in its cache for a configurable length of time sufficient to be effectively used as will be understood by those skilled in the art.

In step the network element relays the credential and the corresponding credential handle to one or more disk elements D modules such as those to which the network element wishes to forward the requests as mentioned above. In response e.g. assuming no errors exist as described herein each disk element adds the credential CRED 2 to its corresponding credential cache e.g. in step at a location indexed by the corresponding credential handle e.g. at entry corresponding to handle 2 in field .

Once the credential handle has been established for a particular credential at both the network element and disk element or if in step the credential has already been cached with an established handle requests may be sent between the network element and the disk element over a session using the credential handle in step as described herein. The procedure ends in step .

In addition or alternatively in accordance with one or more embodiments described herein the network element may further send a series of chained requests to one or more disk elements for the same credential credential handle with an indication that the requests use the same credential without sending the credential or credential handle to the disk element. For instance a network element may send a large series of requests to one or more disk elements e.g. for a large amount of stored data or a large file for the same client . By using a special CF message type flag for the current credential credential traffic within the cluster fabric may be further reduced e.g. removing the need for any credential field as well as potentially reducing the processing of the credential at the disk element.

Typically in accordance with this embodiment the first request CF message of the series of requests contains a credential and the type flags field may specifically indicate that this credential is to be used for the series of requests e.g. using a SET AS CURRENT CRED indication . Notably the current credential that is to be used for the series of chained requests may be a full credential or a credential handle indexing a cached credential as described above. The receiving disk element then stores the credential or credential handle within a special entry of its credential cache that is used to indicate the current credential accordingly. Subsequently any remaining requests of the series of chained requests may be sent with an indication that the requests are for the same credential as the first request i.e. the credential of the series of chained requests without sending the credential to the disk element i.e. using a message type flag indicating that a CURRENT CRED is to be used . That is when the disk element receives a request for the current credential entry of the credential cache is utilized for the request. Those skilled in the art will understand that while the CF message type field is illustratively used to indicate the current credential the credential field may alternatively be used with a similar indication e.g. with a credential handle specifically indicating the current credential .

Moreover in accordance with an alternative embodiment the disk element may be configured to interpret the requests as a series of chained requests e.g. using a is type indication or other means as will be understood by those skilled in the art . Thus the disk element may simply use whichever credential has been sent in the first message of that chain as the current credential for any remaining requests of the series. Also while the current credential is generally only defined for the scope of a chain there may be occasions where the same client accounts for a large proportion of the network element s requests to the disk element. Setting the current credential to correspond to this client may also allow the network element to more efficiently relay the credential for this client as the CURRENT CRED e.g. a favorite credential with or without a series of chained requests further reducing overall traffic in the cluster fabric .

In addition to the techniques described above e.g. to set use and respond to credential handles other management and maintenance mechanisms of credential caching may be used in accordance with the present invention. For instance the disk elements D modules generally manage their own caches . Cached entries may be removed evicted by the disk elements or an entire cache may be invalidated at is any time. The length of time a cache entry remains in the cache may be a decision local to the disk elements. Also other reasons for allowing the disk elements to control their own caches may include e.g. where the network elements N modules and disk elements D modules are located on different nodes .

Further the network element manages its own cache but may occasionally desire to check verify the status of the disk elements caches . For instance the network element may send a CF message e.g. a GET GRED message type to a disk element to determine the content credential of that disk element s credential cache that is indexed by a particular credential handle in sent message indexed by in cache . Also the network element may request that the disk element remove and or invalidate a particular credential handle in cache with a CF message having a DISCARD CRED message type . In either case credential field of the CF message may be populated by the desired credential handle accordingly. Those skilled in the art will understand that other messages requests updates etc. in addition to those described herein may be sent between the network element and disk element to manage maintain credential caching in a storage cluster and that those shown herein and their illustrative types are merely examples.

Notably in addition to utilizing credential handles and or current credentials the network elements N modules may still pass full credentials in credential field of CF message to the disk elements D modules with each request in a conventional manner i.e. inline credentials. For example a message type flag indicating an INLINE CRED may be used to indicate that the receiving disk element use the inline credential for that particular request e.g. only and that the disk element need not store the credential of the message in cache . Also no credential handle need be created cached at the network element although may be for other reasons . Particularly maintaining the ability to utilize inline credentials is advantageous in the event many users clients each issue a small number of requests to the cluster storage system . That is where a client having a credential only issues a small number of requests it may be more efficient to add a per message overhead i.e. full credentials than to endure the round trip messaging to establish a credential handle as described above. On the other hand as described herein credential handles may be better suited for a smaller number of users that send a large number of requests. Accordingly network elements may selectively determine which credentials to cache to apply handles based on one or more factors such as cache size number of requests etc.

While there have been shown and described illustrative embodiments that efficiently transmit credentials between network elements and disk elements in a clustered storage system it is to be understood that various other adaptations and modifications may be made within the spirit and scope of the present invention. For example the embodiments have been shown and described herein with using clustered storage systems particularly network elements and disk elements and the associated cluster interface. However the embodiments of the invention in its broader sense are not so limited and may in fact be used with any devices nodes that exchange credentials in a similarly applicable manner as will be understood by those skilled in the art. Also while the above description illustratively describes utilizing various protocols and specific messages those skilled in the art will understand that other mechanisms e.g. protocols and mesas sages may be used to transmit credentials in accordance with the present invention.

In addition while the above embodiments describe creating the credential handles at the network elements N modules and relaying the credential handles to the disk elements D modules an embodiment of the present invention may also create credential handles at the disk elements. For instance the network element may receive a request may cache credentials for the request and may forward the request to the appropriate disk element s . In accordance with this additional embodiment the disk element may then create an associated credential handle for the cached credential of the request and may return the credential handle to the network element from which the request was received. For example the network element may send a credential caching request to the disk module to perform such services as in above. In this manner the network element may use the credential handle as created defined by the disk element in a manner similar to handles created by the network element as described above.

Advantageously the novel technique efficiently transmits credentials between network elements and disk elements in a clustered storage system. By establishing credential caches on the network elements and disk elements traffic sent within the clustered storage system between the network elements and disk elements particularly credential information may be substantially reduced. Also processing of the credential information may be reduced in the network elements and disk elements e.g. particularly where large credentials are used.

The foregoing description has been directed to particular embodiments of this invention. It will be apparent however that other variations and modifications may be made to the described embodiments with the attainment of some or all of their advantages. Specifically it should be noted that the principles of the present invention may be implemented in non distributed file systems. Furthermore while this description has been written in terms of N and D modules the teachings of the present invention are equally suitable to systems where the functionality of the N and D modules are implemented in a single system. Alternately the functions of the N and D modules may be distributed among any number of separate systems wherein each system performs one or more of the functions. Additionally the procedures processes and or modules described herein may be implemented in hardware software embodied as a computer readable medium having program instructions firmware or a combination thereof. Therefore it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention.

