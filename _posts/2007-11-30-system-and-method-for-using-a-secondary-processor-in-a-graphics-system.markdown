---

title: System and method for using a secondary processor in a graphics system
abstract: A system, method and apparatus are disclosed, in which a processing unit is configured to perform secondary processing on graphics pipeline data outside the graphics pipeline, with the output from the secondary processing being integrated into the graphics pipeline so that it is made available to the graphics pipeline. A determination is made whether to use secondary processing, and in a case that secondary processing is to be used, a command stream, which can comprise one or more commands, is provided to the secondary processing unit, so that the unit can locate and operate on buffered graphics pipeline data. Secondary processing is managed and monitored so as to synchronize data access by the secondary processing unit with the graphics pipeline processing modules.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08922565&OS=08922565&RS=08922565
owner: QUALCOMM Incorporated
number: 08922565
owner_city: San Diego
owner_country: US
publication_date: 20071130
---
This disclosure relates to parallel processing in a graphic processing system and more particularly synchronizing use of a secondary processor in connection with other processing units such as a central processing unit and a graphics processing unit to perform graphics processing in parallel including reintegration of data processed by such a secondary processor into a graphics processing pipeline.

A graphics processing unit GPU is a dedicated graphics rendering device used to generate computerized graphics for display on a display device. A GPU is typically used with a general purpose central processing unit CPU to process graphic image data e.g. three dimensional computerized graphic image data. In such a case a GPU can implement a number of primitive graphics operations to create three dimensional images for display on a display device more quickly than using a CPU to draw the image for display on the display device. Typically a GPU includes hardware that implements some number of the complex algorithms in hardware.

A typical GPU receives an image geometry and uses a pipeline approach to generate graphics which can be output for example for display on a display device. A typical graphics pipeline includes a number of stages which operate in parallel with the output from one stage possibly being used at another stage in the pipeline. For example a typical graphics pipeline comprises vertex shader primitive assembly viewport transformation primitive setup rasterization hidden primitive and pixel rejection attribute setup attribute interpolation and fragment shader stages.

A vertex shader is applied to the image geometry for an image and generates vertex coordinates and attributes of vertices within the image geometry. Vertex attributes include for example color normal and texture coordinates associated with a vertex. Primitive assembly forms primitives e.g. point line and triangle primitives from the vertices based on the image geometry. Formed primitives can be transformed from one space to another using a transformation e.g. a viewport transformation which transforms primitives from a normalized device space to a screen space. Primitive setup can be used to determine a primitive s area edge coefficients and perform occlusion culling e.g. backface culling and 3 D clipping operations.

Rasterization converts primitives into pixels based on the XY coordinates of vertices within the primitives and the number of pixels included in the primitives. Hidden primitive and pixel rejection use the z coordinate of the primitives and or pixels to determine and reject those primitives and pixels determined to be hidden e.g. a primitive or pixel located behind another primitive or pixel in the image frame a transparent primitive or pixel . Attribute setup determines attribute gradients e.g. a difference between the attribute value at a first pixel and the attribute value at a second pixel within a primitive moving in either a horizontal X direction or a vertical Y direction for attributes associated with pixels within a primitive. Attribute interpolation interpolates the attributes over the pixels within a primitive based on the determined attribute gradient values. Interpolated attribute values are sent to the fragment shader for pixel rendering. Results of the fragment shader can be output to a post processing block and a frame buffer for presentation of the processed image on the display device.

It is beneficial to facilitate the graphics pipeline processing to achieve increased throughput. Efforts have been made to increase throughput by optimizing software that implements a portion of the graphics pipeline. However such an approach is costly since it typically requires significant programmer effort and time to generate the optimized program code. Increased throughput might be achieved using dedicated hardware. However such an approach involves additional cost for the dedicated hardware which hardware is only available to be used for a dedicated purpose.

The present disclosure seeks to address failings in the art and to provide efficiencies in graphics image processing to use a secondary processing unit to perform graphics processing in a graphics processing pipeline to supplement the processing performed by other processing units such as a graphics processing unit and or a central processing unit to identify a data dependency associated with such processing and integrate output generated by the secondary processing unit into the graphics processing pipeline to satisfy such data dependency.

A system method and apparatus are disclosed in which a processing unit is configured to perform secondary processing on graphics pipeline data outside the graphics pipeline with the output from the secondary processing being integrated into the graphics pipeline so that it is made available to the graphics pipeline. A determination is made whether to use secondary processing and in a case that secondary processing is to be used a command stream which can comprise one or more commands is provided to the secondary processing unit so that the unit can locate and operate on buffered graphics pipeline data. Secondary processing is managed and monitored so as to synchronize data access by the secondary processing and one or more processing modules in the graphics pipeline.

In accordance with embodiments of the present disclosure an opportunity to use a secondary processing unit or secondary processor with a graphics processing pipeline is identified and graphics pipeline data is made available to the secondary processing unit. Graphics pipeline data generated by the secondary processing unit is reintegrated into the graphics pipeline. By way of a non limiting example the secondary processor is a digital signal processor which is configured as a lighting module to generate lit colors from color data made available to the digital signal processor from the graphics pipeline.

In so doing embodiments of the present disclosure provide an ability to balance the processing load using available secondary processor s . A secondary processor that might otherwise remain idle can be used to facilitate graphics pipeline processing performed by a graphics processing unit and or processing performed by a central processing unit or other processing unit. Thus for example operations that may otherwise wait for a processing resource can be directed to an available secondary processor which results in faster throughput. Advantageously it has been determined that there is an increase in throughput e.g. as measured in frames per second using a secondary processor over processing in which the secondary processor is not used. In addition embodiments of the present disclosure can use information fed back from the secondary processing to perform load balancing. The feedback can be used for example to determine when a secondary processor has reached a certain threshold processing level. When the secondary processor is determined to reach a threshold processing capacity processing can be directed to another processing unit such as a central processing unit.

In addition embodiments of the present disclosure provide an ability to make use of a processing unit for other than its primary processing purpose to perform one or more other secondary functions if such processing unit is available. Use of such hardware e.g. a processing unit that might otherwise be idle results in more efficient use of the hardware.

In accordance with an aspect of the present disclosure a method comprises in response to a draw request determining whether or not a processing unit is available to assist in graphics pipeline processing the processing unit having a primary processing function requesting allocation of the secondary processor to perform a secondary processing function other than the primary processing function of the processing unit to assist in graphics pipeline processing and in a case that the allocation request is successful making graphics pipeline data available to the processing unit monitoring the status of processing by the processing unit and integrating data output by the processing unit into the graphics pipeline data.

In accordance with another aspect of the present disclosure a computer readable memory medium which stores program code is provided the program code comprises code to determine whether or not a processing unit is available to assist in graphics pipeline processing the processing unit having a primary processing function request allocation of the secondary processor to perform a secondary processing function other than the primary processing function of the processing unit to assist in graphics pipeline processing and in a case that the allocation request is successful make graphics pipeline data available to the processing unit monitor the status of processing by the processing unit and integrate data output by the processing unit into the graphics pipeline data.

In accordance with another aspect of the present disclosure an apparatus comprises a graphics processing unit configured to implement a graphics pipeline and a secondary processing manager coupled to the graphics processing unit the secondary processing manager configured to determine whether or not a processing unit coupled to said secondary processing manager is available to assist in graphics pipeline processing said processing unit having a primary processing function request allocation of said secondary processor to perform a secondary processing function other than the primary processing function of said processing unit to assist in graphics pipeline processing and in a case that the allocation request is successful the secondary processing manager is further configured to make graphics pipeline data available to said processing unit monitor the status of processing by said processing unit and integrate data output by the processing unit into the graphics pipeline data.

In accordance with yet another aspect of the present disclosure an apparatus comprises a graphics processing unit configured to implement a graphics pipeline and a secondary processing management means coupled to the graphics processing unit the secondary processing management means comprising means for determining whether or not a processing unit coupled to said secondary processing manager is available to assist in graphics pipeline processing said processing unit having a primary processing function means for requesting allocation of said secondary processor to perform a secondary processing function other than the primary processing function of said processing unit to assist in graphics pipeline processing in a case that the allocation request is successful said secondary processing management means further comprising means for making graphics pipeline data available to said processing unit means for monitoring the status of processing by said processing unit and means for integrating data output by the processing unit into the graphics pipeline data.

This brief summary has been provided so that the nature of the invention may be understood quickly. A more complete understanding of the invention can be obtained by reference to the following detailed description of the preferred embodiment s thereof in connection with the attached drawings.

Certain embodiments of the present disclosure will now be discussed with reference to the aforementioned figures wherein like reference numerals refer to like components.

In accordance with one or more embodiments a system method and apparatus are disclosed in which a secondary processor unit is configured to operate on graphics pipeline data with the output from secondary processor being integrated into the graphics pipeline such that the output is made available to one or more modules executing in the graphics pipeline. In accordance with such embodiments a determination is made whether or not to use the secondary processor and in a case that the secondary processor is to be used a command stream is provided to the secondary processor. For example the command stream can comprise one or more commands. Each command provided to the secondary processor contains information identifying the current command. In a case that there is another command the current command contains information that identifies the next command. In a case that the current command is the last command the current command contains information to identify the current command as the last command. The command stream provides information to the secondary processor which information can include but is not limited to input and or output data storage location s and a feedback storage location.

In accordance with one or more embodiments the secondary processor is a digital signal processor DSP which is configurable to perform primary processing e.g. process audio and or video data and which can be configured to perform secondary processing. In accordance with one or more such embodiments the DSP is shared such that it is available to perform audio and or video data processing and can assist with graphics pipeline processing when available e.g. not processing audio video data. For the sake of simplicity only embodiments disclosed herein are described with reference to a second processor as a DSP. It should be apparent that any processor or processing unit can be used with embodiments of the present disclosure.

In the example of computing device includes a central processing unit CPU GPU a DSP as an example of a secondary processor a display unit and a memory module e.g. a random access memory RAM memory module or modules. The components of computing device e.g. CPU GPU DSP and memory module can communicate using a bus which can comprise any type of bus or device interconnect now known or later discovered. CPU can comprise a general purpose or a special purpose microprocessor. For example CPU may comprise a reduced instruction set computer RISC processor designed by ARM Inc. having offices at various locations around the world including Irvine Calif. and whose parent company is ARM Holdings PLC of Cambridge UK. By way of a further non limiting example CPU may comprise a Core 2 Processor provided by Intel Corporation of Santa Clara Calif. or another type of microprocessor. GPU is a dedicated graphics computing device. GPU can be an Imageon media co processor provided by AMD of Sunnyvale Calif. or another type of graphics processing unit for example. GPU can be integrated into the motherboard of computing device can be present on a graphics card that is installed in a port in the motherboard of computing device or can be otherwise configured to interoperate with computing device for example.

Display unit which is coupled to computing device can comprise a monitor a television a projection device a liquid crystal display a plasma display panel a light emitting diode LED array a cathode ray tube display electronic paper a surface conduction electron emitted display SED a laser television display a nanocrystal display or another type of display unit for example. In the example of display unit can be a part of computing device . For instance display unit can be a screen of a mobile telephone. Alternatively display unit can be external to computer device and can be in communication with computing device via a wired or wireless communications connection or other connection for example. By way of a non limiting example display unit can be a computer monitor or flat panel display connected to a personal computer via a wired or wireless connection.

Software application can comprise any software application capable of executing via CPU such as a video game a graphical user interface engine a computer aided design program for engineering or artistic applications or another type of software application that uses two dimensional 2D or three dimensional 3D graphics by way of non limiting examples. When CPU is executing software application software application can invoke subroutines of a graphics processing application programming interface API such as any one or more of an OpenVG API an OpenGL API a Direct3D API a Graphics Device Interface GDI Quartz QuickDraw or another type of 2D or 3D graphics processing API by way of non limiting examples.

In accordance with at least one embodiment when software application invokes a subroutine of graphics processing API graphics processing API invokes one or more subroutines of a GPU driver which execute via CPU on computing device . GPU driver can comprise a set of software and or firmware instructions that provide an interface between graphics processing API and GPU for example. When graphics processing API invokes a subroutine of GPU driver GPU driver formulates and issues a command that causes GPU to generate displayable graphics information. For example when graphics processing API invokes a subroutine of GPU driver to draw or render a batch of graphics primitives GPU driver provides GPU with a processing configuration which GPU uses to render the batch of graphics primitives. GPU renders the batch of graphics primitives and outputs a raster image of the graphics primitives for example.

A command formulated by GPU driver can identify graphics processing configuration s that GPU is to use to perform the command which configuration s can identify a set of instructions to be executed by GPU a set of state register values and other types of information that GPU might need to perform the command.

In a case that GPU driver stores the graphics processing configuration s in memory GPU driver can reference the storage locations in memory module corresponding to the graphics processing configuration s in the command formulated by GPU driver . When GPU receives the command GPU can retrieve from memory the graphics processing configuration s referenced in the command received from GPU driver .

In accordance with at least one embodiment a command decoder not shown of GPU decodes the command from GPU driver and configures one or more of processing elements of the GPU to perform the command using data e.g. position color texture etc. data retrieved from memory .

In accordance with one or more embodiments the processing elements or modules of GPU implement a graphics pipeline. In accordance with such embodiments the GPU s processing elements can implement the graphics pipeline in a parallel mode such that the processing elements operate on data in parallel with output from one processing element being used as input to another processing element. By way of a non limiting example a first processing element performs a first graphics operation on a first set of initial input data and outputs a first set of intermediate results to a second processing element. The initial input data can comprise data corresponding to one or more vertices which data can comprise coordinate and attribute data for example. Vertex coordinates identify a location within an image based on for example a four dimensional coordinate system with X Y and Z width height and depth coordinates and a W coordinate forms a homogenous coordinate. Vertex attributes can include color normal and texture coordinates associated with a vertex for example. The second processing element can perform another graphics operation on the first set of intermediate results output by the first processing element and output a second set of intermediate results to a third processing element and so on. While the second processing element is performing the second graphics operation the first processing element can be performing the first graphics operation on a second set of initial input data.

The GPU and its processing elements can continue in this manner until the last processing element outputs a pixel object to one or more buffers in memory module or output this new pixel object to some other destination. A pixel object is data that describes a pixel. Each pixel object may specify multiple color values and can specify a transparency level of the pixel. In some circumstances a pixel object may specify a first color in a first color format and a second color in a second color format.

In accordance with one or more embodiments of the disclosure the GPU s processing modules can include software executed by the GPU dedicated hardware modules and or programmable processing modules configured to perform one or more of the GPU s processing modules. The GPU s processing modules implement a graphics pipeline which can comprise vertex shader primitive assembly viewport transformation primitive setup rasterization hidden primitive and pixel rejection attribute setup attribute interpolation and fragment shader stages for example.

Embodiments of the present invention can assign a secondary use to DSP or other secondary processor to operate on data used in the graphics pipeline. In accordance with one or more embodiments the secondary use is different from the secondary processor s primary use. For example DSP can be used to process audio and video data and can further be used to implement one or more lighting modules that operate on graphics pipeline data. In so doing the secondary processor can supplement the resources otherwise used to implement a graphics pipeline.

In accordance with embodiments of the present disclosure the secondary processor is used when it is determined that the secondary processor is not being used for its primary purpose s . For example in a case that DSP is determined to be idle i.e. not processing audio or video data a request is made to allocate the DSP for use as a secondary processor in connection with the graphics pipeline. In such a case DSP can be used to perform some form of secondary processing e.g. lighting on graphics pipeline data or other processing e.g. skinning etc.

In the example shown in a DSP is being used as a secondary processor. It should be apparent that any processing unit can be used as a secondary processor in accordance with one or more embodiments of the present disclosure. The SPMM receives notification when an application issues a draw call. The SPMM analyzes the draw call and associated information provided by the application to determine whether processing of the draw call includes processing that can be performed by a secondary processor. For example the SPMM determines whether processing of the draw call involves application of one or more lighting models to the color data. By way of another non limiting example the SPMM can examine the draw call to determine whether or not skinning is to be applied.

In a case that the SPMM determines that processing can be performed by a secondary processor the SPMM attempts to allocate the secondary processor for the secondary processing. For example the SPMM communicates with a real time operating system RTOS of the DSP to request the DSP . The communication includes a call back used by the RTOS to notify the SPMM whether or not the DSP is available e.g. whether or not the SPMM s allocation request was successful. If the RTOS determines that the DSP is available e.g. is not being used for its primary purpose the RTOS loads a DSP module which comprises the secondary processing module B and a secondary processing interface module SPIM A.

The secondary processing module B comprises the program code used to perform the secondary processing. The SPIM A comprises program code configured to interface with the SPMM such as providing feedback to feedback memory area A in memory module via communication path . The SPMM provides information to SPIM A via communication path which identifies feedback area A the storage location of the input data and output data e.g. locations in data buffer s C. In addition SPIM A provides information to processing module B which information can be used by the processing module B to perform the secondary processing e.g. lighting.

In accordance with one or more embodiments the SPMM uses communication path to provide information associated with a set of commands referred to as a stream of commands or a command stream used by the processing module B. In accordance with one or more such embodiments the SPMM communicates an initial message to SPIM A which comprises a pointer to a first command of a command stream stored in a command stream area B of memory module and a pointer to feedback area A in memory module . Briefly a command in the command stream includes information to identify the location of input and output data in data buffer s C the location of feedback A pointer to next command in stream or indication that the current command is the last command and other information such as lighting models used in a case that DSP module performs lighting. The contents of a command are described in more detail below.

The SPMM loads each command into command stream B via communication path and forwards a pointer to the first command in command stream B to SPIM A via communication path and the initial message sent by the SPMM to the SPIM A. Thereafter the SPIM A uses information contained in the first or current command to locate the next command in the command stream B or to identify the first current command as the last command. The SPIM A can access feedback A command stream B and or data buffer s C based on information contained in a given command in the command stream and the initial information provided by the SPMM via communication path . The DSP module which includes the SPIM A and processing module B can access one or more areas of memory via communication path for example.

The data contained in data buffer s C is used by both processing module B and the graphics pipeline processing modules . In a case that there is at least one data dependency between the module B and at least one of the modules the SPMM synchronizes data access by the modules B and based on information provided by SPIM A stored in feedback A and information provided by the SPIM which operates in connection with the graphics pipeline processing module s . For example the SPMM can use information in feedback A to notify the SPIM that lit color data is available for processing by one or more graphics pipeline process modules . By way of a further non limiting example the lit color data can be made available to a clipping module of the graphics pipeline processing module s once the SPMM determines that the color data corresponding to all of the primitives needed by the clipping module have been processed by processing module B. The SPMM and the SPIM can communicate via communication pathway e.g. the SPIM notifies the SPMM that one or more of the graphics pipeline processing module s is ready to process data and or the SPMM notifies the SPIM that data is available to be processed by the graphics pipeline processing module s .

In addition the SPMM can use information in the feedback area A to determine when an area in command stream B can be overwritten with a new command in the command stream. By way of a non limiting example the feedback A comprises information identifying the latest command completed by the secondary processing module B. In a case that the secondary processing module B is no longer accessing a command in the command stream B and the SPMM determines that the command is no longer needed the SPMM can elect to use the area for a new command in the command stream. The SPMM might determine that the command is no longer needed in a case that the graphics pipeline has finished processing the graphics pipeline data corresponding to the command.

In accordance with one or more embodiments the SPMM SPIM A and SPIM comprise program code that is executed by one or more processing units or processors. Such processing units can include without limitation the CPU the DSP and the GPU . By way of a non limiting example the SPMM and the SPIM comprise program code that is executed by the CPU and the SPIM A comprises program code executed by the DSP . By way of a further non limiting example the SPMM s program code is executed by the CPU the SPIM comprises program code executed by the GPU and the SPIM A comprises program code executed by the DSP . It should be apparent however that any one or more processing units can be used to implement the program code of the SPMM the SPIM A and the SPIM . By way of a further non limiting example bus can be used to facilitate the communication paths and and or communication between SPMM RTOS DSP module which comprises SPIM A and processing module B memory module SPIM and graphics pipeline processing module s . Communication path can be used by one or more of graphic pipeline processing modules to access graphics pipeline data stored in data buffer s C for example.

If the SPMM determines at step that there is an opportunity to use secondary processing processing continues at step wherein the SPMM requests the secondary processor. For example the SPMM sends a request to the DSP s RTOS to load DSP module and provides a call back for the RTOS to notify the SPMM whether or not the SPMM s request succeeded or failed. If it is determined at step that the RTOS notifies the SPMM that the request failed processing continues at step to notify the graphics pipeline that there is no secondary processing. In such a case and in accordance with one or more embodiments the SPMM can notify the CPU to perform the lighting.

If the RTOS notifies the SPMM that the request for the secondary processor succeeded processing continues at step of . At step the SPMM prepares the first command in the command stream and stores the first command in the command stream B. In accordance with one or more embodiments the SPMM uses a linked list approach to communicate the command stream to the secondary processor. By way of a non limiting example each command contains a pointer to the next command. By way of a further non limiting example a command can contain a pointer to any command in the command stream such as a pointer to a previous command in the command stream. In a case where the current command is the last command the pointer to the next command contains a value e.g. a hexadecimal value of 0xFFFFFFFF which identifies the current command as the last command.

In accordance with one or more embodiments the SPMM may not know at the time it stores a command in command stream B whether or not there are to be additional commands. In such a case SPMM stores a value of zero as a pointer to the next command in the linked list to notify the SPIM A that there may be additional commands. In a case that the module B completes processing associated with a current command SPIM A looks at the pointer in the command just completed to locate a next command if any in the command stream B. If the pointer is set to a value of zero the SPIM A knows that the SPMM has not yet updated the pointer. In such a case the SPIM A can wait a period of time before checking the pointer to see whether the SPMM has updated the pointer. If the pointer has a non zero value the SPIM A examines the value to determine whether it points to a next command in the command stream B or indicates that the completed command is the last command in the command stream. In the latter case the SPMM can store a value e.g. a hexadecimal value of 0xFFFFFFFF in the pointer to notify the SPIM A that there are no more commands to be processed in the current command stream and the DSP can be used to perform its primary or other processing.

At step the SPMM sends the initial message to the secondary processor containing information corresponding to the first command. The message sent by the SPMM to the SPIM A has information corresponding to the first command. The message sent by the SPMM notifies the secondary processor that it can commence processing and provides information to locate the first command. In accordance with one or more embodiments of the present disclosure and with reference to an initial message comprises a pointer to the command in the command stream memory B information identifying the size of the command s storage area in the command stream memory B and a pointer to the feedback A storage area of memory module . Referring again to after the SPMM sends the message notifying the secondary processor of the first command in the command stream at step the SPMM s processing continues at step to determine whether there are additional commands in the command stream.

If the SPMM determines at step that there is at least one additional command that is to be generated for the current draw call processing continues at step . At step the SPMM prepares the new command and stores the new command in the command stream B. At step the SPMM sets the pointer in the immediately preceding command e.g. the first command in the command stream B to point to the new command in the command stream B e.g. to point to a location in command stream B at which the new command is to stored. As with the first command the new command and any succeeding command contains a pointer which points to the next command if a next command is generated by the SPMM or an indicator that the new command is the last command if there is no next command . In accordance with one or more embodiments after the initial message is sent to the secondary processor the SPMM and the secondary processor s processing module e.g. DSP module communicate via the command stream B and the feedback A. In so doing overhead can be minimized since there is no need to send messages between the two processing modules. The DSP module navigates the linked list of commands in the command steam B to process data and provides feedback to the SPMM by writing status information to feedback A of memory module . In accordance with one or more embodiments the DSP module operates asynchronously and independently with respect to the SPMM and the graphics pipeline processing modules .

Once the SPMM updates the pointer in the preceding command to point to the new command processing continues at step to determine whether or not any additional commands remain to be generated. If not processing continues at step to update the pointer contained in the last command to a value e.g. a hexadecimal value of 0xFFFFFFFF to notify the SPIM A that the command is the last command in the current command stream B and processing ends for the current draw call. If there are additional draw calls processing continues at step to prepare a command stream in connection with another draw call.

The SPIM A provides an interface between the SPMM and processing module B. In accordance with one or more embodiments SPIM A receives information corresponding to the command stream generated by the SPIM facilitates processing performed by the processing module B monitors the processing module s B processing status and provides feedback on the processing module s B processing. illustrates a program code process flow implementing the SPIM A in accordance with one or more embodiments of the present disclosure.

At step the SPIM A receives the initialization message from the SPIM . By way of a non limiting example the SPIM A receives the initialization message which includes a pointer to a location in command stream B that corresponds to the first command information to identify the size e.g. in bytes of the first command and a pointer to a location in feedback A area. At step the SPIM A uses the information in the message to locate the first command in the command stream B and to identify whether the current command is the last command.

At step the SPIM A makes the information contained in the current command available to the processing module B. For example location information e.g. pointers and size information is used to initiate a data move operation to access e.g. load and or store data in data buffer s C. In addition the command can include a location of color data in data buffer s C such as a pointer to input color data associated with a first vertex and an increment to add to the pointer to locate color data for a next vertex. The current command can further comprise a pointer to a location in an output buffer in data buffer s C associated with the first vertex as well as an increment to locate the output location for color data associated with the next vertex. By way of a further non limiting example in a case that processing module B performs lighting the current command can include one or more lighting models. As another non limiting example in a case that the processing module B performs skinning the command can include skinning matrices. In accordance with one or more embodiments the first command can provide a complete set of the lighting models or skinning matrices with subsequent commands identifying any changes in the lighting models or skinning matrices specified in the previous command.

At step the SPIM A monitors the progress of the processing module B and at step updates information in feedback A with information identifying a status of processing performed by the processing module B. provides an example of information that can be stored in the feedback A in accordance with one or more embodiments of the present disclosure. In accordance with one or more such embodiments each command identifies a finite set of vertices and a command is considered to be complete once the processing module B has processed the vertex data associated with the vertices identified by the command. Feedback A can comprise information to identify the latest command completed by the processing module B e.g. last command identifier ID and a pointer to the command in command stream B.

Referring again to the SPIM A proceeds at step to use information in the current command to make the data used in processing available to the processing module B and to update the feedback A with a status of the secondary processing.

As discussed above and in accordance with one or more embodiments the secondary processor operates asynchronously and independent of the SPMM and the graphics pipeline processing modules . In at least one case however the secondary processing e.g. the processing performed by the DSP module is synchronized with processing performed by the graphics pipeline processing modules so that data that is processed by the secondary processor and that is to be further processed by the graphics pipeline processing modules is synchronized. In such a case the SPMM operates in connection with the SPIM which can provide an interface between the graphics pipeline processing modules and the SPMM to manage data access by the graphics pipeline processing modules such that the modules use data that has been processed by the secondary processor. In accordance with one or more embodiments SPMM and SPIM can comprise a single module.

In accordance with one or more embodiments the value set in the primitive list can be used by the SPMM to determine whether data associated with primitives to be processed by the graphics pipeline are first being processed by a secondary processor. At step the SPMM accesses the value set in the primitive list and at step the SPMM determines whether or not secondary processing is being used. If SPMM determines at step that secondary processing is being performed SPMM synchronizes access by the graphics pipeline processing modules to data being processed by the secondary processor so that the secondary processor completes its processing of the data that is to be further processed by the graphics pipeline processing modules before the data is made available to the modules .

By way of a non limiting example if the value stored in the primitive list indicates that secondary processing is not being used data accessed by the graphics pipeline processing modules need not be synchronized with data access by the secondary processing module B. In such a case the graphics pipeline processing modules can operate in a non synchronization mode which does not involve synchronizing data access between the graphics pipeline processing modules use of vertex data with use of such vertex data by secondary processing module B. In a case that the value stored in the primitive list indicates that secondary processing is being used the graphics pipeline processing modules operated in a synchronization mode to synchronize the modules access to vertex data with that of the processing module B.

If data access is to be synchronized in accordance with one or more embodiments SPMM determines at step using feedback information provided by SPIM A a state of the processing module B. In accordance with one or more embodiments the SPIM A stores information in feedback A which identifies the processing state of processing module B by identifying the last primitive completed by processing module B. In accordance with one or more embodiments primitives are assigned a sequential identifier so that SPMM is able to determine at step and based on the feedback information supplied by SPIM A that primitives whose identifiers are equal to or less than the primitive identifier supplied by the SPIM A have been completed by the processing module B. At step SPMM in conjunction with SPIM allows the graphics processing modules to access the data stored in data buffer s C associated with the primitives determined to have been processed by the processing module B.

In non synchronization mode the model view transform module retrieves the vertex data including lit color data operates on vertex data other than the lit color data and stores the vertex data in the post transform buffer . In non synchronization mode the model view transform module is instructed to transfer the color data with the other vertex data. Although the transform module does not modify the color data it retrieves the lit color data from the pre transform buffer and stores the lit color data in the post transform buffer as instructed so that the color data is available for processing by a succeeding module in the graphics pipeline e.g. the viewport transform module . In the example shown in the viewport transform module accesses the post transform buffer to retrieve the lit color data forwarded by the model view transform module and uses the lit color data e.g. interpolates color data in its transformation operation s .

In the non synchronization mode the model view transform module writes the color data to the post transform buffer . However if transform module were to write the color data to the post transform buffer the transform module could overwrite the lit color data written to buffer by the secondary processor . In synchronization mode the model view transform module receives notification e.g. notification from SPIM to not transfer color data to the post transform buffer . By foregoing the transfer of the color data as part of the vertex data written to the post transform buffer by the model view transform module the transform module avoids overwriting the lit color data written to the post transform buffer by the secondary processor .

In synchronization mode SPIM can provide a status of the data stored in post transform buffer so that the viewport transform module retrieves vertex data that includes the lit color data output by the secondary processor . By way of a non limiting example SPMM and SPIM can monitor the feedback A to identify whether the secondary processor has processed the vertices associated with primitives that the viewport transform module is to process so that module processes vertex data that includes lit color data. For example a command can include information that associates a command with the primitive list whose vertices are being processed by the command. In accordance with one or more embodiments there is a one to one correspondence between a command and an associated primitive list such that one command is used by the secondary processor to process all of the primitives in the associated primitive list. Thus once processing is determined to be complete for a given a command the primitives in the associated primitive list are available to be processed by the viewport transform module .

In accordance with one or more embodiments each command is given an identifier and command identifiers are assigned in sequential order. In so doing it is possible to determine whether processing for a given command is completed based on the last command identifier information contained in feedback A. For example commands that have a command identifier value that is equal to or less than the value identified in the last command ID are considered to be completed by the secondary processor while commands that have a command identifier value greater than the last command ID value are considered to be unfinished by the secondary processor .

Information item s and comprise identification information for use with the current command . In accordance with one or more embodiments the following information can be used to facilitate secondary processing management and control. The following provides examples of such information items 

timestamp Identifies the current command that is being processed by the secondary processor. SPIM A can output this timestamp in feedback A to indicate that the secondary processor is currently processing this command for example.

primitiveTimeStamp the variable comprises a timestamp for use in identifying the primitive list that corresponds to the current command . The value of the primitive timestamp can be used to map a command to a given primitive for example. The primitive timestamp can be ignored by the secondary processor.

Granularity An optional variable for use in accordance with one or more embodiments. The granularity variable indicates a number of vertices associated with command that comprise a vertex group or subset of the vertices associated with command . In accordance with one or more embodiments the secondary processor outputs information as feedback to indicate that a number of vertices that comprise a vertex group have been processed. In a case that command processes vertices the granularity instructs the SPIM A to provide feedback upon completion of a number of the vertices e.g. a vertex group which is a subset of the vertices associated with command . Using the granularity value the SPIM A can provide feedback as each vertex group is processed which feedback can be in addition to the feedback provided by SPIM A when the secondary processor completes processing all of the vertices associated with command thus providing additional and or a finer level of feedback.

vertexCount A variable that comprises a value indicating a number of vertices to be processed in connection with the current command .

nextCommandGroupSize This variable identifies the size of the next command. If there is no next linked command the variable can be set to zero. Otherwise the value comprises a value that reflects the number of bytes contained in the next command.

nextCommandGroupPtr This variable comprises all or a portion of next command ID information which can comprise a pointer to the next command in command stream B. If there is no next command the value can be set to a NULL value. Otherwise the value comprises a pointer to a memory location that corresponds to the initial storage location e.g. in command stream B of the next command.

Information items comprise information e.g. pointers and strides that can be used to locate stored data e.g. data stored in data buffer s C. The following provides examples of such information items 

vertexInPtr A variable that comprises a pointer to a buffer that contains input vertex positions. In accordance with one or more embodiments the value of this variable can be NULL. By way of a non limiting example a lighting program being executed by the secondary processor may use normals instead of positional information associated with vertices in a case that processing involves an infinite lighting model. In a case that the processing involves one or more of a spotlighting or positional lighting models the vertexInPtr can be used as a pointer to storage that stores positional data for the one or more vertices to be processed.

vertexOutPtr A variable that comprises a pointer to a buffer into which the secondary processor can write skinned vertices. The vertexOutPtr variable is used in a case that the secondary processor performs skinning.

colorsInPtr A variable that comprises a pointer to a buffer that stores vertex colors RGBA . Each set of red green blue and alpha value set comprises a vertex color group. In a case that two sided lighting is performed the buffer stores two vertex color groups in succession in the buffer. Each vertex color group is separated by vertexOutSize bytes. such that the next vertex color group can be located by adding the value of the vertexOutSize variable to a current colorsInPtr value. If the colorsInPtr variable has a NULL value a Material data structure is used as the input color group for each vertex.

colorsOutPtr A variable that comprises a pointer to a buffer that stores the color output generated by the secondary processor. Two color groups are output in succession by the secondary processor for each vertex in a case that two sided lighting is enabled. Each vertex color group is separated by vertexOutSize bytes.

normalsInPtr A variable that comprises a pointer to a buffer that contains vertex normals corresponding to the vertices pointed to by the vertexInPtr e.g. the vertices that are currently being processed by the secondary processor. If the normalsInPtr variable has a NULL value the secondary processor uses a CurrentNormal for all vertices.

boneIndicesPtr A variable that comprises a pointer to an array of bytes that index the matrix palette for use in skinning vertices. By way of a non limiting example the number of indices equals the number of vertices times the number of bones per vertex e.g. as indicated by a boneCount variable.

boneWeightsPtr A variable that points to a buffer that contains s15.16 bone weights that can be used during a vertex skinning process. By way of a non limiting example the number of weights equals the number of vertices times the number of bones per vertex e.g. as indicated by a boneCount variable.

vertexInSize A variable that indicates a number of bytes contained in one input vertex structure per vertex . By way of a non limiting example the value associated with this variable can be used as a stride to calculate a next vertex position in the vertex buffer.

vertexOutAndColorSize A variable that identifies a number of bytes contained in one output vertex structure per vertex . By way of a non limiting example the value associated with this variable can be used as a stride to calculate a next output position for either positions or colors.

numDimensions A variable specifying a number of elements per position vector 3 XYZ 4 XYZW . If the number is 3 W can be assumed to be 1.0. By way of a non limiting example the value associated with this variable can be used as a stride to calculate a pointer to the positional data for the next vertex.

Information items comprise other processing information that can be used in secondary processing. The following provides examples of such information items 

CurrentNormal XYZ A variable that contains the normal to be used in a case that normalsInPtr is a NULL pointer value. This normal is applied to all vertices referenced in the command stream.

rescaleNormalsFlag A variable that indicates whether or not to rescale the vertex normals. If the flag is set e.g. to a value of 0xFFFFFFFF the secondary processor rescales the vertex normals before the lighting equation per the OpenGL ES Specification section 2.11.3 .

RescaleNormalizeFlag A variable that indicates when to rescale the vertex normals. If the first significant bit e.g. bit is set the secondary processor normalizes the normals after transformation but before lighting as specified in the OpenGL ES Specification section 2.11.3 . If bit is set the secondary processor can use the rescale normal algorithm as stated in the OpenGL specification or use the standard normalize in all cases. Since normalize can be used in all cases bit can be set whenever it is appropriate to normalize the normals and bit can also be set when the secondary processor is permitted to use rescale normals as an alternative.

twoSidedLightingFlag A variable that indicates whether or not to perform two sided lighting. If the flag is set e.g. to a value of 0xFFFFFFFF the secondary processor computes two colors per vertex one for each side of the vertex relative to the normal . In accordance with one or more embodiments the twoSidedLightingFlag can be used to indicate that there are multiple colors e.g. one for each side associated with a vertex.

lightingEnabledFlag A variable used to indicate whether or not to perform lighting. If the flag is set e.g. to a value of 0xFFFFFFFF the secondary processor runs the lighting calculation on the vertices and outputs one or two colors per vertex depending on whether or not the twoSidedLighting flag is enabled. In accordance with one or more embodiments the lightingEnabledFlag can be used in a case that lighting is optionally performed during secondary processing that performs multiple operations e.g. lighting and skinning.

numActiveLights A variable that specifies a number of lights to be applied per vertex. In accordance with one or more embodiments up to 8 lights are supported and active lights are in numerical order. e.g. 3 active lights refer to lights .

numLightsUpdated A variable tht specifies a number of lighting information arrays pointed to by the lightingInfoPtr variable value. In accordance with one or more embodiments a light information array sent with a command is to be updated before the lighting calculation is performed on vertices for the current command and any active light that is not updated uses its previous values.

lightUpdateMask A variable that comprises bit fields that indicate which lights are to be updated using the lightingInfoArrayPtr. The number of bits set corresponds to the numLightsUpdated entry. The least significant bit corresponds to light and bit corresponds to light . If the most significant bit is set 0x8000 there is an updated material structure for the current command.

Material A data structure that can be used if needed to update lighting model data if the such data was updated. The presence of this structure can be identified by setting the value of the most significant byte of the lightUpdateMask variable. An example of a material data structure definition is provided below.

UpdatedLights A data structure that comprises if needed a number e.g. numLightsUpdated of lighting information structures each of which comprises the new data for lights that have changed since the last command. In accordance with one or more embodiments the secondary processing uses the lightUpdateMask variable to map the light structures to the actual lights being updated.

boneCount A variable that comprises a number of bones per vertex to be used in skinning. In accordance with one or more embodiments if the value is equal to 0 zero the secondary processor applies matrix palette 0 which comprises the MVT but does not output the transformed vertices in this case e.g. so that the eye space vertices are used for the lighting calculation only.

matrixPalettePtr A variable that comprises a pointer to a buffer of 4 4 fixed point matrices containing the matrix palette entries changes since the last CCG. A size of this buffer is indicated by the includedMatricesSize entry and the index map is contained in the MPInUse bit masks.

includedMatricesSize A variable that indicates a size in bytes of matrix palettes pointed to by the matrixPalettePtr. In accordance with one or more embodiments the buffer need only include updated matrices and fields in the MPInUse mask variable are used to determine an appropriate index location at which to copy the data.

MPInUse A 16 bit mask in which each bit set corresponds to an updated matrix palette that is included in the buffer pointed to by the matrixPalettePtr variable. The least significant bit corresponds to matrix index while the most significant bit corresponds to matrix index for example.

MPInUse A 16 bit mask in which each bit set corresponds to an updated matrix palette that is included in the buffer pointed to by the matrixPalettePtr. The least significant bit corresponds to matrix index while the most significant bit corresponds to matrix index for example.

MPInUse A 16 bit mask in which each bit set corresponds to an updated matrix palette that is included in the buffer pointed at by the matrixPalettePtr. The least significant bit corresponds to matrix index while the most significant bit corresponds to matrix index for example.

The following provides an example of contents of material data structures that can be used by the secondary processing e.g. lighting performed in accordance with one or more embodiments of the present disclosure 

Light Model Ambient Scene Color RGBA Comprises an Ambient Scene color set that can be used for the lighting model.

Material Emissive RGBA Comprises a fixed point RGBA color set that can be used for the Material Emissive color.

Material Ambient RGBA Comprises a fixed point RGBA color set that can be used for the Material Ambient color.

Material Diffuse RGBA Comprises a fixed point RGBA color set that can be used for the Material Diffuse color.

Material Specular RGBA Comprises a fixed point RGBA color set that can be used for the Material Specular color.

Material Specular Exponent Comprises a fixed point Material Specular Exponent factor which can range between 0.0 and 128.0

The following provides additional examples of a data structure e.g. light model data structure which can be used by the secondary processing in accordance with one or more embodiments. By way of a non limiting example a light model data structure can exist for each light model used in lighting performed in secondary processing.

Spotlight Cutoff Cosine Comprises a cosine cutoff value for a spotlight. For example the cosine values can range from 1.0 to 0.0 0 degrees to 90 degrees or 1 180 degrees . In a special case of 1 180 degrees the light is an omnidirectional light and not a spotlight.

Light Position XYZW Comprises a fixed point light position or direction. If the value of the W component is 0 then the light is an infinite directional light otherwise it is a positional light. If W is zero Attenuation and Spotlight values can be ignored.

Embodiments of the present disclosure provide a system method and apparatus in which a secondary processor unit is configured to operate on graphics pipeline data with the output from secondary processor being integrated into the graphics pipeline such that the output is made available to one or more modules executing in the graphics pipeline. In accordance with such embodiments a determination is made whether or not to use the secondary processor and in a case that the secondary processor is to be used a command stream which can comprise one or more commands is provided to the secondary processor. The secondary processing uses information contained in the command stream and operates on buffered graphics pipeline data in synchronization with one or more graphics pipeline processing modules so that neither the secondary processor s processing module nor any graphics pipeline processing module overwrites data. An SPMM operates in combination with one or more SPIMs to synchronize data access by the secondary processing and the graphics pipeline processing modules using feedback information comprising a processing status of the secondary processing module.

In so doing embodiments of the present disclosure provide an ability to balance the processing load using available secondary processor s . A secondary processor that might otherwise remain idle can be used to facilitate graphics pipeline processing performed by a graphics processing unit and or processing performed by a central processing unit or other processing unit. Thus for example operations that may otherwise wait for a processing resource can be directed to an available secondary processor which results in faster throughput. Advantageously it has been determined that there is an increase in throughput e.g. as measured in frames per second using a secondary processor over processing in which the secondary processor is not used. In addition embodiments of the present disclosure can use information fed back from the secondary processing to perform load balancing. The feedback can be used for example to determine when a secondary processor has reached a certain threshold processing level. When the secondary processor is determined to reach a threshold processing capacity processing can be directed to another processing unit such as a central processing unit.

In addition embodiments of the present disclosure provide an ability to make use of a processing unit for other than its primary processing purpose to perform one or more other secondary functions if such processing unit is available. Use of such hardware e.g. a processing unit that might otherwise be idle results in more efficient use of the hardware.

In one or more exemplary embodiments the functions described can be implemented in hardware software and or firmware or any combination thereof. If implemented in hardware the functions can be implemented in one or more microprocessors microcontrollers digital signal processors DSPs application specific integrated circuits ASICs field programmable gate arrays FPGAs or the like. Such components can reside within a communication system data writing and or reading system or other systems. If implemented in software the functions can be stored on or transmitted over as one or more instructions or code on a computer readable medium. Computer readable media includes tangible computer storage media and communication media including any medium that facilitates transfer of a computer program from one place to another. A storage media can be any available media that can be accessed by a computer. By way of example and not limitation such computer readable media can comprise RAM Flash memory read only memory ROM electrically erasable programmable read only memory EEPROM compact disc read only memory CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer. The term computer readable medium can also be defined as a tangible computer program product. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

While the apparatus and method have been described in terms of what are presently considered to be the most practical and preferred embodiments it is to be understood that the disclosure need not be limited to the disclosed embodiments. It is intended to cover various modifications and similar arrangements included within the spirit and scope of the claims the scope of which should be accorded the broadest interpretation so as to encompass all such modifications and similar structures. The present disclosure includes any and all embodiments of the following claims.

