---

title: Concurrent management of adaptive programs
abstract: A method for concurrent management of adaptive programs is disclosed wherein changes in a set of modifiable references are initially identified. A list of uses of the changed references is next computed using records made in structures of the references. The list is next inserted into an elimination queue. Comparison is next made of each of the uses to the other uses to determine independence or dependence thereon. Determined dependent uses are eliminated and the preceding steps are repeated for all determined independent uses until all dependencies have been eliminated.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08627301&OS=08627301&RS=08627301
owner: Intel Corporation
number: 08627301
owner_city: Santa Clara
owner_country: US
publication_date: 20070518
---
The present disclosure relates to adaptive computer programs and the management thereof. In particular the present disclosure teaches processes for the management of adaptive programs in a parallel environment such as a multi core processing system.

In the most general terms an adaptive program is a program in which changes in input are automatically propagated to the output. That is to say the output reflects changes in input values without having to rerun the whole program and only those parts affected by the changes are re evaluated. The advent of multi core processing technologies enables parallel processing of different kinds of applications many of which often require a divide and conquer approach.

For applications such as video vision graphics audio physical simulation gaming and mining such parallelism allows the program to meet application speed requirements and take advantage of faster multi core technologies. Adaptive programming is especially useful in such multi core processor systems and has been shown to significantly improve the running time of such divide and conquer style methods. Current approaches to adaptive programs have mainly been explored in the context of functional languages and the approaches have been tailored to uni processor based sequential execution methods. Efforts to date to manage adaptive programming processes have been exclusively serial in nature and have lacked advances in concurrent or parallel adaptive programming.

This disclosure presents primitives that enable a parallelizable approach to adaptive programming in imperative non declarative languages. This disclosure also presents methods and mechanisms that allow one to efficiently perform change propagation in a parallel process as in multi core processors enabling effective optimization of data parallelism for multi core architecture which will further enable and promote parallel software development.

Although the following detailed description will proceed with reference being made to illustrative embodiments many alternatives modifications and variations thereof will be apparent to those skilled in the art. Accordingly it is intended that the claimed subject matter be viewed broadly.

A key aspect of an adaptive program is the automatic tracking and efficient propagation of changes in the system state. To implement this functionality each step in the program is tracked essentially recording how all pieces of data are produced and consumed and inter leaving control flow or data flow constraints are tracked. One way of obtaining this information is by exhaustively recording the state in a program s execution trace. The steps in the trace essentially describe the different operations that can be performed and how changes need to be propagated through the system.

Each independent unit of data is typically abstracted opaquely by a modifiable reference modref . Modrefs are immutable in the sense that they may be written to only once. In order to change the value associated with a modref the original is invalidated and a new modref is created to replace the original. The modref s application programming interface API essentially provides three primitive operations read write and create. Create creates a new modref cell whereas write updates the value associated with a modref. Read allows the program to use the value of a modref that has been previous written into and records within the structure of the given modref where and when the value has been used. Moreover if the data is not available the program must perform some evaluation to produce the data and populate the modref before execution continues. Read operations have traditionally been performed with eager evaluation methods and this imposes a sequential evaluation order.

Traditionally modrefs have been processed with eager evaluation methods in a serial execution setting each modref always holds data before it is read and is empty before it is written. Eager evaluation generally refers to a mode of operation in which tasks are executed evaluated as soon as they are created. On the other end of the spectrum lazy evaluation refers to a mode of operation in which tasks are executed only when their results are required. A first feature of the disclosed system is a new primitive called a lazy modref . Lazy or lenient evaluation refers to a mode of operation in which tasks need not be executed as soon as they are created however idle resources processors hardware threads etc. are free to process created tasks as they desire.

In general if the number of resources is large then there is a high probability that the tasks would have been processed before their results are required.

Lazy modrefs improve on traditional modrefs by allowing such lenient or lazy evaluation methods. These methods are the basis for parallelizing adaptive programs. In the disclosed setting a lenient execution model is used where each lazy modref can be empty typically after creation. Alternatively the lazy modref may contain a ready to read value or a continuation that will work to populate the value once executed. This continuation may also populate the lazy modref with yet another continuation. This continues in loop fashion until the lazy modref is populated with a data value. This is guaranteed to eventually occur under correct usage of the API and framework. When the lazy modref holds such a continuation the programmer has setup a process to eventually write to the lazy modref when executed. Since each process can be executed leniently the programmer may not have written to the lazy modref yet. The lazy modref s API provides the same three primitive operations as traditional modrefs create write and read with similar methods. However a fundamental difference is that lazy modrefs signatures are based on destination passing style methods and that the caller manage the memory used to store the result. Decoupling the store in this way is essential for enabling lenient evaluation methods and forms the basis for parallelizing adaptive programs.

A set of interconnected modrefs tracks changes to the system state. The execution trace is abstracted out as a binary tree of modrefs that describes nodes where data is created and consumed and where the different control and data flow dependencies leading to these nodes are created and consumed. The dependency constraints are exposed through the seq split primitives. This information may be used to identify nodes where the computation can be parallelized.

A second feature of the disclosed system is a mechanism for parallelizing change propagation in an adaptive program. Change propagation describes the process of updating system state in response to some change in the input set. The parallel change propagation method is similar to the serial change propagation method except that in order to preserve correctness in the presence of parallelism we need to rely on recording extra information about uses of modrefs. This information stored in the modrefs themselves is used at runtime to identify nodes that need to be recomputed to make appropriate adjustments to the output values. Any given modref may have multiple read locations that may be dependent on each other. A separate mechanism maintains and facilitates querying for these relationships which is called the dependence structure .

The method works as shown in . A set of changed modrefs is first identified which correspond to the parts of the program s input that have changed. Next is computed a list of uses reads of these modrefs using the records made in their structures each time they re used. This list is called the invalidated uses . Next is computed each invalidated use and inserted into an elimination queue which is similar to a conventional queue except that its methods for insert differ when an element is to be inserted it is compared against every element in the queue for dependence. If any element in the queue is dependent the new element precedes this element in question according to our dependence structure the dependent element is dropped from the queue. Likewise if the element being inserted is found to be dependent on any element already in the queue the insertion process stops and the new element is dropped.

Once each invalidated use has been processed with the elimination queue the elements left in the queue are independent of one another as well as independent of all elements originally in the set of invalidated uses. Modrefs are next examined for changes in value upon the occurrence of which re execution proceeds for each use which is itself a continuation in parallel. Upon re execution some other modrefs may change value upon which the change propagation method for each of these or each subset of these is re instated.

Unlike prior art approaches there are several opportunities for parallelization in the disclosed process. First each execution of the program itself has independent components which may be executed in parallel. Next since these components independence is stored precisely by the dependence structure false dependencies causing needless re execution are circumvented and the ability to re execute these components in parallel is gained should they require re execution.

This is the first and only system that is capable of parallel change propagation. This is the only work that supports imperative language features. This is the first approach to parallelize adaptive programs.

Next order maintenance in adaptive programs is addressed. Order maintenance involves three operations insert remove and compare which modify and query a total ordering. Insert is the operation that adds a new element to the ordering immediately after an existing element. Remove removes a given element. Given two elements in the ordering compare computes whether they have a less than an equal to or a greater than relationship. In the order maintenance routine of the disclosure the problems traditionally associated with order maintenance are solved for the three operations with amortized constant time on a machine where arithmetic can be done in constant time. This disclosure solves traditional order maintenance problems for concurrent adaptive or incremental computation for fine grained dependent task graphs in constant time. Additionally this disclosure enables the use of a truly lock free data structure for concurrent updates.

In existing adaptive programs a total ordering is used to efficiently represent and later query the execution trace. This total order is used when querying dependency information and forms the basis for doing insert read and compare operations in constant time. However this representation fails to support parallel execution methods. Since each step of the method has a distinct position in the trace of the method only serial updates may be realized. To elaborate once they are included in the total ordering steps that are conceptually independent may appear to be dependent. The presently disclosed representation solves this problem by efficiently encoding the dependency information while eliminating such false dependencies. This provides a means for identifying and scheduling parallel tasks while retaining the constant time bounds.

One can check for dependency by comparing the rank in the two total orders TO and . In general approximation of a partial order is made through a combination of total orders. Specifically a combination of two total orders may be used for a large class of programs to recover the original partial order which conveys dependency information exactly. illustrates the gist of this approach. Intuitively the approach corresponds to choosing two complementary topological sorts of the partial order. This method may select the two total orders correctly. In one embodiment no more than constant overhead is added for each operation when compared to the original scheme.

All of the dependency information contained within the trace of the adaptive program may be represented as a binary tree. A language may be developed that can be used to verify this property. While there may be arbitrary dependencies in the task graph the reduction to a binary tree is performed by annotating the graph using three special nodes read nodes split nodes and sequence nodes. Read nodes represent a data dependency on some cell of memory and may have a single child which conceptually encloses the use of this data value. Split and sequence nodes represent control flow and each has two children. Sequence node children are ordered and are referred to as first and second children. Split nodes introduce independence and their children are referred to as left and right children. After annotating with these nodes the original task graph reduces into a binary tree. The two total orderings can be thought of as two topological sorts of this binary tree though they are created on line as the tree is created. The first total ordering is a depth first walk of the tree where first is visited before its sibling second in sequence nodes and left is visited before its sibling right in split nodes. This is generally called English ordering. The second ordering is the same except that children of split nodes are visited in reverse order right and then left which is generally called Hebrew ordering.

Referring to the herein disclosed order maintenance scheme is depicted in schematic form. In the diagram ranking of the orders is in accordance with the following guide 

The disclosed scheme maintains these two total orderings in a manner that is similar to the way a single total order is traditionally maintained except that any two dependent read nodes A and B will appear in both orderings with A before B whereas two independent read nodes C and D will appear in differing orders in the two total orderings. One will report that D precedes C and the other will report that C precedes D. The particular order that reports D first versus C first is of no consequence so long as both dependence and independence with constant overhead may be detected using these differing outcomes.

Two instances of the original total ordering data structure are used. Each total ordering is a doubly linked list of labeled elements where the label is a 32 bit or 64 bit word that represents its relative position in the ordering. Each read node introduces two elements into each total order to mark its beginning and ending points. Each split node and sequence node introduces a single element into each total order to mark its middle which is an element that separates the node s two children and each of its children s successors. The methods of mapping threads uses this middle element abstraction to distribute work to a worker thread. New threads look for work using the middle elements that correspond to split nodes. Note that this ensures that all worker threads work on logically independent regions of the data structure. Thus another feature of the scheme is the lack of reliance on locks for accessing and updating the total ordering data structure concurrently. This is the first work aimed at developing a concurrent order maintenance data structure yet these methods have the same complexity bounds as the state of the art for sequential versions.

Various features aspects and embodiments have been described herein. The features aspects and numerous embodiments described herein are susceptible to combination with one another as well as to variation and modification as will be understood by those having skill in the art. The present disclosure should therefore be considered to encompass such combinations variations and modifications. The terms and expressions which have been employed herein are used as terms of description and not of limitation and there is no intention in the use of such terms and expressions of excluding any equivalents of the features shown and described or portions thereof and it is recognized that various modifications are possible within the scope of the claims. Other modifications variations and alternatives are also possible. Accordingly the claims are intended to cover all such equivalents.

