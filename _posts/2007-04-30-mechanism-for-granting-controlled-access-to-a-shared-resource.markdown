---

title: Mechanism for granting controlled access to a shared resource
abstract: Disclosed are methods and systems for granting an application-specific integrated circuit (ASIC) in a multi-ASIC environment controlled access to a shared resource. A system includes a first ASIC, a second ASIC, and a shared memory that stores a shared resource and a data set partitioned into fields. The first ASIC writes data to a first subset of the fields and reads data from the fields. The first ASIC includes first logic that computes a first value based on the data read from the fields. The second ASIC writes data to a second subset of the fields and reads data from the fields. The second ASIC includes second logic that computes a second value based on the data read from the fields. Based on the first and second values respectively computed by the first and second logic, only one of the first and second ASICs gains access to the shared resource.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08068114&OS=08068114&RS=08068114
owner: Advanced Micro Devices, Inc.
number: 08068114
owner_city: Sunnyvale
owner_country: US
publication_date: 20070430
---
In some computing environments it is desirable to have multiple processing blocks or application specific integrated circuits ASICs that can access a single shared resource such as a shared memory. For example some computer systems use multiple graphics processor units GPUs to improve graphics processing performance. In such computer systems the GPUs may write to and or read from a shared memory.

For example depicts a block diagram illustrating a system that includes two GPUs a GPU A and a GPU B . Block diagram also includes various software elements such as an application e.g. a video game application application programming interface API and a driver that execute on a host computer system and interact with GPU A and or GPU B to perform graphics processing operations for output to a display . During the performance of these operations GPU A and GPU B may read from and or write to a local memory A and a local memory B respectively. In addition GPU A and GPU B may also read from and or write to a shared memory . Because GPU A and GPU B may each access shared memory there must be a mechanism to insure that only one GPU accesses a particular location of shared memory at a time. If such a mechanism is not included the data in shared memory could become corrupted.

A conventional mechanism that is used to restrict access to a shared resource in a multi processing environment is a semaphore. A semaphore may be implemented as a single memory location that stores a count which can be read modified written in an atomic operation. A semaphore may be used for example in a producer consumer environment to insure that the producer and the consumer do not access the same portion of the shared memory at the same time. A producer is a process that writes data to a shared memory and then updates the count thereby indicating that data stored in the shared memory is ready for consumption. The consumer is a process that reads the data from the shared memory that is ready for consumption and then decrements the count stored in the semaphore.

The conventional semaphore mechanism could be implemented in a multiple GPU environment but such an implementation would require a single point of control. For example a single memory controller could be coupled to each GPU or one of the GPUs could be designed as a master GPU. Although such approaches would provide controlled access to a shared memory such approaches require additional chip area because additional wires would be needed to couple the GPUs to the single memory controller or the master GPU. Furthermore such approaches may result in timing lags because if a first GPU in the multi GPU environment stalls the other GPUs coupled to the first GPU may also stall.

Given the foregoing what is needed is a method and system that provide a mechanism for granting controlled access to a shared resource without requiring a single point of control.

The features and advantages of the present invention will become more apparent from the detailed description set forth below when taken in conjunction with the drawings in which like reference characters identify corresponding elements throughout. In the drawings like reference numbers generally indicate identical functionally similar and or structurally similar elements. The drawing in which an element first appears is indicated by the leftmost digit s in the corresponding reference number.

It is noted that references in the specification to one embodiment an embodiment an example embodiment etc. indicate that the embodiment described may include a particular feature structure or characteristic but every embodiment may not necessarily include the particular feature structure or characteristic. Moreover such phrases are not necessarily referring to the same embodiment. Further when a particular feature structure or characteristic is described in connection with an embodiment it is submitted that it is within the knowledge of one skilled in the art to affect such feature structure or characteristic in connection with other embodiments whether or not explicitly described.

Embodiments of the present invention provide mechanisms for granting an application specific integrated circuit ASIC in a multi ASIC environment controlled access to a shared resource without requiring a single point of control. According to these embodiments each ASIC is configured to write to a dedicated field or portion of a shared memory and read from the shared memory. Based on data read from the shared memory or memory locations within the shared memory each individual ASIC is further configured to compute a value. An individual ASIC uses the value that it computes to determine whether it may access the shared resource. In this way the individual ASICs respectively determine whether they may access the shared resource. Because the ASICs do not have to communicate with a single point of control to determine whether they may access the shared resource embodiments of the present invention can be implemented using smaller chip area compared to implementations that require a single point of control. In addition embodiments of the present invention can be implemented without a timing lag that may be associated with implementations that require a single point of control.

A person skilled in the relevant art s will appreciate that the embodiments described herein are applicable to any ASICs that are included in a multi ASIC environment such as graphics processing units GPUs included in a multi GPU environment central processing units CPUs included in a multi CPU environment or a combination of GPU s and CPU s included in a multi GPU CPU environment. It is to be appreciated that such multi ASIC CPU GPU embodiments and combinations thereof are contemplated within the spirit and scope of the present invention. For illustrative purposes and not limitation embodiments of the present invention are described herein in terms of GPUs included in multi GPU environments.

For example depicts a block diagram of a system illustrating a plurality of GPUs configured to access a shared resource in accordance with an embodiment of the present invention. As shown in system includes a GPU A a GPU B and a shared memory . GPU A includes logic A and executes a thread A . Similarly GPU B includes logic B and executes a thread B . Shared memory includes a data set and a shared resource . In an embodiment shared resource may be included in data set as shown in . The operation of system is described below.

Logic A and logic B respectively determine whether GPU A and GPU B may access shared resource based on data read from data set . In particular logic A is configured to write to a first set of dedicated fields or portions of data set and read from data set . Logic A is further configured to compute a first value based on the data it reads from data set . Responsive to this first value thread A executing on GPU A either accesses shared resource or does not access shared resource . Similarly logic B writes to a second set of dedicated fields or portions of data set and reads from data set . Logic B is further configured to compute a second value based on the data it reads from data set . Responsive to this second value thread B executing on GPU B either accesses shared resource or does not access shared resource . As described in more detail herein the mechanism that logic A and logic B respectively use to compute the first and second values ensures that thread A and thread B do not simultaneously access the same portion of shared resource at the same time.

In one embodiment logic A and logic B use a semaphore mechanism to determine controlled access to shared resource . In this embodiment a single memory location in shared memory is dedicated to each GPU in system . The cumulative memory represents a single logical semaphore. To determine the logical semaphore value the dedicated memory locations are read and added together. The logical semaphore value is used to determine whether thread A or thread B may access shared resource .

In another embodiment logic A and logic B use a request acknowledgement mechanism. In this embodiment GPU A and GPU B are each configured to write to data set to set respective dedicated bits that indicate a request for access to shared resource . GPU A and GPU B can each read data set . In response to a request for access by GPU A logic A computes a first acknowledgement value based on the data it reads from data set . Similarly in response to a request for access by GPU B logic B computes a second acknowledgement value based on the data it reads from data set . Based on the first and second acknowledgement values only one of GPU A and GPU B is granted access to a given portion of shared resource at a given time.

As mentioned above an embodiment of the present invention uses a semaphore mechanism to determine whether a GPU in a multi GPU environment may access a shared resource. First an overview of this semaphore mechanism is presented. Second an example is described in which this semaphore mechanism is used for communicating the frame status of streaming video. Third example computer code implementing this semaphore mechanism is presented. Finally example activity of two GPUs in a multi GPU environment is presented.

A semaphore mechanism can be used to maintain data integrity across multiple client thread accesses. In a conventional semaphore mechanism a semaphore is a single memory location that can be read modified written in an atomic operation. A producer sends a signal command that increments a value stored at the memory location. For example if the value stored at the memory location is 0x00000001 a signal command from the producer increments the valued stored at the memory location to 0x00000002. A consumer sends a wait command that stalls i.e. blocks if the value is equal to 0 and decrements the value if the value is greater than 0. For example if the value is 0x00000000 a wait command from the consumer causes the consumer to block whereas if the value is 0x00000001 a wait command from the consumer decrements the value to 0x00000000. Conventionally the atomic operation is handled by a single hardware entity such as a single uninterruptible command or a shared memory controller.

The conventional semaphore mechanism could be used in a multi GPU environment but this would require a single shared memory controller. As mentioned above using a single shared memory controller is not desired because it can cause time delays and requires additional chip area. If there is not a single shared memory controller the conventional semaphore mechanism cannot be used in a multi GPU environment. As described in more detail below an embodiment of the present invention expands the conventional semaphore mechanism to handle a plurality of logically atomic clients such as a plurality of GPUs but does not require a single shared memory controller.

In this embodiment a single memory location is dedicated to each GPU in a multi GPU environment. The cumulative memory of all the dedicated memory locations represents a single logical semaphore. For example in a system that uses a 32 bit semaphore and includes two GPUs the single logical semaphore would require 64 bits of memory. In this example each GPU in the two GPU system would read modify write to a dedicated 32 bits of the 64 bits.

To determine a logical semaphore value corresponding to the single logical semaphore a GPU in the multi GPU environment reads all the dedicated memory locations and adds the values stored in each of the dedicated memory locations. The sum of all the values corresponds to the single logical semaphore value. For example the value corresponding to a first GPU in a two GPU environment may be 0xFFFFFFF1 and the memory location corresponding to a second GPU in the two GPU environment may be 0x00000001. In this example the single logical semaphore would be 0xFFFFFFF2 equal to 0xFFFFFFF1 plus 0x00000001 .

According to an embodiment there is no need to reset individual dedicated semaphore memory locations to avoid flipping back to 0 because each dedicated semaphore is treated as a signed value. For example in a two GPU environment in which one GPU acts exclusively as a producer and the other GPU acts exclusively as a consumer the value stored at the memory location of the producer may be 0xFFFFFFFF and the value stored at the memory location of the consumer may be 0x00000001. In this example the summed state of the producer and consumer would be 0x00000000 i.e. the number of signal commands is equal to the number of wait commands. A new signal command from the producer would increment the value stored at the memory location of the producer to 0x00000000 equal to 0xFFFFFFFF plus 0x00000001 . Thus the summed state would be 0x00000001 which indicates that the logical semaphore is ready for a consumer request.

The multi summed semaphore embodiment is based on several underlying concepts. First each individual semaphore always correctly reflects the signal versus wait count for a given GPU in a multi GPU environment. Although it may appear to other GPUs that this count bounces as a pending wait command is attempting to become unblocked the count is still accurate. Furthermore the sum of all semaphores is always less than or equal to the total number of outstanding signal commands. If the sum of all the semaphores is less than the total number of outstanding signal commands then there may be a false block by a consumer but it will not result in the integrity of data being compromised. In addition although two wait commands competing for the same signal command can starve each other such a starvation condition will never occur if the total number of signal commands is greater than or equal to the total number of wait commands.

In an embodiment a dedicated memory location is pre decremented on a wait command before summing the other dedicated memory locations. In this embodiment a consumer only blocks if the summed value is negative. If the consumer does block the dedicated memory location is incremented to compensate for the pre decrement.

For example depicts a flowchart illustrating a method for responding to a wait command in accordance with an embodiment of the present invention. As shown in method begins with the issuance of a wait command . Wait command may be issued by a consumer embodied in a first GPU.

In a step the dedicated semaphore for the first GPU is decremented. For example if the dedicated semaphore for the first GPU is 0x00000003 then it will be decremented to 0x00000002 in response to wait command .

In a step all the semaphore locations are read. Then in a step all the semaphores are summed into a register that is the same size as the individual semaphores. For example the semaphores may be summed into a 32 bit register. Because there is data contention from different GPUs the summed value will be less than or equal to the actual accumulated signal requests including this wait across all GPUs.

In a step it is determined whether the summed value is negative. The summed value is determined to be negative if the highest bit is set. If the summed value is negative then the dedicated semaphore corresponding to the first GPU is incremented to compensate for the pre decrement as shown in step . Thereafter the first GPU will stall as shown in step .

If however the summed value is non negative then the first GPU can access the shared resource as shown in step .

Shared memory includes data structure and a frame buffer . Data structure includes a first semaphore dedicated to GPU A and a second semaphore dedicated to GPU B . Frame buffer comprises a ring buffer that may store a plurality of frames of streaming video data including frame frame frame frame frame frame frame and frame 

GPU A further includes a memory controller A . DISP block is coupled to memory controller A which also includes semaphore logic A . Memory controller A is in turn coupled to data structure and frame buffer of shared memory . Based on the coupling between memory controller A and shared memory GPU A may read modify write first semaphore and may read second semaphore of data structure . In other words first semaphore is stored at a dedicated memory location corresponding to GPU A . In response to a request for access to frame buffer by GPU A memory controller A reads first semaphore and second semaphore and logic A sums the contents thereof to compute a logical semaphore value. Based on this logical semaphore a determination is made as to whether DISP block is permitted to read frames of frame buffer as described in more detail below.

GPU B further includes a memory controller B . DISP block and UVD block are each coupled to memory controller B which also includes logic B . Memory controller B is in turn coupled to data structure and frame buffer of shared memory . Based on the coupling between memory controller B and shared memory GPU B may read modify write second semaphore and may read first semaphore of data structure . In other words second semaphore is stored at a dedicated memory location corresponding to GPU B . In response to a request for access to frame buffer by GPU B memory controller B reads first semaphore and second semaphore and logic B sums the contents thereof to compute a logical semaphore value. Based on this logical semaphore a determination is made as to whether DISP block is permitted to read frames from frame buffer . UVD block writes frames to frame buffer as described in more detail below.

The operation of system is now described. Generally speaking UVD block of GPU B produces frames of video that are consumed by DISP block of GPU B and DISP block of GPU A . That is the function of UVD block is to continually store frames of video in frame buffer and the function of DISP block and DISP block is to perform graphics processing operations on the frames of video in frame buffer . For example UVD block may store frames of video corresponding to a news broadcast in frame buffer DISP block may provide a first type of graphics overlay on this video such as a stream of closing stock prices that appear at the bottom of the video and DISP block may provide a second type of graphics overlay on this video such as the current time . Because there are two consumers in the example of FIG. namely DISP block and DISP block UVD block writes two copies of each frame to frame buffer . DISP block consumes one copy of each frame and DISP block consumes the other.

UVD block sends signal commands through memory controller B to second semaphore to indicate that frames in frame buffer are ready for consumption. UVD block writes frames to frame buffer in a circular manner such that a first frame of video is written to frame a second frame of video is written to frame a third frame of video is written to frame and so on until it writes an eighth frame of video to frame . After writing to frame UVD block writes the next frame to frame and then proceeds to write to subsequent frames as set forth above. For example suppose first semaphore is initially 0x00000000 and second semaphore is initially 0x00000000. For a first frame of video UVD block writes one copy of this frame to frame and another copy of this frame to frame . In addition UVD block sends two signal commands through memory controller B to second semaphore . The two signal commands increment a count in second semaphore by two thereby indicating that two frames in frame buffer are ready for consumption. Thus the two signal commands will cause second semaphore to be incremented from 0x00000000 to 0x00000002. For each subsequent frame of video UVD block writes to frame buffer and increments the count in second semaphore in a similar manner.

DISP block determines whether there are frames in frame buffer that are ready for consumption based on data in data structure . DISP block sends a wait command through memory controller A causing first semaphore to be decremented by one. From the example above decrementing first semaphore by one will cause first semaphore to be 0xFFFFFFFF. In addition the wait command causes memory controller A to read first semaphore and second semaphore and logic A to sum these semaphores into a register such as a 32 bit register thereby resulting in a logical semaphore value. From the example above memory controller A reads 0xFFFFFFFF from first semaphore and 0x00000002 from second semaphore . Thus the logical semaphore value computed by logic A will be 0x00000001 equal to 0xFFFFFFF plus 0x00000002 . Because the logical semaphore is non negative DISP block may proceed to consume a frame in frame buffer .

In a similar manner to DISP block DISP block determines whether there are frames in frame buffer that are ready for consumption based on data in data structure . From the example above a wait command for GPU B will cause second semaphore to be decremented by one thereby resulting in a value of 0x00000001. In addition the wait command causes memory controller B to read first semaphore and second semaphore and logic B to sum these semaphores into a register such as a 32 bit register thereby resulting in a logical semaphore value. From the example above memory controller B reads 0xFFFFFFFF from first semaphore and 0x00000001 from second semaphore . Thus the logical semaphore value computed by logic B will be 0x00000000 equal to 0xFFFFFFFF plus 0x00000001 . Because the logical semaphore value is non negative DISP block may proceed to consume a frame in frame buffer .

Subsequent frames are written by UVD block and consumed by DISP block and DISP block in a similar manner to that described above as will be apparent to a person skilled in the relevant art s from reading the description contained herein.

As mentioned above with respect to an embodiment of the present invention uses a request acknowledgement mechanism to determine whether a GPU in a multi GPU environment may access a shared resource. First an overview of this request acknowledgement mechanism is presented. Then this mechanism is described in embodiments involving two GPUs four GPUs and eight GPUs.

Method begins at a step in which at least one GPU in the multi GPU environment writes data to a dedicated field or portion of a data set. For example the data set may be data set depicted in . The organization of data set is dependent on the number of GPUs included in the multi GPU environment as described in more detail below with respect to and . In an embodiment a first GPU sets a bit in the data set to indicate that the first GPU is requesting access to the shared resource.

In a step at least one GPU reads data from all the dedicated fields of the data set. In an embodiments these dedicated fields include an identification ID of each GPU requesting access to the shared resource and an ID of the last GPU to access the shared resource as described in more detail below.

In a step each GPU that is requesting access to the shared resource computes an acknowledgement value based on the data read from all the dedicated fields of the data set. In an embodiment the acknowledgement value is computed based on i the ID of each GPU requesting access to the shared resource ii the last GPU to access the shared resource and iii and the ID of the first GPU. The acknowledgement value may be computed using hardware software firmware or a combination thereof. In an embodiment the acknowledgement value is computed using a one bit adder as described in more detail below.

In a step only one of the GPUs that is requesting access to the shared resource is granted access responsive to the computed acknowledgement value s . For example if a first GPU computes an acknowledgement value that is non zero the first GPU accesses the shared resource however if the first GPU computes an acknowledgement value that is zero the first GPU is denied access to the shared resource. In this example method is such that only one GPU in the multi GPU environment will compute an acknowledgement value that is non zero. As a result only one GPU in the multi GPU environment will be granted access to the shared resource.

In an embodiment method is implemented by using a data structure that includes a double word DW for a shared resource e.g. semaphore and a DW for each pair of GPUs in a multi GPU environment. The DW for each pair of GPUs indicates a request for the shared resource DW GPUx Req and indicates which of the pair was the last to request access to the shared DW Last GPU Req .

This embodiment is easily expandable to several GPUs. Additional pairs of GPUs can be incorporated into the multi GPU environment by adding additional DWs to the data structure. Each additional DW will include a new byte field called Last GPU Pair Req field to support hierarchical arbitration.

In an embodiment method is implemented in hardware. In this embodiment a one bit adder is used to compute an acknowledgement value. Such a hardware implementation does not require significant chip area. For example in one embodiment only one additional wire is needed to implement this mechanism in a two GPU environment compared to a single GPU environment.

For illustrative purposes and not limitation method is described below in terms of a two GPU environment a four GPU environment and an eight GPU environment. In this description the shared resource is a semaphore. It is to be appreciated however that method may be implemented to granted access to other types of shared resources. For example method may be implemented as a pure mutex mechanism.

In an embodiment the request acknowledgement mechanism of is implemented in an environment that includes two GPUs. In this embodiment the request acknowledgement mechanism of implements the decision tree shown in Table 1.

As mentioned above method is implemented by writing to and reading from a data set such as data set of . illustrates an embodiment in which data set is organized into two double words DWO and DW . DW comprises a semaphore such as a 32 bit semaphore. DW includes three fields a Last GPU Req ID a GPU Req and a GPU Req. Each of these fields is described below.

The Last GPU Req ID field corresponds to the ID of the last GPU to request access the semaphore. This field may be written to and read from by both GPU and GPU . In an embodiment the last GPU Req ID field includes bits through of DW .

The GPU Req field indicates whether GPU is requesting access to the semaphore. This field may be written to by GPU and may be read from by both GPU and GPU . In other words the GPU Req field is a portion of DW that is dedicated to GPU . In an embodiment the GPU Req field includes bits through of DW.

The GPU Req field indicates whether GPU is requesting access to the semaphore. This field may be written to by GPU and may be read from by both GPU and GPU . In other words the GPU Req field is a portion of DW that is dedicated to GPU . In an embodiment the GPU Req field includes bits through of DW.

Based on the data written to and read from the data structure illustrated in GPU and GPU respectively determine whether they may access the semaphore. depicts a flowchart illustrating a sequence of operations that each GPU follows to determine whether it may access the semaphore. Flowchart begins at a step in which a GPU in the two GPU environment requests access to the semaphore. For example GPU GPU or both GPU and GPU may request access to the semaphore.

In a step the GPU requesting access to the semaphore sets its unique request ID in the corresponding field in the data structure shown in . If GPU requests access to the semaphore then GPU sets a bit in the GPU Req field for example by writing a 1 to the GPU Req field. In an embodiment GPU sets bit zero of DW. If GPU requests access to the semaphore then GPU sets a bit in the GPU Req field for example by writing a 1 to the GPU Req field. In an embodiment GPU sets bit eight of DW.

In a step the GPU requesting access to the semaphore sets the Last GPU Req field to its ID. If GPU is the last to request access to the semaphore then GPU writes a zero to the Last GPU Req field. If GPU is the last to request access to the semaphore then GPU writes a one to the Last GPU Req field.

In a step the GPU requesting access to the semaphore reads data from the data set. For example the requesting GPU reads the data from the Last GPU Req field the GPU Req field and the GPU Req field. Based on this data the requesting GPU computes an acknowledgement value. In an embodiment the acknowledgement value is computed in accordance with the following equation ack GPU0 Req GPU1 Req Last GPU Req GPU s ID Eq. 1 wherein ack represents the acknowledgement value GPU Req represents the value in the GPU Req field GPU Req represents the value in the GPU Req field Last GPU Req represents the value in the Last GPU Req field and GPU s ID represents the value of the GPU requesting access to the semaphore. For example suppose GPU and GPU each request access to the semaphore and GPU was the last GPU to request access to the semaphore. Based on this data GPU computes an acknowledgement value as follows ack GPU 0 1 1 1 0 3 mod 2 1 Similarly GPU computes an acknowledgement value as follows ack GPU 1 1 1 1 1 4 mod 2 0

In a step the GPU requesting access to the semaphore determines whether the acknowledgement value that it computed is equal to zero. If it is zero then that GPU re executes step . From the example above GPU re executes step because the acknowledgement value that it computed was equal to zero.

If however the acknowledgement value is not equal to zero then that GPU can access the semaphore as indicated in a step . From the example above GPU would be able to access the semaphore because the acknowledgement value that it computed was equal to one. If that semaphore s value is zero the GPU must release the lock on the semaphore so a signal can occur. This is considered a Failed Wait Semaphore. The semaphore is left unchanged the GPU s GPUx Req field is cleared on the write back and Last GPUx Req ID is unchanged. This allows the other GPU to have its turn since the failed GPU removed its Req.

The computation of the acknowledgement value of Eq. 1 may be implemented by hardware software firmware or a combination thereof. depicts an embodiment in which the computation of Eq. 1 is implemented by a one bit adder included in logic A of GPU A or logic B of GPU B . In this embodiment the input to one bit adder includes one bit from the Last GPU Req field such as bit of DW one bit from the GPU Req field such as bit of DW one bit from the GPU Req field such as bit of DW and the ID of the GPU that requested access to the semaphore.

As mentioned above method may be implemented in a pure mutex situation. In such an embodiment the semaphore DW is not required in the data structure of .

In an embodiment the request acknowledgement mechanism of is implemented in an environment that includes four GPUs. In this embodiment the request acknowledgement mechanism of implements the decision tree collectively shown in Tables 2A and 2B.

Referring to in a four GPU embodiment data set is organized into three double words DW DW and DW . DW comprises a semaphore such as a 32 bit semaphore. DW and DW include byte fields to support hierarchical arbitration. DW and DW are described below.

DW includes four fields a Last GPU Req ID of GPUs field a Last GPU Req ID of GPUs field a GPU Req field and a GPU Req field. The Last GPU Req ID of GPUs field indicates whether GPU GPU GPU or GPU was the last GPU to request access to the semaphore. This field may be written to and read from by all four GPUs in the four GPU environment. In an embodiment the Last GPU ID of GPUs includes bits through of DW .

The Last GPU Req ID of GPUs field indicates whether GPU or GPU was the last GPU to request access to the semaphore. This field may be written to by both GPU and GPU and may be read from by all four GPUs in the four GPU environment. In an embodiment the Last GPU Req ID of GPUs includes bits through of DW .

The GPU Req field indicates whether GPU is requesting access to the semaphore. This field may be written to by GPU and may be read from by all four GPUs in the four GPU environment. In other words the GPU Req field is a portion of DW that is dedicated to GPU . In an embodiment the GPU Req field includes bits through of DW .

The GPU Req field indicates whether GPU is requesting access to the semaphore. This field may be written to by GPU and may be read from by all four GPUs in the four GPU environment. In other words the GPU Req field is a portion of DW that is dedicated to GPU . In an embodiment the GPU Req field includes bits through of DW .

DW includes three fields a Last GPU Req ID of GPUs field a GPU Req field and a GPU Req field. The Last GPU Req ID of GPUs field indicates whether GPU or GPU was the last GPU to request access to the semaphore. This field may be written to by both GPU and GPU and may be read from by all four GPUs in the four GPU environment. In an embodiment the Last GPU ID of GPUs includes bits through of DW .

The GPU Req field indicates whether GPU is requesting access to the semaphore. This field may be written to by GPU and may be read from by all four GPUs in the four GPU environment. In other words the GPU Req field is a portion of DW that is dedicated to GPU . In an embodiment the GPU Req field includes bits through of DW .

The GPU Req field indicates whether GPU is requesting access to the semaphore. This field may be written to by GPU and may be read from by all four GPUs in the four GPU environment. In other words the GPU Req field is a portion of DW that is dedicated to GPU . In an embodiment the GPU Req field includes bits through of DW .

In a similar manner to that described above with respect to the fields of the data structure of are set in response to a GPU requesting access to the semaphore. Based on the data read from the data set each individual GPU is configured to compute an acknowledgement value ack . depicts a flowchart illustrating an example method for computing the ack.

In a step a requesting GPU generates a unique bit pattern denoted A based on a concatenation of bits read from DW and DW and an ID corresponding to the requesting GPU. With respect to bits and of DW are concatenated with bits and of DW . With respect to the ID corresponding to the requesting GPU is determined from a four location by seven bit wide look up table as illustrated in Table 3. The computation of the unique bit pattern A is summarized by the following equation DW2 16 8 0 DW1 24 16 8 0 AND Requesting GPU s ID Eq. 2 wherein DW represents the concatenation of bits and of DW DW represents the concatenation of bits and of DW and Requesting GPU s ID is the seven bit ID of the requesting GPU as determined from the look up table illustrated in Table 3.

In a step the requesting GPU computes the ack from bits contained in the unique bit pattern A. In particular the ack is computed in accordance with the following equation ack 6 5 OR 4 3 2 1 OR 0 1 Eq. 3 wherein A x represents the x th bit of the unique bit pattern A. The ack formula of Eq. 3 is used by all GPUs.

The computation of the unique bit pattern A of Eq. 2 and the ack of Eq. 3 may be implemented by hardware software firmware or a combination thereof. depicts an embodiment in which the computation of the unique bit pattern A is performed by an ADD gate included in logic of the GPUs in the four GPU environment. In this embodiment the input to ADD gate includes i the concatenation of DW and DW and ii the unique ID of each requesting GPU that may be obtained for example from a look up table. Alternatively the unique ID for each GPU may be obtained through appropriate use of a multiplexer or some other type of circuit as would be apparent to a person skilled in the relevant art s .

An example is now described to illustrate the computation of the ack in a four GPU embodiment. For this example suppose that GPU GPU and GPU each request access to the semaphore and that GPU does not request access to the semaphore. Suppose further that 1 between GPU and GPU GPU was the last to request access to the semaphore 2 between GPU and GPU GPU was the last to request access to the semaphore and 3 between all the GPUs GPU was the last to request access to the semaphore. This information is summarized in Table 4A.

Each GPU requesting access to the semaphore e.g. GPU GPU and GPU reads data from data set to determine whether that GPU may access the semaphore. First each GPU computes the concatenation of DW and DW . From the bit patterns shown in Table 4A this concatenation is equal to 1110001 as illustrated in the first row of Table 4B. Second each requesting GPU computes the unique bit pattern A in accordance with Eq. 2 by ANDing the concatenation of DW and DW with its unique GPU ID. The unique bit pattern A that each requesting GPU computes is illustrated in the third row of Table 4B. Then each requesting GPU computes an ack in accordance with Eq. 3. As illustrated in the fourth row of Table 4B only GPU computes an ack that is non zero. Thus only GPU is granted access to the semaphore even though GPU and GPU also requested access.

The request acknowledgement mechanism described above scales to an unlimited number of requesters. As mentioned above additional pairs of GPUs may be incorporated into the multi GPU environment by adding additional DWs to data set . For example illustrates an example configuration of data set for an embodiment in eight GPUs use the request acknowledgement mechanism described above to receive controlled access to a semaphore.

Embodiments of the present invention such as GPU A GPU B logic A logic B method of method of method of method of or any part s or function s thereof may be implemented using hardware software or a combination thereof and may be implemented in one or more computer systems or other processing systems. Useful machines for performing the operation of the present invention include general purpose digital computers or similar devices.

In fact in one embodiment the invention is directed toward one or more computer systems capable of carrying out the functionality described herein. An example of a computer system is shown in .

The computer system includes one or more processors such as processor . Processor may be a general purpose processor. Processor is connected to a communication infrastructure e.g. a communications bus cross over bar or network . Various software embodiments are described in terms of this exemplary computer system. After reading this description it will become apparent to a person skilled in the relevant art s how to implement the invention using other computer systems and or architectures.

Computer system can include a graphics processing system which performs graphics processing tasks for rendering images to an associated display . Graphics processing system may include the graphics hardware elements described above in reference to and such as GPU A and GPU B although the invention is not so limited. In an embodiment graphics processing system is configured to perform features of the present invention such as the multi summed semaphore mechanism and the request acknowledgement mechanism described above. Graphics processing system may perform these steps under the direction of computer programs being executed by processor and or under the direction of computer programs being executed by one or more graphics processors within graphics processing system .

Computer system also includes a main memory preferably random access memory RAM and may also include a secondary memory . The secondary memory may include for example a hard disk drive and or a removable storage drive representing a floppy disk drive a magnetic tape drive an optical disk drive etc. The removable storage drive reads from and or writes to a removable storage unit in a well known manner. Removable storage unit represents a floppy disk magnetic tape optical disk etc. which is read by and written to by removable storage drive . As will be appreciated the removable storage unit includes a computer usable storage medium having stored therein computer software and or data.

In alternative embodiments secondary memory may include other similar devices for allowing computer programs or other instructions to be loaded into computer system . Such devices may include for example a removable storage unit and an interface . Examples of such may include a program cartridge and cartridge interface such as that found in video game devices a removable memory chip such as an erasable programmable read only memory EPROM or programmable read only memory PROM and associated socket and other removable storage units and interfaces which allow software and data to be transferred from the removable storage unit to computer system .

Computer system may also include a communications interface and an audio interface connected to speakers . Communications interface allows software and data to be transferred between computer system and external devices. Examples of communications interface may include a modem a network interface such as an Ethernet card a communications port a Personal Computer Memory Card International Association PCMCIA slot and card etc. Software and data transferred via communications interface are in the form of signals which may be electronic electromagnetic optical or other signals capable of being received by communications interface . These signals are provided to communications interface via a communications path e.g. channel . This channel carries signals and may be implemented using wire or cable fiber optics a telephone line a cellular link an radio frequency RF link and other communications channels.

In this document the terms computer program medium and computer usable medium are used to generally refer to media such as removable storage drive a hard disk installed in hard disk drive and signals. These computer program products provide software to computer system . The invention is directed to such computer program products.

Computer programs also referred to as computer control logic are stored in main memory and or secondary memory . Computer programs may also be received via communications interface . Such computer programs when executed enable the computer system to perform the features of the present invention as discussed herein. In particular the computer programs when executed enable the processor to perform the features of the present invention. Accordingly such computer programs represent controllers of the computer system .

In an embodiment where the invention is implemented using software the software may be stored in a computer program product and loaded into computer system using removable storage drive hard drive or communications interface . The control logic software when executed by the processor causes the processor to perform the functions of the invention as described herein.

In another embodiment the invention is implemented primarily in hardware using for example hardware components such as application specific integrated circuits ASICs . Implementation of the hardware state machine so as to perform the functions described herein will be apparent to persons skilled in the relevant art s .

In yet another embodiment the invention is implemented using a combination of both hardware and software.

In addition to hardware implementations of GPU A and GPU B such GPUs may also be embodied in software disposed for example in a computer usable e.g. readable medium configured to store the software e.g. a computer readable program code . The program code causes the enablement of embodiments of the present invention including the following embodiments i the functions of the systems and techniques disclosed herein such as granting a GPU in a multi GPU environment controlled access to a shared resource ii the fabrication of the systems and techniques disclosed herein such as the fabrication of GPU A and GPU B or iii a combination of the functions and fabrication of the systems and techniques disclosed herein. For example this can be accomplished through the use of general programming languages such as C or C hardware description languages HDL including Verilog HDL VHDL Altera HDL AHDL and so on or other available programming and or schematic capture tools such as circuit capture tools . The program code can be disposed in any known computer usable medium including semiconductor magnetic disk optical disk such as CD ROM DVD ROM and as a computer data signal embodied in a computer usable e.g. readable transmission medium such as a carrier wave or any other medium including digital optical or analog based medium . As such the code can be transmitted over communication networks including the Internet and internets. It is understood that the functions accomplished and or structure provided by the systems and techniques described above can be represented in a core such as a GPU core that is embodied in program code and may be transformed to hardware as part of the production of integrated circuits.

It is to be appreciated that the Detailed Description section and not the Summary and Abstract sections is intended to be used to interpret the claims. The Summary and Abstract sections may set forth one or more but not all exemplary embodiments of the present invention as contemplated by the inventor s and thus are not intended to limit the present invention and the appended claims in any way.

