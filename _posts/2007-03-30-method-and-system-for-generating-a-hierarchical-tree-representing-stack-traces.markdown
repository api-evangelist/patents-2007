---

title: Method and system for generating a hierarchical tree representing stack traces
abstract: A system and method are provided to generate a hierarchical tree representing stack traces. In one embodiment, stack trace elements in a plurality of stack traces relating to profiling of an application executing at a first virtual machine are identified, the stack trace elements relating to profiling events being detected during the profiling of the application. The identified stack trace elements are sorted as one of parent elements; parent/child elements, or child elements based on a number of times a stack trace element has appeared in the plurality of stack traces and its relationship with other elements in the plurality of stack traces. A tree having nodes to represent the stack trace elements is created such that that the child elements branch from the parent/child elements or the parent elements, and the parent/child elements branch from the parent elements.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08336033&OS=08336033&RS=08336033
owner: SAP AG
number: 08336033
owner_city: Walldorf
owner_country: DE
publication_date: 20070330
---
Embodiments of the invention relate generally to the field of data processing systems. More particularly the embodiments of the invention relate to generating a hierarchical tree representing stack traces.

A memory on any computing system is a limited resource. No matter how fast computing systems become they always depend upon a finite amount of memory in which to run their software applications. As a result software developers should consider this resource when writing and developing software applications.

The Java programming language differs from many traditional programming languages e.g. C C by the way in which memory is allocated and deallocated. In languages like C and C memory is explicitly allocated and deallocated by the application programmer developer. This can greatly increase the time spent by programmers in tracking down coding defects in regards to deallocating memory. The Java programming language presents several features that appeal to developers of large scale distributed systems such as write once run anywhere portability portable support for multithreaded programming support for distributed programming including remote method invocation garbage collection and an appealing object model have encouraged Java use for systems with a size and complexity far beyond small applets. However the developers of these applications often encounter problems such as memory leaks performance and scalability problems synchronization problems and programming errors.

Java runtime environments e.g. Java virtual machine provide a built in mechanism for allocating and deallocating memory. In Java memory is allocated to objects. The Java virtual machine VM or JVM automatically handles the amount and allocation of memory upon an object s creation. The Java runtime environment employs a garbage collector GC to reclaim the memory allocated to an object that is no longer needed. Once the GC determines that the object is no longer accessible e.g. when there is no longer any references to it stored in any variables the fields of objects or the elements of any arrays etc. it reclaims the allocated memory. When objects in a Java application are no longer referenced the heap space the object occupied is to be recycled so that the space becomes available for subsequently created objects.

Although having garbage collection improves productivity it is not entirely immune from a class of bugs called memory leaks. A memory leak can occur when a program or in the case of Java the VM allocates memory to an object but never or only partially deallocates the memory when the object is no longer needed. As a result a continually increasing block of memory may be allocated to the object eventually resulting in an Out Of Memory Error OOME . In other words a memory leak occurs when memory is allocated but it is never or only partially reclaimed. Memory leaks can also occur when a data structure e.g. hashtable is used to associated one object with another and even when neither object is required any longer the association with the data structure remains preventing the objects from being reclaims until the data structure is reclaimed. Stated differently when a lifetime of the data structure is longer than that of the objects associated with it memory leaks are caused.

Memory leaks are of particular concern on Java based systems e.g. Java 2 Platform Enterprise Edition J2EE platforms which are to run twenty four hours a day seven days a week. In this case memory leaks even seemingly insignificant ones can become a major problem. Even the smallest memory leak in code that runs 24 7 may eventually cause an OOME which can bring down the VM and its applications or even all VMs running on a particular application server instance. This can cause critical performance problems.

It is generally preferred to profile memory use and debug memory leaks in an application code in the early stages of development to provide an early detection of memory problems long before the production stage. Although garbage collection makes code much safer because having the developer to explicitly delete objects from memory is prone to human error garbage collection is not a panacea. For example if the developer does not manage the references to the Java objects carefully it can result in a memory leak problem such as a reference to an object is stored within an instance or class field this reference may exist throughout the life of the application and unless desired is regarded a memory leak.

Within a distributed application server environment having thousand of concurrent users performance and scalability problems are typical. The causes of problems are various such as synchronization problems extensive access to shared resources e.g. database systems bad configuration settings etc. To provide consistency within such a system locks with various validity scopes e.g. VM local application server wide and system wide are used however deadlock situations and synchronization problems exist.

Several performance monitoring profiling and debugging tools are used to examine software applications to determine resource consumption within the Java runtime environment JRE . For example a profiling tool may identify the most frequently executed methods and objects created in an application. A type of software performance and debugging tool is a tracer. However such tools are very limited in detecting and exposing system inefficiencies and problems e.g. memory leaks while consuming great amounts of system resources by requiring overhead tasks such as starting and restarting of VMs in special modes. Further such tools are also limited in providing necessary information about system problems and the limited information that these tools may provide is not useful for applications comprising several thousand objects. This leaves developers with often insurmountable amounts of code to manually evaluate to track down the problem objects variables such as the specific class method calls etc. For example conventional profiling tools like Optimizelt and JProbe when used require restarting of VMs and servers which results in loss of production and system resources particularly when restarting a productive system. Moreover the starting of a server and its VMs further adds to the system overhead by increasing memory consumption which also harms the normal work of the server and server software. The restarting of the server adds overhead in regards to the Central Processing Unit CPU as the server would have to start up from scratch.

A system and method are provided to generate a hierarchical tree representing stack traces. In one embodiment stack trace elements in a plurality of stack traces relating to profiling of an application executing at a first virtual machine are identified the stack trace elements relating to profiling events being detected during the profiling of the application. The identified stack trace elements are sorted as one of parent elements parent child elements or child elements based on a number of times a stack trace element has appeared in the plurality of stack traces and its relationship with other elements in the plurality of stack traces. A tree having nodes to represent the stack trace elements is created such that that the child elements branch from the parent child elements or the parent elements and the parent child elements branch from the parent elements.

The above attributes may be implemented using a computer program a method a system or apparatus or any combination of computer programs methods or systems. These and other details of one or more embodiments of the invention are set forth in the accompanying drawings and in the description below.

As used herein references to one or more embodiments are understood as describing a particular feature structure or characteristic included in at least one implementation of the invention. Thus phrases such as in one embodiment or in an alternate embodiment appearing herein describe various embodiments and implementations of the invention and do not necessarily all refer to the same embodiment. However they are also not necessarily mutually exclusive. Descriptions of certain details and implementations follow including a description of the figures which may depict some or all of the embodiments described below as well as discussing other potential embodiments or implementations of the inventive concepts presented herein.

Java applications can vary in both size and complexity. In addition certain large Java application e.g. 10 000 classes and 1 000 000 methods with 100 000 000 method calls may run 24 7 long living applications . Within a long living application major problems e.g. memory leaks are expected to occur in terms of both stability and performance. For example a single long living object that increases in size by 1 byte between each GC cycle will eventually cause the application and VM to crash due to an OOME. Although such a crash may take a long time e.g. 1 bytes per GC cycle millions of free bytes of memory it will inevitably occur. Furthermore when dealing with such long applications and productive systems mere use of commercial and non commercial conventional profiling tools and debugging tools having JVMPI and JVMTI profiling interfaces and JVMDI debugging interface respectively are not suitable and cannot provide the necessary profiling debugging and monitoring information. Even when dealing with suitable systems such conventional tools cause high memory footprints and are not effective without having to restart the VM and are known to disturb user sessions inherent to the VM.

In one embodiment a vendor specific proprietary interface and implementation are provided as described throughout this document e.g. see . This implementation can be made an integral part of a VM e.g. JVM SAP JVM and allow for on demand examining of system problems including in productive systems without restarting the underlying VM. These system problems can range anywhere from memory leaks to performance scalability and synchronization problems. In one embodiment on demand refers to examining e.g. profiling tracing debugging and or monitoring system problems in runtime such as without the need for restarting the underlying VM.

In one embodiment profiling is performed using profiling infrastructure that resides at backend VM that is being profiled. Profiling infrastructure includes a number of components as described in to perform trace profiling. In one embodiment using profiling infrastructure no default profiling agent or default implementations and instances e.g. JVMPI JVMTI are needed or employed. Without having the default agent employed a direct communication is established between backend VM and frontend VM via server Java API and client Java API and profiling protocol . Any number of VMs may be used as backend or frontend VMs. Furthermore when performing profiling trace in an offline profiling mode an external profiling file is used to store profiling trace data. Starting and stopping of profiling trace maybe performed in a number of ways such as using a Graphical User Interface GUI based monitoring tool . The profiling data is written using various components of profiling infrastructure and displayed to the user using any number of display devices. These display devices may include GUI based display devices. In one embodiment using profiling infrastructure on demand profiling is performed which refers to performing the profiling without restarting the underlying VM . Stated differently the profiling is performed in runtime without any interruptions or restarting of the underlying VM .

Profiling infrastructure can be used for starting profiling traces for certain users or applications such as using profiling annotations. Profiling annotations refer to a concept of tagging threads with certain semantic information from an application server environment. Here Java API is provided which allows for annotating a Java thread with one or more of the following information user name application name request identifier and session identifier. If profiling traces are started a thread filter for such information is provided and thus a profiling trace can be started only a certain user or application. A Java API is also provided on the client side such as client Java API that communication with server Java API via a profiling protocol . Client includes frontend VM which includes any arbitrary VM that represents a native application that speaks e.g. in case of online profiling the profiling protocol and or knows e.g. in case of offline profiling the profiling file format of profiling file . Backend VM is the one that is being profiled.

It is to be noted that the VMs may not be VMs and instead be any program or application e.g. a native application or program that is compatible with the components of and related to the profiling infrastructure . For example the frontend VM is illustrated here merely as an example for brevity and clarity. It is however contemplated that a frontend VM or any VM for that matter is not necessary for embodiments of the present invention. For example in one embodiment instead of employing a VM any program or application that is compatible with the mechanisms and components described herein is acceptable and functional and can be employed and implemented. Stated differently for example any program that can read and speak the described components e.g. components of profiling infrastructure protocols e.g. socket communication protocol APIs e.g. server and client side APIs parameters profiling files etc. is compatible and can be used instead of a VM such as the frontend VM . This is applicable throughout this document wherever there is mention of a VM .

The illustrated mechanism provides both an online mechanism for interactive profiling and an offline mechanism for non interactive profiling. When starting profiling the backend VM any profiling parameters including the desired mode e.g. an online or offline mode are specified. If started in the online mode the profiling backend VM opens a port and waits for a connection. The profiling frontend VM attach to this connection via the profiling protocol and Java APIs . The starting running and stopping of profiling and tracing is then performed. In one embodiment online profiling is performed via internal components such as Java APIs or external components such as a monitoring tool e.g. Java VM monitor . Online profiling may also be performed using a command line such as java agentlib jdwp transport dt socket address 8000 suspend n or bin java monjdwp transport dt socket address 8000 server y. For the offline mode profiling files are used to store profiling data and a special interface is provided to couple the backend VM with the frontend VM via client Java API to allow for starting and stopping of traces. In some cases server Java API can also be used to perform offline profiling. Offline profiling may also be performed using monitoring tool and or using a command line such as java XX Profiling XX ProfilingAlloationTrace.

When the profiling mechanism is started in the offline or non interactive mode the profiling information is stored in an external medium e.g. file system and can be analyzed after the profiling run. This way the profiling information may then be used for port mortem analysis however traces can still be started and stopped in an interactive manner. In contrast the online or interactive mode allows for analyzing the profiling information online. For example if a class statistic trace has been enabled and a garbage collection happens the profiling information can be directly accessible through a stream based interface.

Furthermore to have no performance degradation in case of running in a non profiling mode e.g. when no profiling is being performed VM may maintain a global flag indicating whether profiling is enabled or not. The flag may be requested each time any profiling data is written. For example a profiling trace for garbage collection events may be implemented in the following way when a garbage collection is performed the global profiling flag is checked. If profiling is enabled the flag is checked to indicate whether garbage collection events are to be profiled. This can also be done via some VM global flags. If the garbage collection trace is enabled the backend VM may be called to collect the desired data.

In one embodiment profiling controller framework is used for starting and stopping profiling runs and traces. Controller framework allows the user to specify profiling options or settings that the user would want to enable. These profiling settings to be applied are divided into distinct areas such as functional profiling settings and filter settings. The functional profiling settings determine the area to be profiled e.g. allocation trace reference trace etc. while the filter settings define the validity scope e.g. user session thread VM etc. of the functional profiling settings. For example an allocation trace can be started for a specified user. Java API and graphical user interface GUI are provided in communication with profiling controller framework . GUI is used to enable the user to directly specify the desired profiling settings without any system guidance. Additionally a wizard similar interface is provided. GUI also allows for an expert mode and for a wizard guided mode. Controller framework may include a profiling evaluation module for analyzing a performed profiling run. For example the Java API can be used for getting the complete low level profiling information gathered within a corresponding profiling run as well as for getting condensed problem oriented profiling information. The condensed profiling information may be used to directly pinpoint various problematic areas. For example if the user has performed performance analysis using a time based sampling approach the Java API may enable a client to directly receive information about the time consuming methods. The user may view this information via GUI at a display device at the client.

Controller framework is used for starting and stopping profiling runs and traces which includes starting and stopping various profiling options further described later . For each profiling run the user is free to determine the set of traces to be started. For example the user may start an allocation trace using the allocation trace module together with a class statistic trace. A user defined name may be assigned to each non interactive profiling run and used later on to evaluate the gathered profiling information. Considering interactive profiling runs the user is able to evaluate the profiling information online and therefore the profiling information may be available through a stream based interface.

Furthermore controller framework may be independent of the surrounding application server environment. Stated differently controller framework refers to the underlying VM currently executing a profiling request e.g. starting an allocation trace . The corresponding application server infrastructure may be responsible for starting and stopping the desired trace on other VMs. For example if an allocation trace is started for a certain user session at VM the application server infrastructure accounts for starting the allocation trace in the VMs executing requests for the user session. Controller framework enables the application server infrastructure to specify thread filters . A thread filter may contain the following information client user session identifier request identifier application name and component name. On the one hand controller framework may provide a facility to tag these pieces of information to a thread. On the other hand if a certain profiling run is to be started a thread filter is provided. Hence for example a trace may be stared only for a certain user. Accordingly the application server is responsible for setting the current thread state e.g. client user session identifier etc. . In one embodiment an application server includes a J2EE server.

In one embodiment the profiling options include functions cases such as memory debugging e.g. memory leak detection performance analysis synchronization monitoring and application debugging e.g. detecting called methods . These profiling functions further include a number of sub functions such as heap dump coupling of debugging and profiling infrastructure time based sampling memory based sampling method statistic allocation trace silent allocation trace allocation statistic trace loitering trace garbage collection trace garbage collection statistic class statistic trace permanent generation statistic trace local garbage collection trace shared garbage collection statistic other traces such as reference trace object death trace object movement trace shared closure trace global reference trace method trace time method trace input output I O trace monitor trace shared lock trace method count trace execution line trace scheduler trace and exception trace.

Solving a memory leak problem may include a couple of processes such as identifying the Java classes or objects caused the memory leak and determining where in the infrastructure or application code the leak occurred. Many of the sub functions can be used to solve memory leak problems. Class statistic trace functionality is provided to help identify the Java classes that cause memory leaks. Class statistic trace includes getting an overview of all living classes within particular VM including class name class loader description the number of object instances and the accumulated net and gross size of all object instances. The information may be traced after each full local garbage collection. Reference trace includes detecting the objects holding references to leaking objects. It also provides the complete reference chain to a specific object instance. This information may also be available after one full local garbage collection.

If the class statistic trace reveals that specific objects are created over and over again using the allocation trace module the allocation trace may be enabled to check for the exact allocation place. Using the allocation trace module the allocation trace enables the user to specify a class filter . Silent allocation trace is a derivate of allocation trace. When an allocation trace is started each object which is allocated and adheres to a user defined class filter is assigned to an object identifier. Although the allocation trace enables the user to get informed about object allocations the user may not get the information when the corresponding object dies. In that case object death trace allows the user to check for those objects are garbage collected and no longer alive. Object movement trace makes allows the checking of why certain objects are kept alive while the allocation trace allows for getting information when certain objects are created.

Shared closure trace provides for getting object information each time shared closures are created deleted copied or mapped. Global references may be used across multiple invocations of a Java Native Interface JNI method and also across multiple threads. A global reference remains valid until it is freed by the programmer and ensures that the referenced object is not garbage collected. For relatively complex scenarios a dump of the current Java heap is performed. The heap dump function allows for getting a dump of the current overall object state.

In some cases memory leaks occur due to the fact that a failed clean up operation. For example considering a cache based on shared closures at regular intervals the cache might be cleared. If the clean up operation were interrupted at the end of the operation e.g. due to a VM abort exception most cache entries would probably be deleted however some entries might still exist. Thus a memory leak may be resulted if the cache were not able to remove any of the existing entries. The detection of this kind of memory leak could be difficult since most object instances of the corresponding class are removed and merely a few exist. Thus class statistic trace may not be the right choice to detect such a memory leak. One characteristic of this problem is that the memory leak is caused by objects which may not be used any longer. The loitering trace performed via loitering trace module facilitates the detection of objects which are not used for a long time.

Various performance problems may be caused by any number of reasons such as choosing the wrong algorithm for a problem repeatedly recalculating the same result excessive allocating of temporary objects too many I O operations or transferring too much memory etc. Profiling helps improving the performance by determining what is it that is to be optimized. Profiling identifies parts of the overall system for which optimization can have an impact on the overall performance. Optimizing a function which only amounts to a miniscule fraction of the overall runtime may not have noticeable benefits. Profiling also determines how the optimization is to be done. Checking for optimization options of those parts that are identified during the first process. Time based sampling is used to get an overview of methods which consume the most CPU resources of the application. Time based sampling works by dumping a stack trace of the currently active thread at regular intervals. Memory based sampling works analogously to the time base sampling however instead of dumping a stack trace in time intervals t stack trace is sampled after an amount of memory M is allocated on the Java heap. This way those methods that allocate the largest number of bytes on the Java heap are identified.

When time based sampling shows that a method uses a large amount of time the reason for this resource consumption might be that a call of the method is expensive or the method is called very often. To find out how many times a particular method was called method statistic trace may be used. Together with time based sampling method statistic trace may also allow for calculating the average runtime of a specific method e.g. the cumulative time divided by the method count . Method trace is used to get more detailed information than method statistic. Time method trace can be used to provide very detailed trace information. Time method trace provides for detecting method calls that for any number of reasons take a particularly long time. To see if garbage collection is properly configured or if a particular problem related to garbage collection exists local GC statistic is used which includes dumping a statistical entry for each local garbage collection partial and full for each garbage collection run. Shared GC statistic is emitted when a local GC detects that a shared GC has happened and has not been dumped yet. The shared GC statistic contains the number and size of the collected shared classes shared interned strings and shared classes.

Another source of performance problems is related to I O. These I O related problems include a network connection being operated at its bandwidth maximum the latency being too high an external system being overloaded etc. To check for an I O problem I O trace allows for tracing the timing of each I O operation. I O trace can be used in analysis to check for operations where huge amounts of data were transmitted the I O operation took an extraordinary amount of time or a huge amount of small I O operations was performed.

Java has an explicit support for multithreading and concurrency at the language level. Although these welcome features the typical problems with multithreading and concurrency are deadlocks race conditions thread starvation and scalability problems. Synchronization monitoring is provided to detect such problems. For example synchronization monitoring includes monitor trace that identifies deadlock or scalability problems and gathers information about locks used inside a VM. To find synchronization problems a thread trying to acquire a lock is identified and once it is identified the lock is freed by the thread. Shared lock trace is used to identify deadlocks between VMs and scalability problems of a server instance. Shared lock trace provides information about different kinds of shared lock activities like entering and leaving. Further for such problems above scheduler trace is used to know why a thread was scheduled and why it gave up control of the CPU and for how long the entire VM was waiting on external I O or just sleeping.

In one embodiment application debugging is used to provide those the debugging functionalities that are not supported by conventional debugging instances and protocols such as JVMDI Java Debug Wire Protocol JDWP etc. For example application debugging covers functionalities such as call coverage and line coverage. Regarding call coverage method count trace may deliver a number of calls to a method. Regarding line coverage execution line trace may deliver information about code lines that were executed. Method call trace is used to find all methods that are called. When the method call trace is enabled the VM counts method calls and when the method call trace is disabled the VM dumps the collected information such as name and signature of a method and the number of times it was called. Execution line trace may be used to find out the lines of code that are not executed. When the execution line trace is triggered it enables the VM to write out information about the method and code line each time a byte code is interpreted and or the line number changes. Such information can help the developer find out the lines of code that are not covered particular test cases.

Method trace may be employed to trace or profile the debugging process of an application. For example the method trace is used to find out what has happened before the program reaches a certain point. Such information may be used to trace back the program flow and find out in which way the program reached that point of code. Exception trace is another functionality that may be employed to trace or profile the debugging process of an application. This information can be used to trace back the reasons for exceptions that followed up and for different execution branches.

In one embodiment a dedicated Java API and a GUI is provided to allow for starting and stopping of various functionalities and uses e.g. allocation trace loitering trace GC trace and other traces and for getting the corresponding profiling and tracing results. To determine and analyze the profiling and tracing results an expert mode and or a guided mode are provided. For example a guided mode may directly pinpoint any problem areas.

Profiling infrastructure is compatible with multiple clients. For example depending on the surrounding application server infrastructure and whether any clients are handled in a special way the profiling infrastructure may perform in compliance with several clients simultaneously and remain multiple client compliant. Profiling infrastructure also allows for restricting profiling runs to certain clients while the surrounding application server environment may assure that the current client information is assigned to the respective thread. Furthermore profiling infrastructure may be started on demand which includes performing profiling infrastructure functionalities e.g. profiling tracing etc. without restarting the entire application server or even the underlying VM . If no profiling option is enabled by a certain user there is no impact on the response time caused by the profiling infrastructure . However if profiling is enabled it may depend on the started profiling options and filter settings about how the overall system performance is influenced. For example if a method trace is started on an application server without any filter settings e.g. user classes etc. the performance may decrease to an extent. Therefore the profiling infrastructure as well as the application server infrastructure must provide options to restrict profiling runs. This way profiling may be enabled for a particular user or session while users and sessions remain unaffected. In addition profiling infrastructure provides reasonable and necessary filter settings for various profiling traces.

Class filters are implemented to allow for limiting profiling trace outputs by limiting the process of profiling to for example specific traces. For example if a developer seeks to profile only Java object allocations which refer to java.lang.HashMap instances then using class filters a profiling allocation trace with a class filter applying exclusively to java.lang.HashMap instances is started. Thread filters relate to profiling annotations e.g. specifying annotations such as when an allocation trace exists. Thread filters may also be used by the user to specify when and or where a trace is to be triggered and or used. Buffer framework is used to compress and decompress any type of data or information that is being communicated stored etc. Communication framework is used to facilitate communication of any data or information between and within various components elements modules systems servers VM etc. Communication framework is also used to determine and facilitate the storing of data or information such as storing the data using files or socket connections.

ID service is employed to specify variables such a class a name of the class etc. to assign identification to them. Once class class names etc. are assigned an ID e.g. a number they are then mapped with each other and with various components and variables via a mapping packet instead of mapping by names. Using ID service the same can be done with threads and methods. For example by assigning IDs instead of names to threads and methods when dumping is performed the IDs of threads and methods are dumped rather than their names. This technique of using IDs e.g. numbers instead of using the names is efficient fast and saves memory.

For example an allocation event is considered. ID numbers are mapped to various packet names such as java.Hashtable is mapped to 2000 the thread named main is assigned 3 and the user named Hansi is assigned 7 . Stack trace is then commenced using command lines such as com.sap.test line 30 com.sap.submethod line 2003 etc. The even information may then be provided as 2000 3 etc. It is known that ID number 2000 was mapped to the underlying hashtable while ID number 3 was mapped to the thread. Using these ID s names e.g. main Hansi etc. are not needed and instead IDs are used which provides an easier technique for packet name mapping. Similarly object ID service is used to assign IDs e.g. numbers to objects so the IDs can be used to for example identify and compare the objects instead of using object names.

In one embodiment profiling information and any other relevant data is displayed at a display device via GUI at a client so that a user can access and evaluate the displayed information. The information may also be stored at a database and or file system for subsequent retrieval and analysis. Although Java components such as J2EE server Java VM Java heap and Java memory errors etc. are discussed here for simplicity and brevity it should be noted however that the underlying principles and embodiments of the present invention may be implemented within any type of object oriented and runtime environments. Moreover it should be noted that requirements and examples used in this document do not necessarily reflect the real values that a system or program would actually produce. For example garbage collection may be invoked multiple times while checking the VM heap memory size so that there are different VM implementations and according to a relevant VM specification a given VM implementation might not clean up the memory immediately after it has been requested to do so. Thus to be sure that a memory cleanup is provoked the memory size may be checked and the garbage collection may be invoked again as necessary.

Garbage collection as described here includes a process designed to identify and reclaim blocks of memory that are dispensed by a memory allocator but are no longer alive or live e.g. no longer being used as determined for example by not being reachable from any currently referenced objects or entities . Garbage collection can sometimes be handled as a background task by runtime systems rather than as an explicit task by user programs. Garbage collection can also be handled as an inlined task. Garbage collection can be used to reclaim memory in runtime systems and there are some well known garbage collection algorithms e.g. reference counting mark sweep mark compact and copying algorithms .

A VM e.g. VM is an example of a runtime system. A VM refers to an abstract machine that includes an instruction set a set of registers a stack a heap and a method area such as a machine or processor. A VM essentially acts as an interface between program code and the actual processor or hardware platform on which the program code is to be executed. The program code includes instructions from the VM instruction set that manipulates the resources of the VM. The VM executes instructions on the processor or hardware platform on which the VM is running and manipulates the resources of that processor or hardware platform so as to effect the instructions of the program code. For example a Java source program can be compiled into program code such as bytecode. Bytecode can be executed on a VM such as JVM running on any processor or platform. The JVM can either interpret the bytecode one instruction at a time or the bytecode can be further compiled for the real processor or platform using a just in time JIT compiler.

The illustrated VM includes a JVM e.g. SAP JVM which is used as an example however other examples of VMs which can be used in various embodiments include Advanced Business Application Programming ABAP language VMs Common Language Runtime CLR VMs and the like. ABAP is a programming language for developing applications for SAP systems such as SAP R 3 system which is a widely installed business application system developed by SAP AG of Walldorf Germany. The CLR is a managed code execution environment developed by Microsoft Corp. of Redmond Wash. For simplicity and brevity the discussion in this document focuses on virtual machines and in particular Java virtual machine but it is to be understood that the techniques described herein can also be used with other types of runtime systems.

A runtime system includes a code execution environment that executes instructions or code in user requests and that provides runtime services for that code. Code runtime services may include functionality such as process thread and memory management e.g. laying out objects in the server memory sharing objects managing references to objects and garbage collecting objects . Enhanced runtime services may include functionality such as error handling and establishing security and connectivity.

The illustrated server includes a J2EE server engine node which supports Enterprise Java Bean EJB components and EJB containers at the business layer and Servlets and Java Server Pages JSP at the presentation layer . It is understood that processes taught by the discussion above can be practiced within various software environments such as for example object oriented and non object oriented programming environments Java based environments such as a J2EE environment or environments defined by other releases of the Java standard other environments e.g. a .NET environment a Windows NT environment each provided by Microsoft Corporation and the like.

Online profiling is started via Java APIs e.g. server and client Java APIs using monitoring tools e.g. Java VM monitor and or using command lines. If the profiling is to be performed offline the offline profiling mode is triggered for for example non interactive profiling. Offline profiling can also be started using monitoring tools using command lines and or via Java APIs as described above. At processing block any profiling data obtained from offline profiling is stored at an external source such as a profiling file. The data at the profiling file may be stored in zipped format. At decision block whether the process of profiling be continued is determined. If yes the profiling continues with decision block . If not the profiling status is switched to the non profiling mode at processing block . This non profiling mode is maintained at processing block .

Since most stack traces are different near the top of a stack trace column as shown in tree is generated and used to minimize the number of times various stack traces or elements are stored. For example as illustrated common stack trace elements such as stack trace elements H A I and even stack trace element T are plotted and stored in their respective nodes in tree as and when necessary. By reducing the number of nodes and the number of times a node is stored in tree the memory consumption in the underlying VM is greatly reduced. For example when tree is compared with the hash table of it can be observed that for the same number of stack trace elements the hash table has twenty one 21 entries while the tree has merely eleven 11 nodes which greatly reduces memory consumption in the VM.

Furthermore when a profiling tool is used at the VM to perform profiling sessions it can use the same sharing of stack trace elements at nodes without having to monitor the entire tree or going all the way up to the commonest node H . For example when a new stack trace element such as stack trace element M is added via node there remains no need for the profiling tool to re evaluate the two preceding common stack trace elements H A at nodes but rather simply look at the most recently added stack trace element M at node because the two common stack trace elements H A at nodes are not re plotted or re stored. In this example the newly encountered stack trace element M is added via node and branched out of the last stack trace element A at node . Further memory and profiling performance improvement is archived by having the most recent stack trace elements at nodes of each thread stored in tree in addition to the corresponding stack trace elements at nodes . Using this technique the underlying VM can determine efficiently which stack traces remained since the last time a stack trace was requested for the thread and thus tree is to be searched starting from the nodes of the last or most recent stack trace elements at nodes . This is especially useful when stack traces are requested very often e.g. when every allocation of an object is to be traced in a profiling session . Hence both the memory consumption and performance at a VM and therefore CPU efficiency are improved by having stack traces at nodes represented in a tree like hierarchical structure .

In one embodiment stack trace elements at nodes are detected and then sorted as parent stack trace elements at parent nodes parent child stack trace elements at parent child nodes and child stack trace elements at child nodes . For example since element H at node common to every other element at nodes it is provided once and as a parent to other elements at nodes by having the parent child elements at parent child nodes branch out of parent element H at parent node and child elements at child nodes further branching out of the parent child elements at parent child nodes . Now stack trace elements at nodes are regarded and sorted as parent child elements at parent child nodes because they are child elements to the parent element H at parent node but they are parent elements to the child elements at child nodes . As illustrated stack trace child elements at child nodes do not have any elements branching out of them. However if a new stack trace element was to be added to a child element the child element at child node would then become a parent child element at parent child node. For example referring to if a new element E via a new node is to be added to the child element T at child node it would turn the child element T at child node into a parent child element at parent child node and the new element E at node is then be classified as the child element E linked to the element T at node via branch and node . The word representing the stack trace link or string or the like then looks like HATE at nodes and linked by branches . Branches are used to link nodes .

Now referring back to tree may include a TST that provides an implementation of an N ary search tree for large values of N representing stack trace elements here N being the size of the alphabet . For example for brevity simplicity and clarity tree encodes the following words as stack trace elements and strings of stack trace elements HAT HAM HAS HAD HOT HIT and HIP . In one embodiment each node having stack trace elements and relevant information are linked together via a number of branches . Nodes may further contain characters and identifications of various sorts e.g. alphabet number alpha numeric etc. corresponding to each line in each method of a stack trace that is relevant to a profiling event detected from profiling at the underlying VM. Using this technique only a small amount of storage or memory is need and consequently a large amount of storage or memory is prevented from being consumed. Although a node may be linked using any number of branches e.g. node has three branches linking to nodes but not all nodes e.g. nodes or branches e.g. branches linking the node e.g. node may be used for each search.

When searching for a given string of stack trace element corresponding to a method relating to a profiling event the process starts at the node having the most comment stack trace element such as in the illustrated embodiment at top node H and the first character of the string is then compared to that of the node . If the character in the string is lower than that of the character of the node another link e.g. left link to node A is followed and the same process or action is performed at that node . If the character in the string is higher than that of the main node another link e.g. right link to node I is followed and the same process is performed at that node . If the character in the string is the same as that of the character of the main node the next or second character of the node is compared and the process continues with the middle link to node O . The process continues on with the following nodes in each case until a match for the last character is found and as such the string is found at tree . If no match is found tree does not contain the string. Using this technique even for a large N tree uses only a little memory and is used to store stack traces and other relevant information at nodes .

Each stack trace encountered is determined using the aforementioned procedure from the start with the most common node to the next until either a match is found or not. A comparison of the tree with the hash table of indicates that most common stack traces are found in the bottom frames or rows of the hash table such as rows and having common elements as H A etc. corresponding to the common elements such as H A etc. in the tree . In one embodiment a complete stack trace is found in tree and a corresponding identification ID is returned which may have been previously added to each node . If a complete stack trace is not found a new node having the stack trace is added to complete the stack trace tree . Using this technique the already known parts of the stack trace are known and thus the ID s of the one or more stack traces that contain the one or more shared frames is are removed. Therefore when a mapping between the stack trace and its ID is performed merely the new nodes corresponding to the new or top level frames of a hash table are dumped and the common nodes corresponding to the common or low level frames of a hash table are referred to by the ID of the stack trace that contains them too. This technique can be later used by an application that examines the data such as in the matter that instead of storing an entire stack trace it can store merely the new nodes referencing the stack trace and therefore further saving the memory and storage.

Since for a given thread how much of a stack trace has changed since the last time it was received can be detected e.g. by noticing method returns another optimization can be done to reduce CPU time. For example for every thread the last stack trace is stored for every frame in a hash table for which the node in the tree is matched. Thus if a new stack trace is to be received the newest node for a corresponding thread is detected since the newest nodes or the higher frame rows of a hash table are the most different from each other. This means the search for the matching frame can be started in the tree directly at the node corresponding to the last matching frame which saves a great deal of CPU time. For example if a profiling tool performing profiling at a VM needs to search for the newest stack trace or stack trace element it merely needs to check the most recent nodes instead of going through the entire tree and there is no need to go up to the main node . This saves a great amount of CPU time.

For example in comparison with a hash table such as the one illustrated in the search starts at the main row and continues up to the last row such as row to encounter the newest stack trace such as stack trace element T following the TOS . In one embodiment using the tree when a VM or a profiling tool at the VM or the like needs to go directly to a recently added stack trace element such as stack trace element T it needs to go directly to the node matching that stack trace element and does not have to go up to the main node H which is already known and thus there remains no need to go up to it. Hence this technique saves CPU time by limiting the amount of search as well as memory space by limiting the number of nodes such as 11 nodes for tree as opposed to 21 nodes for the hash table of . Furthermore any nodes of nodes of tree that are not being used or the information provided by these nodes is longer necessary such nodes may be deleted to further save memory and CPU time and provide room for newer nodes to be linked.

In one embodiment the commonality of stack trace elements before they are placed at various nodes is determined by for example detecting the number of time a stack trace element has occurred in various stack traces. For example a parent node includes a parent stack trace element that is more common than a parent child element at a parent child node which is more common than a child stack trace element at a child node . In other words for example a parent stack trace element e.g. stack trace element H at node appears in or is associated with or is common to a greater number of stack traces in this example element H at node is associated with or common to all stack traces than a parent child stack trace element e.g. stack trace element A at node which appears in or is associated with or is common to a greater number of stack traces in this example element A at node is associated with stack traces having elements T M S and D at nodes and respectively than a child stack trace element e.g. stack trace element T at node . Stated differently parent stack trace elements are likely to be common to more stack traces than parent child stack trace elements that are common to more stack traces than child stack trace elements but are common to fewer stack traces than parent stack trace elements. Throughout this document for brevity and simplicity the number of occurrences of stack traces elements at nodes in various stack traces is references how common a stack trace element at nodes is to various stack traces and thus the higher the number of occurrences in stack traces the more common the stack trace element compared to other stack trace elements and conversely the fewer the number of occurrences in stack traces the less common the stack trace element.

Similarly nodes O T P are also shown to be implemented a bit differently from the way they are illustrated in tree . Here in one embodiment node P branches from node T which branches from node O branching from the most common node H via the middle node I . It is contemplated that node may also branch directly from node H . Nodes H O T and P form the example stack trace string codes HOT and HOP . In the middle link node T branches from node I which branches from node H forming the example stack trace string code HIT .

It is contemplated that any references to Java based components such as Java application server Java VMs Java stack traces etc. are provided as examples and that the mechanism and other embodiments of the present invention can also be used with other non Java based environments and components. Furthermore a backend VM may reside at the same J2EE engine as the tree generation module or at another J2EE engine or at another server. A server and a client may include servers and clients similar to server and client respectively of .

In one embodiment ID service identifies each stack trace at the underlying VM and works with tree generation module to generate the tree . Stack traces are generated during a profiling session of an application e.g. Java application at a VM. A profiling session may include various traces etc. that are performed on the application running at the VM as described elsewhere in this document. Tree contains nodes to provide the stack trace information being identified and gathered by the ID service and plugged into the nodes by the tree generation module . The illustrated embodiment of the tree generation module further contains node addition movement module to provide the addition and movement of nodes as illustrated in . In one embodiment stack traces are deleted as they come to being provided by tree . Similarly any nodes of tree that are not being used or are the information provided by these nodes is longer necessary such nodes may be deleted to further save memory and CPU time and provide room for newer nodes to be linked.

At processing block the stack trace elements are sorted as parent elements parent child elements and or child elements as described elsewhere in this document. A tree generation module working with the ID service creates a tree or tree like hierarchical structure e.g. TST is generated at processing block . The tree includes nodes that are used to represent the detected and identified stack trace elements. The tree may be generated one node at a time and remain dynamic with changing profiling and stack trace information system requirements and user needs or desires saving memory saving CPU time and the like. At decision block whether any additional stack trace elements are detected and identified and that are to be added to the tree is determined. If yes one or more nodes representing the new stack trace elements are added to the tree at processing block . The addition of new nodes is performed using anode addition movement module of the tree generation module. If not the process continues with decision block where a determination is made as to whether any nodes are to be moved within the tree. This may be done for various reasons changing stack trace information changing profiling user choice system choice providing a better and more efficient representation of the tree saving memory saving CPU time and the like. If yes the nodes that are to be moved are moved to a better or more desirable place in the tree by linking the moving nodes to one or more existing nodes as necessary at processing block . The move is performed using the node addition movement module of the tree generation module. If not the process continues with decision block where a determination is made as to whether the tree has become to large having unnecessary or unwanted or unused nodes. If yes in one embodiment one or more nodes that are unnecessary or unwanted or unused are removed from the tree. In another embodiment the entire tree may be deleted and recreated with necessary and desirable nodes such as when this process saves more memory and or CPU time than simply removing the nodes from the tree. If not the process continues with processing block by sending the tree to the virtual machine at the client. At processing block the tree is then displayed via a viewer or display device coupled to the client for the user to view and evaluate the tree.

Processes taught by the discussion above may be performed with program code such as machine executable instructions which can cause a machine such as a virtual machine a general purpose processor disposed on a semiconductor chip a special purpose processor disposed on a semiconductor chip etc. to perform certain functions. Alternatively these functions may be performed by specific hardware components that contain hardwired logic for performing the functions or by any combination of programmed computer components and custom hardware components.

One or more modules components or elements described throughout this document such as the ones shown within or associated with the on demand profiling infrastructure of profiling mechanism of may include hardware software and or a combination thereof. In a case where a module includes software the software data instructions and or configuration may be provided via an article of manufacture by a machine electronic device hardware. An article of manufacture may include a machine accessible readable medium having content to provide instructions data etc. The content may result in an electronic device for example a filer a disk or a disk controller as described herein performing various operations or executions described. A machine accessible medium includes any mechanism that provides i.e. stores and or transmits information content in a form accessible by a machine e.g. computing device electronic device electronic system subsystem etc. . For example a machine accessible medium includes recordable non recordable media e.g. read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices etc. as well as electrical optical acoustical or other form of propagated signals e.g. carrier waves infrared signals digital signals etc. etc. The machine accessible medium may further include an electronic device having code loaded on a storage that may be executed when the electronic device is in operation. Thus delivering an electronic device with such code may be understood as providing the article of manufacture with such content described above. Furthermore storing code on a database or other memory location and offering the code for download over a communication medium via a propagated signal may be understood as providing the article of manufacture with such content described above. The code may also be downloaded from a remote computer e.g. a server to a requesting computer e.g. a client by way of data signals embodied in a propagation medium e.g. via a communication link e.g. a network connection .

Client systems may execute multiple application or application interfaces. Each instance or application or application interface may constitute a user session. Each user session may generate one or more requests to be processed by server . The requests may include instructions or code to be executed on a runtime system such as VM on server such as the requests made via the on demand profiling infrastructure and its components and modules as described throughout this document.

In addition to what is described herein various modifications may be made to the disclosed embodiments and implementations of the invention without departing from their scope. Therefore the illustrations and examples herein should be construed in an illustrative and not a restrictive sense. The scope of the invention should be measured solely by reference to the claims that follow.

