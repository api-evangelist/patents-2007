---

title: Fast depth of field simulation
abstract: A method, system, and computer-readable storage medium are disclosed for rendering a scene with a simulated depth of field blur. In one embodiment, the scene comprises a plurality of polygons, each polygon comprises a respective plurality of vertices, and each of the vertices has a respective depth. A respective blur radius may be determined for each vertex of each polygon as a function of the depth of the vertex. A respective blur radius may be determined for each pixel in each polygon based on the blur radii for the vertices of the polygon. Each pixel in each polygon may be rendered using the respective blur radius determined for the pixel.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08035641&OS=08035641&RS=08035641
owner: Adobe Systems Incorporated
number: 08035641
owner_city: San Jose
owner_country: US
publication_date: 20071128
---
The present invention is directed to computer systems and more particularly it is directed to the simulation of depth of field effects using computer systems.

As the power and complexity of personal computer systems increase graphics operations are increasingly being performed using dedicated graphics rendering devices referred to as graphics processing units GPUs . As used herein the terms graphics processing unit and graphics processor are used interchangeably. GPUs are often used in removable graphics cards that are coupled to a motherboard via a standardized bus e.g. AGP or PCI Express . GPUs may also be used in game consoles and in integrated graphics solutions e.g. for use in some portable computers and lower cost desktop computers . Although GPUs vary in their capabilities they may typically be used to perform such tasks as rendering of two dimensional 2D graphical data rendering of three dimensional 3D graphical data accelerated rendering of graphical user interface GUI display elements and digital video playback. A GPU may implement one or more application programmer interfaces APIs that permit programmers to invoke the functionality of the GPU.

A GPU may include various built in and configurable structures for rendering digital images to an imaging device. Digital images may include raster graphics vector graphics or a combination thereof. Raster graphics data also referred to herein as bitmaps may be stored and manipulated as a grid of individual picture elements called pixels. A bitmap may be characterized by its width and height in pixels and also by the number of bits per pixel. Commonly a color bitmap defined in the RGB red green blue color space may comprise between one and eight bits per pixel for each of the red green and blue channels. An alpha channel may be used to store additional data such as per pixel transparency values.

Vector graphics data may be stored and manipulated as one or more geometric objects built with geometric primitives. The geometric primitives e.g. points lines polygons B zier curves text characters etc. may be based upon mathematical equations to represent parts of vector graphics data in digital images. The geometric objects may typically be located in two dimensional or three dimensional space. An object in three dimensional space may lie on a plane referred to as a layer. To render vector graphics on raster based imaging devices e.g. most display devices and printers the geometric objects are typically converted to raster graphics data in a process called rasterization.

In rendering digital images the use of depth of field effects may be desired. In traditional photography a depth of field blur may result from the inability of a camera lens to keep all the elements of the photograph in focus simultaneously. Consequently elements that are out of focus may be blurred. It may be desirable to simulate such a depth of field effect in a digital image.

In one prior approach to rendering digital images using a depth of field blur scene information is gathered from several points on the lens of the camera. The scene information is blended during the rendering of a pixel in the image to simulate a depth of field blur. For example a ray tracing renderer may use this approach to sample the incoming light from various points on the lens. However many rays must typically be cast to generate an accurate depth of field blur thereby unduly increasing the rendering time.

In another prior approach to rendering digital images using a depth of field blur a renderer applies the depth of field blur to the rendered image as a post process using the depth information stored in the image. For example a scanline renderer may use this approach by rendering with a pinhole camera and blurring the resulting image based on the distance of each pixel from the camera. However unless the blur is diffused up to a depth boundary the blurring may inappropriately mix colors at various depths in the image. Additionally by requiring an additional process after the image has been rendered this approach may also unduly increase the rendering time.

Various embodiments of systems methods and computer readable storage media for simulating a depth of field effect in a rendered scene are disclosed. In one embodiment a scene may comprise a plurality of polygons each polygon may comprise a respective plurality of vertices and each of the vertices may have a respective depth. The polygons may be sorted by depth. A blur radius may be determined for each vertex of each polygon as a function of the depth of the vertex. A blur radius may be determined for each pixel in each polygon based on the blur radii for the vertices of the polygon. In one embodiment the blur radius may be determined for each pixel through interpolation of the blur radii of the vertices of the polygon. Each pixel in each polygon may be rendered using the respective blur radius determined for the pixel. The rendered scene may then be displayed on a display device.

In one embodiment each vertex of each polygon may be expanded i.e. move out from a center of the polygon by the respective blur radius of the vertex. Similarly each texture coordinate for each vertex of each polygon may be expanded from the center of the polygon by the respective blur radius of the vertex. In one embodiment the blur radii may be recalculated for each expanded vertex. Polygons that intersect or mutually obscure one another may be split for rendering using the painter s algorithm.

The polygons may be rendered in depth order from furthest to nearest. In rendering each pixel in each polygon texture values within the blur radius determined for the pixel may be sampled. The sampled texture values may be averaged to generate a color for the pixel. The pixels in each polygon may be written to an image buffer.

While the invention is susceptible to various modifications and alternative forms specific embodiments are shown by way of example in the drawings and are herein described in detail. It should be understood however that drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed but on the contrary the invention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.

Using embodiments of the systems and methods described herein a depth of field blur in a digital image may be simulated efficiently using a graphics processing unit GPU . is a diagram illustrating one embodiment of a graphics processing unit GPU configured for rendering images with a depth of field blur. The GPU also referred to herein as a graphics processor may comprise a dedicated graphics rendering device associated with a computer system. An example of a suitable computer system for use with a GPU is illustrated in . Turning back to the GPU may include numerous specialized components configured to optimize the speed of rendering graphics output. For example the GPU may include specialized components for rendering three dimensional models for applying textures to surfaces etc. For the sake of illustration however only a limited selection of components is shown in the example GPU of . It is contemplated that GPU architectures other than the example architecture of may be suitable for implementing the techniques described herein. The GPU may implement one or more application programmer interfaces APIs that permit programmers to invoke the functionality of the GPU. Suitable GPUs may be commercially available from vendors such as NVIDIA Corporation ATI Technologies and others.

The GPU may include a host interface configured to communicate with a data source e.g. a communications bus and or processor s of a host computer system or the host system itself . For example the data source may provide image input data e.g. a scene comprising one or more geometric objects in three dimensional space and or executable program code to the GPU . In some embodiments the host interface may permit the movement of data in both directions between the GPU and the data source . The GPU may also include a display interface for providing output data to a data target . For example the data target may comprise a display device and the GPU along with other graphics components and or interfaces may drive the display by providing graphics data at a particular rate from a screen buffer e.g. the image buffer .

In one embodiment the GPU may include internal memory . The GPU memory also referred to herein as video memory or VRAM may comprise random access memory RAM which is accessible to other GPU components. As will be described in greater detail below the GPU memory may be used in some embodiments to store various types of data and instructions such as input data output data intermediate data program instructions for performing various tasks etc. In one embodiment the GPU may also be configured to access memory of a host computer system via the host interface .

In one embodiment program instructions may be stored in the memory of the host computer system and executed by the host computer system to generate rendered image output based on the image input . The image input may include a scene comprising one or more geometric objects in three dimensional space e.g. as vertices and associated data in a tessellation . In one embodiment the rendered image output may include a simulated depth of field blur that is generated using the GPU according to the techniques described herein.

In one embodiment the GPU may include GPU program code that is executable by the GPU to perform aspects of the techniques discussed herein. For example the geometric objects in the image input may be rasterized to pixels by a rasterizer during a rendering process including execution of the GPU program code on the GPU . Elements of the GPU program code may be provided to the GPU by a host computer system e.g. the data source and or native to the GPU . In one embodiment the GPU program code may comprise a vertex shader . A vertex shader comprises program instructions that are executable by the GPU to determine properties e.g. position of a particular vertex. A vertex shader may expect input such as uniform variables e.g. constant values for each invocation of the vertex shader and vertex attributes e.g. per vertex data . In one embodiment the GPU program code may comprise a fragment shader . The fragment shader may also be referred to as a pixel shader . The fragment shader comprises program instructions that are executable by the GPU to determine properties e.g. color of a particular pixel. A fragment shader may expect input such as uniform variables e.g. constant values for each invocation of the fragment shader and pixel attributes e.g. per pixel data . In generating the rendered image output both the vertex shader and the fragment shader may be executed at various points in the graphics pipeline.

The GPU memory may comprise one or more buffers and each buffer may comprise a two dimensional array of pixel data e.g. color values and or pixel metadata e.g. depth values stencil values etc. . As illustrated in for example the GPU memory may comprise an image buffer . The image buffer may store intermediate or final pixel values generated in the rendering process. In one embodiment the image buffer may comprise a single sampling buffer wherein each pixel in the buffer is represented by a single set of color and alpha values e.g. one color value for a red channel one color value for a green channel one color value for a blue channel and appropriate values for a one or more alpha channels . In another embodiment the image buffer may comprise a multi sampling buffer usable for automatic anti aliasing.

In one embodiment each polygon in the scene i.e. each object in the image input may be blurred to simulate a depth of field effect as the scene is rendered. Each polygon may be blurred via a convolution whose kernel size is a function of the distance of the polygon or layer from the camera. The blurred rendered polygon may then be composited into the final scene. The depth of field simulation may include modeling a pinhole camera and the pinhole camera may be associated with the attributes of focal length and aperture to approximate the depth of field blur. In one embodiment suitable application programming interfaces APIs e.g. OpenGL APIs may be used to program the vertex shader and or fragment shader of the GPU to perform aspects of the depth of field simulation on the GPU. By implementing the depth of field simulation on the GPU a substantial acceleration of the depth of field simulation may be achieved in comparison to depth of field simulation techniques on a CPU.

The parameter focus distance is the distance e.g. in pixels from the camera that is in focus. The parameter lens focal length is the focal length e.g. in pixels of the simulated camera lens. The parameter camera aperture is the width e.g. in pixels of the camera s aperture. The parameter depth of vertex is the distance e.g. in pixels of the vertex from the camera. If the camera parameters are converted to pixels from their typical expression in terms of inches or centimeters a conversion factor of 72 pixels per inch may be used.

As shown in block each polygon and its associated texture coordinates may be expanded by the blur radius. Each vertex may be moved away from the centroid of the polygon by an amount equal to the blur radius for the vertex. In this manner the polygon may be expanded non uniformly to accommodate a spatially varying blur. To move each vertex outward by its associated blur radius the blur radius may be added to a radial vector extending from the center of the polygon to the original vertex. In one embodiment this technique may be applied to polygons that are star convex e.g. rectangles and triangles . The texture coordinates of the expanded vertices may also be expanded and the region outside the original polygon may be transparent black. The size of the polygon grows with the depth of field blur and the edge of the polygon may be partially transparent after the expansion.

In one embodiment the operations shown in blocks and may be performed on the host computer system i.e. on the CPU . In another embodiment the operations shown in blocks and may be performed through execution of the vertex shader on the GPU .

As shown in block any intersecting polygons and polygons that mutually obscure one another may be split in preparation for rendering according to the painter s algorithm. In one embodiment intersecting polygons and polygons that mutually obscure one another may be split along the line of intersection after they have been expanded by their respective blur radii. The split polygons may be stored in a BSP tree which can be traversed to produce a rendering order suitable for the painter s algorithm.

As shown in block the split and un split polygons may be sorted thereby generating the image input shown in in preparation for rendering according to the painter s algorithm. In one embodiment the polygons may be sorted on the CPU before being sent to the GPU e.g. as image input . Using the GPU each polygon may be rendered into the scene based on the expanded vertices and blur radii as discussed in greater detail below.

As shown in block the vertex shader may accept a blur radius as a vertex attribute for each vertex and pass it as a varying variable to the fragment shader. In one embodiment the blur radius passed as a vertex attribute may be slightly different than the one used to calculate the new vertex position because the calculated blur radius was for a vertex of the unexpanded polygon. However the difference between the originally calculated blur radius and the recalculated blur radius may be small and inconsequential. The optional recalculation of the blur radii is discussed further with respect to .

As shown in block the blur radius for each pixel in each polygon may be determined by interpolation of the blur radii at the vertices. Based on the blur radii at the vertices specified as varying variables the GPU may determine the blur radius for each pixel in the polygon by interpolation of the blur radii at the vertices. In one embodiment this interpolation may be performed automatically in a rasterization step performed between execution of the vertex shader and execution of the fragment shader in the GPU . The rasterization step may be performed by a rasterizer included in the GPU . Because the depth may vary across a polygon the blur radius may vary across a polygon. The blur radius may thus be rasterized by the GPU in a perspectively correct manner so that the blur effect will vary from pixel to pixel and so that the blur effect will be correct for the relative depth.

In rendering the scene with a simulated depth of field effect each polygon in the image input may be rendered. In the fragment shader each polygon may be composited into the scene as the depth of field blur is applied to the pixels in the polygon. As discussed above the painter s algorithm may be used so that the polygons are rendered in depth order from furthest to nearest. As shown in block the fragment shader may sample the texture values within the blur radius at each pixel to determine a color for the pixel. The fragment shader may determine a weighted average of the colors and alpha values within the blur radius. At each pixel to be rendered the fragment shader may sample the associated texture within a circular sampling region centered at the pixel and having the same radius as the blur radius. The sampling may produce a color value for the pixel. The color value may be further modified by additional processing associated with lighting motion blur etc.

Any suitable technique may be used to sample the texture within the sampling region. In one embodiment for example all the texels i.e. texture elements within the sampling region may be averaged. The upper limit of the blur may be fixed to avoid large fragment programs when the GPU compiler unrolls the sampling loop. The texel averaging may be combined with a polygon antialiasing pass in which the color and transparency values are calculated as a weighted average of neighboring values. In another embodiment a Poisson sampling pattern with a fixed number of samples may be used to sample the sampling region. The sampling points may be scaled to fit the sampling region. The size of the sampling radius may be estimated and a sampling pattern based on the size may be supplied accordingly. In yet another embodiment the sampling may be split into a horizontal sweep and a vertical sweep through the sampling region.

As shown in block each blurred rendered polygon may be composited into the scene. Each polygon may be rendered with an appropriate depth of field blur into an image buffer . In one embodiment each polygon may be rendered into an offscreen buffer and then the blurred result in the offscreen buffer may be composited into the frame buffer.

In one embodiment the blur radii R R and R at the expanded vertices may be copied from the respective original blur radii R R and R. In another embodiment the blur radii R R and R at the expanded vertices may instead be generated by re calculating the blur radii. By calculating a new set of blur radii R R and R at the expanded vertices the rasterizer may assign the correct radius for the pixel representing a vertex of the original triangle. In one embodiment the original triangle is always enclosed in the expanded triangle therefore each of its vertices has barycentric coordinates whose values lie between 0 and 1 with respect to the expanded vertices. Thus each original vertex may comprise a weighted average of the expanded vertices such that 0012 1012 2012 

The coefficients a b c d e f g h and i may be calculated from the ratio of areas of the barycentric triangles. For example the coefficients of the vertex B may be related to the areas of the three triangles and as follows area 012 area 012 area 020 area 012 area 001 area 012 

The coefficients d e f g h and i may be similarly determined. The blur radii R R and R for the expanded vertices may be obtained by solving the following system of linear equations 0012 1012 2012 

In one embodiment a specialized graphics card or other graphics component may be coupled to the processor s . The graphics component may include a GPU such as the GPU illustrated in . Additionally the computer system may include one or more imaging devices . The one or more imaging devices may include various types of raster based imaging devices such as monitors and printers. In one embodiment the one or more imaging devices may comprise one or more display devices that are coupled to the graphics component for display of data provided by the graphics component .

In one embodiment program instructions that may be executable by the processor s to implement aspects of the rendering and depth of field simulation techniques described herein may be partly or fully resident within the memory at the computer system at any point in time. The memory may be implemented using any appropriate medium such as any of various types of ROM or RAM e.g. DRAM SDRAM RDRAM SRAM etc. or combinations thereof. The program instructions may also be stored on a storage device accessible from the processor s . Any of a variety of storage devices may be used to store the program instructions in different embodiments including any desired type of persistent and or volatile storage devices such as individual disks disk arrays optical devices e.g. CD ROMs CD RW drives DVD ROMs DVD RW drives flash memory devices various types of RAM holographic storage etc. The storage may be coupled to the processor s through one or more storage or I O interfaces. In some embodiments the program instructions may be provided to the computer system via any suitable computer readable storage medium including the memory and storage devices described above.

The computer system may also include one or more additional I O interfaces such as interfaces for one or more user input devices . In addition the computer system may include one or more network interfaces providing access to a network. It should be noted that one or more components of the computer system may be located remotely and accessed via the network. The program instructions may be implemented in various embodiments using any desired programming language scripting language or combination of programming languages and or scripting languages e.g. C C C Java Perl etc. It will be apparent to those having ordinary skill in the art that computer system can also include numerous elements not shown in as illustrated by the ellipsis shown.

In various embodiments the elements shown in may be performed in a different order than the illustrated order. In any of the operations described in the elements may be performed programmatically i.e. by a computer according to a computer program . In any of the operations described in the elements may be performed automatically i.e. without user intervention .

Although the embodiments above have been described in detail numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.

