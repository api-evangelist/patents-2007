---

title: High speed processing of financial information using FPGA devices
abstract: Methods and systems for processing financial market data using reconfigurable logic are disclosed. Various functional operations to be performed on the financial market data can be implemented in firmware pipelines to accelerate the speed of processing. Also, a combination of software logic and firmware logic can be used to efficiently control and manage the high speed flow of financial market data to and from the reconfigurable logic.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07921046&OS=07921046&RS=07921046
owner: Exegy Incorporated
number: 07921046
owner_city: St. Louis
owner_country: US
publication_date: 20070619
---
This application claims priority to provisional patent application 60 814 796 filed Jun. 19 2006 and entitled High Speed Processing of Financial Information Using FPGA Devices the entire disclosure of which is incorporated herein by reference.

This patent application is related to the following patent applications U.S. patent application Ser. No. 09 545 472 filed Apr. 7 2000 and entitled Associative Database Scanning and Information Retrieval now U.S. Pat. No. 6 711 558 U.S. patent application Ser. No. 10 153 151 filed May 21 2002 and entitled Associative Database Scanning and Information Retrieval using FPGA Devices now U.S. Pat. No. 7 139 743 published PCT applications WO 05 048134 and WO 05 026925 both filed May 21 2004 and entitled Intelligent Data Storage and Processing Using FPGA Devices published PCT patent application WO 06 096324 filed Feb. 22 2006 entitled Method and Apparatus for Performing Biosequence Similarity Searching U.S. patent application Ser. No. 11 293 619 filed Dec. 2 2005 entitled Method and Device for High Performance Regular Expression Pattern Matching and published as 2007 0130140 U.S. patent application Ser. No. 11 339 892 filed Jan. 26 2006 and entitled Firmware Socket Module for FPGA Based Pipeline Processing U.S. patent application Ser. No. 11 381 214 filed May 2 2006 and entitled Method and Apparatus for Approximate Pattern Matching U.S. patent application Ser. No. 11 561 615 filed Nov. 20 2006 entitled Method and Apparatus for Processing Financial Information at Hardware Speeds Using FPGA Devices and published as 2007 0078837 and U.S. patent application Ser. No. 11 760 211 filed Jun. 8 2007 and entitled Method and System for High Speed Options Pricing the entire disclosures of each of which are incorporated herein by reference.

Speed of information delivery is a valuable dimension to the financial instrument trading and brokerage industry. The ability of a trader to obtain pricing information on financial instruments such as stocks bonds and particularly options as quickly as possible cannot be understated improvements in information delivery delay on the order of fractions of a second can provide important value to traders.

For example suppose there is an outstanding bid on stock X that is a firm quote to buy 100 shares of Stock X for 21.50 per share. Also suppose there are two traders A and B each trying to sell 100 shares of stock X but would prefer not to sell at a price of 21.50. Next suppose another party suddenly indicates a willingness to buy 100 shares of Stock X for a price of 21.60. A new quote for that amount is then submitted which sets the best bid for Stock X to 21.60 up 10 cents from its previous value of 21.50. The first trader A or B to see the new best bid price for Stock X and issue a counter party order to sell Stock X will hit the bid and sell his her Stock X for 21.60 per share. The other trader will either have to settle for selling his her shares of Stock X for the lower 21.50 price or will have to decide not to sell at all at that lower price. Thus it can be seen that speed of information delivery can often translate into actual dollars and cents for traders which in large volume situations can translate to significant sums of money.

In an attempt to promptly deliver financial information to interested parties such as traders a variety of market data platforms have been developed for the purpose of ostensible real time delivery of streaming bid offer and trade information for financial instruments to traders. illustrates an exemplary platform that is currently known in the art. As shown in the market data platform comprises a plurality of functional units that are configured to carry out data processing operations such as the ones depicted in units whereby traders at workstations have access to financial data of interest and whereby trade information can be sent to various exchanges or other outside systems via output path . The purpose and details of the functions performed by functional units are well known in the art. A stream of financial data arrives at the system from an external source such as the exchanges themselves e.g. NYSE NASDAQ etc. over private data communication lines or from extranet providers such as Savvis or BT Radians. The financial data source stream comprises a series of messages that individually represent a new offer to buy or sell a financial instrument an indication of a completed sale of a financial instrument notifications of corrections to previously reported sales of a financial instrument administrative messages related to such transactions and the like. As used herein a financial instrument refers to a contract representing equity ownership debt or credit typically in relation to a corporate or governmental entity wherein the contract is saleable. Examples of financial instruments include stocks bonds commodities currency traded on currency markets etc. but would not include cash or checks in the sense of how those items are used outside financial trading markets i.e. the purchase of groceries at a grocery store using cash or check would not be covered by the term financial instrument as used herein similarly the withdrawal of 100 in cash from an Automatic Teller Machine using a debit card would not be covered by the term financial instrument as used herein . Functional units of the system then operate on stream or data derived therefrom to carry out a variety of financial processing tasks. As used herein the term financial market data refers to the data contained in or derived from a series of messages that individually represent a new offer to buy or sell a financial instrument an indication of a completed sale of a financial instrument notifications of corrections to previously reported sales of a financial instrument administrative messages related to such transactions and the like. The term financial market source data refers to a feed of financial market data directly from a data source such as an exchange itself or a third party provider e.g. a Savvis BT Radianz provider . The term financial market secondary data refers to financial market data that has been derived from financial market source data such as data produced by a feed compression operation a feed handling operation an option pricing operation etc.

Because of the massive computations required to support such a platform current implementations known to the inventors herein typically deploy these functions across a number of individual computer systems that are networked together to thereby achieve the appropriate processing scale for information delivery to traders with an acceptable degree of latency. This distribution process involves partitioning a given function into multiple logical units and implementing each logical unit in software on its own computer system server. The particular partitioning scheme that is used is dependent on the particular function and the nature of the data with which that function works. The inventors believe that a number of different partitioning schemes for market data platforms have been developed over the years. For large market data platforms the scale of deployment across multiple computer systems and servers can be physically massive often filling entire rooms with computer systems and servers thereby contributing to expensive and complex purchasing maintenance and service issues.

This partitioning approach is shown by wherein each functional unit can be thought of as its own computer system or server. Buses and can be used to network different functional units together. For many functions redundancy and scale can be provided by parallel computer systems servers such as those shown in connection with options pricing and others. To the inventors knowledge these functions are deployed in software that is executed by the conventional general purpose processors GPPs resident on the computer systems servers . The nature of general purpose processors and software systems in the current state of the art known to the inventors herein imposes constraints that limit the performance of these functions. Performance is typically measured as some number of units of computational work that can be performed per unit time on a system commonly called throughput and the time required to perform each individual unit of computational work from start to finish commonly called latency or delay . Also because of the many physical machines required by system communication latencies are introduced into the data processing operations because of the processing overhead involved in transmitting messages to and from different machines.

Despite the improvements to the industry that these systems have provided the inventors herein believe that significant further improvements can be made. In doing so the inventors herein disclose that the underlying technology disclosed in the related patents and patent applications listed and incorporated herein above to fundamentally change the system architecture in which market data platforms are deployed.

In above referenced related patent application Ser. No. 10 153 151 it was first disclosed that reconfigurable logic such as Field Programmable Gate Arrays FPGAs can be deployed to process streaming financial information at hardware speeds. As examples the Ser. No. 10 153 151 application disclosed the use of FPGAs to perform data reduction operations on streaming financial information with specific examples of such data reduction operations being a minimum price function a maximum price function and a latest price function. See also the above referenced and incorporated Ser. No. 11 561 615 patent application .

Since that time the inventors herein have greatly expanded the scope of functionality for processing streams of financial information with reconfigurable logic. With the invention described herein vast amounts of streaming financial information can be processed with varying degrees of complexity at hardware speeds via reconfigurable logic deployed in hardware appliances that greatly consolidate the distributed GPP architecture shown in such that a market data platform built in accordance with the principles of the present invention can be implemented within fewer and much smaller appliances while providing faster data processing capabilities relative to the conventional market data platform as illustrated by for example the inventors envision that a 5 1 or greater reduction of appliances relative to the system architecture of can be achieved in the practice of the present invention.

As used herein the term general purpose processor or GPP refers to a hardware device that fetches instructions and executes those instructions for example an Intel Xeon processor or an AMD Opteron processor . The term reconfigurable logic refers to any logic technology whose form and function can be significantly altered i.e. reconfigured in the field post manufacture. This is to be contrasted with a GPP whose function can change post manufacture but whose form is fixed at manufacture. The term software will refer to data processing functionality that is deployed on a GPP. The term firmware will refer to data processing functionality that is deployed on reconfigurable logic.

Thus as embodiments of the present invention the inventors herein disclose a variety of data processing pipelines implemented in firmware deployed on reconfigurable logic wherein a stream of financial data can be processed through these pipelines at hardware speeds.

Also disclosed as an embodiment of the invention is a ticker plant that is configured to process financial market data with a combination of software logic and firmware logic. Through firmware pipelines deployed on the ticker plant and efficient software control and management over data flows to and from the firmware pipelines the inventors herein believe that the ticker plant of the preferred embodiment is capable of greatly accelerating the speed with which financial market data is processed. In a preferred embodiment financial market data is first processed within the ticker plant by software logic. The software logic controls and manages the flow of received financial market data into and out of the firmware logic deployed on the reconfigurable logic device s preferably in a manner such that each financial market data message travels only once from the software logic to the firmware logic and only once from the firmware logic back to the software logic. As used herein the term ticker plant refers to a plurality of functional units such as functional units depicted in that are arranged together to operate on a financial market data stream or data derived therefrom.

These and other features and advantages of the present invention will be understood by those having ordinary skill in the art upon review of the description and figures hereinafter.

The data store can be any data storage device system but is preferably some form of a mass storage medium. For example the data store can be a magnetic storage device such as an array of Seagate disks. However it should be noted that other types of storage media are suitable for use in the practice of the invention. For example the data store could also be one or more remote data storage devices that are accessed over a network such as the Internet or some local area network LAN . Another source destination for data streaming to or from the reconfigurable logic device is network by way of network interface as described above. In the financial industry a network data source e.g. the exchanges themselves a third party provider etc. can provide the financial data stream described above in connection with .

The computer system defined by main processor and RAM is preferably any commodity computer system as would be understood by those having ordinary skill in the art. For example the computer system may be an Intel Xeon system or an AMD Opteron system.

The reconfigurable logic device has firmware modules deployed thereon that define its functionality. The firmware socket module handles the data movement requirements both command data and target data into and out of the reconfigurable logic device thereby providing a consistent application interface to the firmware application module FAM chain that is also deployed on the reconfigurable logic device. The FAMs of the FAM chain are configured to perform specified data processing operations on any data that streams through the chain from the firmware socket module . Preferred examples of FAMs that can be deployed on reconfigurable logic in accordance with a preferred embodiment of the present invention are described below.

The specific data processing operation that is performed by a FAM is controlled parameterized by the command data that FAM receives from the firmware socket module . This command data can be FAM specific and upon receipt of the command the FAM will arrange itself to carry out the data processing operation controlled by the received command. For example within a FAM that is configured to compute an index value such as the Dow Jones Industrial Average the FAM s index computation operation can be parameterized to define which stocks will be used for the computation and to define the appropriate weighting that will be applied to the value of each stock to compute the index value. In this way a FAM that is configured to compute an index value can be readily re arranged to compute a different index value by simply loading new parameters for the different index value in that FAM.

Once a FAM has been arranged to perform the data processing operation specified by a received command that FAM is ready to carry out its specified data processing operation on the data stream that it receives from the firmware socket module. Thus a FAM can be arranged through an appropriate command to process a specified stream of data in a specified manner. Once the FAM has completed its data processing operation another command can be sent to that FAM that will cause the FAM to re arrange itself to alter the nature of the data processing operation performed thereby. Not only will the FAM operate at hardware speeds thereby providing a high throughput of target data through the FAM but the FAMs can also be flexibly reprogrammed to change the parameters of their data processing operations.

The FAM chain preferably comprises a plurality of firmware application modules FAMs . . . that are arranged in a pipelined sequence. As used herein pipeline pipelined sequence or chain refers to an arrangement of FAMs wherein the output of one FAM is connected to the input of the next FAM in the sequence. This pipelining arrangement allows each FAM to independently operate on any data it receives during a given clock cycle and then pass its output to the next downstream FAM in the sequence during another clock cycle.

A communication path connects the firmware socket module with the input of the first one of the pipelined FAMs . The input of the first FAM serves as the entry point into the FAM chain . A communication path connects the output of the final one of the pipelined FAMs with the firmware socket module . The output of the final FAM serves as the exit point from the FAM chain . Both communication path and communication path are preferably multi bit paths.

The application software layer corresponds to high level functionality such as the type of functionality wherein one or more users interact with the application to define which data processing operations are to be performed by the FAMs and to define what data those data processing operations are to be performed upon.

The next layer is the module application programming interface API layer which comprises a high level module API and a low level module API . The high level module API can provide generic services to application level software for example managing callbacks . The low level module API manages the operation of the operating system OS level device driver software . A software library interface interfaces the high level module API with the low level module API . Additional details about this software library interface can be found in the above referenced patent application Ser. No. 11 339 892.

The interface between the device driver software and the firmware socket module serves as the hardware software interface for the system . The details of this interface are described in greater detail in the above referenced patent application Ser. No. 11 339 892.

The interface between the firmware socket module and the FAM chain is the firmware module interface . The details of this interface are described in greater detail in the above referenced patent application Ser. No. 11 339 892.

It is worth noting that in either the configuration of or the firmware socket can make memory accessible to the PCI X bus which thereby makes memory available for use by the OS kernel as the buffers for transfers from the disk controller and or network interface controller to the FAMs. It is also worth noting that while a single FPGA is shown on the printed circuit boards of and it should be understood that multiple FPGAs can be supported by either including more than one FPGA on the printed circuit board or by installing more than one printed circuit board in the computer system. depicts an example where numerous FAMs in a single pipeline are deployed across multiple FPGAs.

As shown in inbound data from the kernel to the card is moved across the bus in the computer system to the firmware socket module and then delivered by the firmware socket module to the FAM chain . Outbound data from the card to the kernel are delivered from the FAM chain to the firmware socket module and then delivered by the firmware socket module across the PCI X bus to the software application executing on the computer system. As shown in the three interacting interfaces that are used are the firmware module interface the hardware software interface and the software library interface .

In an effort to improve upon conventional market data platforms the inventors herein disclose a new market data platform architecture an embodiment of which is shown in . The market data platform shown in consolidates the functional units shown in into much fewer physical devices and also offloads much of the data processing performed by the GPPs of the functional units to reconfigurable logic.

For example with the architecture of the feed compressor can be deployed in an appliance such as system shown in . The reconfigurable logic can be implemented on a board as described in connection with or . Feed compressor is used to compress the content of the financial data stream arriving from various individual sources. Examples of compression techniques that can be used include the open standard glib as well as any proprietary compression technique that may be used by a practitioner of the present invention. Appropriate FAM modules and a corresponding FAM pipeline to implement such a feed compression operation can be carried out by a person having ordinary skill in the art using the design techniques described in connection with the above referenced patent and patent applications and basic knowledge in the art concerning feed compression. As a result a variety of hardware templates available for loading on reconfigurable logic can be designed and stored for use by the market data platform to implement a desired feed compression operation.

Preferably the feed compressor device is deployed in a physical location as close to the feed source as possible to thereby reduce communication costs and latency. For example it would be advantageous to deploy the feed compressor device in a data center of an extranet provider e.g. Savvis BT Radianz etc. due to the data center s geographic proximity to the source of the financial market data . Because the compression reduces message sizes within the feed stream it will be advantageous to perform the compression prior to the stream reaching wide area network WAN thereby improving communication latency through the network because of the smaller message sizes.

WAN preferably comprises an extranet infrastructure or private communication lines for connection on the inbound side to the feed handlers deployed in device . On the outbound side WAN preferably connects with device as explained below. It should be noted that WAN can comprise a single network or multiple networks and segmented by their inbound outbound role in relation to platform . It is also worth noting that a news feed with real time news wire reports can also be fed into WAN for delivery to device .

Device can be deployed in an appliance such as system shown in . The reconfigurable logic can be implemented on a board as described in connection with or . Whereas the conventional GPP based system architecture shown in deployed the functional units of feed handling ticker plant rule based calculation engines an alert generation engine options pricing Last Value Cache LVC servers supplying snapshot and or streaming interfaces historical time series oriented databases with analytics and news databases with search capabilities in software on separate GPPs the architecture of can consolidate these functions either partially or in total in firmware resident on the reconfigurable logic such as one or more FPGAs of device .

Feed handlers which can also be referred to as feed producers receive the real time data stream either compressed from the feed compressor as shown in or uncompressed from a feed source and converts that compressed or uncompressed stream from a source specific format e.g. an NYSE format to a format that is common throughout the market data platform . This conversion process can be referred to as normalization . This normalization can be implemented in a FAM chain that transforms the message structure converts the based units of specific field values within each message maps key field information to the common format of the platform and fills in missing field information from cached or database records. In situations where the received feed stream is a compressed feed stream the feed handler preferably also implements a feed decompression operation.

LVCs maintain a database of financial instrument records whose functionality can be implemented in a FAM pipeline. Each record represents the current state of that financial instrument in the market place. These records are updated in real time via a stream of update messages received from the feed handlers. The LVC is configured to respond to requests from other devices for an up to the instant record image for a set of financial instruments and redistribute a selective stream of update messages pertaining to those requested records thereby providing real time snapshots of financial instrument status. From these snapshots information such as the latest price for a financial instrument can be determined as described in the above referenced Ser. No. 10 153 151 application.

Rule based calculation engines are engines that allow a user to create his her own synthetic records whose field values are derived from calculations performed against information obtained from the LVC information extracted from a stream of update messages generated from the LVC or from alternate sources. These rule based calculation engines are amenable to implementation in a FAM pipeline. It should also be noted that the rule based calculation engine can be configured to create new synthetic fields that are included in existing records maintained by the LVC. The new values computed by the engine are computed by following a set of rules or formulas that have been specified for each synthetic field. For example a rule based calculation engine can be configured to compute a financial instrument s Volume Weighted Average Price VWAP via a FAM pipeline that computes the VWAP as the sum of PxS for every trade meeting criteria X wherein P equals the trade price and wherein S equals the trade size. Criteria X can be parameterized into a FAM filter that filters trades based on size types market conditions etc. Additional examples of rule based calculations that can be performed by the rule based calculation engine include but are not limited to a minimum price calculation for a financial instrument a maximum price calculation for a financial instrument a Top 10 list for a financial instrument or set of financial instruments etc.

An alert generation engine can also be deployed in a FAM pipeline. Alert generation engines are similar to a rule based calculation engine in that they monitor the current state of a financial instrument record or set of financial instrument records and the alert generation engine will trigger an alert when any of a set of specified conditions is met. An indication is then delivered via a variety of means to consuming applications or end users that wish to be notified upon the occurrence of the alert.

Option pricing is another function that is highly amenable to implementation via a FAM pipeline. An option is a derivative financial instrument that is related to an underlying financial instrument and the option allows a person to buy or sell that underlying financial instrument at a specific price at some specific time in the future. An option pricing engine is configured to perform a number of computations related to these options and their underlying instruments e.g. the theoretical fair market value of an option or the implied volatility of the underlying instrument based upon the market price of the option . A wide array of computational rules can be used for pricing options as is known in the art. Most if not all industry accepted techniques for options pricing are extremely computation intensive which introduces significant latency when the computations are performed in software. However by implementing option pricing in a FAM pipeline the market data platform can significantly speed up the computation of option pricing thereby providing in important edge to traders who use the present invention. An example of options pricing functionality that can be deployed in firmware is described in pending U.S. patent application Ser. No. 11 760 211 filed Jun. 8 2007 the entire disclosure of which is incorporated herein by reference.

A time series database is a database that maintains a record for each trade or quote event that occurs for a set of financial instruments. This information may be retrieved upon request and returned in an event by event view. Alternative views are available wherein events are rolled up by time intervals and summarized for each interval. Common intervals include monthly weekly daily and minute bars where the interval is specified to be some number of minutes. The time series database also preferably compute a variety of functions against these historic views of data including such statistical measures as volume weighted average price VWAP money flow or correlations between disparate financial instruments.

A news database maintains a historical archive of news stories that have been received from a news wire feed by way of the feed handler. The news database is preferably configured to allow end users or other applications to retrieve news stories or headlines based upon a variety of query parameters. These query parameters often include news category assignments source identifiers or even keywords or keyword phrases. The inventors herein note that this searching functionality can also be enhanced using the search and data matching techniques described in the above referenced patent and patent applications.

Appropriate FAM modules and corresponding FAM pipelines to implement these various functions for device can be carried out by a person having ordinary skill in the art using the design techniques described in connection with the above referenced patent and patent applications and basic knowledge in the art concerning each function. As a result a variety of hardware templates available for loading on reconfigurable logic can be designed and stored in memory such as on a disk embodied by data store in connection with for use by the market data platform to implement a desired data processing function. Persistent data storage unit can be accessible to device as device processes the feed stream in accordance with the functionality described above. Storage can be embodied by data store or other memory devices as desired by a practitioner of the invention.

Traders at workstations or application programs running on an entity s own trading platform can then access the streaming financial data processed by device via a connection to local area network LAN . Through this LAN connection workstations and application program also have access to the data produced by devices and . Like devices and devices and can also be deployed in an appliance such as system shown in wherein the reconfigurable logic of system can be implemented on a board as described in connection with or .

Device preferably consolidates the following functionality at least partially into firmware resident on reconfigurable logic an order book server an order router direct market access gateways to exchanges Electronic Communication Networks ECNs and other liquidity pools trading engines an auto quote server and a compliance journal.

An order book server is similar to a LVC in that the order book server maintains a database in memory e.g. in memory device on board of financial instrument records and keeps that database up to date in real time via update messages received from the feed handlers. For each record the order book server preferably maintains a sorted list of the bids and offers associated with all outstanding orders for that instrument. This list is known as the book for that instrument. The order information for each instrument is received from a variety of different trading venues in stream and is aggregated together to form one holistic view of the market for that particular instrument. The order book server is configured to respond to requests from workstation users or application programs to present the book in a number of different ways. There are a variety of different views including but not limited to a top slice of the book that returns orders whose prices are considered to be within a specified number of price points of the best price available in the market the best price being considered to be the top of the book a price aggregate view where orders at the same price point are aggregated together to create entries that are indicative of the total number of orders available at each price point and an ordinary view with specific trading venues which are the source of orders excluded.

An order router is a function that can take a buy or sell order for a specified financial instrument and based upon a variety of criteria associated with the order itself or the end user or application submitting the order route the order in whole or in part to the most appropriate trading venue such as an exchange an Alternate Trading System ATS or an ECN.

The direct market access gateway functionality operates to relay orders to a trading venue such as an exchange ECN ATS etc. via WAN . Before sending an order out however the gateway preferably transforms the order message to a format appropriate for the trading venue.

The trading engine functionality can also be deployed on reconfigurable logic. An algorithmic trading engine operates to apply a quantitative model to trade orders of a defined quantity to thereby automatically subdivide that trade order into smaller orders whose timing and size are guided by the goals of the quantitative model so as to reduce the impact that the original trade order may have on the current market price. Also a black box trading engine operates to automatically generate trades by following a mathematical model that specifies relationships or conditional parameters for an instrument or set of instruments. To aid this processing the black box trading engine is fed with real time market data.

An auto quote server is similar to a black box trading engine. The auto quote server operates to automatically generate firm quotes to buy or sell a particular financial instrument at the behest of a market maker wherein a market maker is a person or entity which quotes a buy and or sell price in a financial instrument hoping to make a profit on the turn or the bid offer spread.

A feed compliance journal can also be implemented in a FAM pipeline. The feed compliance journal functions to store information in persistent storage related to the current state of the entire market with regard to a particular financial instrument at the time a firm quote or trade order is submitted to a single particular marketplace. The feed compliance journal can also provide a means for searching storage to provide detailed audit information on the state of the market when a particular firm quote or trade order was submitted. The inventors herein note that this searching functionality can also be enhanced using the search and data matching techniques described in the above referenced patent and patent applications.

As mentioned above in connection with device appropriate FAM modules and corresponding FAM pipelines to implement these various functions for device can be carried out by a person having ordinary skill in the art using the design techniques described in connection with the above referenced patent and patent applications and basic knowledge in the art concerning each function. As a result a variety of hardware templates available for loading on reconfigurable logic can be designed and stored for use by the market data platform to implement a desired data processing function. Persistent data storage unit which can be embodied by data store can be accessible to device as device processes the feed stream in accordance with the functionality described above.

Device preferably implements an internal matching system engine in firmware resident on reconfigurable logic. An internal matching system engine operates to match a buyer s bid with a seller s offer to sell for a particular financial instrument to thereby execute a deal or trade. An indication of a completed trade is then submitted to the appropriate reporting and settlement systems. The internal matching system engine may create bids or offers as would a market maker in order to provide an orderly market and a minimum amount of liquidity by following a set of programmatically defined rules.

Device preferably implements an order management system OMS in firmware resident on reconfigurable logic. An OMS operates to facilitate the management of a group of trading accounts typically on behalf of a broker. The OMS will monitor buy and sell orders to ensure that they are appropriate for the account owner in question based upon his her account status credit and risk profiles. The OMS typically incorporates a database via persistent storage which may be embodied by data store used to hold account information as well as an archive of orders and other activity for each account.

Device preferably implements entitlements and reporting functionality. A market data platform such as system is a mechanism for distributing data content to a variety of end users. Many content providers charge on a per user basis for access to their data content. Such content providers thus prefer a market data platform to have a mechanism to prohibit or entitle access to specific content on an individual user basis. Entitlement systems may also supply a variety of reports that detail the usage of different content sets. To achieve this functionality device in conjunction with database preferably operates to maintain a database of users including authentication credentials and entitlement information which can be used by devices and for entitlement filtering operations in conjunction with the data processing operations performed thereby.

Device preferably implements management and monitoring for the market data platform . Management and monitoring functionality provides a means for users to operate the applications running within the platform and monitor the operational state and health of individual components thereon. Preferably the management and monitoring functionality also provides facilities for reconfiguring the components as well as means for performing any other appropriate manual chores associated with running the platform.

Device preferably implements publishing and contribution server functionality. Contribution servers also known as publishing servers allow users to convert information obtained from an end user application or some other source within his her enterprise into a suitable form and to have it distributed by the market data platform .

As mentioned above in connection with devices and appropriate FAM modules and corresponding FAM pipelines to implement these various functions for devices and can be carried out by a person having ordinary skill in the art using the design techniques described in connection with the above referenced patent and patent applications and basic knowledge in the art concerning each function. As a result a variety of hardware templates available for loading on reconfigurable logic can be designed and stored for use by the market data platform to implement a desired data processing function. Persistent data storage units and can be accessible to devices and respectively as those devices process the data in accordance with the functionality described above.

In deploying this functionality at least in part upon reconfigurable logic the following modules submodules of the functions described above are particularly amenable to implementation on an FPGA fixed record format message parsing fixed record format message generation FIX message parsing FIX message generation FIX FAST message parsing FIX FAST message generation message compression message decompression interest and entitlement filtering financial instrument symbol mapping record ID mapping price summary LVC update retrieve normalize LVC order book cache update retrieve normalize OBC generic LVC GVC minute bar generation programmatic field generation with LVC OBC etc. historic record search and filter book based algorithmic order routing trade order generation basket calculation including ETF index and portfolio valuation and autoquote generation. It should be understood by those having ordinary skill in the art that this list is exemplary only and not exhaustive additional modules for financial data processing can also be employed in a FAM or FAM pipeline in the practice of the present invention.

With fixed record format message parsing a fixed format message is decomposed into its constituent fields as defined by a programmable data dictionary . Entries within the data dictionary describe the fields within each type of message their positions and sizes within those messages and other metadata about the field such as data type field identifiers etc. . Preferably the data dictionary is stored in persistent storage such as data store of the system . Upon initialization of the FAM pipeline on board the data dictionary is then preferably loaded into memory for usage by the FAM pipeline during data processing operations.

With fixed record format message generation a fixed format message is generated by concatenating the appropriate data representing fields into a message record. The message structure and format is described by a programmable data dictionary as described above.

With FIX message parsing a FIX formatted message is decomposed into its constituent fields as defined by a programmable data dictionary as described above FIX being a well known industry standard for encoding financial message transactions.

With FIX message generation a FIX formatted message is generated by concatenating the appropriate data representing the fields into a FIX message record. Once again the message structure and format is described by a programmable data dictionary as described above.

With FIX FAST message parsing a FIX and or FAST message FAST being a well known variation of FIX is decomposed into its constituent fields as defined by a programmable data dictionary as described above.

With FIX FAST message generation a FIX formatted and or FAST formatted message is generated by concatenating the appropriate data representing fields into a FIX FAST message record. The message structure and format is defined by a programmable data dictionary as described above.

With message compression a message record is compressed so as to require less space when contained in a memory device and to require less communication bandwidth when delivered to other systems. The compression technique employed is preferably sufficient to allow for reconstruction of the original message when the compressed message is processed by a corresponding message decompression module.

With interest and entitlement filtering a stream of messages coming from a module such as one of the caching modules described below e.g. price summary LVC order book OBC or generic GVC is filtered based upon a set of entitlement data and interest data that is stored for each record in the cache. This entitlement and interest data defines a set of users or applications that are both entitled to receive the messages associated with the record and have expressed an interest in receiving them. This data can be loaded into memory from storage during initialization of the board or from Application Software during normal operation of the board . An exemplary embodiment of a FAM configured to perform interest and entitlement filtering is described hereinafter with respect to .

With financial instrument symbol mapping a common identifying string for a financial instrument typically referred to as the symbol is mapped into a direct record key number that can be used by modules such as caching modules LVC OBC GVC to directly address the cache record associated with that financial instrument. The record key number may also be used by software to directly address a separate record corresponding to that instrument that is kept in a storage preferably separate from board . An exemplary embodiment of a FAM configured to perform symbol mapping is described hereinafter with respect to .

With record ID mapping a generic identifying string for a record is mapped into a direct record key number that can be used by a caching module e.g. LVC OBC GVC or software to directly address the record in a storage medium.

The price summary Last Value Cache update retrieve normalize LVC operation operates to maintain a cache of financial instrument records whose fields are updated in real time with information contained in streaming messages received from a message parsing module and to enhance or filter the messages received from a message parsing module before passing them on to subsequent processing modules. The type of update performed for an individual field in a record will be defined by a programmable data dictionary as described above and may consist of moving the data field from the message to the record updating the record field by accumulating the data field over a series of messages defined within a time bounded window updating the record field only if certain conditions as defined by a set of programmable rules are true or computing a new value based upon message and or record field values as guided by a programmable formula. The type of enhancement or filtering applied to an individual message may consist of replacing a message field with one created by accumulating the data over a series of messages defined within a time bounded window flagging a field whose value falls outside of a programmatically defined range of values or suppressing the message in its entirety if the value of a field or set of fields fails to change with respect to the corresponding values contained within the cache record. An exemplary embodiment of a FAM configured to perform LVC updating is described hereinafter with respect to and .

The order book cache update retrieve and normalize OBC operation operates to maintain a cache of financial instrument records where each record consists of an array of sub records that define individual price or order entries for that financial instrument. A sort order is maintained for the sub records by the price associated with each sub record. The fields of the sub records are updated in real time with information contained in streaming messages received from a message parsing module. Sub records associated with a record are created and removed in real time according to information extracted from the message stream and the sort order of sub records associated with a given record is continuously maintained in real time. The type of update performed for an individual field in a sub record will be defined by a programmable data dictionary and may consist of moving the data field from the message to the sub record updating the sub record field by accumulating the data field over a series of messages defined within a time bounded window updating the sub record field only if certain conditions as defined by a set of programmable rules are true or computing a new value based upon message and or record or sub record fields as guided by a programmable formula. The OBC includes the ability to generate various views of the book for a financial instrument including but not limited to a price aggregated view and a composite view. A composite view is a sort order of the price or order entries for a financial instrument across multiple exchanges. The OBC also includes the ability to synthesize a top of book quote stream. When an update operation causes the best bid or offer entry in a given record to change the OBC may be configured to generate a top of book quote reporting the current best bid and offer information for the financial instrument. A synthesized top of book quote stream has the ability to report best bid and offer information with less latency than an exchange generated quote stream. This may be used to accelerate a variety of latency sensitive applications.

The Generic Last Value Cache GVC operation operates to maintain a cache of records whose fields are updated in real time with information contained in streaming messages received from a message parsing module. The structure of a record and the fields contained within it are defined by a programmable data dictionary as described above. The type of update performed for an individual field in a record will be defined by a programmable data dictionary and may consist of moving the data field from the message to the record updating the record field by accumulating the data field over a series of messages defined within a time bounded window updating the record field only if certain conditions as defined by a set of programmable rules are true or computing a new value based upon message and or record field values as guided by a programmable formula.

A minute bar generation operation operates to monitor real time messages from a message parsing module or last value cache module for trade events containing trade price information or for quote events containing quote price information and create minute bar events that summarize the range of trade and or quote prices that have occurred over the previous time interval. The time interval is a programmable parameter as is the list of records for which minute bars should be generated and the fields to include in the generated events.

A Top 10 list generation operation operates to monitor real time messages from a message parsing module or last value cache module for trade events containing price information and create lists of instruments that indicate overall activity in the market. Such lists may include where N is programmatically defined top N stocks with the highest traded volume on the day top N stocks with the greatest positive price change on the day top N stocks with the largest percentage price change on the day top N stocks with the greatest negative price change on the day top N stocks with the greatest number of trade events recorded on the day top N stocks with the greatest number of large block trades on the day where the threshold that indicates whether a trade is a large block trade is defined programmatically.

A programmatic field generation via LVC OBV GVC etc. operation operates to augment messages received from a message parsing module with additional fields whose values are defined by a mathematical formula that is supplied programmatically. The formula may reference any field within the stream of messages received from a message parsing module any field contained within a scratchpad memory associated with this module or any field contained within any record held within any the record caches described herein.

A programmatic record generation with LVC OBC GVC etc. operation operates to generate records that represent synthetic financial instruments or other arbitrary entities and a series of event messages that signal a change in state of each record when the record is updated. The structure of the records and the event messages are programmatically defined by a data dictionary. The field values contained with the record and the event messages are defined by mathematical formulas that are supplied programmatically. The formulas may reference any field within the stream of messages received from a message parsing module any field contained within a scratchpad memory associated with this module or any field contained within any record held within any the record caches described herein. Updates to field values may be generated upon receipt of a message received from another module or on a time interval basis where the interval is defined programmatically. A basket calculation engine is one example of programmatic record generation. A synthetic instrument may be defined to represent a given portfolio of financial instruments constituent instruments in an Exchange Traded Fund ETF or market index. The record for that synthetic instrument may include fields such as the Net Asset Value NAV and total change.

A historic record search and filter operation operates to filter messages received from a message parsing module that represent a time series of events to partition the events into various sets where each set is defined by a collection of criteria applied to event attributes. The event message structure criteria and attributes are all programmatically defined. Event attributes include but are not limited to financial instrument symbol class of symbol time and date of event type of event or various indicator fields contained within the event. Multiple events within a set may be aggregated into a single event record according to a collection of aggregation rules that are programmatically defined and applied to attributes of the individual events. Aggregation rules may include but are not limited to aggregating hourly events into a single daily event aggregating daily events into a single weekly event or aggregating multiple financial instruments into a single composite instrument.

These functions as well as other suitable financial data processing operations as embodied in FAMs can then be combined to form FAM pipelines that are configured to produce useful data for a market data platform. For example a feed compressor FAM pipeline can employ FAMs configured with the following functions fixed record format message parsing fixed record format message generation FIX message parsing FIX message generation FIX FAST message parsing FIX FAST message generation message compression and message decompression.

The output of FAM is then passed to FAM which is configured as a rule based calculation engine as described above. FAM also receives data from a real time field value cache to obtain LVC data as does the top 10 list FAM . Cache is preferably embodied by memory of board . The output from the rule based calculation engine FAM is then passed to parallel FAMs and . FAM serves as a message multiplexer and receives messages from the outputs of FAMs and . FAM receives the messages multiplexed by FAM and serves to encode those messages to a desired format. FAM serves as an alert engine whose function is explained above and whose output exits the pipeline. FAM serves as a value cache update engine to ensuring that cache stays current.

FAM operates to map the known symbol for a financial instrument or set of financial instruments as defined in the parsed message to a symbology that is internal to the platform e.g. mapping the symbol for IBM stock to an internal symbol 12345 . FAM receives the output from FAM and serves to update the LVC cache via memory . The output of FAM is then provided in parallel to FAMs and .

FAM operates as a Top 10 list generator as described above. FAM operates as a Minute Bar generator as described above. FAM operates as an interest entitlement filter as described above and FAM operates as a programmatic calculation engine as described above. The outputs from FAMs and are then provided to a message formatter FAM which operates as described above to construct a fixed format message of a desired format from the outputs of FAMs and .

In performing these tasks FAM is aided by memory that stores templates and field maps as well as memory that stores a symbol index. FAM is also aided by memory as well as memory which serves as an LVC cache. Memory is also accessed by FAM while memory is also accessed by FAM . FAM accesses interest entitlement memory as loaded from storage or provided by Application Software during initialization of the board .

Message Parser FAM ingests a stream of messages parses each message into its constituent fields and propagates the fields to downstream FAMs. Message fields required for processing in FAMs and are passed to FAM . Other message fields are passed to Message Synchronization Buffer FAM . Message Parser FAM may be implemented to support a variety of message formats including various types of fixed formats and self describing formats. A preferable message format provides sufficient flexibility to support the range of possible input events from financial exchanges. In a preferred implementation the Message Parser FAM may be configured to support different message formats without altering the firmware. This may be achieved by loading message format templates into Template Field Map buffer . Message Parser FAM reads the message format description from buffer prior to processing input messages to learn how a given message is to be parsed.

Like FAM in Symbol ID Mapping FAM operates to map the known symbol for a financial instrument or set of financial instruments as defined in the parsed message to a symbology that is internal to the platform e.g. mapping the symbol for IBM stock to an internal symbol 12345 . Preferably the internal platform symbol identifier ID is an integer in the range 0 to N 1 where N is the number of entries in Symbol Index Memory . Preferably the symbol ID is formatted as a binary value of size M log N bits. The format of financial instrument symbols in input exchange messages varies for different message feeds and financial instrument types. Typically the symbol is a variable length ASCII character string. A symbology ID is an internal control field that uniquely identifies the format of the symbol string in the message. As shown in a symbology ID is preferably assigned by the feed handler as the symbol string format is typically shared by all messages on a given input feed.

A preferred embodiment of the Symbol ID Mapping FAM maps each unique symbol character string to a unique binary number of size M bits. In the preferred embodiment the symbol mapping FAM performs a format specific compression of the symbol to generate a hash key of size K bits where K is the size of the entries in the Symbol Index Memory . The symbology ID may be used to lookup a Key Code that identifies the symbol compression technique that should be used for the input symbol. Preferably the symbol mapping FAM compresses the symbol using format specific compression engines and selects the correct compressed symbol output using the key code. Preferably the key code is concatenated with the compressed symbol to form the hash key. In doing so each compression technique is allocated a subset of the range of possible hash keys. This ensures that hash keys will be unique regardless of the compression technique used to compress the symbol. An example is shown in wherein the ASCII symbol for a financial instrument is compressed in parallel by a plurality of different compression operations e.g. alpha numeric ticker compression ISIN compression and commodity compression . Compression techniques for different symbologies can be selected and or devised on an ad hoc basis as desired by a practitioner of the invention. A practitioner of the present invention is free to select a different compression operation as may be appropriate for a given symbology. Based on the value of the key code the symbol mapping FAM will pass one of the concatenations of the key code and compression results as the output from the multiplexer for use as the hash key.

Alternatively the format specific compression engines may be implemented in a programmable processor. The key code may then be used to fetch a sequence of instructions that specify how the symbol should be compressed.

Once the hash key is generated the symbol mapping FAM maps the hash key to a unique address in the Symbol Index Memory in the range 0 to N 1. The Symbol Index Memory may be implemented in a memory on chip within the reconfigurable logic device or in off chip high speed memory devices such as SRAM and SDRAM that are accessible to the reconfigurable logic device. Preferably this mapping is performed by a hash function. A hash function attempts to minimize the number of probes or table lookups to find the input hash key. In many applications additional meta data is associated with the hash key. In the preferred embodiment the location of the hash key in the Symbol Index Memory is used as the unique internal Symbol ID for the financial instrument.

The primary hash function h1 x is computed as follows. Compute hash function B x where the result is in the range 0 to Q 1. Use the result of the B x function to lookup a displacement vector d x in table T containing Q displacement vectors. Preferably the size of the displacement vector d x in bits is equal to M. Compute hash function A x where the result is M bits in size. Compute the bitwise exclusive OR of A x and d x . This is one example of near perfect hashing where the displacement vector is used to resolve collisions among the set of hash keys that are known prior to the beginning of the query stream. Typically this fits well with streaming financial data where the majority of the symbols for the instruments trading in a given day is known. Methods for computing displacement table entries are known in the art.

The secondary hash function h2 x is computed by computing a single hash function C x where the result is always prime relative to N. Hash functions A x B x and C x may be selected from the body of known hash functions with favorable randomization properties. Preferably hash functions A x B x and C x are efficiently implemented in hardware. The set of H3 hash functions are good candidates. See Krishnamurthy et al. Proc. of the IEEE 15th Int l Conf. on Application Specific Systems Architectures and Processors September 2004 pp. 365 375 the entire disclosure of which is incorporated herein by reference .

Once the hash function H x produces an address whose entry is equal to the input hash key the address is passed on as the new Symbol ID to be used internally by the ticker plant to reference the financial instrument. As shown in the result of the hash key compare function may be used as a valid signal for the symbol ID output.

Hash keys are inserted in the table when an exchange message contains a symbol that was unknown at system initialization. Hash keys are removed from the table when a financial instrument is no longer traded. Alternatively the symbol for the financial instrument may be removed from the set of known symbols and the hash table may be cleared recomputed and initialized. By doing so the displacement table used for the near perfect hash function of the primary hash may be optimized. Typically financial markets have established trading hours that allow for after hours or overnight processing. The general procedures for inserting and deleting hash keys from a hash table where open addressing is used to resolve collisions is well known in the art.

In a preferred embodiment the symbol mapping FAM also computes a global exchange identifier GEID that maps the exchange code and country code fields in the exchange message to an integer in the range 0 to G 1 as shown in . Similar to the symbol field for financial instruments the exchange code and country code fields uniquely identify the source of the exchange message. The value of G should be selected such that it is larger than the total number of sources financial exchanges that will be generating input messages for a given instance of the system. Hashing could be used to map the country codes and exchange codes to the GEID. Alternatively a direct addressing approach can be used to map country and exchange codes to GEIDS. For example the exchange code and country codes can each be represented by two character codes where the characters are 8 bit upper case ASCII alpha characters. These codes can then be truncated to 5 bit characters in embodiment where only 26 unique values of these codes are needed. For each code these truncated values are concatenated to generate a 10 bit address that is used to lookup a compressed intermediate value in a stage 1 table. Then the compressed intermediate values for the exchange and country code can be concatenated to generate an address for a stage 2 lookup. The result of the stage 2 lookup is the GEID. The size of the intermediate values and the stage 2 address will depend on the number of unique countries and the max number of exchanges in any one country which can be adjusted as new exchanges open in different countries.

Symbol mapping FAM passes input message field values the symbol ID and global exchange ID to Last Value Cache LVC Update FAM . LVC Update FAM serves to update the LVC cache via memory as well as message fields that may depend on record field values. One example is the tick direction which indicates if the price in the message is larger or smaller than the previous price captured in the record.

As shown in and the LVC memory manager retrieves one or more records associated with the financial instrument. The LVC memory manager passes the record and message fields to the LVC message record updater. The LVC message record updater contains a set of update engines that update the record and message fields according to specified business logic. The business logic for field updates may vary according to a number of parameters including event type trade quote cancel etc. financial instrument type security option commodity etc. and record type. In a preferred embodiment the update engines are directed by business logic templates contained in Templates Field Maps . Techniques for template driven update engines are well known in the art.

Record fields may include but are not limited to last trade price last trade size last trade time best bid price best bid size best bid time best ask price best ask size best ask time total trade volume daily change tick direction price direction high trade price high price time low trade price low price time and close price. In a preferred embodiment record fields also include derived fields such as total trade volume at bid total trade volume at ask traded value traded value at bid traded value at ask and volume weighted average price VWAP .

As reflected in and a preferred embodiment of the LVC Update FAM maintains a composite record and a set of regional records for every financial instrument observed on the input feeds. A composite record reflects the current state of the financial instrument across all exchanges upon which it trades. A regional record reflects the current state of the financial instrument on a given exchange. For example if stock ABC trades on exchanges AA BB and CC then four records will be maintained by the LVC Update FAM one composite record and three regional records. If an input message reports a trade of stock ABC on exchange BB then the LVC Update FAM updates the composite record for ABC the regional record for ABC on exchange BB and the message fields according to the business logic for stock trade events on exchange BB.

As shown in the LVC Memory Manger uses the symbol ID and global exchange ID to retrieve the composite and regional record. In a preferred embodiment the symbol ID is used to retrieve an entry in the record management memory. The entry contains a valid flag a composite record pointer and a regional list pointer. The valid flag indicates whether the symbol ID is known record s have been allocated and the pointers in the entry are valid.

If the valid flag is set the LVC Memory Manager uses the composite record pointer to retrieve the composite record from the record storage memory. The composite record is passed to the LVC message record updater where it is stored in a composite record buffer for processing by the update engines. The LVC Memory Manger uses the regional list pointer to retrieve a regional list from the record storage memory. Note that regional list blocks may also be stored in the record management memory or in another independent memory. The regional list block contains pointers to the regional records for the financial instrument identified by the symbol ID. Since each regional record reflects the state of the instrument on a given exchange a global exchange ID is stored with each regional pointer. The pointer to the regional record associated with the exchange specified in the message is located by matching the global exchange ID computed by the Symbol ID Mapping FAM. The LVC Memory Manger uses the regional pointer associated with the matching global exchange ID to retrieve the regional record from the record storage memory. The regional record is passed to the LVC message record updater where it is stored in a regional record buffer for processing by the update engines.

If the valid flag in the record management memory entry is not set then the LVC Memory Manager creates a new composite record a new regional list block and a new regional record for the financial instrument. The initial values for record fields may be drawn from Templates and Field Maps . The regional list block will be initialized with at least one entry that contains a pointer to the new regional record and the global exchange ID received from the Symbol ID Mapping FAM. The LVC Memory Manger uses a free space pointer to allocate available memory in the record storage memory. After the memory is allocated the free space pointer is updated. Freeing unused memory space defragmenting memory and adjusting the free space pointer may be performed by the LVC Memory Manager or by control software during market down times. Techniques for freeing memory space and defragmenting are well known in the art. Once the records are initialized in record storage memory the LVC Memory Manger writes the pointers into the management memory entry and sets the valid flag.

The LVC Memory Manager may also encounter a case where the valid flag in the memory management entry is set but a matching global exchange ID is not found in the regional list. This will occur when a known financial instrument begins trading on a new exchange. In this case the LVC Memory Manager allocates a new regional record and creates a new entry in the regional list block.

Once the record and message fields are loaded into their respective buffers the update engines perform the field update tasks as specified by the business logic. Upon completion of their update tasks the update engines signal the LVC Memory Manager. When all processor engines complete the LVC Memory Manager writes updated records back to record storage memory. Processing can be deployed across the plurality of update engines in any of a number of ways. In one embodiment a given record and its related message fields are passed through a sequence of update engines arranged in a pipeline. In another embodiment each record and its related message fields are passed directly to an update engine that is configured to perform processing appropriate for the type of processing that the record and message fields needs. Preferably the LVC updater is configured to balance the distribution of records and message fields across the plurality of different update engines so that a high throughput is maintained. In an exemplary embodiment each update engine is configured to be responsible for updating a subset of the record fields either regional or composite with multiple engines operating in parallel with each other.

The LVC message record updater passes updated message fields and interest lists to the Interest Entitlement Filter FAM . An interest list contains a set of unique identifiers for users applications that registered interest in receiving updates for the financial instrument. In a preferred embodiment the set of user identifiers is specified using a bit vector where each bit position in the vector corresponds to a user identifier. For example a 4 bit vector with the value represents the set of user identifiers 3 1. The size of the interest list in bits is equal to the total number of user subscriptions allowed by the Ticker Plant. In a preferred embodiment each record contains an interest list that is updated in response to user subscribe and unsubscribe events. By maintaining an interest list in the composite record the Ticker Plant allows a subscription to include all transactions for a given financial instrument on every exchange upon which it trades. Preferably each interest list for a given record is stored with that record in the record storage memory. Control software for the ticker plant which maintains the set of interest lists for each record in a control memory can be configured to advise the LVC FAM of a new interest list vector for a given record so that the record storage memory can be updated as appropriate. Other types of subscriptions such as exchange based subscriptions may also be enabled by the FAM pipeline.

In a preferred embodiment the record storage memory and or the record management memory is an external memory to the reconfigurable logic such as a Synchronous Random Access Memory SRAM or Synchronous Dynamic Random Access Memory SDRAM device. Read and write transactions to external memory devices incur processing delays. A common technique for improving processing performance is to mask these delays by performing multiple transactions in a pipelined fashion. The LVC Memory Manger is designed as a pipelined circuit capable of performing the various processing steps in parallel therefore allowing it to mask memory latencies and process multiple messages in parallel. Doing so enables the LVC Memory Manger to process more messages per unit time i.e. achieve higher message throughput. By employing a functional pipeline the LVC Memory Manager preferably recognizes occurrences of the same symbol ID within the pipeline and ensure correctness of records in update engine buffers. One method for doing so is to stall the pipeline until the updated records associated with the previous occurrence of the symbol ID are written back to record storage memory. In a preferred embodiment the LVC Memory Manager utilizes a caching mechanism to always feed the correct record field values to the update engine buffers. Techniques for a memory cache are well known in the art. The caching mechanism can be embodied as a memory preferably a high speed memory located either on chip within the reconfigurable logic device or off chip e.g. an SRAM or SDRAM device accessible to the reconfigurable logic device . However it should also be noted that the cache can also be embodied by a full memory hierarchy with a multi level cache system memory and magnetic storage. A record typically stays in the cache memory for the duration of a trading day. Such recently updated records can then be flushed out of the cache during an overnight processing roll and archived. However it should be noted that the cache can be configured to maintain records so long as space is available in the cache for storing new records in which case a FIFO scheme can be used to maintain the cache.

The LVC Update FAM passes interest lists the global exchange ID and updated message fields to the Interest Entitlement FAM . The Interest Entitlement FAM computes a single interest list that is used to distribute the output message to the set of users applications that have registered interest and are entitled to receive the message. As previously described interest may be registered by subscribing to updates for the regional or composite interest as well as subscribing to all updates from a given exchange. Access to real time financial data is typically a purchased service where the price may vary depending on the scope of data access. In a preferred embodiment a ticker plant is capable of accepting subscription requests from users applications with varying levels of data access privileges.

As shown in a preferred embodiment of the Interest Entitlement FAM operates on interest lists specified as bit vectors. The global exchange ID is used to lookup the exchange interest list in the exchange interest table. By using an exchange interest list the embodiment of allows traders to request notification of everything traded on a given exchange without individually subscribing to every instrument traded on that given exchange. Note that a global interest list specifying users interested in all events may also be stored in a register in the FAM. As shown in all interest list vectors applicable to a message are combined using a bitwise OR operation. The resulting composite interest list vector contains the set of users that are interested in receiving the output message. An entitlement ID is used to lookup an entitlement mask. The entitlement ID may be specified by the feed handler that receives messages from the exchange or alternative mechanisms such as a lookup based on message fields such as the global exchange ID event type and instrument type. Similar to the interest lists the entitlement mask specifies which users applications are entitled to receive the output message. The entitlement mask is applied to the combined interest list using a bitwise AND operation. The result is the final entitled interest vector specifying the set of entitled and interested users applications. If the entitled interest bit vector is empty e.g. all zeros the message can be dropped from the pipeline. This entitled interest list and the message fields received from the LVC Update FAM are passed to the Message Formatter FAM .

As previously described the Message Formatter FAM serves to construct an output message from updated fields received from the Interest Entitlement Filter FAM and fields contained in the Message Synch Buffer FAM . In a preferred embodiment the format of the output message is specified by the Templates and Field Maps . In a preferred embodiment the output message includes the entitled interest list computed by the Interest Entitlement Filter. A subsequent functional block in the Ticker Plant processes the interest list and transmits copies of the output message to the interested and entitled users applications.

Financial market data generated by exchanges is increasing at an exponential rate. Individual market events trades quotes etc are typically bundled together in groups and delivered via an exchange feed. These exchange feeds are overwhelmingly delivered to subscribers using the Internet Protocol over an Ethernet network. Due to constraints on packet size dictated by the network environment data groups transmitted by the exchange tend to be limited to sizes less than 1500 bytes.

As market data rates increase the number of data groups that must be processed by a ticker plant increases. In typical ticker plant environments each network packet received by the ticker plant must be processed by the network protocol stack contained within the Operating System and delivered to a user buffer. This processing includes one or more data copies and an Operating System transition from kernel or supervisor mode to user for each exchange data packet. An increase in data rates in turn increases the processing burden on the ticker plant system to deliver individual exchange data messages to the user level process.

The device depicted in uses a novel approach to efficiently deliver the exchange data to the user process. shows the exemplary data flow for inbound exchange traffic in a ticker plant. Exchange data enters the ticker plant at and is processed by the Operating System supplied network protocol stack. Typical ticker plants use a user mode interface into the network protocol stack at . This method of connecting to the protocol stack incurs processing overhead relating to buffer copies buffer validation memory descriptor table modifications and kernel to user mode transitions for every network data packet received by the ticker plant. As shown in an Upject Driver is employed that interfaces with the operating system supplied network protocol stack at the kernel level at . Individual data packets are processed at the kernel level and copied directly into a ring buffer at thus avoiding subsequent data copies and kernel to user mode transitions incurred when accessing the protocol stack via the user mode interface.

The ring buffers employed by the Upject Driver are shared memory ring buffers that are mapped into both kernel and user address spaces supported by the Operating System at . The boundary between kernel mode operations and user mode operations is shown at . Data written to the kernel address space of one of these ring buffers is instantly accessible to the user mode code because both the user mode and kernel mode virtual addresses refer to the same physical memory. Utilizing the shared ring buffer concepts the preferred embodiment of a Ticker Plant does not have to perform user to kernel mode transitions for each network data packet received and thus achieves a performance boost. Additionally the Upject Driver can utilize the shared ring buffer library to directly transfer inbound data to other kernel processes device drivers or user processes at . This versatile shared ring buffer interconnect enables fast track routing of network traffic directly to Reconfigurable logic via the Hardware Interface Driver.

General purpose computers as known in the art employ multi core or multi processor technology to increase the available compute resources in a computer system. Such multi core systems allow the simultaneous execution of two or more instruction streams commonly referred to as threads of execution . To fully utilize the compute power of these multiple processor systems software must be designed to intelligently manage thread usage resource contention and interdependencies between processing threads. The data normalization component of the preferred embodiment of a Ticker Plant employs thread groups to efficiently normalize raw exchange data.

Thread groups improve processing efficiency of the preferred embodiment of a Ticker Plant by using the following techniques 

All of the processing for any single thread group is completely independent of the processing for any other thread group. No data locking or resource management is required during the normalization process which eliminates the possibility of thread blocking due to contention for a shared resource. The preferred embodiment of a Ticker Plant supports a variable number of thread groups at . The number of thread groups and the number of exchange feeds processed by each thread group are configurable enabling the Ticker Plant to efficiently utilize additional compute resources as they become available in future generations of computer systems. The association of inbound data feeds with individual thread groups is defined in a configuration file that is read during initialization processing.

The Hardware Interface Driver in the preferred embodiment of a Ticker Plant is optimized to facilitate the efficient movement of large amounts of data between system memory and the reconfigurable logic. shows the data movement between the Hardware Interface Driver and the reconfigurable logic. User mode application data destined for the reconfigurable logic is written to one of the shared memory ring buffers at . These are the same buffers shown at in . These ring buffers are mapped into both kernel address space and into user space. Data written to these buffers is immediately available for use by the Hardware Interface Driver at . The boundary between user space and kernel space is noted at .

The Hardware Interface Driver is responsible for updating descriptor tables which facilitates the direct memory access DMA data transfers to the reconfigurable logic. Normalized market data events are transferred to the reconfigurable logic at . The reconfigurable logic and Firmware Application Module Chain perform the operational functions as noted above. Processed market events are transferred back to the Hardware Interface Driver at and deposited into a ring buffer at .

A novel feature of the preferred embodiment of a Ticker Plant is the ability to route data to consumers through a fast track by bypassing the time consuming data copies and Operating System mode switches. An operating system mode switch occurs whenever software transitions between user mode processing and kernel mode processing. Mode switches are expensive operations which can include one or more of the following operations software interrupt processing address validation memory locking and unlocking page table modifications data copies and process scheduling. depicts an exemplary design of a low latency data routing module. After processing by the reconfigurable logic market data events are delivered to the Hardware Interface Driver at . Each market data event as shown at contains a routing vector at . This routing vector which is preferably embodied by the entitled interest bit vector is populated by the reconfigurable logic preferably the interest and entitlement FAM and contains the information necessary to deliver each event to the appropriate consumers. A table maintained by the software preferably translates the bit positions of the entitled interest bit vector to the actual entities entitled to the subject data and who have expressed interest in being notified of that data.

The Hardware Interface Driver calls into the MDC Driver for each event received from the reconfigurable logic at . The MDC Driver is responsible for the fast track data routing of individual enhanced market data events. The routing information associated with each event is interrogated at . This interrogation determines the set of destination points for each event. Each event can be routed to one or more of the following kernel modules protocol stacks device drivers and or user processes. Exception events results from maintenance commands and events that require additional processing are routed via a slow path to the user mode background and maintenance processing module at . The background and maintenance processing module has the ability do inject events directly into the Hardware Interface Driver at for delivery to the reconfigurable logic or to the MDC Driver at for delivery to a connected consumer.

Similar to the Upject Driver the MDC Driver also maintains a kernel level interface into the Operating System supplied network protocol stack at . This kernel level interface between the MDC Driver and the protocol stack provides a fast path for delivering real time market events to clients connects via a network at . The event routing logic contained within the MDC Driver interrogates the event routing information contained in each event and passes the appropriate events directly to the network protocol stack.

The MDC driver also has the ability to route market events to other consumers at . These other consumers of real time market events include but are not limited to network drivers for clients connected via a variety of network interconnect methodologies kernel mode modules or device drivers hardware devices including reconfigurable logic and different user mode processes. The MDC Driver is a flexible data routing component that enables the preferred embodiment of a Ticker Plant to deliver data to clients with the lowest possible latency.

Depending on the nature of the client request the background and maintenance processing module can either issue commands to the FAMs contained in reconfigurable logic via the Hardware Interface Driver at or it can respond directly to client request by sending properly formatted responses to the MDC driver at . The MDC Driver uses spinlocks to synchronize responses to client requests with real time market events at . Responses to client requests and real time market events are processed in the same manner by the MDC Driver using common event routing logic. Events and responses destined for a remote client are passed via a fast track path to the Operating System supplied network protocol stack at for delivery to the remote client.

Thus as shown in a platform developed in the practice of the invention can be designed to improve data processing speeds for financial market information all while reducing the number of appliances needed for platform relative to conventional GPP based systems as well as the space consumed by such a platform. With a platform a user such as a trader at a work station or even a customer supplied application software program that accesses the platform via an application programming interface API can obtain a variety of information on the financial markets with less latency than would be expected from a conventional system. This improvement in latency can translate into tremendous value for practitioners of the invention.

While these figures illustrate several embodiments of FAM pipelines that can be implemented to process real time financial data streams it should be noted that numerous other FAM pipelines could be readily devised and developed by persons having ordinary skill in the art following the teachings herein.

Further still it should be noted that for redundancy purposes and or scaling purposes redundant appliances and can be deployed in a given market data platform .

Furthermore it should also be noted that a practitioner of the present invention may choose to deploy less than all of the functionality described herein in reconfigurable logic. For example device may be arranged to perform only options pricing in reconfigurable logic or some other subset of the functions listed in . If a user later wanted to add additional functionality to device it can do so by simply re configuring the reconfigurable logic of system to add any desired new functionality. Also the dashed boxes shown in enclose data processing functionality that can be considered to belong to the same category of data processing operations. That is devices and can be categorized as management operations. Device can be categorized as providing feed handling processing for data access value added services and historic services. Devices and can be categorized as direct market access trading systems. As improvements to reconfigurable logic continues over time such that more resources become available thereon e.g. more available memory on FPGAs the inventors envision that further consolidation of financial data processing functionality can be achieved by combining data processing operations of like categories as indicated by the dashed boxes thereby further reducing the number of appliances needed to implement platform . Further still in the event of such resource improvements over time for FPGAs it can be foreseen that even further consolidation occur including consolidation of all functionality shown in on a single system .

While the present invention has been described above in relation to its preferred embodiments various modifications may be made thereto that still fall within the invention s scope as will be recognizable upon review of the teachings herein. As such the full scope of the present invention is to be defined solely by the appended claims and their legal equivalents.

