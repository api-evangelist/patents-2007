---

title: Recoverable error detection for concurrent computing programs
abstract: A system and method detects communication error among multiple nodes in a concurrent computing environment. One or more barrier synchronization points/checkpoints or regions are used to check for a communication mismatch. The barrier synchronization point(s)/checkpoint(s) can be placed anywhere in the concurrent computing program. Once a node reaches a barrier synchronization point/checkpoint, it is not allowed to communicate with another node regarding data that is needed to execute the concurrent computing program, even if the other node has not reached the barrier synchronization point/checkpoint. Regions can also, or alternatively, be used to detect a communication mismatch instead of barrier synchronization points/checkpoints. A concurrent program on each node is separated into one or more regions. Two nodes communicate with each other when their regions are compatible. If their regions are not compatible, a communication mismatch occurs.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08055940&OS=08055940&RS=08055940
owner: The MathWorks, Inc.
number: 08055940
owner_city: Natick
owner_country: US
publication_date: 20070717
---
This application is a continuation of U.S. patent application Ser. No. 11 488 432 filed Jul. 17 2006 the entire content of which is incorporated by reference herein.

The present application generally relates to a concurrent computing and more specifically to providing detection of communication error in a concurrent computing environment.

MATLAB is a product of The MathWorks Inc. of Natick Mass. which provides engineers scientists mathematicians and educators across a diverse range of industries with an environment for technical computing applications. As a desktop application MATLAB allows scientists and engineers to interactively perform complex analysis and modeling in their familiar workstation environment. With many engineering and scientific problems requiring larger and more complex modeling computations accordingly become more resource intensive and time consuming. However a single workstation can be limiting to the size of the problem that can be solved because of the relationship of the computing power of the workstation to the computing power necessary to execute computing intensive iterative processing of complex problems in a reasonable amount of time.

For example a simulation of a large complex aircraft model may take a reasonable amount of time to run with a single workstation with a specified set of parameters. However the analysis of the problem may also require the model be computed multiple times with a different set of parameters e.g. at one hundred different altitude levels and fifty different aircraft weights to understand the behavior of the model under varied conditions. This would require five thousand computations of the model to analyze the problem as desired and the single workstation would take an unreasonable or undesirable amount of time to perform these computations. Therefore it is desirable to perform a computation concurrently using multiple workstations when the computation becomes so large and complex that it cannot be completed in a reasonable amount of time on a single workstation.

In another example an application can have a mathematical function that is to be integrated in parallel using a quadrature algorithm. In this case the mathematical function must be evaluated a large number of times in order to calculate the integral to a sufficient degree of accuracy and each evaluation of the mathematical function may take a large amount of time. To perform the integration in a reasonable amount of time it would be desirable to have multiple workstations working on the integration in parallel and communicating partial results with one another until a result with sufficient accuracy is reached.

Applications that are traditionally used as desktop applications such as MATLAB need to be modified to be able to utilize the computing power of concurrent computing such as parallel computing and distributed computing. Each machine or workstation needs to have its local copy of the application or at least the part of the application that has the necessary functionality for the machine or workstation to perform concurrent computing and the requested computations. Between the different instances of the application there need to be a way to communicate and pass messages between the machines and workstations so that the multiple machines or workstations in the concurrent computing environment can collaborate with each other.

Message passing is a form of communication used in concurrent computing for different processes on the same or different machines workstations to communicate with each other in the concurrent computing environment. Communication is made by the sending of messages from one machine workstation to another machine workstation. Forms of messages include function invocation signals and data packets. One example of a message passing method that establishes a communication channel between machines or workstations is Message Passing Interface MPI .

When developing concurrent computing programs such as parallel programs especially in the single program multiple data model it is possible to introduce communication mismatches among the multiple nodes in a concurrent computing environment. Communication mismatch can be due to send receive inconsistency caused by an error in program execution flow such as a message was not sent because one of the processes exits a loop in an untimely manner. A mismatch can also be due to incorrect sender or receiver. A bug in the parallel program also can cause a communication mismatch. Some errors are non deterministic such as ones caused by differences in execution times caused by different data inputs. Errors can easily occur when there is a change in execution environment such as a change in parallel platform. A communication mismatch in one part of an application may result in errors becoming apparent in a separate part of the application because the communication mismatch may leave some undeliverable messages in a pending state when these messages are eventually received they will not be what the receiver expects. A deadlock can possibly occur due to communication mismatch and causes the application to hang. As building many core multi processor systems and clusters becomes more popular debugging a communication mismatch in a concurrent computing program becomes exponentially harder.

Some embodiments of the present invention provide a system and method for detecting communication error among multiple nodes in a concurrent computing environment. A checkpoint called barrier synchronization point is used to check for any communication mismatch in a concurrent computing program. The barrier synchronization point can be placed anywhere in a concurrent computing program as desired. Once a node has reached the barrier synchronization point the node suspends execution and becomes idle to wait for other nodes to reach the barrier synchronization point as well. No node can leave the barrier synchronization point until all nodes have entered the barrier synchronization point. If a node attempts to initiate communication with another node that has already entered the barrier synchronization point an error is raised immediately. Once all the nodes have reached the barrier synchronization point any message in the send receive buffer is flushed before resuming to normal execution to ensure that any communication mismatch before the barrier synchronization point does not continue past the barrier synchronization point. Each message to be flushed represents a communication mismatch and a warning or an error can be issued.

Alternatively instead of barrier synchronization points regions can be used to practice the present invention. Nodes that use the region based implementation do not suspend execution when they are leaving one region and entering another. In one embodiment of the present invention each message is packaged with information that identifies the region that the sending node is in so that the receiving node can determine if such message can be successfully received without error. The receiving node checks if the region information in the message is compatible with the region that the receiving node is currently in and an error is raised if there is an incompatibility between the regions. In another embodiment of the present invention a sending node queries the region that the receiving node is in and compares the region of the receiving node with the region that the sending node is currently in. If the receiving node is in a compatible region with the sending node then a message is sent from the receiving node to the sending node. However if the receiving node is in an incompatible region with the sending node then a communication mismatch is detected. In yet another embodiment of the present invention a message is sent by a sending node without information on the region that the sending node is in and the receiving node queries the region that the sending node is in before the receiving node successfully receives the message. If the region of the receiving node is compatible with the region of the sending node then the receiving node successfully receives the message. If the region of the receiving node is incompatible with the region of the sending node then a communication mismatch is detected.

According to one aspect a method may include concurrently executing a concurrent computing program by first and second nodes where the concurrent computing program may include one or more checkpoints processing at the first node an instruction to enter a first one of the one or more checkpoints suspending execution of the concurrent computing program by the first node when the first node enters the first checkpoint determining by the first node when the second node enters a second one of the one or more checkpoints and resuming execution of the concurrent computing program by the first node when the second node enters the second checkpoint.

According to another aspect a node in a system that includes a number of nodes may include means for receiving a concurrent computing program that is to be concurrently executed by the nodes where the concurrent computing program may include a barrier synchronization point means for executing the concurrent computing program means for determining arrival at the barrier synchronization point means for suspending execution of the concurrent computing program after determining arrival at the barrier synchronization point and means for resuming execution of the concurrent computing program when at least one other one of the nodes also arrives at the barrier synchronization point.

According to yet another aspect a computer readable medium may contain instructions for executing a concurrent computing program that is concurrently executed by a number of nodes. The concurrent computing program may include a number of checkpoints. The computer readable medium may include instructions for entering one of the checkpoints instructions for suspending execution of the concurrent computing program after entering the one of the checkpoints instructions for discarding any undelivered messages after suspending execution of the concurrent computing program instructions for determining whether another one of the nodes has also entered the one of the checkpoints and instructions for resuming execution of the concurrent computing program when the other one of the nodes has also entered the one of the checkpoints.

According to a further aspect a method may include concurrently executing a concurrent computing program by first and second nodes where the concurrent computing program may include a number of different regions determining that the first node is currently operating in a first one of the regions of the concurrent computing program determining that the second node is currently operating in a second one of the regions of the concurrent computing program and permitting communication between the first and second nodes when the first region is compatible with the second region.

According to another aspect a system may include a first node and a second node. Each of the first and second nodes may be configured to concurrently execute a concurrent computing program that includes a number of different regions. The first node may be configured to identify one of the regions of the concurrent computing program in which the second node is currently operating determine whether the identified region is compatible with one of the regions of the concurrent computing program in which the first node is currently operating and either send a message to the second node or receive a message from the second node when the identified region is compatible with the one of the regions in which the first node is currently operating.

Some embodiments of the present invention provide a system and method for detecting communication errors among multiple nodes in a concurrent computing environment. A node is used herein to refer to a concurrent computing lab described later . A barrier synchronization point or regions can be used to check for communication mismatch. The barrier synchronization can be placed anywhere in a concurrent computing program. If a communication error occurred before the barrier synchronization point it would at least be detected when a node enters the barrier synchronization point. Once a node has reached the barrier synchronization point it is not allowed to communicate with another node regarding data that is needed to execute the concurrent computing program even if the other node has not reached the barrier synchronization point. Before leaving the barrier synchronization point and resuming execution of the concurrent computing program all messages in the send receive buffer can be flushed so that communication error do not propagate beyond the barrier synchronization point. The concurrent computing nodes can then resume and continue execution of the concurrent computing program and communicate data with each other again. The concurrent computing application does not need to be aborted when a communication error is detected. In another aspect of the present invention a program may be divided into regions instead of using the barrier synchronization points to detect a communication mismatch. If a node attempts to communicate with another node that is currently in an incompatible region then an error is raised to signal the communication mismatch.

The following illustrative embodiments will be described for illustrative purposes relative to a MATLAB based technical computing environment. Although the illustrative embodiment will be described relative to a MATLAB based application one of ordinary skill in the art will appreciate that the present invention may be applied to parallel or distributed processing of technical or non technical computing tasks with other technical or non technical computing environments. Examples of technical computing environments that are suitable to practice with the present invention include ones from software products of LabVIEW or MATRIXx from National Instruments Inc. or Mathematica from Wolfram Research Inc. or Mathcad of Mathsoft Engineering Education Inc. or Maple from Maplesoft a division of Waterloo Maple Inc or R from The R Project for Statistical Computing of Australia or Scilab from Institut national de recherche en informatique et en automatique INRIA of France or Octave from University of Wisconsin of Madison Wis. or products for embedded systems from OPAL RT Technologies Inc. of Ann Arbor Mich.

Some embodiments of the present invention can also be applied to an embedded control system or a network system of embedded controls. An embedded control system includes a physical system that is being controlled by computing hardware such as a microprocessor. The computing hardware is embedded in the physical system by means of sensors and actuators. One embedded control system may contain multiple computing hardware entities and these hardware entities communicate to achieve a desired behavior of the physical system. These hardware entities can work in a concurrent computing environment discussed below . The communication among the multiple computing hardware entities can synchronize in time and the communication of information can be done periodically or aperiodically. For the overall system to behave as desired the communication needs to be validated and missed points of communication need to be identified and the incorrectly communicated information needs to be acted upon such as discarding the incorrectly communicated information and issuing a warning.

Some embodiments of the present invention may apply to concurrent processing of streaming data. The data can be processed in real time. Alternatively data can be stored first before it is being processed. For example a fast Fourier transform may be used to analyze the frequency spectrum of the measured values from a sensor. In case of the on line processing real time processing is typically performed. Real time processing may be employed in off line processing. The measured values from a sensor may be supplied to the nodes in the concurrent computing environment as a stream of data and the processing may be performed by a number of concurrent computations that exploit the communication error and warning detection of the present invention.

The memory may comprise a computer system memory or random access memory such as DRAM SRAM EDO RAM etc. The memory may comprise other types of memory as well or combinations thereof A user may interact with the computing device through a visual display device such as a computer monitor which may include a user interface . The computing device may include other I O devices such a keyboard a touchscreen a camera a microphone and a pointing device for example a mouse for receiving input from a user. Optionally the keyboard and the pointing device may be connected to the visual display device . The computing device may include other suitable conventional I O peripherals. The computing device may further comprise a storage device such as a hard drive CD ROM or other computer readable media for storing an operating system and other related software and for storing application such as parallel computing with MATLAB or distributed computing with MATLAB .

Application may be running a concurrent computing environment to enable concurrent computing on the computing device . The application can also include a communication error detector for detecting a communication error among multiple nodes in the concurrent computing environment . When a communication error is detected a warning can be issued. One of ordinary skill in the art will appreciate that communication error detector can be adapted to be included as part of the application or it can be a stand alone application module script program that responds to calls from the application such as communication error detector . Additionally the operating system and application can be run from a computer readable media such as for example KNOPPIX a bootable CD for GNU Linux.

The computing device may include a network interface to interface to a Local Area Network LAN Wide Area Network WAN or the Internet through a variety of connections including but not limited to standard telephone lines LAN or WAN links e.g. 802.11 T1 T3 56 kb X.25 broadband connections e.g. ISDN Frame Relay ATM wireless connections controller area network CAN or some combination of any or all of the above. The network interface may comprise a built in network adapter network interface card PCMCIA network card card bus network adapter wireless network adapter USB network adapter modem or any other device suitable for interfacing the computing device to any type of network capable of communication and performing the operations described herein. Moreover the computing device may be any computer system such as a workstation desktop computer server laptop handheld computer or other form of computing or telecommunications device that is capable of communication and that has sufficient processor power and memory capacity to perform the operations described herein.

The computing device can be running any operating system such as any of the versions of the Microsoft Windows operating systems the different releases of the Unix and Linux operating systems any version of the MacOS for Macintosh computers any embedded operating system any real time operating system any open source operating system any proprietary operating system any operating systems for mobile computing devices or any other operating system capable of running on the computing device and performing the operations described herein. The operating system may be running in native mode or emulated mode.

The concurrent computing client can be a technical or non technical computing software application. Concurrent computing client may provide a technical computing and or graphical modeling environment for generating block diagram models and to define mathematical algorithms for simulating models. The concurrent computing client may include all or a portion of the functionality provided by the stand alone desktop application of MATLAB . Additionally the concurrent computing client can be any of the software programs available in the MATLAB product family. Furthermore the concurrent computing client can be a custom software program or other software that accesses functionalities of software programs in the MATLAB product family via an interface such as an application programming interface API or by other means. One of ordinarily skill in the art will appreciate the various combinations of client types that may access the functionalities of the system.

In one embodiment of the present invention concurrent computing client is also a concurrent computing lab. In such a configuration communication channels are set up among the concurrent computing labs concurrent computing client and concurrent computing labs A N . Each of the concurrent computing labs including the concurrent computing client has its local copy of a computer program that is executed in the corresponding concurrent computing labs so there is no main concurrent computing lab that distributes executions to the other concurrent computing labs. Alternatively a copy of the computer program can be accessed through a network connection. The local copy of the program for each lab may or may not be identical. The concurrent computing client can additionally have the functionality to accept inputs and or commands from a user related to the computer program using a tool such as an Integrated Development Environment IDE . The concurrent computing client and concurrent computing labs A N can be configured to perform distributed computing or parallel computing.

In one embodiment of the present invention functions can be defined by the concurrent computing client with an application programming interface API and or programming language representing a technical computing task to be executed by either a technical computing environment local to the client or remote on the workstations A N. Tasks can be declared on a concurrent computing client and additionally organized into jobs. A job is a logical unit of activities or tasks that are processed and or managed collectively. A task defines a technical computing command such as a MATLAB command to be executed and the number of arguments and any input data to the arguments. A job is a group of one or more tasks.

In one aspect of the present invention a task can be directly distributed by the concurrent computing client to one or more computing resources such as workstations A N. A computing resource performs technical computing on a task and may return a result to the concurrent computing client .

In another aspect of the present invention the system includes a server on which a scheduler runs. The scheduler can be a scheduler provided with application a generic scheduler or a third party scheduler that is designed and provided by a company or individual that may not provide application . For example given that application is parallel computing with MATLAB by The MathWorks Inc. of Natick Mass. a third party scheduler can be MPI Exec LSF Condor Microsoft Compute Cluster Server or PBS. The server communicates over a network communication channel on the network to the workstations A N. One of ordinary skill in the art will appreciate that any of the workstations A N may include more than one technical computing lab to practice the present invention. Additionally client and server may also include one or more concurrent computing labs.

The scheduler comprises one or more application software components to provide for the automatic distribution of tasks from the concurrent computing client to one or more of the concurrent computing labs A N. The scheduler allows the concurrent computing client to delegate the management of task distribution to the scheduler . The scheduler may also set up for concurrent computing client the concurrent computing labs A N by using the information received from the concurrent computing client regarding the number of concurrent computing labs needed and other configuration information. Hence the concurrent computing client does not need to know the specifics of the concurrent computing labs A N. The concurrent computing client can define a function to submit the task to the scheduler and get a result of the execution of the task. As such the scheduler provides a level of indirection between the concurrent computing client and the concurrent computing labs A N.

This eases the distributed programming and integration burden on the concurrent computing client . The concurrent computing client does not need to have prior knowledge of the availability of the workstations A N. For multiple task submissions from the concurrent computing client the scheduler can manage and handle the delegations of the tasks to the concurrent computing labs A N and hold the results of the tasks on behalf of the concurrent computing client for retrieval after the completion of technical computing of all the tasks distributed by concurrent computing client or at desired intermediate points. In an alternative implementation the concurrent computing labs A N may provide concurrent computing client directly the results of the tasks assigned to concurrent computing labs A N by the scheduler . The scheduler can further include an object oriented interface to provide control of delegating tasks and obtaining results in the system . The scheduler also provides an interface for managing a group of tasks collectively as a single unit called a job and on behalf of a concurrent computing client submitting those tasks making up the job and obtaining the results of each of the tasks until the job is completed. One of ordinary skill in the art will recognize that the functions and operations of the scheduler can be separated into various software components applications and interfaces. Additionally the functions and operations of the scheduler may reside on either the concurrent computing client or one of the concurrent computing labs A N instead of the server .

Additionally each of the client the server and the workstations A N can be running the same or different operating systems with the same or different processors. For example the client can be running Microsoft Windows the server can be running a version of Unix and the workstations A N a version of Linux. Alternatively each of the client the server and the workstations A N can be running Microsoft Windows . One of ordinarily skill in the art will recognize the various combinations of operating systems and processors that can be running on any of the computing devices client server workstations A N . One or ordinary skill in the art will also appreciate that some computing device may not have an operating system. For example an FPGA without an operating system can be configured to perform computations synchronously or asynchronously and put the data on a communication bus.

In one embodiment of the present invention the collaboration is dynamic. In other words a user can modify or change the size of the collaboration by adding another computing resource. The user may be provided on the client with a user interface to modify or change the size of the collaboration or designate a specific resource to add or remove from the collaboration. In another embodiment of the present invention the client can forward the information to the scheduler which will determine a concurrent computing lab to be added or removed from the collaboration.

In step the first node obtains an instruction to enter a barrier synchronization point. The barrier synchronization point can be inserted manually by a user into the concurrent computing program. Alternatively the barrier synchronization point can be inserted automatically by the communication error detector . In one embodiment of the present invention the positions to insert the barrier synchronization points can be dynamically defined. A user can use a rule based system to define where barrier synchronization points are inserted. The barrier synchronization point is used to detect if there is any communication error among the nodes. If a communication error is detected a warning can be issued. The warning can be accompanied by an error code that helps a user to identify the type of communication error that was detected. When a node reaches the barrier synchronization point the node waits for other nodes in the concurrent computing environment to reach the barrier synchronization point before continuing the execution of the concurrent computing program so that the communication among the nodes can be synchronized. For example the following pseudo code shows how a barrier synchronization point can be used in one embodiment of the present invention.

In one embodiment of the present invention the barrier synchronization point is different for each node. In other words the nodes can execute a different number of lines of code before reaching a synchronization point. Hence synchronization points can be assigned differently to different nodes to ensure the correct data are being communicated among the nodes to avoid data mismatch. In another embodiment of the present invention a node only needs to wait for the nodes that the node communicates with when the node reaches a synchronization point. There can be multiple barrier synchronization points in a single concurrent computing program. In one embodiment of the present invention a barrier synchronization point is represented using a single instruction such as a single function call. Alternatively the barrier synchronization point can be represented using a series of instructions. One of ordinary skill in the art will recognize that every barrier synchronization point does not need to be the same. In other words every barrier synchronization point can be implemented differently.

In step the first node suspends execution of the concurrent computing program. The first node then optionally sends a message to the other nodes in the concurrent computing environment that it has entered the barrier synchronization point in step . For example the following function can be used by a node to inform other nodes in the concurrent computing environment that it has reached the barrier synchronization point.

The first node then checks if all the other nodes have entered the barrier synchronization point in step . If all the other nodes have entered the barrier synchronization point then the first node resumes execution of the concurrent computing program in step . If all the other nodes have not entered the barrier synchronization point then the first node waits for all the other nodes to enter the barrier synchronization point before resuming execution of the concurrent computing program in step . For example the following function can be used by the first node to wait for other nodes to reach the barrier synchronization point.

Once all the nodes have entered the barrier synchronization point any undelivered messages may be flushed in step to ensure that before resuming to normal execution of the concurrent computing program in step there are no messages buffered by the communication layer. Each message to be flushed represents a communication mismatch and a warning is issued. Moreover any message received while the first node is waiting at the barrier synchronization point is discarded in step before the first node resumes execution of the concurrent computing program in step . For example the following function can be used to clean up any messages that are sent received while waiting at the synchronization point.

Hence if there is an error due to communication mismatch it would at least be detected when a node enters the barrier synchronization point. Before leaving the barrier synchronization point and resuming execution of the concurrent computing program all messages in the send receive buffer are flushed so that communication errors do not propagate beyond the barrier synchronization point. The concurrent computing nodes can then resume and continue execution of the concurrent computing program and communicate data with each other again. The concurrent computing application does not need to be aborted when a communication error is detected.

In one embodiment of the present invention a state of the first node at the synchronization point is stored in step . When a communication mismatch is detected after the synchronization point then the first node may return to the stored state. There may be multiple synchronization points used in a single concurrent computing program then when a communication mismatch is detected the concurrent computing nodes can return to the last synchronization point and re execute the portion of the program where a communication mismatch is detected. Alternatively the concurrent computing nodes can return the last synchronization point and allow a user to fix any error in the concurrent computing program before re executing the portion where a communication mismatch is detected.

If the first node has already reached the barrier synchronization point before it can receive or send data then the second node would detect a communication error in step . Optionally the second node can receive a message from the first node informing that the first node has entered the barrier synchronization point in step . This can occur before or after the second node attempts to communicate with the first node. If the first node that the second node wants to communicate with has already reached a synchronization point then the second node would eventually obtain an instruction to enter the barrier synchronization point in step as well. Then the second node would suspend execution of the concurrent program in step until all nodes have reached the barrier synchronization point.

In another embodiment of the present invention regions can be defined within a concurrent computing program to detect a communication mismatch. In one preferred embodiment of the present invention the nodes do not suspend execution of their programs when they exit one region and enter another. The local copy of the concurrent program on each node is separated into one or more regions. One of ordinary skill in the art will appreciate that the overall program being executed can be the same on each node but the exact code that is executed on each node may be different such as conditional code that may require one lab to execute one portion of the program while another lab executes another portion. Alternatively each node may execute a different program providing that the region definitions between the different programs are compatible. The local copies of the same program on different nodes may or may not have the same regions definition but the regions definition on each node must be compatible. For example given a program with a conditional code that has 10 lines of code a first node may assign the first five lines to a first region while a second node may assign the next three lines of code to the same first region.

Two nodes can only communicate with each other when their regions are compatible. If their regions are not compatible then there is a communication mismatch. In one embodiment of the present invention each message communication that is sent would include information on the region the sending node is in. When the receiving node receives the message it checks if the message has region information compatible with the current region of the receiving node. If the receiving node is in an incompatible region compared to the region information in the message then an error occurs. Each communication is associated with a particular region and only nodes with compatible regions can communicate with each other.

In one embodiment of the present invention when a node changes from a first region to a second region a message is sent to other nodes in the concurrent computing environment to inform the new region that the node is in. In this case if a receiving node with the current region as the first region is waiting to receive a message from the node that changes from the first region to the second region then the receiving node knows that there is an error since the node has finished execution in the first region and the receiving node will never receive a message from the node while the node is in the first region. However it is possible for a receiving node to start waiting to receive a message from a sending node when the sending node is still in an incompatible preceding region. At this point an error is not raised because sending node can possibly get to the right region and send a message to the receiving node. By the time the receiving node actually receives a message from the sending node the message can possibly be sent while the sending node is in a compatible region with the receiving node. If the region information of the sending node is packaged with the message then the receiving node can check if the region information in the message is compatible with the current region that the receiving node is in. If the regions are not compatible then an error is raised at this point. In another embodiment of the present invention each node can optionally keep a record of the current regions that the other nodes are in. When regions are used to detect a communication mismatch the nodes do not need to suspend execution when it leaves one region and enters another.

In one embodiment of the present invention a compatible region means the same region. Alternatively the definition of a compatible region can be different for each region in the concurrent computing program or concurrent computing node. One of ordinary skill in the art will appreciate that there can be many different ways in defining what a compatible region is and the specific examples mentioned herein should not be used to limit the scope of the present invention.

In one embodiment of the present invention regions are automatically defined by the communication error detector or application . The regions may also be manually defined by a user in the concurrent computing program. A counter variable or comments can be used to define regions. A function call can also be used to define the boundaries between regions such as labRegionBoundary in the following example. A ruled base system can also be used to define the regions. One of ordinary skill in the art will appreciate that there are many ways that one can define regions and the specific examples listed herein should not be used to limit the scope of the present invention.

In one embodiment of the present invention the regions can have a temporal aspect. A region may be defined relative to time. In such a case nodes can only communicate with each other for example using MPI RT if they are in a compatible temporal region. The definition of temporal region can be different on each node in the concurrent computing environment as long as the definitions of temporal regions are compatible. One of ordinary skill in the art will appreciate that a barrier synchronization point can also be defined relative to time. For example the end of a 10 millisecond fragment of data can be used as a barrier synchronization point. If one of the labs returns a result before the 10 milliseconds have passed this may indicate that an error has occurred. One of ordinary skill in the art will appreciate that other operations may be performed on data with a real time aspect.

In one embodiment of the present invention each region has an identification number. The identification number can be an integer or other suitable numerical representation. Alternatively each region can also be identified using alphabets characters symbols or other suitable representation. One of ordinary skill in the art will appreciate that the scope of the present invention is not limited to the specific identification system for the regions mentioned herein and other suitable representation can also be used to identify the different regions.

The following pseudo code illustrates one way of implementing regions using the present invention. The following example assumes that MPI is used with MATLAB to implement regions.

Many alterations and modifications may be made by those having ordinary skill in the art without departing from the spirit and scope of the invention. Therefore it must be expressly understood that the illustrated embodiments have been shown only for the purposes of example and should not be taken as limiting the invention which is defined by the following claims. These claims are to be read as including what they set forth literally and also those equivalent elements which are insubstantially different even though not identical in other respects to what is shown and described in the above illustrations.

