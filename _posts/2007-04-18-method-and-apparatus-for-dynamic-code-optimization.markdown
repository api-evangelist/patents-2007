---

title: Method and apparatus for dynamic code optimization
abstract: A method and an apparatus that optimally compile a source code for a data transformation operation in response to a request from a run-time application are described. A current state of the run-time application is included in the request. The application executes a non-optimized library routine for the data transformation operation while a separate worker thread performs optimized code compilation on the source code for the data transformation operation based on the request at the same time. The request includes a current state of the run-time application. The non-optimized library routine has been pre-built during build time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08615747&OS=08615747&RS=08615747
owner: Apple Inc.
number: 08615747
owner_city: Cupertino
owner_country: US
publication_date: 20070418
---
The present invention relates generally to code optimization. More particularly this invention relates to compiling optimized code during run time.

As the complexity of software applications increases the significance of an optimized library serving commonly used operations called from an application has become more and more important. For example users may demand a faster rendering speed to support high resolution or near life graphic effects when playing an interactive computer game. Usually a static non optimized code library is available for an application to link during link time. These static libraries are often built during build time. Most static libraries are not optimally compiled to consider run time states from calling applications because such states are not available during build time. In some cases there may be too many possible run time states and hence it may be impractical to create optimally compiled library routines.

Although some library routines may be optimally compiled on request during run time such optimizations are typically performed without regard to the number of times an optimized library routine will be called by an application. This is especially true for operations during application start up. However optimized library routines for supporting application start up tasks may be called only once or twice in the entire application life cycle.

Therefore computing resources spent for run time code optimization may be wasted. Additionally an application may take more time optimizing a run time library code than directly executing a corresponding static version. As a result users tend to experience glitches in overall system performance.

An embodiment of the present invention includes methods and apparatuses that optimally compile a source code for a data transformation operation or some other operations in response to a request from a run time application. A current state of the run time application is included in the request. The application executes a non optimized library routine for the data transformation operation or some other operations while a separate worker thread performs optimized code compilation on the source code for the data transformation operation or some other operations based on the request at the same time. The request includes a current state of the run time application. The non optimized library routine has been pre built during build time. This allows the first and possibly a few subsequent requests to be executed through the use of the non optimized library routine concurrently while the optimized code is being compiled and once it is completed the optimized code may be used for further requests for the particular operation.

In an alternative embodiment a source code for a library routine is compiled into an intermediate binary code to be used for run time compiling. At run time an element including a task key is retrieved from a queue to compile an optimized code for the library routine from the intermediate binary code to be stored in a dynamic library.

Other features of the present invention will be apparent from the accompanying drawings and from the detailed description that follows.

A method and an apparatus for dynamic code optimization are described herein. In the following description numerous specific details are set forth to provide thorough explanation of embodiments of the present invention. It will be apparent however to one skilled in the art that embodiments of the present invention may be practiced without these specific details. In other instances well known components structures and techniques have not been shown in detail in order not to obscure the understanding of this description.

Reference in the specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment can be included in at least one embodiment of the invention. The appearances of the phrase in one embodiment in various places in the specification do not necessarily all refer to the same embodiment.

The processes depicted in the figures that follow are performed by processing logic that comprises hardware e.g. circuitry dedicated logic etc. software such as is run on a general purpose computer system or a dedicated machine or a combination of both. Although the processes are described below in terms of some sequential operations it should be appreciated that some of the operations described may be performed in different order. Moreover some operations may be performed in parallel rather than sequentially.

In one embodiment a dynamic code optimization may be designed to provide a run time compilation mechanism to gradually improve the performance of an application over time. Depending on how a user drives an application the dynamic code optimization may build a dynamic compiled code library adapting to a usage pattern of the application. In one embodiment compiling an optimized code into a dynamic code library during application run time using a worker thread may reduce the user experience that a running application stalls while compiling optimized code. The dynamic code library may include optimized routines more likely to be called repetitively for an application. Thereby the longer or the more times a user operates an application the better the application performs.

Additionally the library interface module may be coupled with a dynamic library via a hash engine . A dynamic library may be an optimized executable code storage as a container for executable codes dynamically modified. A library routine in the dynamic library may be compiled after an application calls a library function corresponding to the library routine via for example the library interface module . In one embodiment a library routine in the dynamic library includes optimally compiled codes based on a request from a run time application such as application . The request may include a function name and a plurality of associated parameters such as arguments or options for a function call. In one embodiment application may send a request for a library routine to the library interface module . The library interface module may search for an optimized routine in the dynamic library corresponding to a received request. The search may be based on a hash table of the hash engine indexed according to requests from run time applications such as application .

According to one embodiment the library interface module may determine a task vector based on received requests to find a corresponding optimized library routine. The task vector may be a tightly packed bit vector representing a request from a run time application. In one embodiment the hash engine may retrieve a run time task object based on a task vector. The hash engine may be associated with a task object store including a plurality of run time task objects. A run time task object may include a pointer for optimally compiled codes inside the dynamic library . In one embodiment the hash engine may be coupled to the dynamic library through pointers included in run time task objects. A run time task object may include a null pointer to indicate the corresponding optimized codes are not available in the dynamic library .

According to one embodiment the library interface module may call a run time task object generator module to generate a new run time task object for a run time request received from an application such as application . A new run time task object may be generated when the library interface module fails to find any run time task object from the hash engine according to a received run time request. In one embodiment the generator module may update the hash engine with a newly generated run time task object for example into the object store of the hash engine . The library interface module may update a work queue with a newly generated task object.

According to one embodiment a plurality of run time task objects may be queued in the work queue to schedule tasks for compiling optimized codes such as optimized codes for a plurality of different state vectors or run time states. The work queue may include a queue with elements associated with a plurality of run time task objects. Each associated run time task object in the queue may be stored in the run time task store . The run time task object associated with the head element of the work queue may be scheduled for the next optimized code compilation task. In one embodiment the library interface module may update the work queue by adding or removing elements to the queue . In some embodiments the library interface module may reorder elements inside the queue .

In one embodiment a run time optimization compiler module may run as a worker thread separately from threads running the application in system . A worker thread such as a pthread POSIX thread may have with its own stack while sharing its memory with other threads in the same process. In one embodiment the run time optimization compiler module may perform code optimization according to a run time task object including a task vector. The order of the run time code optimization tasks may be determined according to the queue in the work queue . For example compiler module may retrieve the run time task object associated with the head element of the queue for a new code optimization task after finishing compiling an existing one. A run time object task retrieved by compiler module may be removed from the work queue . In one embodiment compiler module may compile an optimized library routine from a binary intermediate representation of the source codes into the dynamic library . A pointer of the run time task object corresponding to an optimized library routine may be updated to point to the optimized library routine stored in the dynamic library .

Referring back to according to one embodiment process looks up for a task object corresponding to the task key at block . The task object may be a run time task object. The lookup may be performed based on a hashing against the task key such as in hash engine of . A hashing key may be generated from the task key based on a for example 7 bit or 8 bit cyclic add operation to identify a bucket in a hash table for matching the task key. At block process determines if a task object corresponding to the task key is found or not.

In one embodiment a task object may be associated with a predefined set of states. For example a task object may be in a queue state a compiling state a cancel state or a finished state. A task object with a queue state may be scheduled for an optimized run time compilation waiting in a queue such as work queue of . A task object with a compiling state may be associated with a current optimized compilation task being performed by a run time optimization compiler such as in of . In one embodiment a task object with a cancel state may have been removed from a queue previously scheduled for an optimized run time compilation. A task object with a finished state may be associated with a pointer to an optimally compiled library routine for the corresponding task key.

At block in one embodiment process may generate a new task object for the task key if process fails to find a task object matching the task key at block . A task object generation may be performed by a module such as run time task object generator module of . Process may schedule an optimized code compilation for the library routine corresponding to the task key for the newly generated task object by adding the new task object to a work queue such as work queue of at block . In one embodiment a newly generated task object may be assigned a default queue state after being added to a work queue. Process may remove an existing task object from the work queue at block . Process may identify a non optimized library code according to the task object from the static library such as library of at block after updating the work queue at block . In one embodiment process may return a pointer to the identified non optimized library code at block .

If a matching task object is found at block according to one embodiment process may determine if the task object is associated with an optimized library code at block . The task object may be in a finished state when associated with an optimized library code. In one embodiment a task object may include a pointer to the optimized library code in a dynamic library such as library of . Process may return a pointer to the associated optimized code at block . If the matching task object is not associated with an optimized library code process may check if the matching task object has already been scheduled in a work queue e.g. in a queue state at block . If the task object is already scheduled in the work queue process may proceed to update the work queue at block . In one embodiment process may change the order of scheduled optimized compilation tasks in the work queue at block such as increasing the priority of the task object for the current request. In another embodiment process may keep the existing order of the work queue at block . Process may return a pointer to a non optimized library code at block after updating the work queue at block . If the task object is not yet scheduled in the work queue e.g. in a cancel state process may schedule an optimized compilation task for the matching task object at block before executing a corresponding non optimized library code at block . In one embodiment process returns to the calling application after identifying either an optimized library code at block or non optimized library codes at block .

At block process may update the work queue according priorities of task objects. In one embodiment a newly generated task object may be scheduled by appending it to the tail of the work queue. Process may remove cancel a task object associated with the tail element of the work queue to accommodate a newly generated task object. In one embodiment process may remove cancel a plurality of existing task objects from the work queue based on a change of state of a running application. For example process may remove existing task objects associated with graphic operations related to rendering previous frames when a new task object is generated by a current request for rendering a new frame. In one embodiment process may reorder task objects associated with a work queue at block according to the priorities updated at block .

At block process may compile an optimized library code from the source codes corresponding to the task object. In one embodiment the optimized library code is compiled from a binary intermediate representation of the source codes such as binary intermediate codes of of the corresponding non optimized static library e.g. static library of . The binary intermediate representation and the non optimized static library may be based on the same source codes. In one embodiment the optimized code compilation at block may reduce code branches from the corresponding source codes based on the associated task key in the task object. Process may store the compiled optimized library code into a dynamic library such as library of at block . If the work thread running process is not to be terminated e.g. by system shutdown message process may continue at block for additional compilation tasks scheduled in the work queue.

As shown in the computer system which is a form of a data processing system includes a bus which is coupled to a microprocessor s and a ROM Read Only Memory and volatile RAM and a non volatile memory . The microprocessor may retrieve the instructions from the memories and execute the instructions to perform operations described above. The bus interconnects these various components together and also interconnects these components and to a display controller and display device and to peripheral devices such as input output I O devices which may be mice keyboards modems network interfaces printers and other devices which are well known in the art. Typically the input output devices are coupled to the system through input output controllers . The volatile RAM Random Access Memory is typically implemented as dynamic RAM DRAM which requires power continually in order to refresh or maintain the data in the memory.

The mass storage is typically a magnetic hard drive or a magnetic optical drive or an optical drive or a DVD RAM or a flash memory or other types of memory systems which maintain data e.g. large amounts of data even after power is removed from the system. Typically the mass storage will also be a random access memory although this is not required. While shows that the mass storage is a local device coupled directly to the rest of the components in the data processing system it will be appreciated that the present invention may utilize a non volatile memory which is remote from the system such as a network storage device which is coupled to the data processing system through a network interface such as a modem or Ethernet interface or wireless networking interface. The bus may include one or more buses connected to each other through various bridges controllers and or adapters as is well known in the art.

Portions of what was described above may be implemented with logic circuitry such as a dedicated logic circuit or with a microcontroller or other form of processing core that executes program code instructions. Thus processes taught by the discussion above may be performed with program code such as machine executable instructions that cause a machine that executes these instructions to perform certain functions. In this context a machine may be a machine that converts intermediate form or abstract instructions into processor specific instructions e.g. an abstract execution environment such as a virtual machine e.g. a Java Virtual Machine an interpreter a Common Language Runtime a high level language virtual machine etc. and or electronic circuitry disposed on a semiconductor chip e.g. logic circuitry implemented with transistors designed to execute instructions such as a general purpose processor and or a special purpose processor. Processes taught by the discussion above may also be performed by in the alternative to a machine or in combination with a machine electronic circuitry designed to perform the processes or a portion thereof without the execution of program code.

An article of manufacture may be used to store program code. An article of manufacture that stores program code may be embodied as but is not limited to one or more memories e.g. one or more flash memories random access memories static dynamic or other optical disks CD ROMs DVD ROMs EPROMs EEPROMs magnetic or optical cards or other type of machine readable media suitable for storing electronic instructions. Program code may also be downloaded from a remote computer e.g. a server to a requesting computer e.g. a client by way of data signals embodied in a propagation medium e.g. via a communication link e.g. a network connection .

The preceding detailed descriptions are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the tools used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of operations leading to a desired result. The operations are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be kept in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the above discussion it is appreciated that throughout the description discussions utilizing terms such as processing or computing or calculating or determining or displaying or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

The present invention also relates to an apparatus for performing the operations described herein. This apparatus may be specially constructed for the required purpose or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium such as but is not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions and each coupled to a computer system bus.

The processes and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs in accordance with the teachings herein or it may prove convenient to construct a more specialized apparatus to perform the operations described. The required structure for a variety of these systems will be evident from the description below. In addition the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.

The foregoing discussion merely describes some exemplary embodiments of the present invention. One skilled in the art will readily recognize from such discussion the accompanying drawings and the claims that various modifications can be made without departing from the spirit and scope of the invention.

