---

title: Size vector sharing in code generated for variable-sized signals
abstract: A method and apparatus to generate code to represent a graphical model formed of multiple graphical modeling components and at least one variable-sized signal is presented. Each variable-sized signal is represented using a size-vector in the generated code. The generated code is optimized by representing multiple variable-sized signals with the same size-vector such that at least two variable-sized signals share a size-vector in the generated code. The size of the variable-sized signal is capable of changing during the execution of the graphical model. The method and apparatus also identifies the owners of the variable-sized signals.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08260598&OS=08260598&RS=08260598
owner: The MathWorks, Inc.
number: 08260598
owner_city: Natick
owner_country: US
publication_date: 20070111
---
Graphical modeling environments assist in simplifying the process of designing simulating and implementing graphical models for systems. A graphical model is a representation of a system through a graph containing nodes e.g. blocks interconnected by arcs e.g. lines . Nodes are functional entities that perform mathematical operations transformations and or other operations on the data and information that is processed by the system. In some graphical modeling environments the lines represent signals. Signals represent information such as data data types timing information and control information that connect the output and input of various nodes.

In certain graphical modeling environments the signals have a number of attributes such as data dimensions i.e. signal dimensionality and data type. Signal data can be organized into a data structure having one or more dimensions e.g. a vector a matrix etc. .

After creating a model in a modeling environment a user may be able to execute the model by commanding the modeling environment to simulate the system represented by the model. When a model executes the output of the model may be calculated from a specified start time to a specified stop time.

As a model in a graphical modeling environment executes signal dimensionality may need to be known so that signals can be properly processed. If signal dimensionality is allowed to vary while the model executes the time varying information regarding signal dimensions may need to propagate along with the signal values during execution. If the dimensionality of a signal varies while the model executes the signal is referred to as variable size signal. It is therefore important to represent variable sized signals in an efficient way in the generated code for the corresponding model.

In accordance with one exemplary embodiment in a computing device one or more of the variable sized signals of a graphical model formed are identified. The size of a variable sized signal is capable of changing during the execution of the graphical model. A code representing the graphical model is generated representing the dimensionality information for each variable sized signal with a size vector in the generated code. The generated code is optimized by representing a plurality of variable sized signals with one size vector such that at least two variable sized signals share a size vector in the generated code.

In accordance with another exemplary embodiment in a computing device a graphical model formed of a plurality of graphical modeling components and at least one variable sized signal is provided. The size of a variable sized signal is capable of changing during the execution of the graphical model. Each graphical modeling component of the graphical model has at least one input signal and one output signal. The graphical modeling components where the output signal has a same dimension size as the input signal are identified as the owners of their input signals.

Exemplary embodiments described herein automatically generate code to share size vectors among multiple variable sized signals. A size vector holds information regarding the size of a matrix or a vector that represents a variable sized signal in a graphical model. As a variable sized signal changes in size the size vector updates to hold information regarding the new size. Exemplary embodiments recognize that in some instances certain variable sized signals in a graphical model have the same sizes. In those instances variable sized signals with the same size may change sizes together. As such these variable sized signals may share size vectors. For example size vectors may be shared in the model and in code generated from the model. Size vector sharing in the generated code results in less memory allocation and faster code execution.

Signal as used herein represents a set of values. For example a signal may be a set of values that can be stored read from storage manipulated sent from a source to a destination etc. For example a signal may be associated with a path e.g. a connection line in a graphical modeling environment. The path may indicate a source location for the signal and a destination for the signal. In one implementation the signal may be read from the source location and stored at the destination. In another implementation the signal may propagate from the source location to the destination along the path. Signals that can be used with exemplary embodiments can take on different values as a model executes. Signals may have attributes such as dimensionality data type sample rate etc. A signal type refers to a signal that is a member of a class or classes of signals.

At each time instant the value of a signal is in general an N dimensional array where N can take on any positive integer value. For example a scalar signal is represented by a scalar value at each time instant. Thus for example at time t a scalar signal may have a value of 3.14. A 1 dimensional signal is represented as a vector at each time instant. For example at time t a 1 dimensional signal may have a value of 

Dimensions of signals may have sizes associated therewith. For example the size of the 1 dimensional signal discussed above is 3. The 2 dimensional signal discussed above has a size of 4 for the first dimension and a size of 2 for the second dimension.

Table 1 illustrates some possible dimensions of a signal that can be used with exemplary embodiments described herein. The column Signal is shows the representations that can be used to illustrate a signal with dimensions given in the first column. Similarly the column Signal is not shows the representations that may not be used to illustrate a signal with dimensions given in the first column. M and N are positive integers.

Modeling environment allows a user to develop models in the modeling interface . Modeling interface may include an interface that allows a user to interact with one or more models. For example in one implementation modeling interface may include a graphical user interface that allows a user to enter information into model and to receive results from model . In another implementation modeling interface may include a textual interface such as textual interface that allows a user to enter information via for example command line prompts. Using the modeling interface a user can create a model that includes for example an element an element and an element . The elements can be for example graphical objects or textual objects that can model portions of a system such as a dynamic system. The user may use predefined elements or user specified elements to develop a model.

The modeling environment may further include a textual interface that may allow a user to develop a user defined element using a sequence of commands in a textual language. The textual interface may also facilitate debugging and or profiling of a model. Alternatively implementations of the modeling environment may include a separate debugger and profiler.

Simulation engine may include logic to compile and execute the model . The simulation engine may communicate with the modeling interface . Simulation engine can receive a model such as for example a block diagram model a state diagram model a UML model a SysML model a text based model e.g. a sequence of commands etc. that is generated using the modeling interface . Simulation engine can convert the model to an executable form referred to as a compiled model. Simulation engine can repetitively execute the compiled model e.g. via successive time steps from a simulation start time to a stop time specified by the user or until the simulation is interrupted. Alternatively the simulation engine may enable interpretive simulation of the model.

Code building tool may include logic to generate code from a model. For example code building tool can be used to generate code such as source code object code a compiled executable or library for forming an executable of a model provided by the modeling interface etc. Code building tool can also be used to generate a hardware description language representation of the model. Code building tool uses implementations of code for portions of a model to generate executable code instructions etc. in a programming language such as Java Javascript C or C or a hardware description language such as Verilog or Very high speed integrated circuit Hardware Description Language VHDL . To generate code code building tool can convert a source model language representation of a model to a target language. Code building tool may include an extended version of a code building tool such as the Real Time Workshop tool from The MathWorks Inc. of Natick Mass or any portion thereof or may be substantially any software component application for generating executable code instructions etc. in a programming language such as Java C etc. or in a hardware description language such as Verilog VHDL etc.

Code building tool can generate source code for the execution of a model that is provided by the modeling interface and can compile the source code into object code and build an executable program library or substantially any other form of executable instructions. The generated code may be designed to run on any processor microprocessor dual core processor multi core processor cluster of processors operating system computational hardware device component of a computational hardware device etc. In one embodiment the code may include embedded code targeted to run on an embedded system. Additionally the code can be customized to run on a specific target hardware platform. For example the generated code may include fixed point code to run a fixed point processor or code can be generated to emulate fixed point behavior on a floating point processor.

One of ordinary skill in the art will also appreciate that the components of the modeling environment may be provided on a computing device as described below with reference to or alternatively the components of the modeling environment may be coupled to each other via a communication network as described below with reference to .

The computing device may be electronic and may include a display a Central Processing Unit CPU a modem a network interface an input control memory storage etc. The CPU may control each component of the computing device to provide the modeling environment textual interface environment simulation engine and or code building tool . The memory may temporarily store instructions and data and may provide them to the CPU so that the CPU operates the computing device and may run the modeling environment textual interface environment simulation engine and or code building tool based on the stored instructions.

Optionally the computing device may include multiple CPUs for executing software loaded in the memory and other programs for controlling system hardware. Each of the CPUs can be a single or a multiple core processor and may have one or more caches . The code loaded in the memory may run in a virtualized environment such as in a Virtual Machine VM . Multiple VMs may be resident on a single processor. Also part of the application could be run in hardware for example by configuring a field programmable gate array FPGA using an application specific instruction set processor ASIP or creating an application specific integrated circuit ASIC . Further the part of the applications may be run on analog electronic devices or other resources may be used to run part of the application such as graphics processing units GPUs or dedicated hardware such as Fast Fourier Transform FFT processing blocks.

Storage may contain software tools for applications. Storage can include code for the operating system OS of device code for applications running on the operation system including the applications for the modeling interface textual interface environment simulation engine code building tool and data generated from the modeling interface textual interface environment simulation engine and code building tool . Those of ordinary skill in the art will appreciate that parts of the applications can be stored in the CPU cache or memory as well much like the data and even the OS or they can be stored on the network described below with reference to .

The input control may interface with a keyboard a mouse a microphone a camera such as a web camera or other input devices such as for example a motion based input device. The computing device may receive through the input control input data such as the input data for developing a model. The computing device may display on the display user interfaces for displaying the data generated from the modeling interface textual interface environment simulation engine and code building tool .

In the network environment the servers and may provide the clients and with software components or products under a particular condition such as a license agreement. The software components or products may include those for providing the modeling environment and or implementations of code for select elements. The software components or products may also include those for the textual interface environment simulation engine and code building tool coupled to the modeling environment .

In one example the client may perform the modeling of a dynamic system using a software component provided by the server and send the server the model for simulation. The server may return the simulation results to the client and the client may subsequently display the data to the user with the information on the data.

In another example the client may have the modeling environment and may desire additional implementations of code for select models. The client may have implementations of code that are already loaded on the client or may have to download each implementation of code the client desires. In either case the server may store implementations of code that the user can download. The user may be charged a fee to download the implementation of code. The implementation of code may be specialized code that provides an advantage over an implementation of code to which client currently has access.

In another example the client can access the server and or to access a repository of implementations of code. The implementations of code in the repository can be maintained and updated by an administrator. The repository can serve as a central location to access implementations of code for the clients and . The clients may also be able to upload implementations of code to the repository. Alternatively the clients and can access the repository of implementations of code via a network such as the Internet to download or upload implementations of code. The implementations of code may be put under version control in the repository and may have information as well as index terms associated with them. The information can be text or any other format for information storage such as the eXtended Markup Language XML .

Exemplary embodiments are described for illustrative purposes relative to a Simulink compatible modeling environment that enables a graphical model to be built and or executed. A SIMULINK compatible modeling environment provides means e.g. via hardware or software based logic to use a SIMULINK model and or features in the SIMULINK compatible modeling environment. For example a SIMULINK compatible modeling environment may provide means to interface with a SIMULINK model means for importing or exporting a SIMULINK model means for translating a SIMULINK model means for integrating a SIMULINK model etc. Although exemplary embodiments may be described relative to a SIMULINK compatible modeling environment the present invention is not limited to these embodiments and may be applied to graphical modeling and or computing tasks via other graphical modeling environments.

Further examples of graphical modeling environments that may be used to develop and or execute a graphical model in accordance with exemplary embodiments include but are not limited to LabVIEW or MATRIXx from National Instruments Inc. SoftWIRE by Measurement Computing VisSim by Visual Solutions WiT by DALSA Coreco VEE Pro by Agilent Dymola from Dynasim AB Extend from Imagine That Inc. Scicos from The French National Institution for Research in Computer Science and Control INRIA MSC.Adams from MSC.Software Corporation Rhapsody from iLogix Inc. Rational from International Business Machines Corporation ARTiSAN Studio from ARTiSAN Software Tools Inc. SCADE from Esterel Technologies Inc. among others.

Model has three source blocks constant block that outputs a matrix of dimension 1 2 equal to 10 7 sine wave function that outputs a sinusoidal function and constant block that outputs a matrix of dimension 1 2 equal to 90 20 . The input of the model is set by the switch block . The switch block passes through the first top input or the third bottom input based on the value of the second middle input . The first and third inputs are called data inputs. The second input is called the control input. As such the output of the switch is either equal to the output of the constant block or the constant block . Both of these signals are static matrices of size 1 2. Therefore the output of switch is not a variable sized signal it is a static signal.

The output of the switch is then fed into the S Function block . The S function block is set to generate a matrix of ones. The S Function block can be set to manipulate the size attribute of its inputs. For the model illustrated in the S Function is set to change the size attribute of its static signal input to a dynamic signal output C.

The output signal of the S function block becomes the input for the subsystem block . The subsystem block has a variable sized signal input C and a variable sized signal output F. The dynamics of subsystem is illustrated in more detail in .

The variable sized signal A is the output of the switch block and the input of the gain block . The gain block has a scalar value of 1. The gain block multiplies its input signal A by the gain value. Therefore the size of the output signal B of the gain block is variable as well. The output signal B is at the same time one of the two inputs of the MinMax block .

As explained above the S Function block is set to generate a matrix of ones. The output of the S Function block is the variable sized signal C. The variable sized signal C is the other input of the MinMax block . The MinMax block is set to choose the minimum of its inputs signal C and signal B. The MinMax block cannot change the size of the input signals B and C either. In order to be compared by the MinMax block the signals C and B must have the same size. The size of the output signal D of the MinMax block will be equal to the size of either of the inputs of the MinMax block .

The signals B and D are the two input signals of the matrix concatenate block . The matrix concatenate block will concatenate the input signals B and D. The size of the output signal E of the Matrix Concatenate block will be larger than the size of the input signals B and D of the Matrix Concatenate block .

The last element of the subsystem block is the abs block . The abs block takes the absolute value of the input signal E. The size of the output signal F of the abs block will be the same as the size of its input signal E since the abs block is not designed to change the size of its input.

In a SIMULINK compatible environment each block must have the information about whether the block is the owner of the input and output signals when the signal sizes are compatible. Similarly each signal must have the information about which block is the owner of that signal. At code generation time for each block that owns its output a size vector is generated.

Once the variable sized signals A B C D E and F are identified in they can be grouped together according to their owners. Each block of the graphical model may own one or more variable sized signals. Each variable sized signal is owned by one and only one block. Only the owner of the variable sized signal can change the dimension of the signal. All other blocks are exempt from the task. When an owner changes the dimension of its output signal the dimensions of all the signals that it owns may have their dimension changed. The variable sized signals are represented using size vectors in the generated code. Representing a group of variable sized signals with one size vector results in creating a minimum number of size vectors. Having a reduced number of size vectors results in faster simulation. The simulation also consumes less memory. Furthermore size vector sharing results in faster code execution since the memory requirement of the generated code is reduced.

The size vector sharing feature can be implemented to leverage size propagation. The blocks of a SIMULINK compatible environment can be configured to automatically inherit their data attributes such as type and size via forward or backward propagation. Inheriting data attributes minimizes data entry and makes it easier to change the data types of signals as the model evolves. For illustrative purposes it is worthwhile considering how a SIMULINK compatible environment does size propagation.

As described above regarding a model is first created in a modeling environment . Simulation engine creates the simulation of the model. The code building tool generates the corresponding code. For the exemplary embodiments described herein SIMULINK compatible environment may be used to generate models and run simulations. The Real Time Workshop tool from The MathWorks Inc. of Natick Mass. may be used to generate the code.

In one exemplary embodiment an environment may perform size propagation in two passes. For example a forward propagation pass and a back propagation pass may be used. Based on the result of the two passes of size propagation the ownership of variable sized signals is determined. The ownership information is what leads to an efficient code that shares size vectors. An alternative embodiment may perform size propagation using a single pass either forward or back propagation. Other alternative embodiments may derive the ownership of variable sized signals without using propagation techniques.

Size propagation is used to derive allowable size vector sharing. The size propagation comprises two steps forward propagation and backward propagation. Forward propagation starts from root level Inport blocks and follows the direction of signals from the block that writes to a signal to a block that reads from the signal. Forward propagation ends at root level Outport blocks. Backward propagation is performed to resolve dimension of signals left unresolved by forward propagation. For each block in the block diagram based on the operating mode of the block the output signal of a block has either the same dimension as the input in which case size vector sharing is possible or a different dimension in which case the block owns its output signal . After size propagation each signal has one and only one owner block. A one dimensional array may be used to store the ownership information. In case where a variable sized signal may be owned by two separate blocks one block is arbitrarily chosen as the owner.

Size propagation may be used to determine the dimension for all signals. Typically a user will specify the dimension of the input signal of the graphical model. The size propagation then assigns a dimension to all signals of the graphical model. It should be appreciated that other size propagation approaches and approaches that are not propagation based may be used. The above example is intended to be merely illustrative and not limiting.

The flow diagram of depicts exemplary processing that can be used for identifying the owners of the variable sized signals. The processing may begin with identifying the variable sized signals of the models step . Then using forward propagation step the owners of the variable sized signals are identified step . Once the forward propagation is completed step using backward propagation step the variable sized signals are regrouped based on the size of the variable sized signals step . This leads to a reduced number of owners to be represented in the corresponding code.

In one exemplary embodiment each block of the graphical model may have a pre defined property about whether its output inherits the dimension size from its input. As illustrated in a gain block may have four operating modes 

Only in the first operating mode element wise gain produces an output with the same size as the input. The dimensions of the input and the output for each case are illustrated in . The first example of illustrates the case where the operating mode of the gain block is element wise gain . The input is a matrix of size 2 5. The gain of the gain block has a scalar value of 1. The gain block performs a multiplication operation of the input with the scalar value of 1. Therefore the size of the output is equal to the size of the input . Similarly the second example of illustrates the case where the operating mode of the gain block is left multiply gain . The input is a matrix of size 2 5. The gain of the gain block is a matrix K of size 3 2. The gain block performs a left matrix multiplication operation of the input with matrix K of size 3 2. Therefore the size of the output is equal to the size of the matrix multiplication. In this case the size of the output is 3 5.

The third example of illustrates the case where the operating mode of the gain block is right multiply gain . The input is a matrix of size 2 5. The gain of the gain block is a matrix K of size 5 99. The gain block performs a right matrix multiplication operation of the input with matrix K of size 5 99. Therefore the size of the output is equal to the size of the matrix multiplication. In this case the size of the output is 2 99. 2 5 5 99 output 2 99 

The fourth example of illustrates the case where the operating mode of the gain block is right multiply gain where the input is treated as a column matrix . The input is a matrix of size 2 5. The gain block allows the input to be 1 n n 1 or vector of length n for all these cases the input is treated as vector of length n. In the illustrated example n is equal to 2 and K is a matrix of size 3 2. The gain block performs a right matrix multiplication operation of the input treated as a column matrix of size 2 with matrix K of size 3 2. Therefore the size of the output is equal to the size of the matrix multiplication. In this case the size of the output is 3.

Furthermore for a user written S Function block a graphical modeling environment may give a user an Application Programming Interface API to specify whether the output of the block inherits the dimension size from the input of the block. For example in a SIMULINK compatible environment the inheritance can change because blocks can adapt their functionality based on characteristics of inputs and outputs of the blocks.

If a block owns its output signal the block may also own other signals that have a same dimension size as the block s output signal. For example for the graphical model shown in the following ownership information can be derived based on forward propagation 

Backward propagation may follow forward propagation in an exemplary embodiment. The two inputs of the MinMax block are both matrices. These two inputs can have the same dimension. Therefore in this example the ownership of the signals A B and D can be safely transferred to the S Function block . Thus the number of owners can be reduced from three to two. The reduction on owners can translate to improved code generation with less dimension assignment and less memory usage to store the dimensions. If S Function block changes the size of signal C signals A B C and D can have their sizes changed. If concatenation block changes the size of the signal E signal F can have its size changed. The gain block MinMax block and abs block are not owners and thus they cannot change the size of any signals.

For the model illustrated in the generated code may define two size vectors SFunction size and concat size. Operations performed by the S Function Switch Gain and MinMax blocks may use the size vector SFunction size when the dynamic dimension is needed. Abs block and Concatenate blocks may use concat size when the dynamic dimension is needed. Creating a minimum number of size vectors in the generated code may require less effort eliminate the need to do inter procedural analysis and may avoid costly compiler analysis such as alias analysis and expression folding.

The size vector sharing mechanism described herein also applies for model reference i.e. size vectors may be shared among models that reference via model reference mechanisms .

Model reference allows the main model include other models as modular components. The technique provides useful features because it simplifies working with large models by letting the designer build large models from smaller ones. The technique also lets the designer generate code simultaneously for all the modules in the entire model and only regenerate code for modules that change. The technique further allows the designer to develop the modules independently and lets the designer reuse modules and models by reference rather than including the model or module multiple times in the main model. Also multiple models can refer to the same model or module. Model referencing can be applied to models as well as subsystems.

In case of a referenced model the referenced source is a standalone model that can be stored by itself operated on in isolation. It is a model in every sense so it has a selected solver sample time interface error and warning diagnostic settings optimization settings etc. Model referencing technology resolves any discrepancies or conflicts between model settings of the referencing and referenced model. A referenced model may convey its interface information to the referencing model and the referenced model may be stored at the call site. A model may be restricted to only one reference no references at all or a plurality of references.

In case of a referenced subsystem the referenced source is stored in a container called a library. A library subsystem can have the same referencing restrictions. The library subsystem may automatically update the referenced source when changes are made at a call site. The library subsystem can copy over the content of a referenced subsystem to the call site to it can be edited without affecting the source. It may lock the call site to it is read only.

The Subsystem may be created as a standalone model and may be referenced in the main model. In that case the above mentioned size vector sharing may also be performed among models.

A graphical modeling environment may have the capability to generate code for a subsystem as a function. By generating code for a subsystem as a function the above propagation result may lead to cross function size vector reuse. For the model illustrated in a function may be generated for the model named main and another function may be generated for the subsystem named foo . SFunction size and concat size may be defined in the function main and both may be passed in to the function foo. Therefore the function foo can use the size vector SFunction size to carry out the computation of Switch MinMax and Gain . Similarly the function can use the size vector concat size to carry out the computation of the Sum block .

At the code generation time a SIMULINK compatible environment may create an internal representation IR to represent the operations being performed by the block diagram. illustrates an exemplary hash table of IR that is used to organize the ownership information for each variable sized signal. IR conveys the block functionality information using matrix notations. Conventionally matrices are static. A SIMULINK compatible environment may use a dynamic matrix to represent the variable sized signals in IR. A single code construction implementation may be used for a block that accepts both fixed sized and variable sized input signals.

As shown in the initial IR uses matrix operation which is not defined in C and HDL languages. Thus IR must be translated to a scalar operation using scalarization. Scalarization uses information provided in the hash table to scalarize matrix operations involving dynamic matrices. Scalarization generates corresponding loops using either integer constant as loop upper bound if matrix dimension is known at compile time i.e. static matrix or variable as loop upper bound if matrix dimension is not known at compile time i.e. dynamic matrix . For example for the statement Gain out 1 Switch out scalarization will generate the following loop 

The scalarization first derives the dimension of the generated loop. By looking up the hash table it determines that Switch out is a 2 D dynamic matrix whose first and second dimension is given by SFunc size 0 and SFunc size 1 and it also determines that Gain out is a dynamic matrix of the same type and the same size thus it generates a loop for this assignment. Scalarized IR doesn t have any matrix operation and is close to final generated C code or VHDL code in case of using for example HDL coder . Scalarized IR uses only two size vectors SFunc size and Concat size rather than using a different size vector for each variable sized signal.

Scalarization transforms the matrix operations to operations on each matrix element and generates corresponding loops. The symbols with dynamic matrix types are kept after scalarization. C and HDL languages do not have dynamic matrix type. Therefore the IR generated after scalarization still cannot be directly translated to the target language.

Another transformation step called dynamic matrix lowering may be used after scalarization. Dynamic matrix lowering decomposes a symbol with dynamic matrix type to one symbol representing the size and another symbol representing the data buffer. All IR operations accessing the dynamic matrix dimension will be then translated to access to the size vector. All IR operations accessing element of dynamic matrix will be translated to access the element of corresponding data buffer. New symbols may be created during dynamic matrix lowering. These new symbols will be added to the type table and symbol table . Old symbols with dynamic matrix type will not be used in the control flow graph. Thus the old symbols can be eliminated. illustrates the table of types and table of symbols for the new symbols.

There are no size vector assignments to the dimension of output of Gain in the generated code. This is a result of size vector sharing. Gain does not own the dimension of its output signal B. Gain is thus exempt from the task of maintaining the dimension size of its output. Similarly in the final code there will be no assignment to the dimension of output of Switch MinMax and Abs .

All symbols and language constructs used by IR can be translated to C or HDL language. IR may go through other optional transformations before the final code is generated. Providing the dynamic matrix type in IR makes the code construction easier since block code construction algorithm can construct dynamic matrix operations rather than creating For loop. The code generation framework obtains the size vector sharing information for blocks and encodes the information in a symbol table. Scalarization and dynamic matrix lowering leverage the size vector sharing information provided by the size propagation and jointly achieve size vector sharing. As a result the generated code uses less memory and runs faster.

The flow diagram of depicts exemplary processing for automatically generating code for a graphical model that includes at least one variable sized signal. The processing may begin with obtaining a graphical model with at least one variable sized signal step . The variable sized signals having same size may be grouped together step . For example the user may use a block diagram simulation environment such as the SIMULINK environment to execute the graphical model. In order to execute the model the corresponding code for the model needs to be generated. The generated code is optimized because one size vector is used to represent each variable sized signal group step .

The teachings described herein allow the implementation of signals as objects or structures whose attributes are interpreted differently based on processing requirements of a block in a graphical modeling environment. As such each block in the environment can propagate a received signal type with its associated data dimensionality unchanged carry out one or more operations on the data of the received signal type to modify the dimensions of the data to output a signal with the same or different data dimensionalities than the received signal. To accomplish these benefits the modeling interface and textual interface environment operate in conjunction with the graphical model environment to assist in the management and interpretation of the objects representing signals.

Exemplary implementations may generate code for sharing size vectors among multiple signals where some of the signals can be variable sized signals.

The foregoing description of exemplary embodiments of the invention provides illustration and description but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention. For example while a series of acts has been described with regard to and the order of the acts may be modified in other implementations consistent with the principles of the invention. Further non dependent acts may be performed in parallel.

In addition implementations consistent with principles of the invention can be implemented using devices and configurations other than those illustrated in the figures and described in the specification without departing from the spirit of the invention. Devices and or components may be added and or removed from the implementations of A and B depending on specific deployments and or applications. Further disclosed implementations may not be limited to any specific combination of hardware and or software.

For example in one alternative implementation a variable type owner may define the type to be for example a struct in C. The struct may have fields that are manipulated based on the types of operations that will be performed and or types of data to which operations are applied. For example the struct may have fields that are NULLed out so they do not consume memory. An owner associated with the variable may dynamically allocate memory when it becomes necessary to do so. Dynamic operations may also be performed with respect to other things such as objects in general. For example an owner associated with an object may be able to dynamically configure attributes for the object. Owners associated with variables objects etc. may operate in substantially any type of computing environment such as technical computing environments non technical computing environments etc.

Further certain portions of the invention may be implemented as logic that performs one or more functions. This logic may include hardware such as hardwired logic an application specific integrated circuit a field programmable gate array a microprocessor software or a combination of hardware and software.

No element act or instruction used in the description of the invention should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items. Where only one item is intended the term one or similar language is used. Further the phrase based on as used herein is intended to mean based at least in part on unless explicitly stated otherwise.

