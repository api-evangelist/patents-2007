---

title: System and method for reconstructing restored facial images from video
abstract: A system and method for performing a facial image restoration is described. The system includes an active appearance model component for fitting an active appearance model to a facial image found in each of a plurality of video frames, a registration component for registering each pixel of each facial image with comparable pixels of each of the other facial images, and a restoration component for producing a restored facial image from the facial images. The method includes fitting an active appearance model to a facial image found in each of a plurality of video frames, registering each pixel of each said facial image with comparable pixels of each of the other facial images, and producing a restored facial image from the facial images.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08064712&OS=08064712&RS=08064712
owner: UTC Fire & Security Americas Corporation, Inc.
number: 08064712
owner_city: Bradenton
owner_country: US
publication_date: 20070809
---
The present patent application claims priority from provisional patent application Ser. No. 60 886 433 filed Jan. 24 2007 the disclosure of which is hereby incorporated by reference in its entirety.

This invention was made with Government support under Contract No. 2005 IJ CX K060 GOVT awarded by the National Institute of Justice. The Government has certain rights in the invention.

The invention relates generally to a system and method for fitting an active appearance model to a face in frames of a video registering each of the faces and producing a restored facial image using the frames of the video.

Automatic facial recognition at a distance is becoming of greater importance in many real world scenarios such as for example law enforcement surveillance applications. Automatic facial recognition at a distance however has had some challenging aspects. Low image resolution and camera blur contribute to the inability in many instances to obtain accurate facial recognition.

In many surveillance systems in which it is desirable to incorporate automatic face recognition the subject is captured on videos. Known facial recognition algorithms work on still images so facial recognition applications generally extract a single frame of the video with a suitable view of the face. In a sense the known facial recognition applications use only a small portion of the information available in the video.

The present invention describes a system and a method that uses multiple frames of a video to produce restored facial images. The term restored is used herein to denote that the resulting facial image has greater clarity than any individual facial image from any of the multiple video frames.

One exemplary embodiment of the invention is a system for producing restored facial images from frames of a video. The system includes an active appearance model component for fitting an active appearance model to a facial image found in each of a plurality of video frames. The system also includes a registration component for registering each pixel of each said facial image with comparable pixels of each of the other facial images and a restoration component for producing a restored facial image from the facial images.

Another exemplary embodiment of the invention is a method for producing restored facial images from frames of a video. The method includes fitting an active appearance model to a facial image found in each of a plurality of video frames registering each pixel of each facial image with comparable pixels of each of the other facial images and producing a restored facial image from the facial images.

These and other advantages and features will be more readily understood from the following detailed description of preferred embodiments of the invention that is provided in connection with the accompanying drawings.

Embodiments of the invention as described and illustrated herein are directed to a system and a methodology that uses multiple frames of a video to produce restored facial images. With specific reference to there is shown a facial reconstruction system . The system includes a training database a video input an active appearance model within module a registration module a warping module an averaging module and a Wiener filter module .

The training database includes two dimensional and possibly three dimensional facial images. The training database is used to train an active appearance model AAM . The training database may be a publicly available one such as for example the Notre Dame Biometrics Database Collection D Collection D . The facial images from the training database are used by an active appearance model training module to construct a mathematical representation of the appearance and shape of the facial images in general. By appearance is meant the colorization and texture. This mathematical representation may be adjustable.

The first step in multi frame restoration is registration. To combine frames each frame must be mapped such that between a pair of frames xis a function of x. This allows for conversion of the first image coordinates x r c of a real object or scene point to the second image coordinates x r c . One approach to registration is to select a parameterized registration function that can accurately model the actual frame to frame motion such as an AAM.

An AAM applied to facial images is a two stage model of both facial shape and appearance designed to fit the faces of different persons at different orientations. The active shape sub model describes the distribution of the locations of a set of landmark points. show 33 landmark points that will be used in the registration of a series of facial images. Principle Components Analysis PCA and the training set of facial images are used to reduce the dimensionality of the shape space while capturing major modes of variation across the training set population.

The AAM active shape sub model includes a mean face shape that is the average of all the facial shapes in the training set from the database and a set of eigenvectors. The mean face shape is the canonical shape and is used as the frame of reference for an AAM active appearance sub model. Each training set of facial images is warped to the canonical shape frame of reference.

Since each training set of facial images are warped to the canonical shape frame of reference all of the facial images from the training set are presented as if they have the same shape. With shape variation removed the variation in appearance of the facial images is modeled in the second stage using PCA to select a set of appearance eigenvectors for dimensionality reduction.

The completely trained active appearance model of module can produce facial images that vary continuously over appearance and shape. For the purpose of restoring facial images the active appearance model of module is fit to a new face as it appears in one of the video frames. This is accomplished by solving for the face shape and appearance parameters eigen coefficients such that the model generated face matches the face in the video frame. A Simultaneous Inverse Compositional SIC algorithm may for example be used to fit the new face to the one within the video frames.

Video input which may include one or more video cameras or one or more still cameras set to automatically take a series of still photographs obtain multiple frames of video or still photographs each to include a facial image of a subject. It should be appreciated that the video input may be live or forensic video or still photographs. If the video or still photographs are analog based an analog to digital converter would be required prior to transmitting the frames. The output frames of the video input are transmitted to a face detection module which is used to detect the facial image. The detection may be done automatically or manually. An example of manual detection may include the use of a Graphical User Interface. An example of automatic detection may include a facial detection software package marketed by Pittsburgh Pattern Recognition of Pittsburgh Pa.

For each frame and each detected face a vector of shape parameters and a vector of appearance parameters are obtained. The AAM of module receives the eigenvectors of facial shape and appearance from the active appearance model training module . Further an AAM fitting module determines the vectors of shape parameters and of appearance parameters. The vector of shape parameters control the shape of the face while the vector of appearance parameters control the appearance of the face.

While shape parameters and appearance parameters must be estimated to fit the model to a new face only the resulting shape parameters are used for registration. The AAM of module provides the registration needed to align the face across the multiple video or still frames. The active shape sub model portion of the AAM defines the landmark positions in each frame . These landmark positions are the vertices of 49 triangles over the face shown.

The registration accomplished by the registration module of the face between any two frames may become a piecewise affine transformation or a spline transformation with an affine transformation for each of the triangles defined by the corresponding triangle vertices. To avoid a discontinuity close to the edge of the faces the registration of the face is augmented by extrapolating the set of facial landmarks to define an extended border region . As shown 30 new landmarks have been positioned a fixed distance out from the estimated facial edges forming 45 new triangles at the border. A blending mask is used to combine the facial region of the multi frame facial reconstructions with the non facial background region of a single observed frame thus provided a more natural blended result for a viewer. The blending mask M is defined in a base frame that has a value of 1 inside the face region and fades to zero outside of that region linearly with distance to the face region. The blending mask M is used to blend a restored facial image Iwith a fill image Iusing 1 .

During the registration function one of the multiple video or still photographic frames is chosen as a base frame L. Since motion is occurring between the various frames and the motion is generally fluid in a particular direction a frame from the middle of all the frames Lto Lmay be chosen as the base frame L. A new frame of reference His created from that base frame L. The new frame of reference Hhas a greater pixel resolution than the base frame L.

The output from the warping module is input to the averaging module which averages all the warped video or still photographic frames. The averaging may be done by adding up on a pixel by pixel basis and dividing by the number of frames.

The output from the averaging module is then input to the Wiener filter . The video frames that are initially input are formed by the imaging process from a continuous image of a scene that has been convolved with a Point Spread Function PSF sampled on an image grid corrupted by additive white Gaussian noise and quantized. The PSF is responsible for blur that needs to be reduced. The additive noise limits the ability to reduce the blur. A dominant source of noise is CCD electronic noise which is well modeled as additive Gaussian with a flat spectrum.

With all image signals represented in the spatial frequency domain if the transform original image is I the Optical Transfer Function OTF the Fourier Transform of the PSF is H and the additive Gaussian noise signal is N then the observed video frame is .

The Wiener filter is a classic method for single image deblurring. It provides a Minimum Mean Squared Error MMSE estimate of I . With a non blurred image given a noisy blurred observation G and with no assumption made about the unknown image signal the Wiener filter is . The parameter H is the complex conjugate of H and the parameter K is the noise to signal power ratio thus forming the MMSE Wiener filter. In practice the parameter K is adjusted to balance noise amplification and sharpening. If parameter K is too large the image fails to have its high spatial frequencies restored to the fullest extent possible. If parameter K is too small the restored image is corrupted by amplified high spatial frequency noise. As K tends toward zero and assuming H 0 the Wiener filter approaches an ideal inverse filter which greatly amplifies high frequency noise .

The effect of the Wiener filter on a blurred noisy image is to 1 pass spatial frequencies that are not attenuated by the PSF and that have a high signal to noise ratio 2 amplify spatial frequencies that are attenuated by the PSF and that have a high signal to noise ratio and 3 to attenuate spatial frequencies that have a low signal to noise ratio.

The baseline multi frame restoration algorithm works by averaging the aligned face region of consecutive video frames Lto Land applying a Wiener filter to the result. The frame averaging reduces additive image noise and the Wiener filter deblurs the effect of the PSF. The Wiener filter applied to a time averaged frame can reproduce the image at high spatial frequencies that were attenuated by the PSF more accurately than a Wiener filter applied to a single video frame. By reproducing the high spatial frequencies more accurately the restored facial image will have higher effective resolution and greater clarity in detail. This is due to image noise at these high spatial frequencies being reduced through the averaging process. Each of N measurements corrupted by zero mean additive Gaussian noise with a variance gives an estimate of that value that has a variance of N. Averaging N registered and warped images reduces the additive noise variance and the appropriate value of K by a factor of 1 N.

Referring now specifically to there is shown a facial reconstruction system . The system like the system includes a training database video input and an active appearance model within module and each of these components operate similarly as in the system described above. The system further includes a super resolution module for producing a restored facial image .

In operation the system fits an active appearance model to a facial image in each frame. A set of a plurality of frames for example about N 10 consecutive frames are then combined to produce a super resolved image . In one possible embodiment the image formation process which includes face motion camera PSF and sampling is modeled for each frame. To solve for the super resolved image a cost function with an L norm data fidelity component is defined and a Bilateral Total Variation regularization is used. A steepest descent search using an analytic gradient of the cost function yields the super resolved facial image .

Super resolution of the facial images into a restored facial image is accomplished through an appropriate super resolution algorithm such as one similar to the one suggested by Farsiu et al. in Fast and robust multiframe super resolution IEEE Transactions on Image Processing vol. 13 no. 10 pp. 1327 1344 October 2004.

Each of the N input frames Y where i is 1 through N exists in a low resolution frame of reference denoted L. Such a frame of reference encapsulates the image size and active appearance model landmark points. A registration process allows us to warp images between frames of reference. For each L a corresponding high resolution frame of reference H having greater pixel resolution than Lin each dimension is created. The super resolution image is solved for in the frame H where k N 2.

To initialize the super resolution algorithm the initial super resolved image is created by warping the face region of each of the N input frames Yto the frame Hand averaging. The warping scales up and aligns each facial image. The result is blended with the non facial regions of the input image Yscaled up to frame H. The super resolution process uses an image formation model relating each of the input frames Yto an unknown super resolution image X in frame H. With specific reference to an initial super resolved image of a set of iteratively improved super resolved images to shown generally as is transmitted to an image formation model . The image formation model accounts for face motion camera blur and detector sampling as it relates X to each Y. Specifically the appearance shape models for each of the multiple frames 1 to N shown generally as ASM to ASM are input to the image formation model along with the camera blur and the initial super resolved image .

For each input frame the registration operator Fwarps X from frame Hto frame H which has twice the resolution of Lbut is aligned with Y. Nearest neighbor bilinear or any other interpolation may be used for the warping operation. The camera blur operator H is not dependent on variable i and applies the PSF within a high resolution frame H. Most installed surveillance cameras are challenged by determining a true PSF. The image formation model assumes a Gaussian shaped PSF with hand selected width . The sampling operation of the detector is represented by the sparse matrix D that extracts every other pixel in each dimension converting from frame Hto L the frame of reference for the input frame Y. If Vrepresents additive pixel intensity noise the complete linear image formation process is then .

The output Yis then input to the Data Fidelity module which determines the data fidelity cost and the gradient of this cost with respect to the super resolved image pixel values. The data fidelity cost J X as defined below is the Lnorm of the difference between the model of the observations and the actual observations plus a regularization term X . One optimizing algorithm that may be used for determining the super resolved image X is 

Concurrently the initial super resolved image is transmitted to a regularization module which uses a Bilateral Total Variation BTV for inhibiting a solution tending toward degenerate super resolved images. The BTV cost function is 

To solve for the super resolution image X is first initialized to the initial image as described above. The initial image is transmitted to the image formation module and the regularization module . The image formation module outputs a result to the Data Fidelity module . The Data Fidelity module outputs an analytic gradient of the data fidelity cost function and the regularization module outputs an analytic gradient of the regularization cost function . These outputs are input to the iterative optimization module . A steepest descent search using a step size 0.01 and a fixed number of iterations such as for example 30 iterations is used 

When the observed video is color the super resolution processing is applied to the luminance component only. The initial image is converted to the NTSC color space YIQ and the luminance Y component is computed for all input frames. The super resolved luminance result is combined with the chrominance components from the initial image.

Referring to through there is shown a comparison of an original video frame with enhanced video frames. illustrates the results of a Wiener filter on a single video frame. illustrates the results of super resolution utilizing the super resolution algorithm on a plurality of consecutive video frames. It is clear that the clarity of the facial images shown in and C incrementally improves over .

While the invention has been described in detail in connection with only a limited number of embodiments it should be readily understood that the invention is not limited to such disclosed embodiments. Rather the invention can be modified to incorporate any number of variations alterations substitutions or equivalent arrangements not heretofore described but which are commensurate with the spirit and scope of the invention. Additionally while various embodiments of the invention have been described it is to be understood that aspects of the invention may include only some of the described embodiments. Accordingly the invention is not to be seen as limited by the foregoing description but is only limited by the scope of the appended claims.

