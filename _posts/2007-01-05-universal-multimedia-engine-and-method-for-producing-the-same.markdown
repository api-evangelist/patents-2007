---

title: Universal multimedia engine and method for producing the same
abstract: A method, system and apparatus for adapting the multimedia content for presentation by an application that uses, processes or otherwise services the multimedia content (“multimedia application”) is provided. The method includes receiving the multimedia content formatted in accordance with at least one of a plurality of multimedia protocols; using a function abstracted from the plurality of multimedia protocols to adapt the multimedia content in accordance with one or more capabilities of the multimedia application; and sending the multimedia content so adapted to the multimedia application for presentation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07971132&OS=07971132&RS=07971132
owner: Dialogic Corporation
number: 07971132
owner_city: Montreal, Quebec
owner_country: CA
publication_date: 20070105
---
Embodiments of the present invention generally relate to multimedia communications and more particularly to a method system and apparatus for adapting multimedia content for presentation by a multimedia application.

Recent attempts to obtain licenses to obtain technology for delivering multimedia content e.g. speech music video and rich text to a user of a handheld device have uncovered a dysfunctional marketplace for such multimedia delivering technology. That is the attempts have revealed a stagnant marketplace that i has a limited cartel of suppliers ii demands un warranted licensing fees given actual worth of underlying technologies iii is mired in uncertainty given intellectual property coverage and iv offers limited life un scaleable technologies.

As a consequence of this dysfunctional marketplace emergence of new multimedia applications such as real time multimedia applications is hindered. The emergence is hindered because requirements for such emerging real time multimedia applications far exceed today s offerings and capabilities thereof. Considering recent trends of handheld devices for example existing multimedia applications lack the capabilities for fulfilling power footprint performance cost and complexity requirements to reliably inexpensively and optimally deliver real time multimedia content to such handheld devices.

In addition as new multimedia applications are introduced into the marketplace albeit slowly legacy handheld devices are obsolesced due to their inability to scale up to the new multimedia applications. This in turn requires users of such legacy handheld devices to retire their legacy handheld devices and obtain e.g. by purchase and or lease new handheld devices. Unfortunately this process repeats far too often costing the users i.e. consumers seemingly unnecessary spending of capital.

Therefore what is needed in the art is a method system and apparatus for accelerating introduction of new multimedia applications which can be deployed for example in next generation handheld devices. There is a further need for the method system and apparatus to accelerate the introduction of new multimedia applications without necessarily causing obsolescence of the next generation handheld devices and yet be capable of fulfilling power footprint performance cost and complexity requirements to reliably inexpensively and optimally adapt the multimedia content for presentation by the multimedia application in real time near real time or other time sensitive or a time insensitive period.

A method system and apparatus for accelerating introduction of new multimedia applications which can be deployed in for example a next generation handheld device is provided. Embodiments of the method system and apparatus may employ functions abstracted or otherwise formed in accordance with rules procedures conventions etc. that define protocols for processing multimedia content multimedia protocols such as those used to define multimedia CODECs for video audio speech and rich text commercial freeware open source or otherwise.

Included in the method system and apparatus for accelerating introduction of new multimedia applications is a method for adapting the multimedia content for presentation by an application that uses processes or otherwise services the multimedia content multimedia application . This method includes receiving the multimedia content formatted in accordance with at least one of a plurality of multimedia protocols using a function formed in accordance with or otherwise abstracted from the plurality of multimedia protocols to adapt modify append enhance improve etc. collectively adapt the multimedia content in accordance with one or more capabilities of the multimedia application and sending the multimedia content so adapted to the multimedia application.

Advantageously examples of the apparatus system and method allow merging of multiple multimedia delivering technologies into a tightly integrated highly optimized and easy to use multimedia processing module that is capable of fulfilling power footprint performance cost and complexity requirements to reliably inexpensively and optimally adapt the multimedia content for presentation by the multimedia application in real time near real time or other time sensitive or a time insensitive period. This multimedia processing module may be used in or with the next generation of handheld devices such as products that will combine functionality of smart phones Apple iPods Sony Playstation Portables PSPs video players recorders and more.

In the following detailed description numerous specific details are set forth in order to provide a thorough understanding of exemplary embodiments or other examples described herein. However it will be understood that these embodiments and examples may be practiced without the specific details. In other instances well known methods procedures components and circuits have not been described in detail so as not to obscure the following description. Further the embodiments disclosed are for exemplary purposes only and other embodiments may be employed in lieu of or in combination with of the embodiments disclosed.

As summarized above and described in more detail below the method system and apparatus for accelerating introduction of new multimedia applications which can be deployed in for example a next generation handheld device is provided. Embodiments of the method system and apparatus may employ functions abstracted or otherwise formed in accordance with rules procedures conventions etc. that define the multimedia protocols such as those used to define multimedia CODECs for video audio speech and rich text open source or otherwise. By integrating amalgamating assimilating and optimizing the rules procedures conventions etc. that define the multimedia protocols the functions so abstracted hereinafter abstracted functions may be assembled into the aforementioned multimedia processing module.

The system may be disposed in a single device which may be configured for handheld or other use. Alternatively the system may be distributed among a plurality of devices. For example the multimedia processing module and multimedia application may be disposed on a first device which may be configured for handheld use and the multimedia source may be disposed on a second device which may be remotely located from first device. Alternatively the multimedia source multimedia processing module and the multimedia application may be disposed on different devices.

The multimedia processing module is operable to process multimedia content received from multimedia source into adapted multimedia content and communicate the adapted multimedia content to multimedia application for subsequent presentation. To facilitate this the multimedia processing module may be communicatively coupled to the multimedia source via a first communication path over which the multimedia processing module may receive the multimedia content. The multimedia processing module may be also communicatively coupled to the multimedia application via a second communication path over which the multimedia processing module may send the adapted multimedia content.

Each of the first and second communication paths may be formed from one or more linkable segments. These segments may be disposed in one or more wired and or wireless communication networks and or one or more electrical busses of the multimedia source the multimedia processing module and multimedia application .

The multimedia source is operable to source or otherwise provide the multimedia content to the multimedia processing module . Prior to sourcing the multimedia content the multimedia source may capture and or collect the multimedia content.

To facilitate capturing the multimedia content the multimedia source may include natively one or more devices for capturing the multimedia content capture devices . Examples of the capture devices include analog and or digital microphones video cameras still photo cameras embedded or peripheral webcams and the like. Alternatively the multimedia source may gather some or all of the multimedia content from a plurality of foreign e.g. remotely located and or native capture devices.

To facilitate processing the multimedia content the multimedia processing module includes an engine having an input and an output and an application programming interface API . The engine or any other portion of the multimedia processing module may be formed from one or more programmable and or hard coded executable instructions commands directions code and or control data collectively directives for processing the multimedia content received via the input into the adapted multimedia content and for communicating the adapted multimedia content to the output .

The directives and or any other portion of the engine may be implemented in software firmware and or hardware and executed or otherwise addressed and instructed by a processing platform not shown to carry out such processing. To facilitate this the processing platform may include for example any of a general purpose computer a special purpose computer a field programmable gate array FPGA an application specific integrated circuit ASIC a general purpose processor GPP a system on a chip SoC and the like.

The input is operable to receive the multimedia content from the multimedia source . To facilitate reception the input may be configured to receive the multimedia content in streamed non streamed and or other form. In addition the input is also operable to communicate the multimedia content to the engine via a communicative coupling or interface not shown .

The engine in turn is operable to obtain the multimedia content from the input and to apply to the multimedia content one or more of the abstracted functions. These abstracted functions are operable to adapt modify append enhance improve adjust add etc. collectively adapt the multimedia content in accordance with one or more capabilities of the multimedia application multimedia application s capabilities to form the adapted multimedia content.

For example the multimedia application s capabilities may include provisions for tone control and video quality enhancement and or control such as color enhancement and or tinting. The multimedia content may or might not be formatted for such capabilities. Despite this the engine may process the multimedia content so as to form the adapted media content in accordance with the multimedia application s capabilities. The engine may form such adapted media content by applying where appropriate one or more of the abstracted functions for adapting i audio components of the multimedia content with the tone control and or other audio enhancements and or ii video components of the multimedia content with the video quality enhancement and or controls.

The abstracted functions applied by the engine as configured by the API as noted below may be optimized for the multimedia application s capabilities. For example the engine may apply one or more of the abstracted functions to adapt the multimedia content to default to a maximum or other quality level that is consistent with the multimedia application s capabilities. The engine may achieve such quality level by applying the abstracted functions that balance or otherwise regulate the quality level against an amount of functions to be applied.

For example the engine may apply the abstracted functions for adapting the multimedia content to a highest quality level possible while using a least common denominator approach. This may be facilitated by the engine using a minimum number of the abstracted functions to adapt the multimedia content to a maximum quality level consistent with the multimedia application s capabilities. The engine may use other approaches for adapting quality and or performance of the multimedia content.

Because the abstracted functions are abstracted in accordance with the plurality of multimedia protocols the engine is operable to provide interoperability and seamless capabilities negotiations between the multimedia application and the multimedia source . The engine is operable to do this by carrying out handshaking with the multimedia source in accordance with the multimedia protocol associated with the multimedia content and carrying out handshaking with the multimedia application in accordance with the multimedia application s capabilities.

In addition to being operable to adapt the multimedia content the engine is further operable to communicate the adapted multimedia content to the output . In turn the output is operable to communicate the adapted multimedia content to the multimedia application where appropriate.

The multimedia application may be most any application that uses processes or otherwise services collectively services the adapted multimedia content for communication to a user of the device . To facilitate the servicing of the adapted multimedia content the multimedia application may include directives for presenting the adapted multimedia content. These directives may be formed so as to cause the multimedia application to playback audio and or video and or display graphical and or textual components of adapted multimedia content. Examples of the multimedia application include commercial freeware proprietary open source and like type multimedia players and or multimedia generators.

Although the multimedia application is shown as a single unitary element and described as operable to playback different components of the adapted multimedia content the directives of multimedia applications may be formed into a plurality of multimedia applications. This plurality of multimedia applications when combined may have capabilities equivalent or similar to the capabilities of the multimedia application . Alternatively some of the directives of the multimedia application may be omitted when forming the plurality of multimedia applications. This way the capabilities of such plurality of multimedia applications when combined may be different from the capabilities of the multimedia application .

The API is operable to acquire harvest gather garner or otherwise obtain the multimedia application s capabilities. These capabilities may be obtained via i communicative couplings to exposed hooks of the multimedia application ii other communication with the multimedia application and or iii documentation associated with the multimedia application . With respect to obtaining the capabilities via i or ii the API may interface with and extract from multimedia application the multimedia application s capabilities.

With such knowledge the API is operable to interface with the engine to configure the engine for processing the multimedia content. To facilitate this the API includes one or more directives for causing the engine to select the abstracted functions to allow for communication of the adapted multimedia content in accordance with the multimedia application s capabilities.

For example the API may be operable to configure the engine to select the abstracted functions for adapting the audio components of the multimedia content with tone control or other audio enhancement. These functions may adapt the audio components of the multimedia content for user adjustable tone control depending of course on the capabilities of the multimedia application . Alternatively the functions may be implemented to allow static or dynamic adjustment of the tone without interaction from the user.

In addition the API may shield complexity of the engine by employing algorithms that adjust resources of the engine and processing platform to maximize efficiency of power usage and performance flexibility and resource sharing. For example the API can cause the engine to select the abstracted functions to form and communicate to the multimedia application the adapted multimedia content in for example the highest quality possible using the least common denominator approach. The API may configure the engine to select other functions as well.

The foregoing describes the multimedia processing module as having only one input and one output namely the input and the output . However the multimedia processing module may include more than one input and or output. Alternatively each of the input and the output may embody a combined input and output referred to herein as I O . For convenience the input and output are referred to hereinafter as first I O and second I O respectively.

Notwithstanding any such configuration the multimedia processing module may be configured to permit bidirectional or multidirectional flow. As such the multimedia processing module may be operable to communicate adapted multimedia content to the multimedia application and or a multimedia application associated with a device that is foreign to i.e. not native and or separate from the system . This way any adapted multimedia content sourced from the multimedia application or any multimedia content sourced from the multimedia source can be communicated to the foreign multimedia application in a form consistent with one or more of the capabilities of the foreign multimedia application.

As described in more detail below with reference to below the multimedia processing module may apply the abstracted functions for un adapting previously adapted multimedia content or for adapting the multimedia content in accordance with the capabilities of the foreign multimedia application. Beneficially this processing of the previously adapted multimedia or un adapted multimedia content provides interoperability and seamless capabilities negotiations between the foreign multimedia application and the multimedia application and or the multimedia source .

In addition the system may include additional multimedia processing modules not shown . This allows addition of new algorithms or removal of other functionality based on the desired behavior. By allowing such scaling the additional multimedia processing modules may allow for full customization without the cost of writing and re writing custom directives.

Each of the multimedia processing module and the additional multimedia processing modules collectively the multimedia processing modules may be designed such that it is not locked into any specific system protocol platform or data store. In addition each of the multimedia processing modules may be cross platform thereby providing the same services on differing processing platforms. Alternatively and or additionally each of the multimedia processing modules may also be ported to new platforms abstracting operating system and hardware dependencies and may be extendable thereby relieving an application developer of writing code for a specific protocol platform and or database.

Each of the multimedia processing modules may include one or more functional modules which allow the addition of new algorithms or removal of other functionality based on the desired behavior. Like the scaling provided by the ability to add or subtract the number of multimedia processing modules to the system the functional modules may allow for full customization without the cost of writing and re writing custom code.

The process begins at termination block and then transitions to process block responsive to the multimedia source sending the multimedia content to the multimedia processing module . At process block the first I O receives the multimedia content from the multimedia source and then passes it to the engine .

After obtaining the multimedia content from the first I O the engine forms the adapted multimedia content for termination to the multimedia application . To do this the engine may apply to the multimedia content one or more of the abstracted functions to adapt the multimedia content in accordance with the multimedia application s capabilities as shown in process block . After forming the adapted multimedia content the engine communicates the adapted multimedia content to the second I O .

At process block the second I O communicates the adapted multimedia content to the multimedia application . In turn the multimedia application services the adapted multimedia content for presentation as shown in process block .

After process block the process transitions to termination block at which point the process ends. Alternatively the process may be repeated periodically in continuous fashion or upon being triggered as a result of a condition such as reception of additional multimedia content or for further processing of the adapted multimedia content.

In addition to a plethora of various possible embodiments of the process the following describes two examples of the process . Each of the two examples employs the process to carry out multiple communication sessions. Each of the multimedia sessions includes one or more communications in which the multimedia content sourced from one or more multimedia sources is adapted for presentation by one or more multimedia applications.

As with any embodiment of the process each of the communications of the multiple multimedia sessions may be terminated to the multimedia applications in real time near real time other time sensitive period and or a time insensitive period with respect to origination of the multimedia content or reception of the multimedia content at the first or second I O . Alternatively each of the communications of the multiple multimedia sessions may be terminated to the multiple multimedia applications at a rate for preventing or otherwise minimizing degradation in quality and or performance of a stream or other flow of the multimedia content collectively stream .

In addition quality and or performance of the stream may be monitored and or compared given acceptance limits. If either of the quality or performance of the stream fails to satisfy the respective acceptance limits then the process may be adjusted so as to cause the quality and or performance of the stream to fall within the given acceptance limits.

As another alternative some or all portions of the stream may be buffered so that the termination of a given portion of the stream is coterminous or substantially continuous with reception of a subsequent portion of the stream at the first or second I O . Alternatively some or all portions of the stream may be buffered so that reception of the subsequent portion of the stream at the first or second I O is at a non zero but acceptable latency from the termination of the given portion of the stream.

In this example the multimedia sources may be include first second third and fourth multimedia sources. The first multimedia source is operable to source music content the second multimedia source is operable to source mixed multimedia content the third multimedia source is operable to source telephonic audio content and the fourth multimedia source is operable to source video and or still photograph content.

The multimedia applications may include an audio playback application native to the system native audio application an audio playback application foreign to the system foreign audio application a video playback application native to the system native video application and a video playback application foreign to the system foreign video application . Additionally this example employs the process to communicate six multimedia sessions.

The first multimedia session begins at termination block and then transitions to process block responsive to the first multimedia source sending music content to the multimedia processing module at request of the multimedia processing module . At process block the first I O receives the music content from the first multimedia source and passes it to the engine .

The engine in turn forms adapted music content from the music content and the abstracted functions for adapting the music content in accordance with the capabilities of the native audio application. As shown in process block the engine may form the adapted music content by applying the abstracted functions to the music content. This may include for example applying to the music content the abstracted functions for adapting the music content with tone control. Application of these abstracted functions may adapt the music content so as to increase decrease and or level one or more treble bass or other components of the music content. After forming the adapted music content the engine communicates the adapted music content to the second I O .

At process block the second I O communicates the adapted music content to the native audio application. In turn the native audio application services the adapted music content for presentation e.g. playback of the adapted music content to a user of the system as shown in process block .

At some point during the first session the second session begins as shown in termination block . At process block the first I O receives from the second multimedia source the mixed content that is in the form of an announcement of a phone call announcement content such as a calling number identification message commonly referred to as caller identification. After receiving the announcement content the first I O passes it to the engine .

The engine in turn forms adapted announcement content from the announcement content and the abstracted functions for adapting the announcement content in accordance with the capabilities of the native video application. The engine may form the adapted announcement content by applying such abstracted functions to the announcement content as shown in process block . For example the engine may apply the abstracted functions for adapting the announcement content with textual and or video enhancement such as scrolling of or adding visual effects to the announcement content.

After forming the adapted announcement content the engine communicates the adapted announcement content to the second I O . At process block the second I O communicates the adapted announcement content to the native video application. In turn the native video application services the adapted announcement content for presentation e.g. display to the user of the system as shown in process block .

At some point during either or both of the second and or first sessions the third session begins as shown in termination block . At process block the first I O may receive from the second multimedia source additional mixed content associated with the phone call call associated content . This call associated content for example may include i a ringing signal associated with the phone call ii one or more ring tones assigned to or otherwise associated with the ringing signal and or originator of the phone call iii a text to speech synthesized conversion of the phone call announcement and or iv voice content of the phone call for termination to the first multimedia application terminating voice content . The call associated content of course does not include the terminating voice content if the phone call is not answered.

After receiving the call associated content the first I O passes it to the engine . The engine in turn forms adapted mixed content from the call associated content and the abstracted functions for adapting the call associated un adapted music and or adapted music contents in accordance with the capabilities of the native audio application and or the native video application as appropriate.

The engine may form the adapted mixed content by applying to the call associated un adapted music and or adapted music content such abstracted functions as shown in process block . For example the engine may apply the abstracted functions for adapting the call associated un adapted music and or adapted music content to emphasize the call associated content. To facilitate the emphasis of the call associated content the engine may apply the abstracted functions for attenuating the un adapted music and or adapted music content. Alternatively and or additionally the engine may apply the abstracted functions for i amplifying the call associated content or ii otherwise differentiating the call associated content from the un adapted music and or adapted music content.

As another option the engine may apply the abstracted functions for adapting i the un adapted music content to fade out and ii the terminating voice content to fade in. Alternatively the engine may apply abstracted functions for adapting the terminating voice content for immediately presentation.

By forming the adapted mixed content in accordance with the foregoing the servicing of audio components of the adapted mixed content by the native audio application allows a conversation to ensue without the adapted music content being commingled with masking and or otherwise drowning out adapted the terminating voice content.

After forming the adapted mixed content the engine communicates it to the second I O . At process block the second I O communicates the adapted mixed content to the native audio application and or native video application as appropriate. In turn the native audio application and or native video application service the adapted mixed content to allow presentation e.g. playback to the user of the system as shown in process block .

The fourth multimedia session starts at termination block after a device foreign to the system foreign device issues an off hook condition and or answers the phone call and communicates such condition back to the system . After this the system invokes a capture device such as a microphone or other speech pickup device to receive from the user of the system and in turn provide to the third multimedia source voice content that is originated to the foreign audio application hereinafter originating voice content .

At process block the first I O may receive the originating voice content from the third multimedia source . The engine which is handling the adapted mixed content and more particularly the terminating voice content can discern therefrom one or more of the capabilities of the foreign audio application.

At a minimum the engine can discern from the terminating voice content the multimedia protocols used to code such content. Accordingly the engine may form adapted originating voice content in accordance with the capabilities of the foreign audio application.

To form the adapted originating voice content the engine may apply the abstracted functions for adapting the originating voice content in accordance with the capabilities of the foreign audio application as shown in process block . If for example the capabilities of the foreign audio application do not include provisions for applying tone control but the capture device and or the third multimedia source apply tone control to the voice content it receives then the engine may apply the abstracted functions to the originating voice content to remove from the originating voice content any tone control applied thereto by the capture device and or the third multimedia source.

After forming adapted originating voice content the engine communicates it to the second I O . At process block the second I O communicates the adapted originating voice content to the foreign audio application. In turn the foreign audio application services the adapted originating voice content for presentation e.g. playback as shown in process block . Deployment of the second and third sessions allow the system to carry a bidirectional conversation between the native and foreign audio applications thereby providing the interoperability and seamless capabilities negotiations between the native and foreign audio applications.

At some point during the phone call the user of the system decides to invoke a video capture device such as camera to capture streaming video and or still picture content and communicate such content to the fourth multimedia source. The fourth multimedia source may in turn source the streaming video and or still picture content to the multimedia processing engine with or without a request.

The fifth multimedia session may begin responsive to the fourth multimedia source sending to the multimedia processing module the streaming video and or still picture content for origination to the foreign video application by way of a video conference session with the foreign device as shown in termination block . The video conference session may be deployed in combination with or alternatively in lieu of the third and fourth communications sessions. In the latter case the third and fourth communications may terminate as shown in termination block .

At process block the first I O receives from the fourth multimedia source the streaming video and or still picture content. Prior to adapting the streaming video and or still picture content collectively originating video conference content however the API queries the foreign video application to discover its capabilities. The API then configures the engine to select the abstracted functions for adapting the originating video conference content to make communication of adapted originating video content to the foreign multimedia application possible.

At process block the engine forms the adapted originating video content from the originating video conference content and the abstracted functions for adapting the originating video conference content to make the aforementioned communication possible. To form the adapted originating video content the engine may apply such abstracted functions. For example the engine may apply the abstracted functions for adapting the originating video conference content with video quality enhancement and or control such as color enhancement and or tint and or perceptual coding techniques.

After forming the adapted originating video content the engine communicates it to the second I O . At process block the second I O communicates the adapted originating video content to the foreign video application. In turn the foreign video application services the adapted originating video content for presentation e.g. playback to a user of the foreign device as shown in process block .

In addition to the originating video conference content the video conference session may also include a communication of video content from a multimedia source associated with the foreign device for termination to the native video application. The terminating video content may be communicated to the first I O via the third multimedia source.

After reception of the terminating video content the engine forms adapted terminating video content from the terminating video content and the abstracted functions for adapting the terminating video conference content to the capabilities of the native video application. To form the adapted terminating video content the engine may apply these functions to the terminating video conference as shown in process block . The engine may do this by applying the abstracted functions for adapting the terminating video conference content with video quality enhancement and or control such as color enhancement and or tint and or perceptual coding techniques.

After forming the adapted terminating video content the engine communicates it to the second I O . At process block the second I O communicates the adapted originating video content to the native video application. In turn the native video application services the adapted terminating video content to allow presentation e.g. playback to the user of the system as shown in process block .

As an alternative or in addition to communicating the terminating video conference content the user of the device may invoke the native video application to stream to the foreign multimedia application recorded video and still picture content collectively recorded video content . After invoking the native video application to stream the recorded video content the sixth session begins as shown in termination block . To limit repetition of discussion the process is employed to form adapted recorded video content in accordance with the principles disclosed hereinabove.

After forming the adapted recorded video content the user of the device may receive via the native video application a playback of the adapted terminating video conference content while the user of the foreign device may receive via the foreign video application adapted recorded video content and or the adapted originating video content.

Depending on the capabilities of the foreign video application the engine may apply the abstracted functions for adapting in accordance with display capabilities of the foreign video application the recorded video content and the originating video content. For example the abstracted functions for adapting the recorded video content and the originating video content may cause the foreign multimedia application to display both of the adapted recorded video content and the adapted originating video content in split tiled alternating or other formatted displays.

After termination of the video conference and the phone call the second third fourth fifth and sixth multimedia session may terminate as shown in termination block . Similarly the first session may terminate as shown in termination block . Alternatively the process may return to process block while the first multimedia session is active.

At process block the engine may apply the abstracted functions for adapting the un adapted music and or adapted music but not presented content so as to fade in the adapted music content after completion e.g. tear down of the phone call and the video conference session. These abstracted functions may cause the native audio application to fade in the adapted music content at the same position or a position before or after the position from where the native audio application caused the earlier fade out of the adapted music content.

Upon termination of the first session the process may be terminated as shown in block . Alternatively additional sessions may be started in which case the process may be repeated for each of the additional sessions.

In this example the multiple multimedia applications may include a video game application native to the system the native audio application a native mixed media application foreign audio applications and a location based application.

The video game application may be configured for multiplayer networked gaming participation by a user of the system native user and one or more users foreign to the system foreign users . The native audio application may be configured to present adapted terminating voice content to the native user. The native mixed media application may be configured to present adapted mixed content to the native user. The foreign audio applications may be configured to present adapted originating voice content to the foreign users. The location based multimedia application may be configured to locating the system .

The multiple multimedia sources may include a gaming content source a native voice content source foreign voice content sources a mixed multimedia source and a location based content source. The gaming content source is operable to collect and provide video game content generated by the video game application via participation of the native user and or any foreign users. To facilitate the latter the gaming content source is operable to obtain e.g. via queries and responses via a communication link between the system and the foreign device the video game content generated by the foreign users.

The native voice content source is operable provide voice content of a phone call for origination originating voice content to the foreign audio applications. Each of the foreign voice content sources is operable to provide for termination to the native audio application voice content of the phone call terminating voice content terminated from its respective foreign user.

The mixed multimedia source is operable to provide the mixed multimedia content received from a mobile content provider e.g. a mobile television center . The mixed multimedia source may obtain the mixed multimedia content via push and or pull delivery mechanisms including for example via broadcasts from the mobile content provider.

The location based content source is operable to provide location content associated with the system . To facilitate this the location based content source may gather the location content via queries of a global network satellite system including the global positioning system GPS or GLONASS and or other position location system. Additionally this example employs the process to communicate five multimedia sessions.

The first multimedia session begins at termination block and then transitions to process block . At process block the first I O receives the video game content from the gaming content source and then passes it to the engine .

The engine in turn forms adapted game content from the video game content and the abstracted functions for adapting the video game content in accordance with the capabilities of the video game application. To form the adapted game content the engine may apply such abstracted functions to the video game content as shown in process block . By way of example the engine may apply the abstracted functions for adapting the video game content for tactile sensation controls. Application of these abstracted functions may adapt the video game content to add increase decrease and or otherwise adjust tactile sensation components of the video game content.

Alternatively the engine may apply the abstracted functions for adapting the characteristics of the video game content with audio and or video quality enhancement and or control. These enhancements may include for example tone control color enhancement color correction and or tinting.

After forming the adapted game content the engine communicates it to the second I O . At process block the second I O communicates the adapted game content to the video game application. In turn the video game application services the adapted game content for presentation e.g. playback to the user of the device as shown in process block .

At some point during the first session the second session begins as shown in termination block . The second session may begin in response to one or more of the foreign users originating a call to the native user and or the native user supplying an off hook condition or other indication indicating that the call has been answered.

At process block the first I O may receive the originating voice content from the native voice content source and then pass it to the engine . The engine which is handling the adapted game content attempts to discern from information associated with the origination of the phone call one or more capabilities of the foreign audio application that originated the phone call. If any other of the foreign audio applications is connected on the phone call the engine may also attempt to discern the capabilities of such applications. At a minimum the engine can discern from the information the multimedia protocols used to code the originating voice content.

After reception of the originating voice content the engine may form adapted originating voice content from the originating voice content and the abstracted functions for adapting the originating voice content in accordance with the capabilities of the foreign audio application for each foreign user. To form the adapted originating voice content the engine may apply such abstracted functions to the originating voice content as shown in process block . For example the engine may apply one or more of the abstracted functions to adapt the characteristics of the originating voice content so as to remove from such content any tone control applied thereto by the native voice content source.

After forming adapted originating voice content the engine communicates it to the second I O . At process block the second I O communicates to each of the foreign audio applications respective versions of the adapted originating voice content. In turn the foreign audio applications may service their respective versions of the adapted originating voice content for presentation e.g. playback to the respective foreign users as shown in process block .

At some point during either or both of the first and or second sessions the third session begins as shown in termination block . At process block the first I O may receive the terminating voice content from one or more of the foreign audio sources and then pass it to the engine . The engine in turn forms adapted audio content from the terminating voice content the un adapted video game content the adapted game content and the abstracted functions for adapting such content in accordance with the capabilities of the video game application and or the native audio application. To form such content the engine may apply these abstracted functions to the terminating voice content the un adapted video game content and or the adapted game content as shown in process block .

For instance the engine may apply the abstracted functions for adapting the terminating voice content the un adapted video game content and or the adapted game content to limit attenuation and or drowning out of the adapted game content. To do this the engine may apply the abstracted functions for attenuating the terminating voice content. Alternatively and or additionally the engine may apply the abstracted functions for amplifying the un adapted video game content and or the adapted game content.

As another option the engine may apply the abstracted functions for adapting the un adapted video game content and or the adapted game content to fade out. Alternatively the engine may apply the abstracted functions adapt the terminating voice content to fade in or immediately play. This way the servicing of the adapted mixed content by the native audio application allows a conversation to ensue without causing the video game application to undesirably time out or experience other undesirable stoppages in play of the adapted game content. This also prevents the adapted game content from being commingled with and or being masked or otherwise drowned out by servicing of the adapted terminating voice content.

The engine communicates the adapted mixed content to the second I O at some time after forming it. At process block the second I O communicates the adapted mixed content to the video game application and native audio application where appropriate. In turn the video game application and the native audio application service the adapted mixed content for presentation e.g. playback to the user of the system as shown in process block .

As above the second and third sessions allow for bidirectional conversation between the native audio and the foreign audio applications while allowing for simultaneous or substantially simultaneous servicing of adapted game content by the video game application. In turn this allows for interoperability and seamless capabilities negotiations between i the native audio and the foreign audio applications and ii the video game application and the native audio and the foreign audio applications.

Completion of the phone call causes the second and third sessions to terminate as shown in termination block . In this example the first session does not terminate and the process returns to process block .

At process block the engine may apply the abstracted functions for adapting the un adapted game and or adapted game content to fade after completion of the phone call. These functions may be operable to fade in the adapted game content at the same position or a position before or after the position from where the native audio application caused the fade out of the adapted game content.

During the first session the fourth session is started as shown in termination block . At process block the first I O may receive the mixed multimedia content from mixed multimedia source and then may pass it to the engine . The engine in turn forms adapted mixed content from the mixed multimedia content and the abstracted functions for adapting the mixed multimedia content the un adapted video game content and or the adapted game content in accordance with the capabilities of the video game application and or the native mixed media application. To do this the engine may apply such abstracted functions to the mixed multimedia content the un adapted video game content and or the adapted game content as shown in process block .

For example the engine may apply the abstracted functions to adapt the mixed multimedia content the un adapted video game content and or the adapted game content to immediately attenuate or drown out of the adapted game content in lieu of the adapted mixed content. Such processing beneficially allows messages that contain important information e.g. a message issued by the authorities warning of an impending danger or concern such as tornado hurricane other inclement weather conditions bomb threat civil uprising etc to take precedence over adapted game content. To do this the engine may apply to the video game content the abstracted functions for attenuating the video game content. Alternatively and or additionally the engine may apply to the mixed multimedia content the abstracted functions for amplifying the mixed multimedia content.

As another option the engine may apply the abstracted functions for adapting the un adapted video game content and or the adapted game content characteristics to fade out and or for adapting the mixed multimedia content to fade in or immediately play. This way the servicing of the adapted mixed content by the native mixed media application allows the adapted mixed content to be presented without causing the video game application to undesirably time out or experience other undesirable stoppages in play of the adapted game content. This also prevents the adapted mixed content from being commingled with masked by or otherwise drowned out by the servicing of the adapted game content.

After forming the adapted mixed content the engine communicates it to the second I O . At process block the second I O communicates the adapted mixed content and adapted game content to the native mixed media application and the video game application respectively. In turn the native mixed media application and the video game application service the adapted mixed content and the adapted video content for presentation e.g. playback to the native user as shown in process block .

Prior to forming the adapted mixed content a fifth session may be started as shown in termination block . This fifth session may be used to control initiation of the fourth session. For example the fifth session might not allow initiation of the fourth session when the mixed multimedia content e.g. a warning message of impeding danger is not applicable to the location associated with the native user. Alternatively the fifth session may trigger or otherwise cause initiation of the fourth session when the mixed multimedia content e.g. a warning message of impeding danger is applicable to the location associated with the native user.

The fifth multimedia sessions begins at termination block and then transitions to process block . At process block the first I O receives location content from the location based content source and passes it to the engine . The engine in turn forms adapted location based content from the mixed multimedia content and the abstracted functions for adapting the mixed multimedia content associated with the fourth session in accordance with the capabilities of the location based multimedia application as shown in process block . For example the engine may apply such abstracted functions to adapt the mixed multimedia content so as localize the mixed content in accordance with the location content.

After forming the adapted location based content the engine communicates it to the second I O . At process block the second I O communicates to the adapted location based content to the location based multimedia application. In turn the location based multimedia application services the adapted location based content for presentation e.g. playback of the adapted mixed content to the native user as shown in process block .

Although only two examples for employing the process are described other examples are possible as well. In addition the process may support most any number of multimedia sessions depending of course on the capabilities of the system including bandwidth for communicating and or receiving the multimedia content processing power for processing the multimedia content memory capacity and or memory allocation associated with the multimedia processing module .

Referring now to a block diagram depicting an example of a multimedia processing module for adapting multimedia content for presentation by a multimedia application is shown. The multimedia processing module is similar to the multimedia processing module of except as described herein.

The multimedia processing module is operable to process multimedia content received from the multimedia source into adapted multimedia content and communicate the adapted multimedia content to multimedia application for subsequent presentation. To facilitate this the multimedia processing module may be communicatively coupled to the multimedia source via the first communication path over which the multimedia processing module may receive the multimedia content. The multimedia processing module may be also communicatively coupled to the multimedia application via the second communication path over which the multimedia processing module may send the adapted multimedia content.

To facilitate the foregoing the multimedia processing module may include an engine an input interface an output interface an application programming interface a processing platform a bus memory and a host interface . The engine and or any other portion of the multimedia processing module may be formed from one or more directives for processing the multimedia content received via the input interface into the adapted multimedia content and for communicating the adapted multimedia content to the output interface .

The directives and or any other portion of the engine may be implemented in software firmware and or hardware and executed or otherwise addressed and instructed by the processing platform to carry out such processing. To facilitate this the processing platform may include for example any of a general purpose computer a special purpose computer a field programmable gate array FPGA an application specific integrated circuit ASIC a general purpose processor GPP a system on a chip SoC and the like.

To facilitate the processing of the directives the engine includes first second and third abstraction layers and one or more sets of logic collectively abstraction layer logic a data store and a terminal I O . Each of the first second and third abstraction layers and may include one or more of the abstracted functions. These abstracted functions in turn may include one or more common functions and one or more distinctive functions.

The common functions are employed to avoid needless repetition and storage of properties and or distinguishing features of the multimedia protocols. To facilitate this the common functions may be abstracted in accordance with the properties and or distinguishing features that are common to a majority or other significant percentage of the multimedia protocols collectively common properties and or features .

The distinctive functions may be abstracted in accordance with one or more properties and or distinctive features of at least one a minority but not all of the multimedia protocols abstracted. This way the properties or distinguishing features that are not common to majority or other significant percentage of the multimedia protocols can be accommodated to allow the multimedia processing module to process the multimedia content formatted according to most any multimedia protocol.

In addition the first second and third abstraction layers and may define respective levels of abstraction. Each of the levels of abstraction may define the common and distinctive functions for adapting the multimedia content at its corresponding level of abstraction. For example the first second and third abstraction layers and may define respective domains such as a physical domain a logical level domain and an application services domain which when combined in a hierarchal or other manner define a model or protocol stack for adapting the multimedia content.

As part of the model the first abstraction layer as embodied as a physical domain may define the common and distinctive functions that are applicable to adapting the multimedia content at a physical level. The common and distinctive functions for this level typically exhibit characteristics that include at least one of i uncomplicated definitions ii time critical processing iii high reusability and iv localized data dependency utilization for allowing multiple threads and use of parallel hardware. Examples of the common and distinctive functions include functions for interfacing with memory of the data store motion estimation and compensation two dimensional transforms such as DCT and Integer transforms color space conversion such as conversion between RGB and YUV interpolation for enlarging a size of picture and or other transforms video interlace processing two dimensional video smoothing and de blocking filters and the like.

The multimedia i.e. incoming content processed by the common and distinctive functions of the physical domain may flow from a physical medium via the terminal I O through the physical domain and onto the second abstraction layer as embodied as a logical level domain via an interface between the physical and logical level domains physical logical interface . The adapted multimedia i.e. outgoing content processed by the common and distinctive functions of the physical domain may flow from the logical level domain via the physical logical interface through the physical domain and on to the physical medium via the terminal I O .

The logical level domain may define the common and distinctive functions that are applicable to adapting the multimedia content at a logical level. The common and distinctive functions for this level typically exhibit characteristics that include at least one of i moderately complex definitions ii time critical processing and iii stability. Examples of the common and distinctive functions for this domain include functions for video block syntax parsing reconstruction variable length code and or arithmetic code logic simple filtering and transforms Durbin recursion codebook searches quantization and the like.

The multimedia content processed by the common and distinctive functions of the logical level domain may flow from the physical domain via the physical logical interface through the logical level domain and on to the application services domain via an interface between the logical level and application services domains logical application interface . The adapted multimedia content processed by the common and distinctive functions of the logical level domain may flow from the application services domain via the logical application interface domain and on to the physical domain via the physical logical interface.

The third abstraction layer as embodied as an application services domain may define the common and distinctive functions that are applicable to adapting the multimedia content at an application services level. The common and distinctive functions for this level typically exhibit characteristics that include at least one of i highly complex definitions ii infrequently used iii low requirement for time critical processing iv efficient implementation in firmware and v evolving requirements. Examples of the common and distinctive functions for this domain include functions for state machines for frame and header syntax parsing protocol handling and stream synchronization exception handling data buffering logic function scheduling options and steering logic and the like.

The multimedia content processed by the common and distinctive functions of the application services domain may flow to the application services domain via the logical application interface. The adapted multimedia content processed by the common and distinctive functions of the application services domain may flow to the logical level domain via the logical application interface.

The multimedia content need not be processed by the common and distinctive functions of each of the first second and third abstraction layers and to form the adapted multimedia content. Selection of the common and distinctive functions of any or all of the first second or third abstraction layers and may be based on the type multimedia content and the multimedia application s capabilities.

The abstraction layer logic controls selection of the common and distinctive functions for adapting the multimedia content. To facilitate this the abstraction layer logic may interface with one or more of the first second and third abstraction layers and to select and apply the common and distinctive functions to the multimedia content to form the adapted multimedia content.

For example the abstraction layer logic may interface with the first second and third abstraction layers and to select and apply the common and distinctive functions from the second and third abstraction layers but to select and apply only the common functions of the first abstraction layer . Alternatively the abstraction layer logic may interface with the first second and third abstraction layers and to select and apply only the common functions from each of the second and third abstraction layers . Other combinations are possible as well.

As noted above the abstraction layer logic is operable to select the common and distinctive functions based in part on the multimedia application s capabilities. The API may be used to configure the abstraction layer logic to select the common and distinctive in accordance with the multimedia application s capabilities. Like the API of the API is operable to obtain the multimedia application s capabilities. For example the API via execution by the processing platform and or instructions received via host interface may interface with and or extract from the multimedia application the multimedia application s capabilities.

With knowledge of the multimedia application s capabilities the API via execution by the processing platform and instructions received via host interface is operable to interface with and configure the abstraction layer logic . To facilitate this the API may include directives that cause the abstraction layer logic to select the abstracted common and or distinctive functions associated with the abstraction layers and .

The API may also include directives for accessing and adjusting one or more parameters usable by the common and or distinctive functions associated with the first second and third abstraction layers and . These parameters may include at least one parameter for tone control video quality control video enhancement and the like.

The following describes an example of processing streaming video content through the first second and third abstraction layers and for presentation by multimedia application which is operable to present streaming video. The streaming video content originates from the multimedia source and flows to the input interface via the communication path . The streaming video content is then passed to the API . The API in turn configures the abstraction layer logic to identify and select one or more of the common and distinctive functions that are applicable to the multimedia application s capabilities.

Based on this configuration the abstraction layer logic intelligently parses and selectively applies its directives to process the streaming video content through the first second and third abstraction layers and to form adapted streaming video content. The abstraction layer logic may intelligently parses and selectively apply its directives to process the streaming video content in accordance with the distinctive and common functions of the abstraction layers and as follows 

The first abstraction layer as embodied as a physical domain may define the common and distinctive functions that are applicable to adapting the video streaming content at a physical level. The features and functions selected and processed at this first abstraction layer may exhibit the following characteristics straightforward definitions high real time requirements high reusability and localized data dependency allowing multiple threads and parallel hardware. Some examples pertaining to streaming video may include for example memory interface motion estimation and compensation 2D transforms DCT and Integer color space conversion RGB YUV interpolation e.g. picture size enlargement video interlace processing and 2D video smoothing and de blocking filters and the like.

The second abstraction layer as embodied as a logical domain may define the common and distinctive functions that are applicable to adapting the streaming video content at a logical level. The features and functions selected and processed at this second abstraction layer may exhibit for example the following characteristics moderate complexity logic high real time requirements and stable functions. Some examples pertaining to streaming video may include for example video block syntax parsing reconstruction variable length code VLC and arithmetic code logic simple filtering and transforms Durbin recursion codebook searches and quantization and the like.

The third abstraction layer as embodied as an applications services domain may define the common and distinctive functions that are applicable to adapting the streaming video content at an applications services level. The features and functions selected and processed at this third abstraction layer may exhibit for example the following characteristics high complexity logic low real time requirements often seldom used functions efficiently implemented in firmware and functions that may have evolving requirements. Some examples pertaining to streaming video content may include for example state machines for frame and header syntax parsing protocol handling and stream synchronization exception handling data buffering logic function scheduling and options and steering logic and the like.

After processing the adapted streaming video content may be sent to the output interface . In turn the output interface passes the adapted streaming video content via the communication path to the multimedia application for presentation.

With reference now to both and the engine and the engine alone or in combination with the corresponding API and API may be processed into hardware description language HDL logic such as Register Transfer Logic RTL and or multi processor capability logic and then affixed to a tangible media. The HDL logic may be formed using a high level programming code such as C . This high level programming may be optimized and enhanced to create an integrated circuit having a small hardware footprint low power consumption high performance and low complexity.

The HDL logic may be used as an intellectual property IP block or other intellectual property core. The IP block may be processed into a semiconductor device such as a FPGA an ASIC a GPP SoC etc. so as to form a functional integrated circuit that may be used for example in the aforementioned next generation handheld device.

At process block one or more functions for processing the multimedia content in accordance with the multimedia protocols are abstracted from the multimedia protocols to form the abstracted functions. At process block one or more of the first second and third abstraction layers and are formed from the abstracted functions. At process block the abstraction layer logic is formed to effectuate the first second and third abstraction layers and formed at process block .

At process block the abstraction layer logic and the first second and third abstraction layers and formed at process block are processed into HDL logic using conventional processes for forming such HDL logic. At block the HDL logic is affixed to a tangible media.

And at optional process block the API is formed. If formed then at process block the API is processed into HDL logic along with the abstraction layer logic and the first second and third abstraction layers and formed at process block .

At process block the processing platform is formed in a first semiconductor substrate. At process block a first circuit operable to perform the directives of the abstraction layer logic is formed in a second semiconductor substrate and communicatively coupled to the processing platform . This first circuit may be formed using the HDL logic formed at process block of .

At process block a second circuit operable to perform at least one of the abstracted functions of one or more of the first second and third abstraction layers and is formed in the second semiconductor substrate and communicatively coupled to the first circuit. The second circuit may be formed using the HDL logic formed at process block of

At process block a third circuit operable to perform the directives of the API is formed in the second semiconductor substrate and communicatively coupled to the processing platform the first circuit and the second circuit. The third circuit may be formed using the HDL logic formed at process block of

Although the process depicts the processing platform being formed in the first semiconductor substrate and the first second and third circuits being formed in the second semiconductor substrates the processing platform and the first second and third circuits may be monolithically formed. As another alternative the process may be employed to monolithically form the entire multimedia processing module .

Variations of the method apparatus and system described above are possible without departing from the scope of the invention. In view of the wide variety of embodiments that can be applied it should be understood that the illustrated embodiments are exemplary only and should not be taken as limiting the scope of the following claims. For instance in the exemplary embodiments described herein include handheld devices which may include or be utilized with any appropriate voltage source such as a battery and the like providing any appropriate voltage.

In addition any of the communication networks referenced with respect to the communication paths may be a partial or full deployment of most any communication or computer network and thus can include a few or many network elements most of which are not shown. Each of the communication networks may include circuit switched as well as packet data elements to provide transport of the multimedia content and or adapted multimedia content and can be public or private terrestrial wireless or satellite and or wireline.

Each of the networks may include portions of a Public Switch Telephone Network PSTN the Internet core and proprietary public networks wireless voice and packet data networks such as 1G 2G 2.5G and 3G telecommunication networks wireless office telephone systems WOTS and or wireless local area networks WLANs including Bluetooth and or IEEE 802.11 WLANs and the like.

Moreover in the embodiments described above processing platforms computing systems controllers and other devices containing processors are noted. These devices may contain at least one Central Processing Unit CPU and memory. In accordance with the practices of persons skilled in the art of computer programming reference to acts and symbolic representations of operations or instructions may be performed by the various CPUs and memories. Such acts and operations or instructions may be referred to as being executed computer executed or CPU executed. 

One of ordinary skill in the art will appreciate that the acts and symbolically represented operations or instructions include the manipulation of electrical signals by the CPU. An electrical system represents data bits that can cause a resulting transformation or reduction of the electrical signals and the maintenance of data bits at memory locations in a memory system to thereby reconfigure or otherwise alter the CPU s operation as well as other processing of signals. The memory locations where data bits are maintained are physical locations that have particular electrical magnetic optical or organic properties corresponding to or representative of the data bits. It should be understood that the exemplary embodiments are not limited to the above mentioned platforms or CPUs and that other platforms and CPUs may support the described methods.

The data bits may also be maintained on a computer readable medium including magnetic disks optical disks and any other volatile e.g. Random Access Memory RAM or non volatile e.g. Read Only Memory ROM mass storage system readable by the CPU. The computer readable medium may include cooperating or interconnected computer readable medium which exist exclusively on the processing system or are distributed among multiple interconnected processing systems that may be local or remote to the processing system. It should be understood that the exemplary embodiments are not limited to the above mentioned memories and that other platforms and memories may support the described methods.

Exemplary embodiments have been illustrated and described. Further the claims should not be read as limited to the described order or elements unless stated to that effect. In addition use of the term means in any claim is intended to invoke 35 U.S.C. 112 6 and any claim without the word means is not so intended.

