---

title: Method for determining the distance of visibility for a driver of a vehicle
abstract: A method for determining the distance of visibility for a driver of a vehicle in the presence of an element disrupting the visibility of the driver, the method comprising the following steps: determining the luminosity of the pixels of a region of an image taken in the field of vision of the driver, resulting in a luminosity curve, determining a first tangent to the curve of luminosity, determining a second tangent to the curve of luminosity, determining a sweep-line according to the first tangent and second tangent, the sweep-line being representative of the distance of visibility.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08180108&OS=08180108&RS=08180108
owner: Valeo Vision
number: 08180108
owner_city: Bobigny
owner_country: FR
publication_date: 20070614
---
The present invention relates to a method for determining a distance of visibility for a driver of a vehicle in the presence of an element disrupting the visibility of the driver. The disruptive element is for example fog and the vehicle a motor vehicle for example.

According to a known prior art EP 1 422 663 A1 such a method of determination comprises the following steps 

Firstly calculation of the derivative leads to problems in interpretation significant inaccuracies and errors particularly if there is an obstacle on the road over which a vehicle is travelling for example another vehicle a bridge and the like. Indeed such an obstacle will generate a plurality of points of inflection when calculating the derivative hence the difficulty in distinguishing the various points of inflection if they are close to one another and in choosing the good inflection point corresponding to the distance of visibility searched.

Secondly the calculation of the derivative amplifies the noise generated on the luminosity curve causing uncertainties on the curve itself.

What is needed therefore is an improved system and method that provides improvements over prior art systems and methods.

Indeed according to a first object it concerns a method for determining a distance of visibility for a driver of a vehicle in the presence of an element disrupting the visibility of the driver comprising the following steps 

As will be seen below in detail determination of the distance of visibility only utilizes simple linear combinations this determination thus being faster than that of the prior art. Moreover it removes uncertainties related to the noise generated by calculation of the derivatives from the prior art since there is no longer any derivative calculation. Lastly this method can be used in the presence of obstacles on the road without determination of the distance of visibility being disrupted

According to non restrictive embodiments the method for determining the distance of visibility comprises the following additional features 

Thus the global center of gravity G is the resultant of centers of gravity for two homogeneous zones on the road and in the sky. By searching these zones the risk of measurements being disrupted by obstacles road edges central reservation trees etc. is limited. This is useful in bends.

The invention according to a second object concerns a distance determining device for a driver of a vehicle in the presence of an element disrupting the visibility of the driver comprising 

The invention according to a third object concerns a computer program product including one or more sequences of instructions to implement when the program is executed by a processor the method according to any one of the preceding features.

On a vehicle equipped with a camera and driven by a driver who can observe a scene in a field of space located in front of the vehicle when his vehicle is stationary or moving is shown in a diagrammatic way.

Camera is situated at a height h from the surface of road and is located for example in the front of the vehicle or on the side. It is fitted for example behind the windscreen and points to the front of the scene in the traveling direction F of the vehicle. Thus camera comprises a total angular field A which can be compared to the field of space located in front of vehicle this total angular field A being defined by a minimum sight angle illustrated on . A distance of visibility D for a driver will be linked to the position of camera on vehicle .

In order to determine the distance of visibility D for driver when there is an element BR disrupting or modifying the visibility particularly if this disruptive element is fog for anticipating switching on the fog lamps of vehicle the following steps are carried out as illustrated on .

In a first step block camera takes an image I in the field of space located in front of vehicle . The field of space in the non restrictive example given does not comprise any obstacle on road .

In a second step block a search for zones of the image I is carried out each responding to a predicate of homogeneity. This search can be implemented for example in a non restrictive embodiment using a method of segmentation by division fusion such as the quadtree method known by those skilled in the art. The quadtree has a plurality of nodes each node having exactly four node children except the terminal nodes. Each node corresponds to a block that is to say a zone of the image square in shape. Each block associated with a node is analyzed recursively in order to decide if it must be divided into four sub blocks. The recursive analysis stops when each sub block conforms to a photometric homogeneity predicate of the co occurrence matrices.

The application of the search for zones of homogeneity renders the possibility of defining two areas on the image I having for centers of gravity G and G respectively as illustrated on .

The global center of gravity G is then calculated for the two centers of gravity G and G through which a first line is made to pass. This first line is representative of the transparency of the atmosphere. The global center of gravity G represents a pre set point PD through which first line passes. This pre set point PD in another non restrictive example can be the center of the image I.

Thus the global center of gravity G is the resultant of centers of gravity for two homogeneous zones on the road and in the sky. By searching these two homogeneous zones the risk of measurements being disrupted by obstacles road edges central reservation trees etc. is limited. This is useful in bends where the first line centered in the middle of the image would only see one of the two road edges for example.

Each of the points of first line can be characterized by a sweep line BL and by luminosity corresponding to a certain grey level GL.

In a non restrictive embodiment this first line is a vertical straight line. The fact of using a vertical straight line rather than another line curve and diagonal for example renders the possibility of avoiding tedious computation times. This vertical straight line is indicator of the transparency of the atmosphere therefore the luminosity of each point of the environment located on the vertical line will be recorded.

Thus in a third step block a luminosity curve LUX also called densitometric curve of the fog is determined on the basis of the vertical line obtained. The luminosity of the pixels PIX of the vertical line is determined according to the position in height of the pixel on the vertical line . Such a luminosity curve LUX is illustrated on . It presents an inverted S shape in this non restrictive example. It is thus comparable to an S curve.

The curve LUX in y axis represents the value of the grey level GL of points PIX of the vertical line and in x axis the number of the sweep line BL of these same points. Thus point P corresponds to sweep line and has a grey level GL equal to approximately 220. In the same way the point P corresponds to the sweep line and has a grey level GL equal to approximately 40.

It will be noted that the slope of this curve LUX varies according to the characteristic for example concrete tar dirt etc. of road . The lighter the road for example concrete the steeper the slope. On the contrary if it is dark for example tar the slope will be less steep. It will be noted that this luminosity curve LUX comprises noise whose amplitude is commensurate in particular with the heterogeneities of the road fine gravel paving blocks tar marking on the surface skid marks etc. variations in sensitivity differences of grey level between the successive pixels spurious electromagnetic signals electric noise and thermal problems. These noises are high frequency noises.

Thus in a fourth step block the noise on the luminosity curve LUX is filtered by means of filtering FILT in a non restrictive example these means of filtering FILT completing a sliding average on an optical window of a few pixels. The luminosity curve filtered in this way is illustrated on .

In the following steps a method of tangents applied to the S shaped curve of luminosity is used to search a sweep line FBL representative of the distance of visibility D.

Thus in a fifth step block a first tangent AA to the luminosity curve LUX is determined. This tangent AA is tangential at a place of the curve representative of a region of luminosity substantially independent of fog BR. Such a tangent is illustrated on .

As can be seen tangent AA is tangential at the lower part of the curve. This part of the curve is representative of the evolution of luminosity of the ground in a region close to the vehicle and thus substantially independent of the density of the fog this region corresponds to approximately ten meters in front of the vehicle . Line AA would therefore correspond to the luminosity curve of the visible part of the road in the absence of fog.

In a sixth step block a second tangent CC to the luminosity curve LUX is determined. This tangent CC is tangential at a place of the curve representative of stabilization of the luminosity. It is also illustrated on .

In a non restrictive embodiment this second tangent CC is parallel to the first tangent AA . This renders the possibility of quickly determining this second tangent. Second tangent CC touches the curve LUX at a point C which corresponds to the beginning of stabilization of luminosity in the upper part of the image linked to the apparent homogeneity of the sky seen from camera .

In a seventh step block a sweep line FBL is determined according to the first tangent AA and second tangent CC the sweep line FBL being representative of the distance of visibility D. This sweep line FBL is determined in the following way.

In a first part step block a distance d equal to the distance between first tangent AA and second tangent CC is defined and this distance d is divided by two. The distance d is representative of the dynamics of the scene between the darkest zone and the zone of maximum utilizable luminosity the dynamics therefore corresponding to the difference between the weakest and strongest luminosity.

In a second part step block a parallel line BB to the first tangent AA and located at distance d divided by two in a non restrictive mode from this first tangent AA is defined. This median tangent is also illustrated on .

In a third part step block an intersection point F also called inflection point between this parallel straight line BB and the luminosity curve LUX is defined. The sweep line FBL is calculated according to this intersection point F since it corresponds to the y axis of this intersection point F.

In an eighth step block the distance of visibility D is determined according to the sweep line FBL obtained in this way.

One will note that it has been assumed that the sweep line n corresponded to the horizon. In a non restrictive example total angular field A also called field of the objective of camera is comprised between 15 and 30 .

One will also note that as regards this first embodiment measurement on a complete assembly line of vehicles positioning angles of camera including the minimum sight angle can be a little difficult to implement and not very precise.

Also in a second non restrictive embodiment trigonometric calculation of the distance of visibility D is not carried out as indicated above but the distance of visibility D is determined by means of a look up or correspondence table TAB which links the sweep line number FBL found and the distance of visibility D. This table TAB can be downloaded in a memory of a distance determining device PRO namely a computer located in camera for example. Thus reading a look up or correspondence table is more interesting than a trigonometric calculation being a less time hungry processor.

The correspondence table TAB is programmed so as to take into consideration more particularly and in a non restrictive way dispersions of the optics and the optical sensor of the camera which converts photons into electrons and then into video image.

The supports of camera will also be able to be taken into account for programming if need be so as to make allowances for the possible sway of the camera the degrees of freedom of adjustment of camera or the body of vehicle in view of the tolerances as regards pressing assembly production nature of the materials etc. .

Thus according to the value of the distance of visibility D obtained in this way the decision is taken to switch on the fog lamps or otherwise. In a non restrictive example if the value of this distance D is less than a threshold equal to 100 meters it is decided there is fog. The choice is to switch on the fog lamps either by warning the driver so that he does this manually or by doing so automatically. Thus in a non restrictive embodiment a detection signal SIG will be emitted if the distance of visibility D falls below a certain threshold here 100 meters to warn driver of vehicle to switch on his fog lamps.

And if the value lies between 25 and 50 meters the fog is very dense and automatic switching on of the fog lamps will be chosen for example.

In the same way when the distance of visibility becomes normal again the fog lamps can be switched off.

Access to the distance of visibility D can also render the possibility of influencing the intensity of the fog lamps according to the impact of fog BR greater density or lesser density over this distance of visibility. Thus the photometry of the beam of light emitted by the traffic indicator light or the headlamp in particular its light intensity will be modulated adjusted by modulating the power supply to the light sources. This modulation for example will be controlled by an automated system of regulation taking into account the distance of visibility D.

One will note in addition that the detection signal SIG can also be used as a control signal transmitted for example to a CAN Controller Area Network bus connected to a card of the LCS Light System Control type to act directly on the speed of the vehicle which can therefore be controlled as a function of fog BR.

The non restrictive example which was given above on is an example in which there is no obstacle in the field of space .

The method for determining the visibility D described is robust because it also functions with a field of space in which one or more obstacles are present on the road as illustrated on .

As can be seen on camera has taken an image I in which road comprises an obstacle here a bridge O. The distance of visibility D has been shown by a horizontal line on this figure. The curve of luminosity LUX which is deduced from this image I is illustrated on . It presents a corrugated form. As described above the first tangent AA second tangent CC and parallel straight line BB are plotted and in this case three intersection points F F F are obtained with the curve of luminosity LUX as indicated on . To determine the intersection point corresponding to the distance of visibility D the first intersection point from the bottom of the curve of luminosity LUX is used. If it is due to an obstacle instead of fog the principle of detection remains the same the obstacle giving the distance of visibility D. The intersection point searched is here point F.

Thus even if an obstacle is present it is easy to find the intersection point corresponding to the distance of visibility D.

It will be noted that if there were any ambiguity between the intersection point searched F and another intersection point for example F corresponding in fact to an obstacle O if these two points are very close to one another it is possible to detect the intersection point corresponding to the obstacle O so that it is not confused with the point being searched.

Thus in a non restrictive embodiment the distortion corresponding to F on the curve of luminosity LUX is followed for a short set period of time between a moment t and a moment t. The distortion will evolve according to the obstacle O for example the bridge from the middle of the curve of luminosity LUX bridge being focused on infinity in the image I at moment t to the top of the curve bridge being near the vertical of the vehicle at moment t . If it concerns an obstacle on the ground or a major variation in the road surface change from bitumen to concrete for example the distortion will evolve from the middle of the image downwards. The fast evolution of the distortion linked to the obstacle O relative to the intersection point searched F which is relatively or even totally stable to it over the interval of moments t t examined thus renders the possibility of differentiating the two points and finding the correct inflection point F.

One will note that it is possible in a non restrictive embodiment to take into account the attitude of the vehicle when determining the distance of visibility D. The attitude of the vehicle will be calculated by means of a sensor not illustrated fitted to the suspension of the vehicle for example.

Lastly it will be noted that to determine the distance of visibility D as described above vehicle has a distance determining device PRO illustrated on rendering the possibility of implementing the process described and comprising 

Of course these means S to S and FILT can be incorporated in only one set of means or several sets of means.

This device PRO in a non restrictive embodiment is integrated in camera as illustrated on . This mode is more interesting than a mode in which the distance determining device were integrated at a place remote from the camera because if this were the case it would be necessary to convey the video images by means of optical fibers for example resulting in additional cost and additional means requiring a fast distribution rate of the video images from camera to the distance determining device. Means S to S and FILT of the device PRO are hardware software or both.

Thus the method of determination according to the invention can be implemented by a distance determining device consisting of hardware software or both. Such hardware or software can be implemented in various ways such as respectively by means of hardwired electronic circuits or an integrated circuit for example a processor which is programmed in a suitable way. The integrated circuit can be contained in a portable apparatus such as the camera. The integrated circuit comprises one or more sequences of instructions. Thus such a sequence of instructions which is contained for example in a memory of the portable apparatus allows the integrated circuit to perform the various steps of the distance determining method. The sequence of instructions can be stored in the memory by reading a data medium such as in a non restrictive example a hard disk CD or DVD. A service provider can also make such a sequence of instructions available via a telecommunication network such as the Internet for example.

Of course the invention is not limited to the embodiments which have been just described. In particular the method of searching the zones of homogeneity has been described in the case of methods of segmentation by division fusion but other methods of segmentation can be used such as the methods by dividing regions or by growing regions known to those skilled in the art.

Moreover the luminosity has been described with reference to the grey level of the pixels of the image but it can also be represented by another magnitude as a function of the coding of image deployed.

In the same way the method according to the invention has been described in the case of fog detection but the method is also applicable to other elements disrupting or modifying the visibility of the driver. Thus the method described is interesting when there is fog but also as regards any other element disrupting or modifying the visibility of the driver such as dust or smoke or other elements having the same light diffusion characteristics consisting of micrometric sized particles if the road comprises an obstacle such as a bridge or a car located in front of the vehicle of the driver or on the opposite carriageway or does not comprise any obstacle.

Moreover the method described while only utilizing simple linear combinations calculation of tangents is particularly light in computational load and thus fast. Moreover it removes uncertainties related to the noise generated by calculation of derivatives imposed by the search for the inflection point in the prior art method. Lastly the method described is robust because it renders the possibility of establishing distances of visibility even when obstacles are present which were too disruptive for utilizing the method used in the prior art. Finally it is a solution which is simple and not expensive to implement.

While the method herein described and the form of apparatus for carrying this method into effect constitute preferred embodiments of this invention it is to be understood that the invention is not limited to this precise method and form of apparatus and that changes may be made in either without departing from the scope of the invention which is defined in the appended claims.

