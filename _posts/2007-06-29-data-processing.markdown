---

title: Data processing
abstract: Data is stored in data streams of varying size over a network so that a particular data stream may be considered as being stored locally or remotely. A request is received to modify a first data stream, and a frozen condition to the effect that said first data stream is not modifiable is identified. A second data stream that comprises a reference to the first data stream is created, and the information contained in said second data stream is modified according to said request.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08290993&OS=08290993&RS=08290993
owner: Data Equation Limited
number: 08290993
owner_city: Sheffield
owner_country: GB
publication_date: 20070629
---
This application claims the benefit of United Kingdom Application No. 06 13 027.2 filed Jun. 30 2006 which is hereby incorporated by reference in its entirety.

The present invention relates to a method of storing data network apparatus comprising a plurality of data storage devices and at least one processing device instructions executable by a computer or by a network of computers a computer readable medium having computer readable instructions executable by a computer and a computer readable memory system having structured data stored therein so as to represent a data structure.

Data processing environments are known in which data is stored locally on local storage devices. It is also known to store data remotely on networked storage devices. Network transfer of locally and remotely stored data can be slow and difficult for networked users who require access to the data.

According to an aspect of the present invention there is provided a method of storing data wherein the data is stored in data streams of varying size over a network so that a particular data stream may be considered as being stored locally or remotely comprising the steps of receiving a request to modify a first data stream identifying a frozen condition to the effect that the first data stream is not modifiable creating a second data stream that comprises a reference to the first data stream and modifying the information contained in the second data stream according to the request.

A networked environment in which the invention may be implemented is illustrated in . The Internet connects various computer systems and networks around the world. Servers and are directly connected to the internet . Internet Service Provider ISP is connected to computer systems and . Computer system is wirelessly connected on an ad hoc basis to computer system . ISP connects server to the internet . Server is part of a wired LAN which connects computer systems and . In addition computer system is wirelessly connected to server via a wireless access point . Web server connects directly to the internet and provides a LAN that connects computer systems and . Computer systems and are connected to the internet via ISP while computer systems and are connected via wireless modem router which is also connected to the internet via ISP . Computer system is not connected to the internet.

Other methods of connecting computer systems such as servers personal computers and laptops to the internet both wired and wirelessly are possible.

In this example server and computer systems to are part of a digital effects house providing computer generated special effects for films advertisements and so on. Server and computer systems to are part of the same company and therefore share data but work in a different physical location. Servers and provide backup for the data produced by the company and are in different physical locations. Computer systems and are the home computer systems of artists working for the company while computer systems and are laptops of artists who are working within areas that have wireless internet access available known as wireless hotspots.

In such an environment it can be difficult to share and backup data efficiently. Traditional methods of moving data over networks are slow particularly when moving the large amounts of data associated with digital effects. There is therefore a tendency for artists to store their work on their hard drives rather than backing it up to the local servers. Computer theft or hard drive failure can thus lead to the loss of days of work. Communication over the internet is even slower meaning that routine backup to remote servers and may occur only once a day usually overnight. Further many artists often work on the same data at once each working on a different aspect of the editing. This can lead to problems with overwriting of work and lockouts.

Instructions controlling the processing system may be installed from a physical medium such as a CD ROM disk or over a network via network cable . These instructions enable the processing system to interpret user commands from the keyboard and the graphics tablet such that data may be viewed edited and processed.

The processing system shown in is detailed in . The processing system comprises two central processing units CPUs and operating in parallel. Each of these CPUs and has a dedicated secondary cache memory and that facilitates per CPU storage of frequently used instructions and data. Each CPU and further includes separate primary instruction and data cache memory circuits on the same chip thereby facilitating a further level of processing improvement. A memory controller provides a common connection between the CPUs and and a main memory . The main memory comprises two gigabytes of dynamic RAM.

The memory controller further facilitates connectivity between the aforementioned components of the processing system and a high bandwidth non blocking crossbar switch . The switch makes it possible to provide a direct high capacity connection between any of several attached circuits. These include a graphics card . The graphics card generally receives instructions from the CPUs and to perform various types of graphical image rendering processes resulting in images clips and scenes being rendered in real time on the monitor .

A second SCSI bridge facilitates connection between the crossbar switch and a DVD CD ROM drive . The CD ROM drive provides a convenient way of receiving large quantities of instructions and data and is typically used to install instructions for the processing system onto a hard disk drive . Once installed instructions located on the hard disk drive may be fetched into main memory and then executed by the CPUs and . An input output bridge provides an interface for the graphics tablet and the keyboard through which the user is able to provide instructions to the processing system .

If the question asked at step is answered in the affirmative to the effect that the data stream extension is installed then at step at least one application is loaded. This may be for example an image editing application character animation application audio editing application and so on. An application that explores the filesystem and allows the user to view available files could also be loaded.

Data to be edited is loaded at step and edited at step . At step it is saved and at step the user may publish it if required. Typically this happens when the user considers the work to be complete.

Step at which the operating system is loaded is detailed in . At step the core of the operating system is loaded including the kernel. At step available extensions are identified and at step drivers for these extensions are initialised. At step any additional drives are mounted and at step background threads are initialised.

Step at which drives are mounted is detailed in . At step the first drive to be mounted is selected and at step information regarding the drive is loaded. At step the device associated with the drive is identified and at step the path of the drive is identified. At step the path is passed to the device driver which completes the step of mounting the drive.

The contents of the main memory following step are detailed in . Main memory is split into kernel memory and user memory . Kernel memory contains the kernel of the operating system including the file system and a plurality of extensions such as data stream extension extension extension extension and extension .

Within user memory are application instructions loaded at step and application data loaded for editing at step plus background threads associated with the operating system including data stream extension background threads .

Filesystem provides a structure for the data stored on storage devices such as hard drive or a flash memory based storage device known as a USB key or CD ROM. Applications request the opening closing reading and writing of files via the operating system. The way in which these files are stored is not relevant either to the applications or to the higher level operating system. The kernel of an operating system responds to these requests by accessing its filesystem to ascertain the physical location of the files the data comprising which need not be contiguously stored and returning the file as continuous data. Thus file system includes data structures that provide extension interface with the information necessary to retrieve and supply data to applications .

Root directory contains a local stream index file operating system files such as operating system files and and operating system directories such as operating system directories and . An operating system directory contains no more than 256 operating system files and when this space is used up to 256 operating system subdirectories are created. Thus for example operating system directory contains 256 operating system files as does operating system directory operating system directory and operating system directory . For example operating system directory contains operating system files and . Operating system directory as the last created directory probably contains fewer than 256 operating system files.

In a typical operating system without the data stream extension the operating system directory structure as held by filesystem is viewed by applications running in user memory and each file corresponds with a file that can be opened by an application. It is not possible for a user to alter his view of the file structure without altering the filesystem itself for example by moving or renaming files and directories. In contrast when the data stream extension is installed filesystem need not correspond to the user s view of the data. The operating system files contain data streams that are used to make up application directories and application files which are used by applications .

When data stream extension is installed operating system files can be of two types either a file type or block type. File type operating system files contain a portion of data corresponding to at least a part of an application file. In this example files and are of this type. In the present embodiment an operating system file may not exceed eight megabytes MB in size so an application file may be spread over several operating system files. File type operating system files are named according to an arbitrary but consistent convention. In this example the first file of this type is called F0000001.dat the second is called F0000002.dat and so on.

Operating system files and are of this type also. File contains one thousand atomic cache blocks each of which are eight kilobytes kB in size such as blocks and . An atomic cache block such as block contains either a portion of data or a plurality of fragments each of which is a portion of data. A portion of data may be either a part of an application file or a piece of data used by data stream extension to manage the filesystem.

Block type operating system files are named according to an arbitrary but consistent convention. In this example the first file is called C0000001.dat the second is called C0000002.dat and so on.

A data stream is referenced by a data stream ID which is 10 bytes long including a 46 bit session ID and a 34 bit creation ID . A session ID is allocated to each data access manager in the environment shown in . Each computer system running an operating system on which a data stream extension is installed will have a data stream manager although it is not necessary for every computer system shown in to use the data stream extension. Each data access manager then allocates data stream IDs using its allocated session ID and locally generated creation IDs ensuring the uniqueness of data stream IDs within the environment.

A data stream ID is not stored with the data stream and is a reference tool only. A data stream may be duplicated on several storage devices and thus if a particular data stream ID is identified as being required the data stream can be retrieved from any of these storage devices as data streams with the same ID contain identical data.

The contents of header are shown in . Once a data stream is frozen it cannot be changed and thus a flag indicating whether or not the data stream is frozen is at . Once a data stream is frozen it cannot be changed. Thus if it needs to be changed it is duplicated and the duplicate is changed instead. This means that data is generally not deleted but stored in the form of old data streams. Data stream logs store information regarding the predecessors of data streams.

A data stream is encrypted using an 8 byte symmetrical encryption key which is encrypted using an asymmetric public key. Data streams contain references to other data streams as will be shown in and so a data stream header includes an array of referenced data stream IDs. Lastly access control data may be used by applications to control user access privileges.

Reference refers to the whole of data stream which includes a first data element a first reference a second data element a second reference and a third data element . First reference refers to a data element of data stream while second reference refers to a data element of data stream .

Thus when evaluating data stream data element is read first. Reference is then evaluated using array which is an array of data stream IDs and start and end positions within that data stream. Reference comprises a value indicating an offset within the array and thus the evaluation of reference comprises finding the data stream ID stored at the indicated position within array . This leads to element being read from data stream at the indicated position.

Reference within data stream is then evaluated leading to element being read. Reference is then evaluated leading to element being read. Evaluation of data stream continues after reference giving element . Evaluation continues in this way and the eventual portion of data that is constructed is shown at .

Thus data stream although the data it contains consists of element reference and element can be considered to contain the information in data portion .

Using this method it is not necessary to rewrite the whole file when changes are made nor to send the whole file over a network when backing up. For example if a change were made within data element then in traditional filesystems in order to share or back up this change the whole of the virtual data stream would have to be transported via a network. However using the present system only changed data stream must be transported.

Also in order to copy the file it is only necessary to copy root data stream . This will contain the same references to other data streams which need not be copied and thus the whole virtual data stream can be constructed.

The indexing of data streams is performed using B trees. An example of a B tree is shown in . It has a root node intermediate nodes and and leaf nodes and . A B tree can have just a root node and may not have intermediate nodes. However the number of nodes between the root node and each leaf node must be identical throughout the tree.

The leaf nodes contain key value pairs in which a searchable key is paired with a value that is to be retrieved. In this example the key is an integer and the value is a letter. Thus for example the value associated with key is B as shown in leaf node .

Within each node the key value pairs are in order by key and this continues across the leaves Thus leaf contains keys and leaf contains keys and leaf contains keys and and leaf contains keys and . The leaf nodes have a capacity of 8 kilobytes and are typically approximately half full. Additionally each leaf node includes a pointer to the next leaf node such that a listing of all the values indexed can be quickly obtained without needing to traverse the whole tree.

Each intermediate node also contains key value pairs. For each pair the key is the last key in one of its child nodes and the value is a pointer to that node. The pairs in intermediate nodes are also arranged in order by key. The root node has a similar structure to the intermediate nodes except when the root is the only node in the tree when the root node has a similar structure to a leaf node.

The process of searching a B tree is detailed in . At step the root node which in this system is a data stream is selected and at step the keys in the selected node are searched for the search string using a binary search. This may be any string of data for example a file name or a data stream ID.

At step a question is asked as to whether the node has children and if this question is answered in the affirmative then the pointer associated with the key is identified and used to locate the next node. Control is then returned to step and the keys in the child node are searched for the search string.

Eventually the question asked at step is answered in the negative to the effect that the node has no children. In this case the value associated with the found key is the required value and it is returned.

Using B trees can significantly speed up searches of large amounts of data because a search through thousands of records can require the searching of only a few nodes.

Many of the B trees used in the embodiment described herein use data streams as nodes and in this case the pointers in the root and intermediate nodes are data stream IDs. Thus these trees are not stored in a single place but are traversed by starting with the data stream ID of the root node and obtaining data streams as necessary.

As described with reference to data streams are stored either as entire operating system files as blocks within operating system files or as fragments within the blocks. An application directory or file is made up of at least one of these data streams with the referencing illustrated in used when an application directory or file is made up of more than one data stream.

Applications see a different view of the data from that shown in . The application file structure is composed of application files some of which are directories each of which has a file ID and is described by a file object shown in .

File object includes various flags a date indication a size indication and at least one data stream ID . Depending upon the operating system used it may contain two further data stream IDs and . For example some operating systems require two streams of data one containing the data itself and another containing metadata sometimes known as a resource fork. Thus data stream ID is named DATA and data stream ID is named RESOURCE. If further data streams are required then their IDs are stored in a B tree in which the key is the name of the stream of data and the value is the data stream ID. The data stream ID of the root node of this tree is stored at .

If the file object describes an application file then the data stream referenced at contains the actual data making up the file possibly along with other data streams that it references. If the file object describes a file directory then the data stream referenced at is the root node of a B tree that indexes the contents of the directory as will be further described with reference to .

Thus in order to access the application file structure it is necessary to know the data stream ID of the root node of the file object index and the file ID of the root directory of the file structure. With this information it is possible to find the file object of the root directory. In this example the root directory is described by directory index and thus the file object found contains the data stream ID of the root node of the directory index .

If a specific path is to be accessed then the filename of the application directory or application file can be searched for within directory index resulting in a file ID being found. This file ID is then searched for within file object index to obtain a file object and so on through all the subdirectories in the path until the data stream ID of the application file is found. Alternatively the leaf nodes of directory index can be traversed to list the contents of the application directory for example for display in an Explorer environment or application dialog box.

Each virtual disk is actually a small amount of information representing an application file structure. It includes the data stream ID of the root node of the file object index and the file ID of the root directory of the data structure. With this information the file structure can be displayed to the user and without it the file structure is inaccessible. Thus when the user inserts a virtual disk into the virtual disk drive the file structure represented by the information is mounted by the kernel in the same way as drives are mounted during step detailed in .

Virtual disks can be created for any storage location. They can be sent over a network so that another user can access the data transported between computers and so on. This system allows data to be constantly backed up throughout the environment shown in without the need for users password protecting their data or such since without the data stream ID of a directory index other users cannot access that data.

Virtual disks can include any directory that the user sets up including search directories. For example the user can specify that a directory is to include all files created in the last month or all files with a specific extension or all files that contain specific text and so on. Indexing service constantly indexes properties and contents of files to allow this type of directory to be created and updated very quickly. This type of directory is possible because an application file can be stored in more than one application directory since the application file structure is not related to the underlying operating system file structure.

The root directory is described by a directory index. To find this index the system requires the data stream ID of the root node of the file object index and the file ID of the root directory mounted as drive F . It searches the file object index for this file ID to identify the data stream ID of the root node of the directory index for application directory .

A search in this directory index for the filename Project 3 will result in the file ID of application directory being identified. The system searches file object index for this file ID to find the file object for the application directory and identify the data stream ID of the root node of its directory index.

A search in this directory index for the filename Audio identifies the file ID for application directory . The system then searches file object index for this file ID to find the file object for application directory and identify the data stream ID of the root node of its directory index.

A search in this directory index for the filename Scene identifies the file ID for application file . The system then searches file object index for this file ID to find the file object for application directory and identify the data stream that contains the data making up the application file.

The directory structure shown in is constructed by the user and can be changed by the user. Thus it is possible for other users to view the filesystem using a completely different file structure or for the user to view it in more than one different way simply by mounting a different virtual disk. For example if the user wishes to move directory so that it is contained within directory instead of directory he will perform an operation within his application such as a drag and drop to perform this. This will result in an alteration of the directory indices for directories and . In prior art file systems this would move the directory for every other user of the file system. However in the system described herein this move would only affect this virtual disk or view of the filesystem. Other virtual disks would be unaffected since the structure shown in does not reflect the actual underlying storage of the data.

Since file object index is a B tree ordered by file ID file IDs that are similar are stored close to each other. In the present embodiment application directories and application files that are close to each other in the structure shown in are given similar file IDs. The path of a file is split into four parts the root directory plus at least one subdirectory the filename and two halves of the remaining path. Thus for example F project3 effects unfinished scenelist.txt would be split into a first part F project3 a second part effects a third part unfinished and a fourth part scenelist.txt . A hash is created of each part and the hashes combined to create a file ID. This creates similar file IDs for files that are stored in similar locations.

This means that directories and files that are likely to be accessed during the same workflow have IDs clustered within file object index . Since the nodes of file object index are data streams and since frozen data streams are never changed but duplicated a change to a leaf node alters its parent because the leaf node s data stream ID changes meaning that the parent node which contains the data stream ID as a value must change. This change propagates down to the root node. However once a new data stream is created it is not frozen for a period of time meaning that other changes made to the data stream while it is unfrozen do not result in a new data stream being created. For example a first file is edited leading to a new data stream being created for the leaf containing the file object the leaf s parent node and so on to the root node. A short while later a second file is edited its file object being contained within the same leaf node as the first. The relevant data streams of the file object index are already in memory making the reading and editing of them quicker and since the data streams are not yet frozen they can be changed.

Thus clustering changes within leaf nodes results in required data streams being more likely to be in memory and fewer data streams being created within the tree which results in less strain on the file system and computer and also means that when the file object index is synchronised with another fewer data streams need to be duplicated.

Virtual disk data is stored as a data stream and thus in order to access it a data stream ID is required. This data stream ID can be shared between computer systems that have the data stream extension installed to allow other users to view and work on the same virtual disk. Without this data stream ID it is not possible for other users to access the disk.

During step when the user publishes data to the network the system synchronises the user s virtual disk with the copy of the virtual disk on the network. This can be done simply by duplicating the data stream ID of the root node of the file object index. Since data streams are constantly backed up the process of publication is constantly occurring but to the user the process is instantaneous because until the data stream ID is duplicated the process is not completed.

Local stream IDs indicate the actual location of data streams on storage devices and thus a local stream index exists for each storage device accessible by the data access manager .

Extension includes a plurality of data stream managers one for each storage device to which it has access. Thus data stream manager retrieves data streams from the local hard drive data stream manager retrieves data streams from a connected USB flash memory stick and data stream managers and retrieve data streams from networked servers and .

Each data stream manager communicates with a respective local stream manager. For example data stream manager communicates with local stream manager which controls storage on hard drive data stream manager communicates with local stream manager which controls storage on USB stick and data stream manager communicates with local stream manager which controls storage on remote server . Data stream manager communicates with a remote data stream manager on server which itself communicates with a local stream manager on server which controls storage on the hard drive of remote server . Server is called a passive server because it is accessed from a local stream manager on a client computer whereas server is an active server.

The data stream required by data access manager could be stored on any or all of storage devices or . Thus data access manager makes a decision as to which data stream manager is most likely to retrieve the data stream first and forwards the request to that data stream manager for example data stream manager .

On receipt of the OPEN request data stream manager converts the data stream ID to a local stream ID using the local stream index and passes the local stream ID to local stream manager which retrieves the data stream from hard drive . Alternatively data stream manager may return the message that the data stream is not stored on hard drive . If data stream manager does not return the data within a specified period of time then data access manager forwards the request to another data stream manager. On receipt of the data stream the data access manager stops all the data stream managers that are still retrieving the data stream.

Open process of data access manager is shown in . At step an OPEN request is received from a client. The client may be the operating system having received a request for an application file from one of applications or another thread associated with the data stream extension such as a B tree manager the indexing manager and so on additionally data access manager may make a recursive call to itself thus becoming its own client. The request includes a path to the requested filename.

At step the main data stream ID of the application file is identified from local stream index and at step the location of the data stream is identified. At step an open handle is created and at step a memory pointer to the open handle is returned to the client in order that the data stream may be accessed via a READ request.

A question is then asked at step as to whether the filename has been found in the directory index and if the question is answered in the affirmative then control is returned to step and the file object index is searched using the file ID identified. If it is answered in the affirmative then at step a new file ID file object and root data stream are created and control is returned to step .

Since the file object index and directory indices are comprised of data streams the steps of searching them require repeated READ requests to be made for specific data streams. Thus requests made for data streams are not always made by applications but by drivers within extension .

If the question asked at step is answered in the negative to the effect that the object indicates an application file then step is completed.

If the question asked at step is answered in the negative then at step the data access manager selects the data stream manager that is most likely to retrieve the data stream quickly. This selection is made on the basis of recent performance and hinting information stored for each data stream manager comprising ranges of data stream IDs that the data stream manager can access.

At step an OPEN request is sent to the data stream manager selected at step or and at step a question is asked at to whether the location of the data has been received. If this question is answered in the negative then control is returned to step and the next mostly likely data stream to retrieve the data is selected. If the question is answered in the affirmative then at step any other data stream managers that have been sent corresponding OPEN requests are stopped.

At step a question is asked at to whether the data stream is frozen and cannot therefore be opened for read write access. If this question is answered in the affirmative then at step the message DATA STREAM FROZEN is sent to the requesting client in order that the client may send a CLONE request to the data access manager. Following this step or an answer in the negative at step step is concluded.

An OPEN request from the operating system results in an open handle being returned. Multiple requests for the same application file result in multiple open handles. In order to conserve memory each open handle is small and consists mainly of a pointer to a master handle stored in a hash table that contains the required information. Thus as shown in master handle includes flags regarding the state of the file object the file object ID the data stream ID and a pointer to the location of the data. Open handle includes only an indication of state a memory pointer to master handle and an indication of the position reached by the application in reading the file. Open handles and are similarly constructed.

If the data stream is not frozen then at step the local stream index is searched to identify the local stream ID corresponding to the received data stream ID and at step a READ request is sent to local stream manager .

At step the location of the data stream is received from local stream manager and at step the location is returned to data access manager .

At step a CREATE request is sent to local stream manager together with the clone data and at step confirmation of the new data stream is received from local stream manager . At step confirmation is sent to data access manager . The requesting client can then make a new OPEN request for the clone data stream.

At step a question is asked as to whether the type ID indicates an operating system file and if this question is answered in the affirmative then at step the required file is retrieved to memory using the underlying operating system services.

If the question asked at step is answered in the negative then at step a further question is asked as to whether the type ID indicates a block and if this question is answered in the affirmative then at step the block is retrieved to memory.

If the question asked at step is answered in the negative then at step a further question is asked as to whether the type ID indicates a fragment and if this question is answered in the affirmative then at step the block is retrieved to memory.

Following any of steps or a confirmation of read is sent to data stream manager at step . Alternatively if the question asked at step is answered in the negative an error message is returned at step .

At step a question is asked as to whether the required block is already in the atomic cache and if this question is answered in the negative then at step the logical block ID is forwarded to atomic cache manager which loads the block into the atomic cache . At step the header of the block is read to identify the fragment set to which it belongs and the location of the required fragment.

At step a question is asked as to whether the required set of four blocks is already in the atomic cache and if this question is answered in the negative then at step the logical IDs of the blocks making up the fragment set are forwarded to atomic cache manager which loads the blocks into the atomic cache .

The fragments are stored nose to tail without any space between them. When a fragment shrinks or grows the fragments following it move backwards or forwards within the block. The blocks in the fragment set are therefore filled at the same rate rather than the first block being filled followed by the second and so on in order that there is space if possible for a fragment to grow.

Fragments are arranged so that data streams that refer to each other are stored close to each other. This means that in order to access a particular file it is likely that only one set of fragments has to be loaded or more if the file is larger. Additionally each set has child sets so that when related fragments spill out of one set they are then stored in only one other and so on. This increases the clustering effect.

Information identifies the first free array slot in the fragment offsets array . The free slots are a linked list such that the first free slot holds a pointer to the next free slot and so on with the final free slot holding a zero.

Fragment sets can have up to three child sets and thus the parent set of the set is identified at and up to three child sets identified at and . The number of child sets is identified at and the level of the set within the tree structure thus created is identified at .

The logical ID of the required block is identified from fragment set array at step following which the fragment can be read from the block in the atomic block cache.

Once the data has been read into the specified location by local stream manager it can be read by the requesting application. Thus on receipt of a READ request with an open handle and an indication of a memory location at step of Read process on data access manager the open handle is read at step to identify the location of the master handle and the current read position. At step the open handle is read to identify the location of the data.

At step the required amount of data is retrieved and stored at the indicated place in memory and at step a confirmation is sent to the client.

Step at which data is read is detailed in . This algorithm performs the process illustrated in . At step the first data element in the data stream is read and at step the element s offset in the data stream and the size of the data in the element are identified. At step a question is asked as to whether the element is a reference to another data stream. If this question is answered in the affirmative then at step the array offset in the element is identified and at step array is read and the data stream ID at the identified offset is retrieved. At step an OPEN request is sent to data access manager to open the identified data stream and at step a READ request is sent to data access manager to read the identified amount of data from the identified offset of the referred data stream. Thus data access manager recursively calls itself whenever data streams are referenced within a data stream being read. The read data streams are later closed with CLOSE requests.

If the question asked at step is answered in the negative to the effect that the element is not a reference then at step the element is read from the data stream using the offset and data size identified at step . Following either of steps or a question is asked at step at to whether the end of the data stream has been reached. If this question is answered in the negative then control is returned to step and the next element is read. If it is answered in the affirmative then at step then step is completed.

Write process on data access manager is detailed in . At step a WRITE request is received from a client along with an open handle reference and at step the open handle is read to identify the master handle. At step the master handle is read to identify the data stream ID and data stream manager that should be used. At step a WRITE request is sent to the identified data stream manager and at step a confirmation of write is received from the data stream manager with a confirmation being sent to the client at step .

Write process on data stream manager is detailed in . At step a WRITE request along with a data stream ID and data to be written is received from data access manager . At step a WRITE request is sent to local stream manager and at step a question is asked at to whether confirmation of write has been received. If this question is answered in the negative then an error has been received meaning that the local stream manager could not write the data stream to its original location.

Thus at step a CREATE request is sent to local stream manager requesting it to create a new data stream using the same data. After reception of confirmation of create at step a DELETE request is sent to discard the local stream ID at step . Once confirmation is received at step or following an answer in the affirmative at step confirmation of write is sent to data access manager at step .

Write process on local stream manager is detailed in . At step a WRITE request along with a local stream ID is received from data stream manager . The type ID that identifies the way in which the referenced data stream is stored is identified at step .

At step a question is asked as to whether the type ID indicates an operating system file and if this question is answered in the affirmative then at step the file is written.

If the question asked at step is answered in the negative then at step a further question is asked as to whether the type ID indicates a block and if this question is answered in the affirmative then at step the block is written.

If the question asked at step is answered in the negative then at step a further question is asked as to whether the type ID indicates a fragment and if this question is answered in the affirmative then at step the fragment is forwarded to fragment manager for storage.

Following any of steps or a confirmation of write is sent to data stream manager at step . Alternatively if the question asked at step is answered in the negative an error message is returned at step .

Following any of steps or at step the local stream ID of the created stream is passed to data stream manager .

Close process on data access manager is detailed in . At step a CLOSE request along with an open handle is received from an application. At step the open handle ID is removed from hash table and at step the master handle is identified. At step a question is asked at to whether there are any more open handles that reference this master handle. If this question is answered in the negative then at step the master handle is tagged for closing.

When local stream manager writes a block it does not write to the same location but to a new block. The atomic cache table ID is updated to link the logical ID of the block with the physical address of the new block. Periodically the table is paged to disk and at this point the old physical location is no longer relevant and can be overwritten. However should a crash occur before the paging the old table references the logical ID to the physical location of the old block and thus the filesystem is still intact although data may be lost.

Load block process is detailed in . At step the process receives a request from local stream manager that contains the logical ID of a block of data which includes whether the block is to be locked for read write access or read only access. At step a question is asked as to whether the buffer is full. If this question is answered in the affirmative then a block must be removed. The buffer operates a two queue system to calculate the most least recently used modified block and at step this block is paged back to the hard drive . Following this and if the question asked at step is answered in the negative at step a unused physical location within the buffer is obtained by interrogating the atomic cache table and at step the required block is retrieved from the hard drive and locked into memory either for read write access or read only access. A memory pointer is then returned to the local stream manager at step .

Fragment manager which writes fragments to fragment sets is detailed in . At step a fragment to store is received from local stream manager along with the data stream ID of a related fragment. In this embodiment a related fragment belongs to or describes the parent directory of the application file that the fragment describes or an application file within the parent directory. Alternatively a related fragment could be one that includes a reference to the fragment under consideration or is referred to by it. Alternatively again fragments are often nodes or leaves in the file object or directory indices and fragments which are close to each other in the B tree can be considered to be related.

At step a question is asked as to whether this is a new fragment rather than an old one being changed. If this question is answered in the affirmative then at step a fragment set containing related fragments is identified. If there is no space in this set then a child set will be tried followed by a parent set. Up to three child sets will be created for any set. Finally if all children and the parent of the set are full another relevant set will be identified. If the question is answered in the negative then at step the fragment block in which the fragment is stored is identified.

At step a question is asked as to whether the required block is in memory and if this question is answered in the negative then at step the block is requested from atomic cache manager . Following this or if the question asked at step is answered in the negative a further question is asked as to whether the fragment is too large for the fragment set. The space allocated to the fragment can expand and contract into another block in the set if necessary but if the fragment has become too large for the set then it must be stored in another set. Thus if this question is answered in the affirmative then at step the message cannot write is returned to local stream manager . Alternatively the fragment is written at step and confirmation of write is returned to the local stream manager at step .

When a fragment is stored in a space that is too big or too small for it or when a fragment is deleted all the other fragments in the block are moved forwards or backwards and the fragment offsets array is updated with the new positions of the moved fragments.

Background threads provided by the data stream extension include indexing service compression service which compresses frozen data streams backup service which backs up data streams to networked locations and pre fetch service that obtains new data streams that are relevant to the user s virtual disks. Processes and run constantly whenever processing system is idle.

Compression process is detailed in . At step the data streams log is interrogated to find a frozen data stream that is a predecessor of a more recent data stream. At step portions of the data streams that contain or refer to identical data are identified. At step references to the recent data stream are inserted into the predecessor data stream in place of the data.

Thus it is always older data streams that contain references to newer ones thus ensuring that the newer and therefore more current data streams will be more quickly accessed.

This compression process is carried out separately on each computer system in the environment shown in . This can mean that data streams with identical data stream IDs may have a different structure because they reference different new data streams. However when the information is extracted it will be identical. Thus data streams with the same ID may contain different data but are considered to contain identical information.

Back up process is detailed in . At step frozen data streams are identified from data streams log . At step these data streams are read via local stream manager and at step the data streams are sent out to the local server for back up. This process may be repeated by backing up to remote servers and or any other storage device within the environment shown in .

Because it is not possible for a user to access the data contained in the data streams without having the root file object it is possible to constantly back up data streams in this way without any worry of other users accessing them. In traditional systems a back up to server would result in other users being able to view a user s data unless it was password protected which requires user intervention. Using the system described herein backups can be done constantly and automatically without this concern.

Pre fetch process is detailed in . At step a broadcast is received from a server that contains new data streams along with an identification of the virtual disks to which they are relevant. At step a question is asked as to whether any of these virtual disks are used by the system and if this question is answered in the affirmative the data streams are stored locally at step . If it is answered in the negative the broadcast is ignored. This allows a single network transmission to update multiple clients thus reducing network traffic.

Additionally when processing system is idle and if there is sufficient storage space the pre fetch process may also interrogate local or remote servers for changes to relevant virtual disks and receive new data streams in response.

This process ensures as far as possible that any data streams that might be required in the near future are available.

