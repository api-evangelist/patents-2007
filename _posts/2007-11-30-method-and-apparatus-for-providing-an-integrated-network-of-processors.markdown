---

title: Method and apparatus for providing an integrated network of processors
abstract: A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07620738&OS=07620738&RS=07620738
owner: NVIDIA Corporation
number: 07620738
owner_city: Santa Clara
owner_country: US
publication_date: 20071130
---
This application is a divisional of U.S. Pat. No. 7 383 352 U.S. application Ser. No. 11 473 892 filed Jun. 23 2006 which is a divisional of U.S. patent application Ser. No. 10 144 658 filed May 13 2002 now abandoned.

The present invention relates to a novel network architecture. More specifically the present invention integrates the functions of an internet protocol IP router into a network processing unit that resides in a host computer s chipset such that the host computer s resources are perceived as separate network appliances.

However a significant drawback of this data routing architecture is that the host computer s resources or devices are only accessible with the involvement of the host CPU OS. Typically accessing the host resources from external computers is either prohibited or it is necessary to request access through the host computer using high level protocols. If the host CPU OS is overtaxed a substantial latency will exist where data flow may be stuck in the OS stacks.

Therefore a need exists for a novel network architecture that allows a host computer s resources to be perceived as separate network appliances and are accessible without the interference of the host computer s CPU OS.

The present invention is a novel network architecture. More specifically the present invention integrates the functions of an internet protocol IP router into a network processing unit NPU that resides in a host computer s chipset such that the host computer s resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though in one embodiment it is sharing the same chip. A host computer s chipset is one or more integrated circuits coupled to a CPU that provide various interfaces e.g. main memory hard disks floppy USB PCI etc exemplified by Intel s Northbridge and Southbridge integrated circuits.

In operation the host computer has a virtual port i.e. host MAC that is in communication with the network processing unit and communicates with the NPU as if it is an external network appliance using standard networking protocols. In one embodiment the host computer communicates via the NPU with one or more auxiliary or dedicated processing units that are deployed to perform dedicated tasks. These auxiliary processing units can be part of the host or can be deployed separate from the host to meet different application requirements. For example some of these auxiliary processing units include but are not limited to a graphics processing unit GPU an audio processing unit APU a video processing unit VPU a storage processing unit SPU and a physics processing unit PPU . The present disclosure refers to these auxiliary processing units as XPU where the X is replaced to signify a particular function performed by the processing unit. Finally the network processing unit itself is an XPU because it can in addition to routing packets among XPUs perform various processing accelerations on these packets such as authentication encryption compression TCP IPSec VPN PPP encapsulation and so on.

One unique aspect of the present Invention is that the XPUs have logically direct attachments to the NPU which effectively serves as an integrated router thereby allowing XPUs to be seen as separate network appliances. Since these auxiliary processing units have first class status in this logical network architecture they are allowed to communicate with each other or with any external computer e.g. via another NPU directly using standard internet protocols such as IP TCP UDP and the like without the involvement of the host CPU OS. Using this novel architecture the NPU provides both local or host access and remote access acceleration in a distributed computing environment.

Furthermore by virtualizing the remaining resources of the host computer such as its physical memory ROM real time clocks interrupts and the like the present invention allows a single chipset to provide multiple virtual host computers with each being attached to this NPU. Each of these virtual computers or virtual host may run its own copy of an identical or different operating system and may communicate with other virtual computers and integrated networked appliances using standard networking protocols. Effectively the present invention embodies its own hardware level operating system and graphical user interface GUI that reside below the standard host operating system and host computer definition and allow the computer user to easily configure the network or to switch from one virtual computer to another without changing the standard definition of that host computer.

To facilitate understanding identical reference numerals have been used where possible to designate identical elements that are common to the figures.

An operating system is any software platform for application programs typical examples are Microsoft Windows Unix and Apple Macintosh OS. An operating system can be run on top of another operating system an example of a virtual operating system or another underlying software platform possibly as an application program.

In operation the host CPU OS has a virtual port i.e. host MAC that is in communication with the network processing unit and communicates with the NPU as if it is an external network appliance using standard networking protocols e.g. TCP IP protocols. In one embodiment the host computer communicates via the NPU with one or more auxiliary or dedicated processing units that are deployed to perform dedicated tasks. These auxiliary processing units can be part of the host or can be deployed separate from the host to meet different application requirements.

For example some of these auxiliary processing units include but are not limited to a graphics processing unit GPU an audio processing unit APU a video processing unit VPU a physics processing unit PPU and a storage processing unit SPU . Some of these auxiliary processing units can be deployed as part of the media engines whereas the SPU is deployed with the storage devices of the host. Finally the network processing unit itself is an XPU because it can in addition to routing packets among XPUs perform various processing accelerations on these packets such as authentication encryption compression TCP IPSec VPN PPP encapsulation and so on.

In one embodiment the NPU is a network router appliance that resides inside the same box or chassis as the host computer i.e. typically within the same chipset. The NPU serves to connect various other XPUs that performed dedicated functions such as 

Some of the above XPUs have a number of commonalities with respect to their association with the host and the NPU . First an XPU can be accessed directly by the host CPU and O S directly as a local resource. Namely communication is effected by using direct local communication channels.

Second an XPU can be placed on the network via the NPU and accessed remotely from other network nodes as shown in below . This indicates that an XPU is capable of processing information that is encapsulated in network packets.

Third an XPU can be accessed as a remote node even from the local host. Namely communication is effected via the NPU by using network protocols.

Fourth an XPU is always in an on state like most appliances even when the host CPU O S is in the off state. This unique feature allows the XPUs to operate without the involvement of the host CPU OS e.g. extracting data from a disk drive of the host without the involvement of the host. More importantly the host s resources are still available even though the CPU OS may be in a dormant state e.g. in a sleep mode.

Fifth an XPU has at least two sets of processing queues one for non real time packets and at least one for real time packets. This duality of queues combined with similar real time queues in the NPU allows the system of NPU and XPUs to guarantee latencies and bandwidth for real time streams.

Sixth an XPU has two software SW drivers one that manages the host side connection to the XPU and one that manages the remotely accessed component of the XPU. In operation the SW drivers communicate with the XPU using abstract command queues called push buffers PBs . Each driver has at least one PB going from the driver to the XPU and at least one PB going from the XPU to the driver. Push buffers are described in U.S. Pat. No. 6 092 124 and is herein incorporated herein by reference.

Seventh an XPU can also be accessed on the host side directly by a user level application. Namely this involves lazy pinning of user space buffers by the O S. Lazy pinning means to lock the virtual to physical address translations of memory pages on demand i.e. when the translations are needed by the particular XPU. When the translations are no longer needed they can be unlocked allowing the operating system to page out those pages. The virtual to physical mappings of these buffers are passed to the XPU. A separate pair of PBs are linked into the user s address space and the O S driver coordinates context switches with the XPU.

Although the present invention discloses the use of a network processing unit to perform routing functions without the involvement of the CPU OS the CPU OS nevertheless still has an alternate direct communication channel with its resources e.g. storage devices. This provides the host CPU OS with the option of communicating with its resources or media engines via the NPU or directly via local access channels or .

In fact although the CPU OS is not involved with the general routing function in one embodiment of the present invention exception routing issues are resolved by the host CPU OS. For example if the NPU receives a packet that it is unable to process the NPU will forward the packet to the host CPU OS for resolution. This limited use of the CPU OS serves to accelerate host processing while retaining the option to more judiciously use the processing power of the host CPU OS to resolve difficult issues.

Additionally the host resources may also be accessed via the NPU without the involvement of the host CPU OS via input output communication channel e.g. via an USB. For example the present architecture can virtualize the remaining resources of the host computer such as its physical memory read only memory ROM real time clocks interrupts and so on thereby allowing a single chipset to provide multiple virtual hosts with each host being attached to the NPU .

One unique aspect of the present Invention is that the XPUs have logically direct attachments to the NPU that effectively serves as an integrated router thereby allowing XPUs to be seen as separate network appliances. Since these auxiliary processing units have first class status in this logical network architecture they are allowed to communicate with each other or with any external computer e.g. via another NPU directly using standard internet protocols such as IP TCP UDP and the like without the involvement of the host CPU OS. Using this novel architecture the NPU provides both local or host access and remote access acceleration in a distributed computing environment.

It is best to view this system of NPU and XPUs in the context of streams of packetized data that flow within this system. There are various types of streams that are allowed by the system. In this discussion the term host means the combination of host CPU and memory in the context of the O S kernel or a user level process. The term node refers to a remote networked host or device that is attached to the NPU via a wired or wireless connection to a MAC that is directly connected to the NPU e.g. as shown in below .

A host to XPU stream is a stream that flows directly from the host to the XPU . This is a typical scenario for a dedicated XPU e.g. a dedicated GPU via communication path . The stream does not traverse through the NPU

An XPU to host stream is a stream that flows directly from the XPU to the host. One example is a local file being read from the SPU via path . The stream does not traverse through the NPU

A host to XPU to host stream is a stream that flows from host to an XPU for processing then back to the host . One example is where the host forwards voice data directly to the APU for processing of voices into final mix buffers that are subsequently returned to the host via path . The stream does not traverse through the NPU

A host to NPU to XPU stream is a networked stream that flows from the host via NPU to an XPU or . The three parties transfer packetized data using standard networking protocols e.g. TCP IP.

An XPU to NPU to Host is a networked stream that flows from an XPU or via the NPU to the host . The three parties transfer packetized data using standard networking protocols e.g. TCP IP.

A host to NPU to XPU to NPU to host is a networked stream that is the combination of the previous two streams. The three parties transfer packetized data using standard networking protocols e.g. TCP IP.

A host to NPU to Node is a networked stream that flows from the host via the NPU to a remote node e.g. NPU . This allows a local host to communicate and access XPUs of another host via a second NPU

A Node to NPU to Host is a reverse networked stream where the stream flows from a remote node e.g. NPU via the NPU to the host . This allows a remote NPU to communicate with a local host via a local NPU

A Node to NPU to XPU is a networked stream that flows from a remote node via the NPU to an XPU where it terminates. This allows a remote NPU to communicate with a local XPU via a local NPU

An XPU to NPU to Node is a networked stream that flows from an XPU where it originates to a remote node e.g. NPU via local NPU

A Node to NPU to XPU to NPU to Node is a combination of the previous two streams. It should be noted that Node and Node may be the same or different. For example Node is NPU is XPU is NPU is and Node is . Alternatively Node is NPU is XPU is NPU is and Node is

A Host Node XPU to NPU to XPU to NPU to XPU to NPU to Host Node XPU is a stream that originates from the host a remote node or an XPU passes through the NPU to another XPU for some processing then passes through the NPU to another XPU for some additional processing then terminates at the host another remote node or another XPU. It should be clear that the present architecture of a network of integrated processing units provides a powerful and flexible distributed processing environment where both host access and remote access acceleration are greatly enhanced.

Under the present architecture numerous advantages are achieved. First it is beneficial to tightly integrate other computers and network appliances into the same chipset. Second it is very advantageous to offload a host computer s I O functions into a distributed network of intelligent processors where traditional latencies associated with overtaxed CPU OS are resolved. Third it is advantageous to provide these auxiliary I O processors with first class network appliance status within the chipset optionally illustrated in with dash lines without changing the definition of the host computer. Fourth it is advantageous to allow these auxiliary I O processors to be shared among the host computer external computers and internal and external network appliances. Fifth it is advantageous to allow the remaining resources of the host computer to be virtualized so that multiple virtual copies of the host computer may be embodied in the same chipset while sharing the network of intelligent auxiliary I O processors. Finally it is advantageous to use a hardware level operating system and graphical user interface GUI that allow the user to configure the network and seamlessly switch among virtual copies of the host computer or virtual host.

In one embodiment of the present invention real time media streaming is implemented using the above described network of integrated processing units. Specifically media streaming typically involves multiple software layers. Thus latencies can be unpredictable particularly when the software runs on a general purpose computer. More importantly media streaming typically has a severe adverse impact on other applications running on the host computer.

However by attaching media devices such as an APU or GPU to an NPU SPU combination it is now possible to minimize and guarantee latencies as well as offload the main host CPU. For example referring to control requests may arrive from a remote recipient typically attached wireless . These control requests may include play stop rewind forward pause select title and so on. Once the stream is set up the raw data can be streamed directly from a disk managed by the SPU through the NPU to the destination client. Alternatively the data may get preprocessed by the GPU or APU prior to being sent out via the NPU . One important aspect again is that real time media streaming can take place without host CPU involvement. Dedicated queuing throughout the system will guarantee latencies and bandwidth.

This media streaming embodiment clearly demonstrates the power and flexibility of the present invention. One practical implementation of this real time media streaming embodiment is within the home environment where a centralized multimedia host server or computer has a large storage device that contains a library of stored media streams or it may simply be connected to a DVD player a PVR personal video recorder or DVR digital video recorder . If there are other client devices throughout the home it is efficient to use the above network architecture to implement real time media streaming where a media stream from a storage device of the host computer can be transmitted to another host computer or a television set in a different part of the home. Thus the real time media streaming is implemented without the involvement of the host computer and with guaranteed latencies and bandwidth.

In operation illustrates a plurality of virtual hosts which may comprise a plurality of different operating systems e.g. Microsoft Corporation s Windows two separate copies and and Linux a raw video game application or other raw applications where the virtual hosts treat the storage processing unit as a remote file server having a physical storage . In essence one can perceive as illustrating a network of VPCs in a box .

In one embodiment the NPU manages multiple IP addresses inside the system for each VPC. For example the NPU may be assigned a public IP address whereas each of the VPCs is assigned a private IP address e.g. in accordance with Dynamic Host Configuration Protocol DHCP . Thus each of the VPCs can communicate with each other and the SPU using standard networking protocols. Standard network protocols include but are not limited to TCP TCP IP UDP NFS HTTP SMTP POP FTP NNTP CGI DHCP and ARP to name only a few that are know in the art .

It should be understood that the XPUs of the present invention can be implemented as one or more physical devices that are coupled to the host CPU through a communication channel. Alternatively the XPUs can be represented and provided by one or more software applications or even a combination of software and hardware e.g. using application specific integrated circuits ASIC where the software is loaded from a storage medium e.g. a ROM a magnetic or optical drive or diskette and operated in the memory of the computer. As such the XPUs including associated methods and data structures of the present invention can be stored and provided on a computer readable medium e.g. ROM or RAM memory magnetic or optical drive or diskette and the like. Alternatively the XPUs can be represented by Field Programmable Gate Arrays FPGA having control bits.

Although various embodiments which incorporate the teachings of the present invention have been shown and described in detail herein those skilled in the art can readily devise many other varied embodiments that still incorporate these teachings. In the claims elements of method claims are listed in a particular order but no order for practicing of the invention is implied even if elements of the claims are numerically or alphabetically enumerated.

