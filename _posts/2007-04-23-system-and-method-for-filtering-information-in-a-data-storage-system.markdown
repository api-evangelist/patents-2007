---

title: System and method for filtering information in a data storage system
abstract: A storage system filter provides protocol aware filter operations that avoid I/O blocking or calling thread holding. A filter framework includes a filter controller that handles request and response calls to filters that are registered with the filter framework. Filters may be loaded and unloaded in a consistent state, and the filter framework provides services for the filters for common functions. Filters may operate in a user mode or a kernel mode and may be invoked in a synchronous, an asynchronous, or an asynchronous release mode. Filter registration may include registration for I/O resources, and may include tagging of I/O requests and responses to contribute to preventing conflicts.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07809868&OS=07809868&RS=07809868
owner: Network Appliance, Inc.
number: 07809868
owner_city: Sunnyvale
owner_country: US
publication_date: 20070423
---
Embodiments of the present invention relate to data storage and retrieval system and in particular to systems and methods for filtering information in the data storage and retrieval system.

A data storage and retrieval system typically includes one or more specialized computers variously referred to as file servers storage servers storage appliances or the like and collectively hereinafter referred to as filers . Each filer has a storage operating system for coordinating activities between filer components and external connections. Each filer also includes one or more storage devices which can be connected with other filers such as via a storage network or fabric. Exemplary storage devices include individual disk drives groups of such disks and redundant arrays of independent or inexpensive disks RAID groups . The filer is also connected via a computer network to one or more clients such as computer workstations application servers or other computers. Software in the filers and other software in the clients cooperate to make the storage devices or groups thereof appear to users of the workstations and to application programs being executed by the application servers etc. as though the storage devices were locally connected to the clients.

Centralized data storage such as network storage enables data stored on the storage devices to be shared by many clients scattered remotely throughout an organization. Network storage also enables information systems IS departments to store data on highly reliable and sometimes redundant equipment so the data remain available especially in the event of a catastrophic failure of one or more of the storage devices. Network storage also facilitates making frequent backup copies of the data and providing access to backed up data when necessary. Backup applications are available to achieve high data integrity without having a significant impact on performance such as may be obtained with incremental backup applications in which only changed data is recorded in a backup operation.

Filers can also perform other services that are not visible to the clients. For example a filer can treat all the storage space in a group of storage devices as an aggregate. The filer can then treat a subset of the storage space in the aggregate as a volume. 

Filers include software that enables clients to treat each volume as though it were a single storage device. The clients issue input output I O commands to read data from or write data to the volume. The filer accepts these I O commands ascertains which storage device s are involved issues I O commands to the appropriate storage device s of the volume to fetch or store the data and returns status information or data to the clients.

Typically the filer manages storage space on the storage devices on a per volume basis. Disk blocks which represent contiguous physical units of storage are composed of a number of bytes and are used as the fundamental storage constructs to store files. A file may be represented as a number of blocks of storage depending upon the size of the file. The filer keeps track of information related to the volume files and blocks. For example the filer tracks the size of the volume the volume owner access protection for the volume a volume ID and disk numbers on which the volume resides. The filer also keeps track of directories directory and file owners and access protections.

Additional information about files maintained by the filer may include file names file directories file owners and protections such as access rights by various categories of users. The filer may also track file data for reference purposes which file data may include file handles which are internal file identifiers and read offsets and read amounts which determine location and size of a file. The filer also tracks information about blocks that store data and make up files. For example the filer may track blocks that are allocated to files blocks that are unallocated or free to be used as well as information about the blocks. In addition the filer may track internal block data such as block checksums a block physical location a block physical logical offset as well as various special purpose blocks.

An example of a special purpose block is a superblock which contributes to mounting a volume where the superblock includes all the information needed to mount the volume in a consistent state. The superblock contains a root data structure commonly known as an index node inode from which a tree of inodes are located and used to locate other blocks in the volume. The superblock contains information about the volume such as volume configuration or a volume ID. The volume information may be read into a cache when a given associated volume is mounted.

The above described information tracked by the filer collectively constitutes a file system as is well known in the art. For example the filer can implement the Write Anywhere File Layout WAFL file system which is available from Network Appliance Inc. of Sunnyvale Calif. Alternatively other file systems can be used.

According to the exemplary WAFL file system storage space on a volume is divided into a plurality of 4 kilobyte KB blocks. Each block has a volume block number VBN which is used as an address of the block. Collectively the VBNs of a volume can be thought of as defining an address space of blocks on the volume.

Stored in each block is a checksum value that helps to verify data integrity. The checksum is a number resulting from a calculation performed on the contents of the block typically involving all the block storage bytes. If a calculated checksum does not match the stored checksum in the block the block data is likely corrupted and appropriate measures may be taken to recover. The checksum information for each block is a system internal value that is dynamic and not typically available for inspection.

Each file on the volume is represented by a corresponding inode. Files are cataloged in a hierarchical set of directories beginning at a root directory. Each directory is implemented as a special file stored on the same volume as the file s listed in the directory. Directories list files by name typically alphabetically to facilitate locating a desired file. A directory entry for a file contains the name of the file the file ID of the inode for the file access permissions etc. The collection of directory names and file names is typically referred to as a name space. Various name spaces may be created that have specific purposes where each name space has a root directory called a metaroot. 

The inodes directories and information about which blocks of the volume are allocated free etc. as well as block checksum information collectively form system information metadata. An allocated block is a data block that stores data while a free block is one that is unallocated and available to be assigned to store specific data. The metadata may be public or private that is being typically made available to users or not. Some metadata is stored in specially named files stored on the volume and in some cases in specific locations on the volume such as in a volume information block as is well known in the art. When one or more blocks are to be retrieved from disk the operating system may retrieve the blocks to a system cache to satisfy an I O request made by a client. The operating system executes a routine to communicate with appropriate device drivers to cause the desired blocks to be read from the storage device s into the cache. In one implementation of a volume each pointer contains both a physical and a virtual address of the 4 KB block. The physical address is referred to as a physical volume block number PVBN which identifies the physical address of the pointed to block relative to the beginning of the volume. The virtual address is referred to as a virtual volume block number VVBN which identifies the block number relative to the beginning of the container file.

Some storage operating systems implemented in filers include a capability to take snapshots of an active file system. A snapshot is a persistent point in time image of the active file system that enables quick recovery of data after data has been corrupted lost or altered. Snapshots can be created by copying the data at each predetermined point in time to form a consistent image. Snapshots can also be created virtually by using a pointer to form the image of the data. A snapshot can also be used as a storage space conservative mechanism generally composed of read only data structures that enables a client or system administrator to obtain a copy of all or a portion of the file system as of a particular time in the past i.e. when the snapshot was taken.

As part of ordinary operation of the network storage system the operating system employs file system filters to realize certain features. Filters may perform tasks related to filer operations including the storage and retrieval of information. Filter operations may include permitting or preventing access to files or file metadata for example. Filter tasks may include capturing backup information for preserving data or data transfer or conversion as may be the case during migrations or upgrades. Examples of file system filters include antivirus products that examine I O operations for virus signatures or activity user access permissions encryption products and backup agents.

File system filters are typically organized as kernel mode applications that are dedicated to a specific purpose. The file system filter is typically arranged in the I O data path to permit the filter to intercept I O requests and responses. This configuration for a file system filter exhibits several drawbacks including impacting control flow for I O operations little or no control of filter sequence or load order and systematic issues with filters being attached to the operating system kernel. There is also typically no convention with respect to filter construction so that the filters arranged in a sequence may conduct operations that cause conflicts or errors in the operating system potentially leading to crashes. Filters may also be constructed to generate their own I O requests and may be reentrant leading to stack overflow issues and significant performance degradation. There may be redundancy among groups of filters for common operations such as obtaining file path names generating I O requests or attaching to mounted volumes and redirectors as well as buffer management. Some of these common tasks are performed inconsistently among the various filters leading to inefficiency and performance degradation.

File system filter architectures have been proposed to overcome some of the above described drawbacks. According to one configuration a filter manager is provided between an I O manager and data storage devices. The filter manager provides services for execution of filter functions while overcoming some of the above described drawbacks. For example the filter manager can provide a filter callback architecture that permits calls and responses rather than chained dispatch routines. A call to a filter invokes the filter often with passed parameters while a callback represents instructions passed to the filter for execution often to call other procedures or functions. For example a callback to a filter may be in the form of a pointer to a function or procedure passed to the filter. The filter manager can also provide uniform operations for common tasks such as generating I O requests obtaining file path names managing buffers and attaching to mounted volumes and redirectors. In addition the filter manager can maintain a registry of filters and their specific functionality requirements such as specific I O operations. By maintaining a registry of filters the filter manager can load and unload filters with consistent results and states. In addition the filters can be enumerated for various filter management functions.

There are several challenges that are not addressed by the above described filter manager in a file system connected through a network. For example the above described filter manager is specific to a local filer where all requests and responses represent local file access activity. Accordingly the above described filter manager is unable to take advantage of available information contained in the request that might indicate request source or aid in request processing. In addition the above described filter manager is file based and thus unable to provide filtering services for other types of access methods. For example one type of advantageous data access protocol operates on a block basis rather than a file basis. Data access protocols such as iSCSI and Fiber Channel permit direct access to data blocks in a file system and are unrecognized by the above described local filer and filter manager. The filter manager is also unable to identify external sources or addresses for requests and responses that might aid in request processing such as are available in the IP protocol for example. The filter manager is unable to pass high level protocol information to filters through the filter architecture to obtain the advantages that might be possible with the additional information available for processing requests and responses by the filters. Accordingly the filter manager does not have context information for the request or response to be processed. Context information refers to information known to a particular object such as a filter that the object can use or produce as a result of object processing. For example CIFS and NFS file protocol based requests include a client source address which can provide a context for a filter processing the request or response. The above described filter manager does not provide such a context for example.

In addition the filter manager is a kernel mode application and is synchronous to the extent that the filter manager has limitations related to processing threads that must complete before being released. Moreover the filter manager does not act to preserve data or I O operations in the event of a load or unload command.

A number of activities undertaken by a file system would potentially benefit from being configured as filter activities rather than application specific tasks. For example hidden or dynamic information such as some metadata in the active file system may be somewhat difficult to access and provide in response to a client request. Some static processes such as a system snapshot might reveal the condition of various metadata but may not provide hidden or dynamic metadata. The snapshot is also typically further processed for example by tracing through file inodes to obtain the desired results based on the exposed metadata. An Application Programming Interface API may be used to expose hidden metadata but such application specific approaches can be complex and somewhat inefficient with respect to obtaining desired data.

In addition applications may access file system data to perform calculations for achieving file system tasks. One such example is a backup application which typically operates by reading backup related data such as incremental changes to a file system to determine which file system blocks should be read or copied for a back up. Again the application may be somewhat complicated or use system resources in such a way to decrease system efficiency. For example a backup application may provide a particular amount point that obtains modified file information. Other backup applications may search for a last modified time or an archive tag toggle for determining changes to files. A customized dirty region log or a comparison of successive snapshots may be used to prepare the incremental backup information needed to perform read operations to save the desired blocks that have been changed.

A system and method for filtering information in a data storage system provide filter operations that avoid input output I O blocking or holding a calling thread. The filter operations are conducted through a filter framework that includes a filter controller that handles request and response calls to filters that are registered with the filter framework. The filter controller passes protocol information to the filters to permit filter operations that are responsive to the protocol information. Protocol information refers to a systematic format for a request or a response in the data storage system some of which formats include information related to block accesses or source destination of requests or responses that are external to the data storage system. Filters may be loaded and unloaded in a consistent state meaning that outstanding requests or responses processed by a filter are suspended to permit the filter to be loaded or unloaded without changing state in relation to processing requests or responses. The filter framework provides services for the filters for common functions. Filters may operate in a user mode or a kernel mode and may be invoked in a synchronous an asynchronous or an asynchronous release mode. Filter registration may include registration for I O resources and may include tagging of I O requests and responses to contribute to preventing conflicts. The filter can be implemented in a file system as described above or in a general data storage system. For example the filter can be implemented in a device driver for controlling I O for a storage device. Alternately or in addition the filter can be implemented in a disk controller that causes the disk to access the physical locations used to store data.

The filter framework may be implemented as a single binary that is hooked into or coupled to the filer in one or more of a variety of locations. A single binary executable application is a standalone instruction code that can be compiled as a separate module for example. The locations for hooking the filter framework include points in a data flow such as at a client interface a protocol interface a network interface or a messaging interface for communicating with storage devices. The filter framework provides a queue for each point at which the filter framework is coupled to the filer. The queues are maintained on a volume basis. The queues maintain filter call identifiers to enable filters to intercept data in the data path for the point at which the filter framework is coupled to the filer. A filter controller is provided to capture request and responses for file system data and invoke applicable filters. The filter controller may invoke filters according to several different invocation models including synchronous asynchronous and asynchronous release configurations. The use of a synchronous model causes the filters associated with the filter controller to hold incoming I O and block the calling thread until execution completes. An asynchronous configuration causes the filter to hold incoming I O until execution completes but releases the calling thread. The asynchronous release configuration causes the filter to execute without blocking incoming I O or the calling thread.

The filters associated with the filter framework may be loaded or unloaded in the filter framework. The filters are arranged in a particular order for callback operations based on for example priority. A callback represents instructions passed to a given filter for execution often to call other procedures or functions. For example a callback to the filter may be in the form of a pointer to a function or procedure passed to the filter. The filter can produce I O operations with each filter I O being provided with a tag for identification. The filter I O tagging permits the filter framework to identify the originating filter of the filter I O. One advantage to providing filter I O tagging is to avoid conflicts that may occur with multiple I O requests from a single filter source. In addition filter I O tagging contributes to permitting the filter framework to determine if the filter I O has a particular priority based on the filter priority. Filters with higher priority can potentially receive a greater time slice of available processing time. Accordingly by tagging the filter I O the filter framework can allocate processing time to I O requests more appropriately.

In an exemplary embodiment of the present invention the filter framework includes an I O map and an event map that contribute to determining when and how a registered filter should be called. The I O map is a data structure that holds identifiers for filters and I O operations for which the filters are registered. The identifiers are used to provide the registered callbacks for the registered filters while the event map provides information concerning when a particular callback is made. The event map is a data structure that holds identifiers for filters and filter characteristics such as an indication of whether a filter is a remote filter. A filter call results from an evaluation of an expression that involves information taken from the I O map and the event map. The determination of when and how to call a filter can be advantageous when filter calls generate significant amounts of control traffic in the filter framework or filer.

The filter controller invokes the filters through a request callback mechanism on an incoming path and through a response callback mechanism on a return path. The request and response callbacks are registered with the filter controller to permit an organized callback mechanism and progression. A request or response that causes a filter to be invoked involves the use of a particular data structure for each I O operation. The data structure may include system call parameters or dedicated protocol components for internal file system operations. The filters may be operable in a kernel space or a user space with associated support being provided in the filter framework for kernel mode or user mode filter applications. Kernel mode filters can take advantage of the filter framework being coupled to the filer at various points to interact with filer components at the various points. The points at which the filter framework is coupled to the filer that permit kernel mode filter interaction include locations within or before a protocol server between the protocol server and a messaging interface for communicating with data storage devices or located between the messaging interface and the data storage devices. The kernel mode filters can thus be single source based and compiled once but placed into the filer at different points of interaction. User mode filter applications can be of two types local user mode filters and remote user mode filters. The filters typically are associated with a particular volume or snapshots for a particular volume.

According to an aspect of the present invention a resource manager is made available for handling a variety of filter functions. The resource manager provides resources at both a user level and a kernel level.

According to an exemplary embodiment of the present invention a filter controller is interposed in a messaging path between a storage control module and a storage device. The filter controller intercepts messages or requests from the storage control module and invokes the filters through a request callback. The filter controller includes a request handler that begins processing the request in accordance with the nature of the request and the configuration of the filter such as user or kernel mode. The intercepted request is forwarded to the storage device depending upon the status provided by the filter configuration. For example the filter may provide a status to the filter controller and the filter framework that indicates the request should be permitted to be sent to the storage device. The storage device returns a response prompted by the request that is also intercepted by the filter controller. The filter controller then invokes the appropriate filters with a response callback. The filters include response handlers to process the response. Both the request handlers and the response handlers in the filters may provide a status to the filter controller and the filter framework to permit a return from the request or response callback to permit other filters to be called or to generally return status information to the filter controller.

According to another exemplary embodiment the filter framework is interposed between a protocol interface front end and a protocol interface back end to permit protocol conversions to occur before filters related to requests and responses are invoked. According to another exemplary embodiment the filter framework is interposed between a client and a protocol interface so that client requests and responses cause filter invocations within the protocol being used by the client. The filter framework can perform protocol conversion and pass the requests and responses between the client and the protocol interface.

The filter framework provides a number of features including filter loading and unloading. A filter loader registers a filter with the filter controller and identifies resources to be used for filter operations. The filter framework can freeze I O during loading and unloading or starting and stopping a given filter. For example the filter framework can maintain a buffer to permit filter related I O to be halted and stored while the filter changes state such as from loaded to started. The filter loader also provides a counter for each filter to permit tracking of I O operations in the event of a filter unload. The filter framework tracks filter I O and completes processing of the filter I O prior to unloading. The counter maintained for each filter counts down to zero to indicate all I O processing has been completed and that the filter is ready for unloading. The filter loader also provides I O tagging so that filter I O requests and responses can be identified to avoid conflicts.

In accordance with the present invention an exemplary filter that may be used with the filter framework exposes metadata information that is normally difficult to obtain or dynamic in an active file system. The filter takes data from the active file system and prepares a separate directory structure accessed through a metaroot which mirrors the root node of interest of the active file system. The metaroot permits access to directory structures as mirrors of the active file system and the filter can provide various virtualization support for accessing and presenting the data mirrored from the active file system. A client may access the metaroot and directory structures to obtain hidden or dynamic metadata for a volume file or block that is not otherwise typically available. For example the client may use the metaroot to walk through the file system locally or remotely to retrieve hidden or dynamic file system metadata. Hidden metadata may include for example a block checksum a block location physical address or a block access history. The file system filter can redirect a read access applied to the metaroot to the active file system to obtain information about files and file attributes. For example the file system filter can create a file stub to match a file in the active file system. A file stub is an initial file structure that can be filled in with content to form a typical file in a file system. The filter can use the file identifier from the file stub to prepare and present information related to file metadata.

Another exemplary filter supports an incremental backup operation for a file system. The incremental backup can be transparent meaning that backup applications can read incremental changes directly from the active file system. Alternately or in addition the incremental backup operation can take advantage of a change log filter that tracks all changes to the file system for use with a backup application.

The transparent incremental backup avoids a step of calculating an incremental backup set of parameters for doing an incremental backup. The file system filter intercepts writes to the file system and records which file blocks have dirty regions meaning that changes have been made to those file blocks or directories that have not yet been backed up. The filter also checks with backup applications to determine which incremental backups have already been made and supplies data for identifying which further incremental backups should be made. The backup application need not determine which incremental backups need to be made since the filter provides that data transparently. The filter can determine if a read operation is made by a backup application. If the read is for the backup application the dirty region log is consulted to determine if the block has been modified. If the block has not been modified the filter provides a specific response or indication to the read request so that the backup application understands that the block need not be read for backup purposes. The transparent incremental backup may operate in synchronous or asynchronous mode.

The change log file system filter captures requests related to data modification including write delete rename create set attribute set securities and set extended attributes. The filter can operate in a synchronous release mode and may be placed in any order in a cascade or chain of filters called by a filter framework. The filter can generate requests for input and output with the file system. For example the filter may provide an input request for checksum data and output requests for maintaining log information. Client commands captured by the filter in relation to modification to file system data are parsed and used to format log entries that may include information such as a volume ID a file handle including an inode or file ID an operation write delete etc. an offset and a length. Entries are added to a change log in the file system which may be in the form of a B tree. A B tree is a tree data structure that maintains the data in a sorted format while permitting insertions and deletions. Other formats for the change log are equally applicable including a simple sequential log.

The concepts of the file system filter in accordance with the present disclosure derive support from a file system architecture with sophisticated mechanisms for storing maintaining and retrieving data. A discussion of the filing system or filer in which an embodiment of the file system filter architecture is implemented follows below.

The clients may be general purpose computers configured to interact with the node in accordance with a client server model of information delivery. For example interaction between the clients and nodes can enable the provision of storage services. That is each client may request the services of the node and the node may return the results of the services requested by the client by exchanging packets over the connection system which may be wire based optical fiber wireless or combinations thereof. The client may issue packets including file based access protocols such as the Common Internet File System CIFS protocol or Network File System NFS protocol over the Transmission Control Protocol Internet Protocol TCP IP when accessing information in the form of files and directories. Alternatively the client may issue packets including block based access protocols such as the Small Computer Systems Interface SCSI protocol encapsulated over TCP iSCSI and SCSI encapsulated over Fiber Channel FCP when accessing information in the form of blocks.

Each node is illustratively embodied as a dual processor storage system executing a storage operating system OS . Storage OS preferably implements a high level module such as a file system to logically organize the information as a hierarchical structure of named directories files and blocks on the disks. However it will be apparent to those of ordinary skill in the art that node may alternatively comprise a single or more than two processor system. Illustratively one processor can execute the functions of a network module on the node while processor can execute the functions of a disk module . It should also be appreciated that processors may include multiple processing cores thus improving the processing speed of processors

Memory illustratively comprises storage locations that are addressable by the processors and adapters for storing software program code and data structures associated with the present invention. The processor and adapters may in turn comprise processing modules and or logic circuitry configured to execute the software code and manipulate the data structures. Storage OS portions of which are typically resident in memory and executed by the processing modules functionally organizes node by inter alia invoking storage operations in support of the storage service implemented by node . It will be apparent to those skilled in the art that other processing and memory means including various computer readable media may be used for storing and executing program instructions.

Network adapter comprises a plurality of ports adapted to couple node to one or more clients over point to point links wide area networks virtual private networks implemented over a public network Internet or a shared local area network. Network adapter thus may comprise mechanical electrical optical or other connection and signaling components to connect node to a network. Illustratively connection system may be embodied as an Ethernet network or a Fiber Channel FC network. Each client may communicate with node over connection system by exchanging discrete frames or packets of data according to pre defined protocols such as TCP IP.

Storage adapter cooperates with storage OS executing on node to access information requested by clients . The information may be stored on any type of attached array of writable storage device media such as video tape optical DVD magnetic tape bubble memory electronic random access memory micro electro mechanical and any other similar media adapted to store information including data and parity information. However as illustratively described herein the information is preferably stored on disks of disk array . Storage adapter comprises a plurality of ports having input output I O interface circuitry that couples to the disks over an I O interconnect arrangement such as a conventional high performance FC link topology.

Storage of information on each disk array is preferably implemented as one or more storage volumes that comprise a collection of physical storage disks cooperating to define an overall logical arrangement of volume block number VBN space on the volume s . Each logical volume is generally although not necessarily associated with its own file system. Disks within a logical volume file system are typically organized as one or more groups wherein each group may be operated as a Redundant Array of Independent or Inexpensive Disks RAID . Most RAID implementations such as a RAID 4 level implementation enhance the reliability integrity of data storage through the redundant writing of data stripes across a given number of physical disks in the RAID group and the appropriate storing of parity information with respect to the striped data. An illustrative example of a RAID implementation is a RAID 4 level implementation although it should be understood that other types and levels of RAID implementations may be used in accordance with the inventive principles described herein.

To facilitate access to disks storage OS implements a write anywhere file system that cooperates with one or more virtualization modules to virtualize the storage space provided by the disks . A file system logically organizes the information as a hierarchical structure of named directories and files on the disks. Each on disk file may be implemented as set of disk blocks configured to store information such as data whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization module s allow the file system to further logically organize information as a hierarchical structure of blocks on the disks that are exported as named logical unit numbers luns .

Storage OS provides a processing architecture for implementing the file system and includes a variety of components typically found in a sophisticated operating system processing. For example the processing of OS is divided into different modes a kernel mode and a user mode. The kernel mode processing takes advantage of a kernel space while the user mode processing takes advantage of a user space. The kernel space and user space interact to pass information for processing within the different modes and typically the modes are maintained separately. One reason for maintaining the separate modes is security for the file system. Kernel mode operations are typically configured as internal or system oriented operations while user mode operations are typically undertaken by applications and user accesses. Often an application or user submits a request in user mode which prompts a system call that is handled in kernel mode with the response transferring information from the kernel mode operations to the user mode operations.

Processing in OS typically involves interaction between a number of processes each with their own resources such as address space and state information. Processes typically operate in OS in kernel mode and provide system oriented operations such as calls to hardware devices. Processes typically do not interact with each other except through system provided inter processes communication mechanisms.

Processing threads are operational sequences for program execution that may execute in parallel with each other. Processes typically have one or more threads associated with their operation to carry out one or more tasks assigned to the process. In the case of a single processor with a single core or computing engine multiple threads may be executed in parallel through multitasking architectures such as time slicing or event oriented processing. A single processor with a single core executes multiple threads by switching between the threads at specified points so that the processing of multiple parallel threads is not literally simultaneous. In the case of multiple processors or a processor with multiple cores multiple threads may be processed literally simultaneously as may be the case in node with processors as shown in .

Multiple threads may be formed in an application that operates in user mode. Threading implemented by application programs often relies on self governance to permit interruption of threads or thread switching. Unlike typical process configurations threads may typically share state information address space or other resources directly. Context switching between threads is typically very fast in comparison to context switching between processes. Context switching refers to the saving or transfer of state information related to a given thread so that another thread can install state information to provide a context for that thread. In the case of multiple processors or cores threads may execute concurrently which while advantageous can lead to challenges in synchronization. For example while different threads may work on different tasks simultaneously processing or data in one thread may rely on a result from another thread. Accordingly concurrently executing threads often are coordinated or synchronized to attain proper overall execution. A mechanism may be used to prevent a thread from continuing processing until another thread reaches a specified point to permit correct data manipulation or to prevent attempts at simultaneous modification of common data. Such mechanisms for preventing simultaneous access to resources such as data are often referred to as locks. Accordingly one thread may lock access to a resource until processing completes at which point the resource may be accessed by another thread.

Threads that operate in user mode sometimes issue system calls that block the called resource. For example a thread may request resources for performing I O which is often performed synchronously. Synchronous I O operations involve system calls that typically do not return until the I O operation has been completed. Waiting for the system call to return can block the thread or entire process that is awaiting execution by the thread. In addition other threads in the same process are prevented from being executed. Techniques to overcome the effects of blocking system calls include the use of a synchronous interface that uses non blocking I O internally or structuring a program to avoid the use of synchronous I O or other types of blocking system calls.

Threads also typically use locks for resources including data that should not be accessed while being processed or manipulated. The lock will permit a thread to obtain access to the resource excluding all other threads or processes. Managing locks on resources or data can be made the responsibility of the threads requesting the resource or data. In addition or alternatively the use of locks for resources accessed by multiple threads may be managed by a separate scheduling thread or process.

In the illustrative embodiment processes and threads are implemented in storage OS which is preferably the NetApp Data ONTAP operating system available from Network Appliance Inc. of Sunnyvale Calif. Storage OS thus preferably implements a Write Anywhere File Layout WAFL file system. However it is expressly contemplated that any appropriate storage operating system may be enhanced for use in accordance with the inventive principles described herein. As such storage OS should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.

Storage OS comprises a series of software layers organized to form an integrated network protocol stack or more generally a multi protocol engine that provides data paths for clients to access information stored on the node using block and file access protocols. The multi protocol engine includes a media access layer of network drivers for example gigabit Ethernet drivers that interfaces to network protocol layers such as an IP layer and supporting transport mechanisms a TCP layer and a User Datagram Protocol UDP layer . A file system protocol layer provides multi protocol file access and to that end includes support for a Direct Access File System DAFS protocol an NFS protocol a CIFS protocol and a Hypertext Transfer Protocol HTTP . A VI layer implements the VI architecture to provide direct access transport DAT capabilities such as RDMA as required by DAFS protocol . An iSCSI driver layer provides block protocol access over the TCP IP network protocol layers while an FC driver layer receives and transmits block access requests and responses to and from node . The FC and iSCSI drivers provide FC specific and iSCSI specific access control to the blocks and manage exports of luns to iSCSI or FCP components.

Storage OS may establish a session using one of the above described protocols to form a connection between a client and node . The session may rely on a session layer of one of the network protocols discussed above for example through Telnet or FTP. The session implementation can be maintained by a higher level program such as storage OS .

In addition storage OS includes a series of software layers organized to form a storage server that provides data paths for accessing information stored on the disks of architecture . Storage server includes a file system module for managing volumes a RAID system module and a disk driver system module . The RAID system manages the storage and retrieval of information to and from the volumes disks in accordance with I O operations while the disk driver system implements a disk access protocol such as e.g. the SCSI protocol.

The file system implements a virtualization system of the storage OS through the interaction with one or more virtualization modules illustratively embodied as e.g. a virtual disk vdisk module not shown and a SCSI target module . The vdisk module enables access by administrative interfaces such as a user interface of a management framework not shown in response to a user system administrator issuing commands to the node . The SCSI target module is generally disposed between the FC and iSCSI drivers and the file system to provide a translation layer of the virtualization system between the block lun space and the file system space where luns are represented as blocks.

The file system is illustratively a message based system that provides logical volume management capabilities for use in access to the information stored on the storage devices such as disks . That is in addition to providing file system semantics the file system provides functions normally associated with a volume manager. These functions include i aggregation of the disks ii aggregation of storage bandwidth of the disks and iii reliability guarantees such as mirroring and or parity RAID . The file system illustratively implements the WAFL file system having an on disk format representation that is block based using e.g. 4 kilobyte kB blocks and using inodes to identify files and file attributes such as creation time access permissions size and block location . The file system uses files to store some metadata such as that describing the layout of its file system these metadata files include among others an inode file. A file handle i.e. an identifier that includes an inode number is used to retrieve an inode from disk.

Operationally a request from the client is forwarded as a packet over the connection system and onto the node where it is received at the network adapter . A network driver of layer or layer processes the packet and if appropriate passes it on to a network protocol and file access layer for additional processing prior to forwarding to the write anywhere file system . Here the file system generates operations to load retrieve the requested data from disk if it is not cached or resident in core i.e. in memory . If the information is not in memory the file system indexes into the mode file using the mode number to access an appropriate entry and retrieve a logical VBN. The file system then passes a message structure including the logical VBN to the RAID system the logical VBN is mapped to a disk identifier and disk block number disk dbn and sent to an appropriate driver e.g. SCSI of the disk driver system . The disk driver accesses the dbn from the specified disk and loads the requested data block s in memory for processing by the node. Upon completion of the request the node and operating system typically returns a response to the client over the connection system .

As described in greater detail below a file system filter may be implemented in accordance with the present invention in node to intercept the client request and data storage response. Portions of the file system filter may be implemented at various locations within the filer architecture such as at protocol conversion points or disk access points. The file system filter establishes software hooks in storage OS for connecting the file system filter to the filer to take advantage of the above described filer features.

It should be noted that the software path through the storage operating system layers described above used to perform data storage access for the client request received at node may alternatively be implemented in hardware. That is in an alternate embodiment of the invention a storage access request data path may be implemented as logic circuitry embodied within a field programmable gate array FPGA or an application specific integrated circuit ASIC . This type of hardware implementation increases the performance of the storage service provided by node in response to a request issued by the client . Moreover the processing modules of adapters may be configured to offload some or all of the packet processing and storage access operations respectively from processor to thereby increase the performance of the storage service provided by the node . It is expressly contemplated that the various processes architectures and procedures described herein can be implemented in hardware firmware or software and may use storage media that includes various types of read only random access and disk storage.

As used herein the term storage operating system generally refers to the computer executable code operable on a computer to perform data storage and retrieval functions and manage data access and may in the case of a node implement data access semantics of a general purpose operating system. The storage operating system can also be implemented as a microkernel an application program operating over a general purpose operating system such as UNIX or Windows NT or as a general purpose operating system with configurable functionality which is configured for storage applications as described herein.

In addition it will be understood to those skilled in the art that the invention described herein may apply to any type of special purpose e.g. file server filer or storage serving appliance or general purpose computer including a standalone computer or portion thereof embodied as or including a storage system. For example the filter of the present invention can be implemented in a device driver for controlling I O for a storage device. Alternately or in addition the filter can be implemented in a disk controller that causes the disk to access the physical locations used to store data.

Moreover the teachings of this invention can be adapted to a variety of storage system architectures including but not limited to a network attached storage environment a storage area network and a disk assembly directly attached to a client or host computer. The term storage system should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems. It should be noted that while this description is written in terms of a write anywhere file system the teachings of the present invention may be utilized with any suitable file system including a write in place file system.

In an illustrative embodiment the storage server is embodied as data module of the storage OS to service one or more volumes of the disk array . In addition the multi protocol engine is embodied as network module to i perform protocol termination with respect to a client issuing incoming data access request packets over the connection system as well as ii redirect those data access requests to any storage server in architecture . Moreover the network module and data module cooperate to make architecture a highly scalable and distributed storage system. To that end each module includes a cluster fabric CF interface module adapted to implement intra cluster communication among the modules including data module to data module communication for data container striping operations.

The protocol layers e.g. the NFS CIFS layers and the iSCSI FC layers of the network module function as protocol servers that translate file based and block based data access requests from clients into CF protocol messages used for communication with the data module . That is the network module servers convert the incoming data access requests into file system commands that are embedded within CF messages by the CF interface module for transmission to the data modules in architecture . It is these file system commands that are used by the file system filter of the present invention to achieve filtering functions in accordance with filter definitions. Moreover the CF interface modules cooperate to provide a single file system image across all data modules in architecture . Thus any network port of a network module that receives a request from client can access any data container within the single file system image located on any data module of architecture .

Further to the illustrative embodiment network module and data module are implemented as separately scheduled processes of storage OS however in an alternate embodiment the network and data modules may be implemented as pieces of code within a single operating system process. Communication between a network module and data module is thus illustratively effected through the use of message passing between the network and data modules although in the case of remote communication between a network module and data module of different nodes such message passing occurs over the cluster switching fabric . A known message passing mechanism provided by the storage operating system to transfer information between network and data modules processes is the Inter Process Communication IPC mechanism. The protocol used with the IPC mechanism is illustratively a generic file and or block based agnostic CF protocol that comprises a collection of methods functions constituting a CF application programming interface API . An example of such an agnostic protocol is the SpinNP protocols available from Network Appliance Inc.

In accordance with the present invention a file system filter framework is arranged in the above described filer within node . The filter framework may be arranged in a number of configurations to take advantage of the above described features of the filer.

According to an embodiment of the present invention a filter framework or architecture is provided for filter operations related to data access requests and responses to and from a filer. Referring to and filer systems and are shown which include a file system . A filter framework and filters operate to provide filtering functions for filer systems and . A client provides requests for information from file system and receives responses that may include data maintained in file system or information about the data. The request and response for client is directed through a network interface which supports network addressing to route the request and response between client and file system as described above with reference to multi protocol engine .

File system can be implemented as file system illustrated in . File system receives requests and provides responses with the same mechanisms as file system as described more fully above. Filter framework intercepts requests and responses and invokes one or more of filters in accordance with the request or response information. The present invention may also provide various components to realize filter functions some of which may be represented as being located in file system or between components of file system as described in greater detail below.

Filter framework is implemented in node and may be realized as part of storage OS shown in . Accordingly processors may execute instructions related to filter operations. In addition as illustrated in filter framework can be represented as being located in the data path prior to or after network module shown in . Components of the network filter system can be implemented in disk module to permit direct filter access to requests and responses for file system as discussed in greater detail below.

Referring now to and a dataflow and for embodiments of a network filter system architecture is shown. Dataflow includes a protocol interface front end and a protocol interface back end between which is inserted a filter framework . Protocol interface front end can be implemented as multi protocol engine illustrated in while protocol interface back end can be implemented as CF interface module of data modules . Accordingly filter framework is represented as being inserted between CF interface modules to intercept system commands to data module as well as to intercept responses from data module .

For data flows from client to file system dataflow typically commences with a request from client which request is delivered to protocol interface front end . Protocol interface front end converts the request from the I O request format into a system command which is transferred to protocol interface backend through filter framework . The system command is applied to file system to generate a response. For data flows from file system a system response from file system is delivered to protocol interface back end which response is then forwarded to protocol interface front end through filter framework . Protocol interface front end converts the internal system responses from protocol interface back end to a protocol format suitable for transmission of the response data to client . Protocol interface front end thus formats the system responses into standard file or block protocol forms with the more typical file protocols being NFS and CIFS and the more typical block protocols being iSCSI and FC. The request and responses being provided between client and protocol interface front end can be transmitted over an Ethernet or Fiber Channel network.

Filter framework intercepts the system commands and responses between protocol interface front and back ends to perform filtering functions. Upon intercepting a command or response filter framework enumerates filters to make a call to each one in a given order. Filters can be cascaded and some may be in kernel space as supported by kernel level filter support while other filters may be in user space as supported by user level filter support . Kernel level filter support and user level filter support interact to pass information for processing within the separate kernel or user modes where the kernel and user modes are generally maintained separately. Kernel mode operations are typically configured as internal or system oriented operations while user mode operations are typically undertaken by applications and user accesses. A user mode filter submits a request in user mode which prompts a system call through kernel level filter support which system call is handled in kernel mode. The kernel mode response provides kernel mode information to kernel level filter support which in turn delivers user mode responses to user level filter support for use with user mode filters.

Filter framework uses a call model that is dependent upon the operation mode available for the called filter. The call models include a synchronous mode in which the filter holds incoming I O and blocks the calling thread until processing is completed. An asynchronous mode also holds incoming I O until processing is completed but releases the calling thread. An asynchronous release mode permits filter calls in which the filter does not block incoming I O or the calling thread. and illustrate arrangements for filter framework that can use the synchronous mode or the asynchronous mode.

Filter framework also receives or intercepts responses from a file system in a return path. File system can be implemented as file system or as described more fully above. The responses prompt filter framework to enumerate filters and invoke the appropriate filter response callback. A callback represents instructions passed to the filter for execution often to call other procedures or functions. For example a callback to a filter may be in the form of a pointer to a function or procedure that is passed to the filter. Filter framework ensures that I O is properly ordered and in a form appropriate for requests and responses. Filters are also ordered or prioritized and include predefined tags to identify any I O generated by filters . The use of tags to identify I O requests contributes to simplifying processing of the prioritized filters. The I O request tags indicate the source filter for the I O request as well as the priority associated with the filter making the I O request. Filter framework can appropriately allocate processing time for the I O requests in accordance with their priority based on an examination of the associated I O tags.

Kernel level filter support provides support for kernel mode filters as well as providing kernel level services for filters . For example kernel level filter support organizes the input of request response parameters and provides communication and status support on a system level for user level filters and user level filter support . Kernel level filter support provides status information to filter framework related to the status of user level filter support and user level filters located within filters .

Messaging memory share is a communication device used to transfer data between kernel space and user space to contribute to supporting user level filters. The communication used by messaging memory share can take a number of forms including a specified shared memory input output control IOCTL or an IPC socket connection as examples. The communication mechanisms are used to transfer parameters from kernel level filter support to user level filter support as well as to return status to kernel level filter support .

User level filter support receives request response parameters from kernel level filter support enumerates user level filters and invokes user level filter callouts. User level filters in filters register with user level filter support to obtain request and response callbacks related to the filter operations. User level filters can be located locally or remotely depending upon their implementation. For example a filter can be located in the same file system node as OS . A filter that is remotely located may be in another file system node or in any remote filer or file system architecture as well as in other external systems. Remote filters can be useful in implementing filtering operations in systems with special purpose applications that are not typically implemented with OS . For example an email application may use information from filer systems or and can implement filters for the information on a remote basis under control of the email application. In either case of local or remote filters filters register with user level filter support to receive execution calls based upon request or response parameters. The calls may include arguments such as pointers to data structures related to the request or response.

The request parameters may include such components as file operation read write etc. file name and volume that are the target of the operation file operation parameters user credentials and time as examples. The request parameters may also include the origin source such as a source IP address a source host name CIFS export NFS export iSCSI or Fiber Channel related parameters. The response to user level filter support may include parameters such as status and error codes data from file system in the case of a read operation and attributes related to the data or the response.

The status provided to user level filter support may include an error code indicating an operation failure as an example. The absence of an error code indicates success of an operation. The status may also indicate that filter processing should continue or that the operation is pending such as may be the case when a filter is awaiting the completion of further processing. The status may also indicate that further filter processing may be skipped. User level filter support invokes user level filters included in filters with a request or response callout. The various user level filters may provide status indications upon a request or response callout as indicated above.

For control flow purposes if the filter indicates a status of return with error code the call flow returns to user level filter support which is processed through messaging memory share to return flow to the original request from client which may be pending in kernel level filter support . If the filter indicates a status of continue the callout returns to user level filter support which can then call the next user filter in the filter order. If the filter indicates a status of return with pending operation user level filter support holds the current operation and returns a status back to messaging memory share and filter framework to hold the filter callout but release the calling thread back to protocol interface front end . When the pending operation of the filter is completed the filter provides an indication to user level filter support to resume filter callouts.

Once all filters have been called and returned to user level filter support a status is sent through messaging memory share to signal kernel level filter support . Kernel level filter support returns a status to filter framework that indicates how filter framework should further direct the control flow. For example filter framework can forward a current request to protocol interface back end and to file system depending upon whether permitted by the status returned to filter framework . Protocol interface back end provides responses to filter framework as provided by file system which responses may include requested data or information about data in file system . Filter framework can then initiate response callback processing similar to the request callback processing described above. The response provided by file system is the source for initiating the response flow path which ultimately provides a response to client .

The operations described above with respect to dataflow in are similar to those provided in dataflow shown in . Dataflow illustrates filter framework interposed between client and protocol interface rather than between a protocol interface front end and protocol interface back end as shown in . Accordingly protocol conversion is completed within protocol interface to convert between local network protocols and internal system protocols. Filter framework receives the external request and provides the eternal response with client . Accordingly filter framework intercepts network traffic with one or more of an Ethernet interceptor or Fiber Channel interceptor. Filter framework in can thus intercept network traffic from a network module such as by intercepting communication from network adaptor shown in . Filter framework then converts NFS or CIFS requests and SCSI commands from iSCSI or Fiber Channel into a general request for use by protocol interface . Similarly in the response flow path filter framework converts the return response from protocol interface to forms usable with NFS or CIFS as well as SCSI commands.

Referring now to a dataflow for an asynchronous release mode embodiment of a filter framework for a filer is shown. The dataflow typically commences with a request from client which is delivered to a protocol interface front end . Protocol interface front end provides conversion from the I O request format into a system internal request. Protocol interface front end also provides conversion for responses from internal system responses to an I O response in accordance with the chosen protocol. Typical protocols include NFS and CIFS with the request and responses being provided between client and protocol interface front end typically through an Ethernet or Fiber Channel network. The converted internal system requests are delivered to filter framework for filter processing.

Filter framework enumerates filters to make a call to each one in a given order depending upon the request. Filters can be cascaded and some may be in kernel space as indicated by kernel filters while other filters such as user level filters may be in user space. User level filters are supported by user level filter support . Filter framework uses the asynchronous release call model which permits filter calls in which the filter does not block incoming I O or the calling thread. An address space in filter framework provides a location for storing I O information to contribute to permitting the filter to free I O resources and threads. Filter framework also receives responses from file system in a return path. The responses prompt filter framework to enumerate filters and invoke the appropriate filter response call back. Filter framework ensures that I O is properly ordered and in a form appropriate for requests and responses. Filters are also ordered and include predefined tags to identify any I O generated by filters .

The address space in filter framework includes an I O map for use by filters that can operate in asynchronous release mode. The filters register for the type of I O they desire such as I O for a synchronous call or I O for an asynchronous release call. The I O map is used by filters to pass parameters in the asynchronous release mode to permit associated I O and calling threads to be released.

Filter framework also includes an event map that contributes to determining when and how a registered filter should be called. While the I O map includes the registered callbacks for the registered filters the event map provides information concerning when a particular callback is made. The event map is a data structure that holds identifiers for filters and filter characteristics such as an indication of whether a filter is a remote filter. A filter call results from an evaluation of an expression that involves information taken from the I O map and the event map. The determination of when and how to call a filter can be advantageous when filter calls generate significant amounts of control traffic in the filter framework the file system or the network connections. For example a user mode filter may register as a remote filter which may be located at a different physical location from the filter framework. These types of remote user mode filters are discussed above with reference to . Because of the distance and the connection latency involved with calling a remote filter a significant delay can be caused due to data traffic generated in calling the remote filter. Accordingly it may be expeditious to avoid calling the remote filter with every pass through the filter call cascade. It may be more desirable to produce calls to such a filter based on conditioned events as provided by the evaluated expression involving the I O map and the event map in filter framework .

To avoid invoking a filter callback in undesirable circumstances a combination of data taken from the I O map and event map is used to produce a logical expression of when a filter should be called. The logical expression is evaluated in filter framework to permit or defer a filter call. For example a request from client may include I O information for which filter Ufilter1 in filters has registered a call. Upon receiving the request filter framework consults the I O map to determine that Ufilter1 has requested a call based on the registered I O information. Filter framework then evaluates an appropriate logical expression as indicated by the registered call by Ufilter1 and an entry in the event map for Ufilter1 that describes how Ufilter1 should be called. Based on the result of the expression evaluation filter framework will permit or defer the call to Ufilter1.

The I O map includes the I O callbacks available for the given registered filters. The event map provides criteria related to the filter registration to permit construction of a determination for invoking a filter call. The event map may include various parameters to contribute to building an expression that can be evaluated to determine when the filter callback should occur. Exemplary parameters include user credentials client IP or source address time date information a volume directory file designation for the I O that is targeted CPU memory resources available at the time and update totals such as total desired updates for a given volume. Filter framework evaluates the expressions composed of the event map parameters in combination with the I O map to determine when a filter should be called. The conditioned calling of a specified filter helps to avoid message traffic congestion and improve overall filter operation.

An I O request response memory is coupled to filter framework to store request or response parameters. A number of request parameters may be saved in memory such as file operation filename and volume for the target of the operation operation parameters user credentials or time of request. Other parameters that may be saved in memory include source information such as an IP source address or a source host name. Parameters may also include protocol dependent information related file access protocols such as CIFS or NFS export. Block based protocol parameters such as luns may also be stored for protocols such as iSCSI or Fiber Channel for example. Examples of file operations include read write and get attributes. Response parameters that are saved in memory may include status and error codes as well as data related to a read operation and attributes. If memory becomes full or fills to a given threshold a flush to I O log occurs to free memory and retain I O request response parameter data. A flush is an operation to write data from one memory storage to another memory storage to preserve a state of the data such as by saving changes to data held in a cache to a disk storage. Memory may be battery backed by battery power memory support to provide persistent parameter memory.

After a request callout to a filter filter framework need not wait for a filter return to continue processing. If status permits the current request is forwarded to protocol interface backend and on to file system . Responses from protocol interface backend delivered to filter framework are used to call up filter response processing in the same way as filter request processing. Again filter framework need not wait for a filter return from a filter response handler to continue processing.

Kernel filters are invoked by filter framework using memory . The filter invocation involves request and response callouts using a communication structure in memory that is specific to kernel filter callout. An example of the protocol with the communication structure is SpinNP discussed above. Kernel filters register with filter framework for I O requests and responses in asynchronous release mode. The parameters for the I O components of the request and response are similar to those parameters for user level filters described above.

User level filter support also receives request response parameters from memory enumerates user level filters and invokes user level filter callouts. User level filters register with user level filter support to obtain request and response callbacks related to the filter operations. User level filters may be locally or remotely located as discussed above with respect to . The request parameters may include such components as file operation file name and volume for the operation target file operation parameters user credentials and time. The request parameters may also include information related to the origin source such as a source IP address or a source host name. The request parameters may also include CIFS export or NFS export file based requests. Alternately or in addition the request parameters may include block based requests such as those based on iSCSI or Fiber Channel. In general any available parameters desired for filter operation may be registered with user level filter support . The response to user level filter support may include parameters such as return status and error codes data from file system in the case of a read operation and attributes related to the data or the response. The return status provided to user level filter support does not matter in asynchronous release mode since filter framework need not wait for a filter return to continue processing.

Filter framework can forward a current request to protocol interface back end depending upon whether permitted by the status returned to filter framework . Protocol interface back end provides responses to filter framework which can initiate the response callback processing similar to the request callback processing described above. Protocol interface back end also routes current requests and responses to and from file system . File system processes incoming requests applies them to the data storage system and receives a response which is forwarded to protocol interface backend . This sequence provides the initial steps in a response flow path that ultimately provides a response to client .

Referring now to a filter framework is illustrated as being hooked into or coupled to the filer system represented as a filer in one or more of a variety of locations. In this exemplary embodiment filter framework is implemented as a single binary executable application that is coupled to the filer at points . A single binary executable application is a standalone instruction code that can be compiled as a separate module for example. Filer is represented as having a file system front end and a file system back end . File system front end corresponds to a file system layout structure such as WAFL for example as well as a messaging interface suitable for high performance messaging with such protocols as SpinNP as discussed above. File system back end corresponds to a hardware oriented interface for such systems as may provide functions for flushing RAID and volume management.

Point represents filter framework coupled to filer between protocol interface front end and protocol interface back end . Point represents filter framework coupled to filer between protocol interface backend and a file system front end . Point represents filter framework coupled to filer between file system front end and file system back end . Point represents filter framework coupled to filer between a client and protocol front end . Point can be a network interface that receives sends requests responses based on a number of protocols including file and block oriented protocols. A filter controller provides a construct for coupling filter framework to filer . The coupling points or hooks and may be provided through interaction with messaging mechanisms that exist between protocol interface front end protocol interface backend file system front end and file system back end . Each point and has a separate queue within filter framework on a per volume basis. Accordingly queues for points and may be maintained within filter framework for each volume established within file system . The queues represent organized call structures for calling filters that are to be activated at the specified points or . Because different information may be available depending on where a filter is hooked to points or a request from client and response from file system can be captured along the data path where pertinent information is available in relation to specific filter operation. For example a filter hooked to point can obtain protocol related information from protocol interface front end to permit filter operations in relation to protocol information such as IP or network external addresses. Similarly points or permit filter operations on a block access basis rather than a file access basis alone.

A filter may be hooked into one or more points or depending upon entries in the respective queues for calling the specified filter. A filter management interface indicates to filter framework where a filter should be hooked into filer . Filter management interface can indicate to filter framework that a filter should be added to or removed from a queue for one or more of hooking points or . Filter framework provides an Application Programming Interface API to abstract the private details of hooking points and . Filter management interface uses the API to indicate where an inserted filter should be hooked. The operational mode of the filter and registration information for filter calls. The registration information may include request response parameter extractions used in filter operations and full path name extractions which can be file or block oriented. The filter operation mode can be asynchronous or asynchronous release depending upon a selection of hooking points or . Also depending upon filter operation mode one filter can be inserted into multiple hooking points to operate simultaneously at those hooking points.

The hook points for filter framework to be coupled to filer need not be active if a given queue or queues for one or more of hooking points or is empty. That is if there is no filter call in a given queue no change occurs in the operation of filer relative to the associated hooking point. When filter management interface notifies filter controller that a filter should be inserted into a given hooking point filter controller puts a call for the specified filter into the specified queue for the associated hooking point or . Filter controller then enables a data path intercept for the associated hooking point or .

The organization of filter framework with multiple hooking points permits a filter that is single source based meaning it is compiled as a self contained module independent of desired hooking points. The configuration of filter framework permits the filter to be inserted at selectable hooking points without reconfiguring the filter code or recompiling the filter module. Placement of a given filter into a queue for an associated desired hooking point can take place after loading of the filter or as part of the loading procedure.

Kernel mode filters can take advantage of filter framework being coupled to filer at points to interact with particular filer components. Points at which filter framework is coupled to filer permit kernel mode filter interaction with components of filer . The hooking locations include points within or before a protocol server between the protocol server and a messaging interface for communicating with data storage devices or located between the messaging interface and the data storage devices. As discussed above kernel mode filters can be single source based and compiled once but placed into filer at different points of interaction. User mode filter applications can be of two types local user mode filters and remote user mode filters . Local and remote user mode filters may similarly interact with filer at hooking points . Local and remote user mode filters operate through a user level filter support which interacts with a kernel level filter support to make system calls or provide system oriented operations for local and remote user mode filters . Remote user mode filters may be located at a physically remote site or on a separate filer system that may be connected to filer through a network connection such as through cluster switching fabric or connection system illustrated in . In remote user mode filters are illustrated as being available at a same level as local user mode filters through a connection since remote user mode filters interact with filter controller and filter framework similarly to local user mode filters . Because remote user mode filters are registered with filter framework as remote filters an I O map and an event map may be used to provide a determination of when remote user mode filters are actually called as discussed above with respect to filter framework in

In addition to having a selectable insertion point for a filter to be coupled to filer each filter may be compiled with a flag to indicate a desired hooking point . This compile time feature avoids user or administrative interaction through filter management interface to indicate to filter framework where the given filter should be hooked. Filter controller calls filters in a given order which can depend upon priority or location within a queue for example. Because filter priority can vary among the filters in the different queues a filter call to the next filter in a queue may be delayed while higher priority filters in other queues are called and permitted to complete processing. Accordingly filter call order depends upon several factors including priority and queue order. Calls to a given one of filters can be triggered by other filters or can be based on calls or callbacks from filter controller as indicated by the specific I O activities for which the specified filter registers. Filters are typically associated with a particular volume or snapshots for a particular volume.

Referring now to a configuration for a filter framework is illustrated. Filter framework includes a filter loader a filter controller a filter registration an I O tagging and I O and event maps . Filter loader includes a number of counters one for each registered filter. Filter controller includes a request response manager that contributes to handling request and response callbacks. Filter controller communicates with filters through a messaging manager . Messaging manager provides high performance messaging between filter controller and filters and may be realized through one or more communication formats such as shared memory input output control IOCTL or IPC socket connection for example. These communication formats provide a structure for the transfer of parameters from filter controller to filters as well as for the return of status to filter controller .

Upon callout filters may take advantage of a resource manager . Resource manager is made available for handling a variety of filter functions at both a user level and a kernel level. Exemplary features included in resource manager are management components for managing threads memory resource locking file I O volumes snapshots sessions names and messaging.

Filter controller includes a watchdog timer not shown . The watchdog timer is a mechanism for determining if filters are responding properly. The watchdog timer is started or reset when filter controller calls a filter and times out if the filter does not properly respond within the time frame defined by the watchdog timer time interval. If the watchdog timer times out the filter is considered unresponsive and is skipped for further calls in the filter order. The watchdog timer can be implemented as a timer interval or as a counter with a given value that counts at a given rate.

Filter loader registers a filter with filter controller through filter registration and identifies resources to be used for filter operations. Filter framework can freeze I O during loading and unloading or starting and stopping a given filter. For example filter framework can maintain a buffer not shown to permit filter related I O to be halted and stored while the filter changes state such as from loaded to started. In accordance with an exemplary embodiment according to the present invention a filter can be automatically upgraded using the starting stopping loading and unloading functions provided by filter framework and filter loader . A prior version of a filter is stopped to avoid generating additional I O requests. Any pending I O requests are buffered in filter framework . After receiving a confirmation that the prior version filter is stopped filter loader unloads the prior version filter and loads an updated version filter. Once filter loader confirms that the updated version filter is properly loaded filter framework starts the updated version filter. Once filter framework confirms that the updated version filter is started the I O requests are permitted to continue. The continued I O requests may be derived from the buffer provided by filter framework .

Filter loader provides a counter for each filter to permit tracking of I O operations in the event of a filter unload. Filter framework tracks and completes filter I O prior to unloading the specified filter. A counter maintained for each filter counts I O events and counts down to zero to indicate all I O processing has been completed and that the filter is ready for unloading. Filter loader also identifies I O associated with registered filters through I O tagging so that filter I O requests and responses can be identified to avoid conflicts.

Filter framework also includes an I O map and an event map that operate together to determine when and how a registered filter should be called. I O map includes information related to callbacks for registered filters based on I O events. Event map provides criteria for determining when a filter should be called. Even map is aware of the characteristics of registered filters which contribute to formulating a logical expression that can be evaluated to determine when a filter should be called. The expression can include elements from I O map so that calls to registered filters can be made or deferred based on how requested I O events are processed. For example a user mode filter may register as a remote filter in filter registration . The remote filter may be located at a different physical location from filter framework . To avoid data traffic tie ups or processing latency that is typical of remote processing calls to the remote filter may be deferred until a given set of I O events are ready for processing or until other conditions are met as defined by the expression evaluation determined by I O map and event map .

Filter framework is also coupled to a filter management interface for user access to filter framework . Interface may include an API for users to manage filter functions such as loading or unloading filters using filter loader .

Referring now to a request response dataflow is illustrated. Filter controller intercepts requests to a file system and storage devices and make filter calls to filter request handlers . Request handlers begin processing filter functions upon receipt of a request. Request handlers also provide a status to filter controller that indicates how filter controller should continue processing. For example the status may include an error code indicating that a filter operation did not complete successfully. Filters A and B can be user or kernel mode filters.

Filter controller forwards requests to messaging manager which is a high performance messaging protocol system for requests and responses of storage devices . Responses from storage devices are returned to filter controller through messaging manager . Once filter controller receives a response response handlers may be invoked to process the response. Response handlers provide status information to filter controller related to the response processing to indicate how filter controller should proceed with processing.

In accordance with the present invention an exemplary filter that may be used with the filter framework exposes metadata information that is normally difficult to obtain or dynamic in an active file system. The inodes directories and information about which blocks of the volume are allocated free etc. as well as block checksum information collectively form system information metadata. An allocated block is one that is assigned to store specific data while a free block is one that is unallocated and available to be assigned to store specific data. The metadata may be public or private that is being typically made available to users or not. Some metadata is stored in specially named files stored on the volume and in some cases in specific locations on the volume such as in a volume information block as is well known in the art.

Referring now to a block flow diagram shows a filter system with data flow paths for an exemplary filter. A client provides a request for metadata information from file system using typical access protocols such as NFS or CIFS. In accordance with the present invention several options may be provided to client for accessing metadata information such as checksum data physical location data or block access history data. The request is forwarded through protocol interface to filter framework . Filter framework can be similar to filter framework depicted in and operates as described above to provide a filter call mechanism for registered filters. Client protocol interface and file system are the same as those depicted and described with reference to with protocol interface being located between client and filter framework rather than between filter framework and file system .

Metadata filter has two basic components a virtual namespace to store metadata information in the form of a directory structure that mirrors a directory structure in file system and metadata generation. The request from client can specify a particular file or a set of files in given directories. For example a user may change directories such as by traversing a directory tree to reach a particular directory in file system . The particular directory that the user reaches or specifies in a command to invoke metadata filter provides the context for the request and for populating the virtual namespace. Metadata filter creates a mirror directory structure in the virtual namespace based on the directory specified by the context of the request or the current user directory and provides metadata information that can be accessed by the user in the mirror directory structure. For example if the user specifies a directory dir1 dir2 dir3 for a metadata information request metadata filter creates a mirror directory structure dir1 dir2 dir3 in the virtual namespace and provides the requested metadata information in dir3 of the mirror directory structure. In this example dir1 is a metaroot directory meaning that dir1 is a root directory for purposes of the virtual namespace. The metaroot serves as a convenient reference point for the mirror directory structure.

A number of different metadata filters may be provided in filter system and filter framework tracks or maps the different filters and the different metadata information exposed by each filter. Metadata filter operates with a specific metadata request from client which request can be in the form of a command ending in .checksum for a specified file or group of files for example. The request produces an I O directory query that is forwarded to protocol interface and then to filter framework . The request forwarded to filter framework is in the form of an internal request from a file system callout as produced by protocol interface . In an open system i.e. a system with standardized programming or protocol interfaces the internal request can be a system call a vnode operation or a file operation from an I O manager. A vnode is a generic representation of a file handle. Filter framework receives the internal request and determines the filter call model from the options of synchronous asynchronous or asynchronous release modes. The directory query and lookup request prompted by a checksum or physical location metadata information request causes filter to create a namespace with a metaroot that permits the directory of interest to be recreated. For example if the user seeks to do a checksum request for a file A in a directory path dir1 dir2 dir3 metadata filter sets up a metaroot for dir1. Metadata filter then accesses the directory lookup and query functions on file system to obtain the path dir2 dir3. A checksum is derived from the block or file of interest and returned to dir3 in the created namespace. The namespace convention is convenient since users are familiar with the directory construct and need only execute the desired command.

Metadata filter can register with filter framework as either a synchronous or an asynchronous mode filter. Metadata filter includes directory query and lookup filtering as well as options for metadata information such as checksum and physical location information. Filter framework may invoke metadata filter based on the request received from client and obtain directory query and lookup information related to the request. Filter framework may then use the directory query and lookup information to invoke checksum or physical location aspects of metadata filter . The response from the checksum or physical location portions of metadata filter are specifically tagged for return to client . The tags may be used to identify filter responses for use by other filters and requests.

The checksum portion of metadata filter may also respond to the invocation by filter framework with the creation of a file or directory with the same name for each entry in the directory response. The checksum portion of metadata filter may also modify a directory query result to change the metadata information. The response data to client related to metadata checksum information includes a checksum method and the total number of blocks involved in the checksum as well as a block number and a checksum value for each identified block number. A checksum method is the way in which the checksum is calculated such as by cyclic redundancy check CRC or secure hash algorithm SHA or using another algorithm.

The physical location request also causes the formation of a namespace with a metaroot and directory structure mirror . Metadata filter does a directory lookup and query to build the directory structure of interest in the namespace with the metaroot as the top level directory block or identifier. The physical location information may be obtained by reading the physical volume block number of the file or block of interest.

Metadata filter can traverse the physical location name space in file system read the physical file and retrieve the physical locations for each block of the file. The data returned for the request for physical location metadata information includes the total number of blocks and for each block number a physical logical offset on the associated volume and the physical location on the disk with the disk number. When client sends a request for physical locations and the namespace is created and the physical information is returned the information is arranged in a file in the metaroot directory structure that mirrors the directory structure that client sees in file system . Any of the files formed under the metaroot directory structure can be opened and read by client . The files under the specified metaroot have the same name as the original files in the name space of file system .

When client provides the metadata request to protocol interface the request is formatted to provide a number of parameters including a volume ID a file handle a read offset or a read amount. Filter framework provides a request callback into metadata filter using the read parameters. Filter framework may also check the requested metaroot against a metaroot referenced by metadata filter and load an appropriate metadata filter if desired for a particularly specified metaroot.

Checksum metadata requests prompt the checksum portion of metadata filter to determine the appropriate file in the physical name space of file system . The read request may include a directory query that creates a file stub which can then provide the inode number of the desired file in file system . If the read request includes a directory query that returns a virtual file such as a file from metaroot mirror the generation ID of the file may be examined to determine if the appropriate name space is being used and if so whether the inode of the virtual file is the same as the inode provided for the file in file system . Once the inode for the file in file system is determined a block checksum can be determined either by directly calculating the checksum or by making a file system call to obtain a block checksum. Once the checksum value is obtained the response to the read request provides a data structure format that includes the checksum method the total number of blocks and a block number with an associated checksum value for each of the blocks processed by the checksum portion of metadata filter .

The physical location portion of metadata filter similarly calls file system to retrieve a file block location and formats a response to the request that includes a data structure having a block number a physical logical offset on the associated volume a physical location on the associated disk and the disk number.

The data provided through the checksum or physical location portions of metadata filter provide responses to a request by client to expose data that is usually hidden or dynamic such that the data is usually difficult to obtain or calculate. Direct reads to a metaroot applied to metadata filter result in reads being directed to active file system . The desired metadata information whether checksum or physical location or other is produced by metadata filter in the form of a file readable by client . Metadata filter modifies file attributes in the file to produce a file size that is the size of the requested metadata information.

Another exemplary filter provides an incremental backup operation for a file system. The incremental backup can be transparent meaning that backup applications can read incremental changes directly from the active file system. Alternately or in addition the incremental backup operation can take advantage of a change log filter that tracks all changes to the file system for use with a backup application.

Referring now to a flow diagram for a filter system illustrates an incremental backup filter that simplifies the operation of backup applications executed for file system . In accordance with actions by client changes to blocks in file system occur from time to time. Some of the activities that cause requests related to block changes include write delete rename create set attribute set securities and set extended attributes actions or commands. The request is forwarded from client through protocol interface to filter framework . Protocol interface converts the request protocol to internal system format requests. Filter framework determines a call model for invoking a desired filter from among the options of synchronous asynchronous or asynchronous release modes.

Filter system shows two incremental backup filters a change detect filter and a data provider filter . Change detect filter may be called using asynchronous release mode in which change detect filter does not block the incoming I O in the request and does not block the calling thread. Filter framework makes a reference copy of incoming I O parameters for use by filter in accordance with asynchronous release mode.

Filter captures requests related to data modification including commands such as write delete rename create set attribute set securities and set extended attributes. The captured requests are used to update change log for reference during incremental backup reads. Filter can generate requests for input and output with the file system. For example the filter may provide a request for checksum data and output entries for maintaining log information. Client commands captured by the filter in relation to modification to file system data are parsed and used to format log entries that may include information such as a volume ID a file handle including an inode or file ID an operation an offset and a length. Entries are added to a change log in the file system which may be in the form of a B tree. A B tree is a tree data structure that maintains the data in a sorted format while permitting insertions and deletions. Other formats for the change log are equally applicable including a simple sequential log.

The transparent incremental backup avoids a step of calculating an incremental backup set of parameters for doing an incremental backup. The file system filter intercepts writes to the file system and records which file blocks have dirty regions meaning that changes have been made to those file blocks or directories that have not yet been backed up. The filter also checks with backup applications to identify their read requests. The backup applications typically operate by calculating incremental backup information and then reading and storing a copy of the blocks calculated as needing backup. With filter the block reads result in either a block to copy and store provided to the backup application or a return code indicating no need to read. The backup application need not determine which incremental backups need to be made since filter provides that data transparently. Incremental backup data filter can be implemented to operate in asynchronous release mode. Filter uses a change detection to parse requests from client and create entries in change log when appropriate. The parsed request results in information about volume ID file handle including inode and file ID operation offset and length. Backup applications simply access change log to determine the latest blocks for backup.

Referring to metadata filter change detect filter and incremental backup data filter register with filter framework for callback operations such as callbacks based on requests and responses. In addition filters and register for I O priority which determines where in a cascade of filters registered with filter framework filters and will be called. When filters and register with a higher I O priority they are called before other filters that register with a lower I O priority. As with other filters filters and receive an I O tag generated by filter framework so that I O generated from filters and can be identified. Identification through the use of tags assigned by filter framework helps to avoid conflicts that may occur with filters requesting the same resources or filters that may cause or exhibit re entrant behavior.

Depending upon the position of filter framework in the filer filters and may operate on converted system internal requests and responses or may operate on requests and responses within higher level protocols such as external or network protocols. Filter framework also provides management functions for filters and such as loading and unloading starting and stopping and filter configuration. Filter framework produces callbacks upon implementation of each of the above functions. Filters and implement callbacks as well such as for file open file read file lookup file write get attribute and directory read for examples. The callback model used by filter framework may be the synchronous mode the asynchronous mode or the asynchronous release mode as determined by filters and upon registration with filter framework .

Filters and also include version information to take advantage of versioning in filter framework . For example filter framework permits filter upgrades that can be implemented on the basis of inconsistent versions of a filter. Filter framework can determine an inconsistent version during an upgrade and cause a previous version filter to be stopped and unloaded and an updated filter version to be loaded and started.

The request and response callbacks implemented by filters and take advantage of contextual information in the request and response parameters. The request and response parameters may include a file name of a file to be opened user credentials external source address information such as a source IP a process and process name information or a time for request or response.

The operations herein described are purely exemplary and imply no particular order. Further the operations can be used in any sequence when appropriate and can be partially used. With the above embodiments in mind it should be understood that the invention can employ various computer implemented operations involving data stored in computer systems. These operations are those requiring physical manipulation of physical quantities. Usually though not necessarily these quantities take the form of electrical magnetic or optical signals capable of being stored transferred combined compared and otherwise manipulated.

Any of the operations described herein that form part of the invention are useful machine operations. The invention also relates to a device or an apparatus for performing these operations. The apparatus can be specially constructed for the required purpose or the apparatus can be a general purpose computer selectively activated or configured by a computer program stored in the computer. In particular various general purpose machines can be used with computer programs written in accordance with the teachings herein or it may be more convenient to construct a more specialized apparatus to perform the required operations.

The invention can also be embodied as computer readable code on a computer readable medium. The computer readable medium is any data storage device that can store data which can be thereafter be read by a computer system. Examples of the computer readable medium include hard drives accessible via network attached storage NAS Storage Area Networks SAN read only memory random access memory CD ROMs CD Rs CD RWs magnetic tapes and other optical and non optical data storage devices. The computer readable medium can also be distributed over a network coupled computer system so that the computer readable code is stored and executed in a distributed fashion. The computer readable medium can also be distributed using a switching fabric such as used in compute farms.

The foregoing description has been directed to particular embodiments of this invention. It will be apparent however that other variations and modifications may be made to the described embodiments with the attainment of some or all of their advantages. Specifically it should be noted that the principles of the present invention may be implemented in non distributed file systems. Additionally the procedures processes and or modules described herein may be implemented in hardware software embodied as a computer readable medium having program instructions firmware or a combination thereof. Therefore it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention.

