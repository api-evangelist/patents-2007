---

title: Efficient image representation by edges and low-resolution signal
abstract: An exemplary method for encoding an image includes receiving image data, detecting edges in the image data, selecting at least some of the detected edges, encoding the selected edges as selected edge information, down-sampling the image data, encoding the down-sampled image as down-sampled image information and multiplexing the selected edges information and the down-sampled image information. In such a method, the selected edges information and the down-sampled image information can be stored as an encoded image file. Other exemplary methods, devices, systems are also disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08116581&OS=08116581&RS=08116581
owner: Microsoft Corporation
number: 08116581
owner_city: Redmond
owner_country: US
publication_date: 20070628
---
Media content e.g. images and videos often exist in compressed form to reduce storage space and to facilitate transport. For example a media server typically accesses compressed media and streams the compressed media to a client capable of decompressing the media for presentation. Compression is extensively used in transmission storage and playback in various applications.

The compressed media are usually generated by the following process. First raw media contents are predicted from their temporal and or spatial neighbors. Second the predicted residues are transformed to frequency domain. At last the coefficients are quantized and entropy coded to generate the compressed representation. In general natural images and videos contain rich edges and contours which still exist after prediction. These edges constitute the high frequency part of media which are difficult to encode because the energy of signal becomes somewhat scattered after transformation to the frequency domain. Often edges and contours contain important structural media content however transform based representation has a problem to preserve and utilize edges and contours.

For example consider mosquito noise which is a type of edge busyness distortion that appears near crisp edges of objects in MPEG and other video frames compressed using lossy techniques that rely on the discrete cosine transform DCT . More specifically mosquito noise occurs at decompression as the decoding engine approximates discarded data by inverting the transform model. In video mosquito noise appears as frame to frame random aliasing at the edges e.g. resembling a mosquito flying around a person s head where edges exist between the person s head and a solid background . In general as TV and computer screens get larger mosquito noise and other artifacts become more noticeable.

For image compression techniques that rely solely on the DCT a Fourier related transform similar to the discrete Fourier transform but using only real numbers edges and contours are totally invisible. Another type of transform the wavelet transforms is a time frequency transform however wavelet based compression techniques only use structure information in context models for arithmetic coding. Consequently DCT and wavelet techniques fall short in their ability to represent media in a manner that preserves edge and contour information. Further in both DCT based and wavelet based compression techniques it is not easy to access structure information in a compressed stream or a compressed file. Techniques are presented herein that allow for preservation of edge and contour information as well as access to such information.

An exemplary method for encoding an image includes receiving image data detecting edges in the image data selecting at least some of the detected edges encoding the selected edges as selected edge information down sampling the image data encoding the down sampled image as down sampled image information and multiplexing the selected edges information and the down sampled image information. In such a method the selected edges information and the down sampled image information can be stored as an encoded image file. Other exemplary methods devices systems are also disclosed.

An exemplary technique preserves edge and contour information using transform based and pixel based approaches. This technique down scales selected low frequency regions for representation in a frequency domain and maintains selected high frequency regions in a pixel domain. Thus for a given image each low frequency part of the image can be described by a low resolution signal that can be efficiently processed by conventional transform based approaches while each high frequency part of the image can be described by edges extracted at high resolution for processing directly in the pixel domain. When media content is reconstructed the high frequency signal can be used to interpolate the down scaled image from low resolution to for example its original resolution. Since edge information is a separated component of the media representation it can be made available for any of a variety of purposes e.g. indexing searches classification machine vision scientific analyses etc. .

Various techniques also allow for access to such structural information in compressed stream. For example a search application may access this information to perform better media searches.

Various figures include blocks which are typically software modules for performing one or more actions. For example a block may be processor executable instructions that upon execution perform one or more actions. In certain instances such blocks may be implemented as hardware or hardware and software. With respect to hardware MPEG 4 encoder and or decoder chips are examples of hardware commonly used for TV set top boxes DVD players DVD recorders digital media adapters portable media players etc.

Various conventional still image compression techniques are defined by the Joint Photographic Experts Group JPEG . A baseline JPEG lossy process which is typical of many DCT based processes involves encoding by i dividing each component of an input image into 8 8 blocks ii performing a two dimensional DCT on each block iii quantizing each DCT coefficient uniformly iv subtracting the quantized DC coefficient from the corresponding term in the previous block and v entropy coding the quantized coefficients using variable length codes VLCs . Decoding is performed by inverting each of the encoder operations in the reverse order. For example decoding involves i entropy decoding ii performing a 1 D DC prediction iii performing an inverse quantization iv performing an inverse DCT transform on 8 8 blocks and v reconstructing the image based on the 8 8 blocks. While the process is not limited to 8 8 blocks square blocks of dimension 2n 2n where n is an integer are preferred.

Various conventional video compression techniques are defined by the Moving Pictures Experts Group MPEG which provides a fairly widespread standard for digital terrestrial cable and satellite TV DVDs digital video recorders DVRs etc. MPEG uses lossy DCT compression within each frame similar to JPEG. MPEG also uses interframe coding which further compresses the data by encoding only the differences between periodic frames. With interframe coding a video sequence can be represented as key frames that contain full content and delta frames which are encoded with incremental differences between frames. For example a delta frame typically includes information about image blocks that have changed as well as motion vectors e.g. bidirectional etc. or information about image blocks that have moved since the previous frame. Delta frames tend to be most compressed in situations where video content is quite static.

As explained in the Background section lossy DCT compression does not adequately handle edges and contours. In particular as compression ratio increases high frequency content noise increases. A type of distortion known as edge busyness finds distortion concentrated at the edges of objects. Edge busyness can be further characterized by temporal and spatial characteristics of media content. For example edge busyness occurs when a reconstructed edge varies slightly in its position from one scan line to another due to quantizer fluctuations. As already mentioned a more specific type of edge busyness is mosquito noise a distortion that appears near crisp edges of objects in MPEG and other video frames that are compressed using DCT.

With respect to the bit stream information may be in the form of data packets. Various media systems e.g. WINDOWS Media Player can receive media in a packetized format. In addition header and or other information are optionally included wherein the information relates to such packets e.g. padding of packets bit rate and or other format information e.g. error correction etc. .

The decompression process generally involves decoding quantized coefficients dequantizing coefficients and performing an inverse transform . As already explained where edges exist especially high contrast edges energy can be dispersed by transformation to the frequency domain. In turn when the inverse transform is performed the dispersed energy can end up in a pixel other than the corresponding original pixel. The reconstructed image illustrates this as noise along an edge noting that such noise may be present along all edges especially high contrast edges.

The method is shown with reference to the first image from a standard test video file commonly known as the Foreman test video see e.g. test media associated with the Consultative Committee on International Telegraphy and Telephony . This image is segregated into a low frequency part and a high frequency part noting that each of the low frequency part and the high frequency part can represent various regions of the images. More specifically the high frequency part represents edges and the low frequency part represents various regions that reside between edges. Thus the method includes a high frequency process left side of a low frequency process right side of and processes to distinguish and to combine low and high frequency information center of .

In the encoding phase an edge detection and selection block detects edges in the original image thins these edges to a predetermined width e.g. a one pixel width and then selects some of the edges through a use of a rate distortion criterion. Overall the detection and selection block defines the high frequency part of the image in a manner that can be described losslessly per an edge encoding block . Details of an exemplary method for edge encoding are discussed further below.

With respect to the low frequency part of the image a down sampling block down samples the image with edges to create a low resolution image. The down sampling process can operate with assistance of the selected edges see dashed line from block to block . After down sampling an image encoding block encodes the low resolution image.

As indicated in the selected edges and the low resolution image are encoded i.e. compressed and multiplexed by a multiplex block to form an encoded image . The encoded image may be a data file suitable for storage or transmission or a data stream e.g. packetized or other format . Where a video is provided various images of the video may be processed using the encoder to generate an encoded video.

As described in more detail below a process for encoding selected edges can encode a selected edge as a start point and a series of chain direction values e.g. a chain code . This information may be stored as a data structure accessible by a search engine and or it may be used to index an image based on the selected edge information e.g. start point information and chain direction information . For example indexing may index an image based on edge characteristics such as number of edges e.g. based on information in a binary start point map and edge length e.g. number of values in a chain code .

As mentioned conventional encoding techniques do not encode edges separately consequently edge information is not readily available for indexing searches etc. Consider machine vision example where images are acquired for quality control. Such images may include edge information that relates to certain quality aspects while other non edge regions are useful for other quality aspects. In this example separate edge encoding allows a search algorithm to uncover edge abnormalities e.g. number of start points and or short average edge length which may correspond to a broken product based on edge information alone. In the instance a particular image is identified as associated with a potentially defective product the down sampled information may be used to reconstruct a high resolution image to more fully understand the defect see e.g. description of decoding phase below.

The decoding phase of the method includes the decoder receiving the encoded image . The decoding process is bifurcated into an edge decoding step performed by an edge decoding block and an image decoding step performed by an image decoding block . Accordingly two kinds of encoded data are received one is the low resolution image which can be decoded using corresponding image decoding scheme and the other is the edges which can be decoded using an exemplary edge decoding scheme . After edge decoding and image decoding a generation block generates a high resolution image by up sampling the decoded low resolution image with the decoding edges. Thus the decoding phase of the method can decode selected edges information and down sampled image information to generate an up sampled image having a resolution greater than the down sampled image.

Overall the method provides for efficient image representation by edges and a low resolution signal. Such a technique can reduce noise associated with edges allow for indexing based on edge characteristics etc.

Most classical edge detection techniques define the concept of an edge as the zero crossing positions of a Laplacian of a Gaussian filtered image. For example shows an edge region profile and second derivative for a single edge point as located between the double edge points of the edge region . In the example of the location of an edge is in the middle of the region. As a result the local structure is described as a single zero crossing edge with a scale or width parameter as indicated in edge region . However since the scale or width of an edge area varies arbitrarily in natural images such description lacks precision which can lead to performance loss.

As shown in double edge points separate the whole region into three sub regions left of edge edge and right of edge . Each of these sub regions is relatively smooth without large discontinuities in intensity e.g. for the grayscale example of . As described herein regardless of the types of edge detection used e.g. filters or other edge detection techniques the steps of down sampling e.g. block or up sampling e.g. block should operate in image sub regions where a sub region does not cross an edge. Accordingly to this approach edges can be maintained as sharp as possible.

The edges extracted from an original image can reduce the distortion of an up sampled image while the number of bits to encode them should also be considered. An exemplary edge selection process uses a rate distortion criterion to determine the efficiency of an edge. The rate distortion criterion can be formulated as follows 

With respect to non edge pixels these pixels locate in the smooth regions between two edges and they are down sampled or up sampled with the 6 tap filter as mentioned. When the filter crosses an edge it will be cut and the pixel values within this area will be extended as shown in the filter across edges schematic of .

After generating chain code sequences for all the selected edges the edge image is separated into two parts one part is the chain code sequence of each selected edge which can be encoded by context based adaptive arithmetic coding and the other part is the start points of all the edges which can be represented by a binary map. As explained below each point in this map indicates in binary code whether the point is a start point 1 or not 0 .

To build context models for arithmetic coding two aspects are considered. First consideration of what contexts are available and useful and second consideration of how many context models are needed and the probability distribution for each context model.

Suppose C is the current chain code Pis the previous one and Pis the one before P. From the edge image shown in most edges have strong directionality and continuity. Therefore Pand Pcan be good predictions for C. The third context is L which is the direction predicted by the low resolution image.

The image map is then divided into four sections according to quad tree geometry coding to produce the image map where one bit for each section is used to indicate whether that section contains at least one start point or not 1 yes and 0 no. If a section does contain at least one start point that section is recursively divided into smaller sections until it reaches end blocks of a predetermined size otherwise a section need not be further divided. End blocks sizes may be selected as desired for example end blocks may be one or more of sizes 2 2 2 3 3 2 and 3 3 e.g. in pixels . Once end block resolution has been reached in each block if it contains only one start point the index of the point is encoded. Otherwise the whole bit pattern of the block is encoded to ensure information for all start points is retained.

The computing device shown in is only one example of a computer environment and is not intended to suggest any limitation as to the scope of use or functionality of the computer and network architectures. Neither should the computer environment be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the example computer environment.

With reference to an exemplary system for implementing an exemplary encoding and or decoding process includes a computing device such as computing device . In a very basic configuration computing device typically includes at least one processing unit and system memory . Depending on the exact configuration and type of computing device system memory may be volatile such as RAM non volatile such as ROM flash memory etc. or some combination of the two. System memory typically includes an operating system one or more program modules and may include program data . This basic configuration is illustrated in by those components within dashed line .

The operating system may include a component based framework that supports components including properties and events objects inheritance polymorphism reflection and provides an object oriented component based application programming interface API such as that of the .NET Framework manufactured by Microsoft Corporation Redmond Wash.

Computing device may have additional features or functionality. For example computing device may also include additional data storage devices removable and or non removable such as for example magnetic disks optical disks or tape. Such additional storage is illustrated in by removable storage and non removable storage . Computer storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. System memory removable storage and non removable storage are all examples of computer storage media. Thus computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media may be part of device . Computing device may also have input device s such as keyboard mouse pen voice input device touch input device etc. Output device s such as a display speakers printer etc. may also be included. These devices are well know in the art and need not be discussed at length here.

Computing device may also contain communication connections that allow the device to communicate with other computing devices such as over a network. Communication connection s is one example of communication media. Communication media may typically be embodied by computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. The term computer readable media as used herein includes both storage media and communication media.

Various modules and techniques may be described herein in the general context of computer executable instructions such as program modules executed by one or more computers or other devices. Generally program modules include routines programs objects components data structures etc. for performing particular tasks or implement particular abstract data types. These program modules and the like may be executed as native code or may be downloaded and executed such as in a virtual machine or other just in time compilation execution environment. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments.

An implementation of these modules and techniques may be stored on or transmitted across some form of computer readable media. Computer readable media can be any available media that can be accessed by a computer. By way of example and not limitation computer readable media may comprise computer storage media and communications media. 

One skilled in the relevant art may recognize however that the techniques described herein may be practiced without one or more of the specific details or with other methods resources materials etc. In other instances well known structures resources or operations have not been shown or described in detail merely to avoid obscuring aspects of various exemplary techniques.

While various examples and applications have been illustrated and described it is to be understood that the techniques are not limited to the precise configuration and resources described above. Various modifications changes and variations apparent to those skilled in the art may be made in the arrangement operation and details of the methods and systems disclosed herein without departing from their practical scope.

