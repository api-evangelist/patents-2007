---

title: Systems and methods for accelerating delivery of a computing environment to a remote user
abstract: The present invention is directed towards a method and system for accelerating delivery of a computing environment to a remote client. The computing environment may include a plurality of files comprising an application program and may be streamed to a remote client from a server. Responsive to a determination of whether transmission of the application may be accelerated, an appliance, intercepting the plurality of files, may accelerate transmission of the application program by applying one or more transport layer transmission acceleration techniques to the plurality of files.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08886822&OS=08886822&RS=08886822
owner: Citrix  Systems, Inc.
number: 08886822
owner_city: Fort Lauderdale
owner_country: US
publication_date: 20070411
---
This application claims the benefit of and priority to U.S. Provisional Patent Application No. 60 744 720 entitled SYSTEMS AND METHODS FOR ACCELERATING DELIVERY OF A COMPUTING ENVIRONMENT TO A REMOTE USER and filed on Apr. 12 2006 which is incorporated herein by reference.

The present invention is directed towards systems and methods for accelerating the delivery of a computing environment including an application and a data file to a remote user of a client at a location remote to the server.

Administering and managing enterprise environments consumes time money and resources. In many cases this is because the application and data management process is decentralized and labor intensive. For example a significant portion of an administrator s time may be spent providing more storage or performing backups for the corporate data or updating servers to handle growth in corporate data. Also an administrator may need to create and provision new servers to handle the growth in data. Additionally an administrator may spend time updating or provisioning a server to provide a particular user application. Additionally a significant portion of corporate data may reside outside the corporate data center. For example corporate documents files and data may exist on or are distributed to various computers remote to the data center.

In an effort to reduce the time money and resources required to administer and manage corporate data and applications many companies have consolidated and centralized servers corporate data and applications. Although consolidation and centralization have reduced some costs and have produced some benefits centralized data and applications introduce additional challenges in providing access to data and applications. One such challenge involves a remote user trying to access a file over a wide area network WAN connection. For example a remote user at a branch office which typically has a network connection to the corporate data center that operates much slower than a LAN connection may try to open over the WAN a Microsoft Office document stored in at a corporate data center. The remote user s access over the network to the file may be delayed due to the latency reliability and bandwidth with the WAN. The delays may be larger for larger files. Furthermore as the distance between the remote user and the corporate data center grows the frequency and length of network delays in accessing files also may increase. Adding virtual private network security and other network layers on the WAN may further reduce bandwidth available to the remote users and increase delays in accessing the file. The lower speed and bandwidth of the remote office may cause unacceptable delays in accessing remote files. To avoid the delays in remote file access remote users may copy and use files locally defeating the purpose of centralized operations. Additionally WAN connections may be less reliable than LAN connections resulting in packet loss and network disconnection. WAN interruptions may occur during a file operation such as saving or opening a document further causing delays experienced by the remote user.

Therefore systems and methods are desired to improve access by remote users to centralized applications and data files including acceleration of the delivery of applications and data files to remote users.

The present invention relates to systems and methods to accelerate delivery of a computing environment of an application and data file to a remote user. The application and data file may be stored or provided via a server remote to the client. For example a user such as a remote employee may use at a branch office a computer that does not have the application and or data file available locally. The user may want to edit a corporate document with a word processing application not available on the remote client. The user can request a computing environment from the server that provides for execution of the desired application by the user via the remote client. For example the server may stream the application to the remote client. The remote client and server may communicate via an appliance that accelerates communications between the remote client and server. For example the appliance may accelerate the streaming of the application to the remote user. In some cases the application or remote user may also request a data file from the server and the appliance accelerates the delivery of the data file to the remote user. As such the present invention provides users at remote locations accelerated access via any network connected device to applications and data files located remotely to the user.

In one aspect the present invention is related to a method for accelerating delivery of a computing environment of an application and a data file to a user of a client at a remote location. The method includes receiving by the server a request from a remote client to execute an application. The remote client and server communicate via an appliance. The method also includes streaming by the server to the remote client an application for execution. The client transmits a request to the server for a data file useable by the application and the appliance accelerates transmission of the data file to the remote client.

In one embodiment of the present invention the method includes accelerating by the appliance streaming of the application to the remote client. In another embodiment the appliance accelerates the transmission of the data file or the streaming of the applications by performing one of the following acceleration techniques 1 compression 2 decompression 3 Transmission Control Protocol pooling 4 Transmission Control Protocol multiplexing 5 Transmission Control Protocol buffering and 6 caching. In another embodiment the method includes accelerating by an acceleration program on the remote client communications between the remote client and the server. In some embodiments of the method the appliance establishes a virtual private network connection or Secure Socket Layer SSL connection with the remote client. In other embodiments the method includes accelerating by the appliance a payload of a network packet communicated via a transport layer connection between the remote client and the server.

In one embodiment of the present invention the method includes transmitting by the appliance an acceleration program to the remote client upon a request from the remote client to establish a connection or a session with the server. In some embodiments the remote client automatically installs and executes an acceleration program upon receipt from the appliance. In other embodiments the method includes performing by an acceleration program on the remote client one of the following acceleration techniques 

1 compression 2 decompression 3 Transmission Control Protocol pooling 4 Transmission Control Protocol multiplexing 5 Transmission Control Protocol buffering and 6 caching. In some embodiments the remote client executes the acceleration program transparently to the application or the server.

In some embodiments of the present invention the method includes determining by the appliance the application is capable of being accelerated and transmitting in response to the determination an acceleration program to the remote client. In other embodiments the appliance caches the data file. In one embodiment the appliance intercepts the request for the data file and transmits to the remote client the cached data file in response to the request.

In another aspect the present invention is related to a system for accelerating delivery to a remote user a computing environment of an application and a data file to a client at a remote location. The system includes an appliance for accelerating communications between one or more remote clients and one or more servers. The system also includes a server receiving a request from a remote client to execute an application. The remote client and the server communicate via the appliance. The server streams to the remote client an application for execution. The client transmits a request to the server for a data file useable by the application and the appliance accelerates transmission of the data file to the remote client.

In some embodiments of the present invention the appliance accelerates streaming of the application to the remote client. In one embodiment the appliance accelerates the transmission of the data file or the streaming of the application by performing one of the following acceleration techniques 1 compression 2 decompression 3 Transmission Control Protocol pooling 4 Transmission Control Protocol multiplexing 5 Transmission Control Protocol buffering and 6 caching. In another embodiment the system includes an acceleration program on the remote client accelerating communications between the remote client and the server. In one embodiment the appliance establishes a virtual private network connection or Secure Socket Layer SSL connection with the remote client.

In some embodiments of the system of the present invention the appliance accelerates a payload of a network packet communicated via a transport layer connection between the remote client and the server. In one embodiment the appliance transmits an acceleration program to the remote client upon a request from the client to establish a connection or a session with the server. In other embodiments the remote client automatically installs and executes an acceleration program upon receipt from the appliance. The acceleration program on the remote client may perform one of the following acceleration techniques 1 compression 2 decompression 3 Transmission Control Protocol pooling 4 Transmission Control Protocol multiplexing 5 Transmission Control Protocol buffering and 6 caching. In one embodiment the remote client executes the acceleration program transparently to the application or the server.

In another embodiment of the system of the present invention the appliance determines the application is capable of being accelerated and transmits an acceleration program to the remote client in response to the determination. In one embodiment the appliance comprises a cache for caching the data file. In some embodiments the appliance intercepts the request for the data file and transmits to the remote client the cached data file in response to the request.

For purposes of reading the description of the various embodiments below the following descriptions of the sections of the specification and their respective contents may be helpful 

Prior to discussing the specifics of embodiments of the systems and methods it may be helpful to discuss the network and computing environments in which embodiments may be deployed. Referring now to a network environment is depicted. In brief overview the network environment comprises one or more clients also generally referred to as clients or local machines in communication with one or more servers also generally referred to as servers or remote machines via one or more networks . In some embodiments a client communicates with a server via an appliance .

Although shows a network and a network between the clients and the servers the clients and the servers may be on the same network . The networks and can be the same type of network or different types of networks. The network and or the network can be a local area network LAN such as a company Intranet a metropolitan area network MAN or a wide area network WAN such as the Internet or the World Wide Web. In one embodiment network may be a private network and network may be a public network. In some embodiments network may be a private network and network a public network. In another embodiment networks and may both be private networks. In some embodiments clients may be located at a branch office of a corporate enterprise communicating via a WAN connection over the network to the servers located at a corporate data center.

The network and or be any type and or form of network and may include any of the following a point to point network a broadcast network a wide area network a local area network a telecommunications network a data communication network a computer network an ATM Asynchronous Transfer Mode network a SONET Synchronous Optical Network network a SDH Synchronous Digital Hierarchy network a wireless network and a wireline network. The topology of the network and or may be a bus star or ring network topology. The network and or and network topology may be of any such network or network topology as known to those ordinarily skilled in the art capable of supporting the operations described herein.

As shown in the appliance also referred to herein as an interface unit is shown between the networks and . In some embodiments the appliance may be located on network . For example a branch office of a corporate enterprise may deploy an appliance at the branch office. In other embodiments the appliance may be located on network . For example an appliance may be located at a corporate data center. In yet another embodiment a plurality of appliances may be deployed on network . In some embodiments a plurality of appliances may be deployed on network . In one embodiment a first appliance communicates with a second appliance . In other embodiments the appliance could be a part of any client or server on the same or different network as the client . One or more appliances may be located at any point in the network or network communications path between a client and a server .

In one embodiment the system may include multiple logically grouped remote machines one or more of which is available to execute applications on behalf of a local machine . In these embodiments the logical group of remote machines may be referred to as a server farm or a farm In some of these embodiments the remote machines may be geographically dispersed. A farm may be administered as a single entity.

The remote machines within each farm can be heterogeneous. That is one or more of the remote machines can operate according to one type of operating system platform e.g. WINDOWS NT manufactured by Microsoft Corp. of Redmond Wash. while one or more of the other remote machines can operate on according to another type of operating system platform e.g. Unix or Linux . The remote machines comprising each farm do not need to be physically proximate to each other remote machine in its farm . Thus the group of remote machines logically grouped as a farm may be interconnected using a wide area network WAN connection or medium area network MAN connection. For example a farm may include remote machines physically located in different continents or different regions of a continent country state city campus or room. Data transmission speeds between remote machines in the farm can be increased if the remote machines are connected using a local area network LAN connection or some form of direct connection.

Remote machines may be referred to as servers file servers application servers or remote machines. In some embodiments remote machines may have the capacity to function as either application servers or as a master application server. In one embodiment a remote machine may include an Active Directory. The local machines may also be referred to as client nodes or endpoints. In some embodiments the local machines have the capacity to function as both client nodes seeking access to applications and as application servers providing access to hosted applications for other local machines .

In one embodiment the local machine communicates directly with one of the remote machines in a farm . In another embodiment the local machine executes a program neighborhood application to communicate with the remote machine in a farm . In still another embodiment the remote machine provides the functionality of a master node. In some embodiments the local machine communicates with the remote machine in the farm through a network . Over the network the local machine can for example request execution of various applications hosted by the remote machines and in the farm and receive output of the results of the application execution for display. The network may comprise synchronous or asynchronous connections and may be a LAN MAN Medium Area Network or a WAN. Additionally a network may comprise a wireless link such as an infrared channel or satellite band. In some embodiments only the master node provides the functionality required to identify and provide address information associated with a remote machine hosting a requested application.

In some embodiments a local machine communicates with a remote machine . In one of these embodiment the remote machine provides functionality of a web server. In another of these embodiments the remote machine receives requests from the local machine forwards the requests to a remote machine and responds to the request by the local machine with a response to the request from the remote machine . In still another of these embodiments the remote machine acquires an enumeration of applications available to the local machine and address information associated with a remote machine hosting an application identified by the enumeration of applications. In yet another of these embodiments the remote machine presents the response to the request to the local machine using a web interface. In one embodiment the local machine communicates directly with the remote machine to access the identified application. In another embodiment the local machine receives application output data from the remote machine the application output data generated by an execution of the identified application on the remote machine .

Referring now to a network environment for delivering and or operating a computing environment on a client is depicted. In brief overview a server includes an application delivery system for delivering a computing environment or an application and data file to one or more clients. The client may include a computing environment for executing an application that uses or processes a data file. The client in communication with the server via networks and appliance may request an application and data file from the server or appliance may forward a request from the client to the server . For example the client may not have locally the application and data file stored or accessible locally. In response to the request the server may deliver the application and data file to the client . For example in one embodiment the server may transmit the application as an application stream to operate in computing environment on client .

The central processing unit is any logic circuitry that responds to and processes instructions fetched from the main memory unit . In many embodiments the central processing unit is provided by a microprocessor unit such as those manufactured by Intel Corporation of Mountain View Calif. those manufactured by Motorola Corporation of Schaumburg Ill. the Crusoe and Efficeon lines of processors manufactured by Transmeta Corporation of Santa Clara Calif. the lines of processors manufactured by International Business Machines of White Plains N.Y. or the lines of processors manufactured by Advanced Micro Devices of Sunnyvale Calif.

Main memory unit may be one or more memory chips capable of storing data and allowing any storage location to be directly accessed by the microprocessor such as Static random access memory SRAM Burst SRAM or SynchBurst SRAM BSRAM Dynamic random access memory DRAM Fast Page Mode DRAM FPM DRAM Enhanced DRAM EDRAM Extended Data Output RAM EDO RAM Extended Data Output DRAM EDO DRAM Burst Extended Data Output DRAM BEDO DRAM Enhanced DRAM EDRAM synchronous DRAM SDRAM JEDEC SRAM PC100 SDRAM Double Data Rate SDRAM DDR SDRAM Enhanced SDRAM ESDRAM SyncLink DRAM SLDRAM Direct Rambus DRAM DRDRAM or Ferroelectric RAM FRAM . In the embodiment shown in the processor communicates with main memory via a system bus described in more detail below . depicts an embodiment of a computer system in which the processor communicates directly with main memory via a memory port. For example in the main memory may be DRDRAM.

In the embodiment shown in the processor communicates with various I O devices via a local system bus . Various busses may be used to connect the central processing unit to the I O devices including a VESA VL bus an ISA bus an EISA bus a MicroChannel Architecture MCA bus a PCI bus a PCI X bus a PCI Express bus or a NuBus. For embodiments in which the I O device is an video display the processor may use an Advanced Graphics Port AGP to communicate with the display. depicts an embodiment of a computer system in which the main processor communicates directly with I O device via HyperTransport Rapid I O or Infiniband. also depicts an embodiment in which local busses and direct communication are mixed the processor communicates with I O device using a local interconnect bus while communicating with I O device directly.

A wide variety of I O devices may be present in the computer system . Input devices include keyboards mice trackpads trackballs microphones and drawing tablets. Output devices include video displays speakers inkjet printers laser printers and dye sublimation printers. An I O device may also provide mass storage for the computer system such as a hard disk drive a floppy disk drive for receiving floppy disks such as 3.5 inch 5.25 inch disks or ZIP disks a CD ROM drive a CD R RW drive a DVD ROM drive tape drives of various formats and USB storage devices such as the USB Flash Drive line of devices manufactured by Twintech Industry Inc. of Los Alamitos Calif.

In further embodiments an I O device may be a bridge between the system bus and an external communication bus such as a USB bus an Apple Desktop Bus an RS 132 serial connection a SCSI bus a FireWire bus a FireWire 800 bus an Ethernet bus an AppleTalk bus a Gigabit Ethernet bus an Asynchronous Transfer Mode bus a HIPPI bus a Super HIPPI bus a SerialPlus bus a SCI LAMP bus a FibreChannel bus or a Serial Attached small computer system interface bus.

General purpose computers of the sort depicted in and typically operate under the control of operating systems which control scheduling of tasks and access to system resources. Typical operating systems include MICROSOFT WINDOWS manufactured by Microsoft Corp. of Redmond Wash. MacOS manufactured by Apple Computer of Cupertino Calif. OS 2 manufactured by International Business Machines of Armonk N.Y. and Linux a freely available operating system distributed by Caldera Corp. of Salt Lake City Utah among others.

For embodiments in which a client machine or a server comprise a mobile device the device may be a JAVA enabled cellular telephone such as the i55sr i58sr i85s or the i88s all of which are manufactured by Motorola Corp. of Schaumburg Ill. the 6035 or the 7135 manufactured by Kyocera of Kyoto Japan or the i300 or i330 manufactured by Samsung Electronics Co. Ltd. of Seoul Korea. In other embodiments comprising mobile devices a mobile device may be a personal digital assistant PDA operating under control of the PalmOS operating system such as the Tungsten W the VII the VIIx the i705 all of which are manufactured by palmOne Inc. of Milpitas Calif. In further embodiments the client may be a personal digital assistant PDA operating under control of the PocketPC operating system such as the iPAQ 4155 iPAQ 5555 iPAQ 1945 iPAQ 2215 and iPAQ 4255 all of which manufactured by Hewlett Packard Corporation of Palo Alto Calif. the ViewSonic V36 manufactured by ViewSonic of Walnut Calif. or the Toshiba PocketPC e405 manufactured by Toshiba America Inc. of New York N.Y. In still other embodiments the mobile device is a combination PDA telephone device such as the Treo 180 Treo 270 Treo 600 Treo 650 or the Treo 700w all of which are manufactured by palmOne Inc. of Milpitas Calif. In still further embodiments the mobile device is a cellular telephone that operates under control of the PocketPC operating system such as the MPx200 manufactured by Motorola Corp. A typical mobile device may comprise many of the elements described above in including the processor and the main memory .

An embodiment is directed towards systems and methods for delivering a computing environment to a remote user at a client located at a remote location from the server . While the methods and systems in this section generally speak of servers the methods and systems below may utilize either servers network appliances or any combination thereof.

Referring now to one embodiment of a system in which remote machines comprise a farm as depicted in is shown. Each remote machine includes a network side interface and a farm side interface . The network side interface of the remote machine may be in communication with one or more local machines or a network . The network can be a WAN LAN or international network such as the Internet or the World Wide Web. Local machines may establish connections with the remote machines using the network .

The farm side interfaces of the remote machines are interconnected with each over communication links so that the remote machines may communicate with one another. On each remote machine the farm side interface communicates with the network side interface . The farm side interfaces also communicate designated by arrows with a persistent store and in some embodiments with a dynamic store . The combination of remote machines the persistent store and the dynamic store when provided are collectively referred to as a farm . In some embodiments a remote machine communicates with the persistent store and other remote machines communicate with the remote machine to access information stored in the persistent store.

Persistent store may be physically implemented on a disk disk farm a redundant array of independent disks RAID writeable compact disc or any other device that allows data to be read and written and that maintains written data if power is removed from the storage device. A single physical device may provide storage for a plurality of persistent stores i.e. a single physical device may be used to provide the persistent store for more than one farm . The persistent store maintains static data associated with each remote machine in farm and global data used by all remote machines within the farm . In one embodiment the persistent store may maintain the remote machine data in a Lightweight Directory Access Protocol LDAP data model. In other embodiments the persistent store stores remote machine data in an ODBC compliant database. For the purposes of this description the term static data refers to data that do not change frequently i.e. data that change only on an hourly daily or weekly basis or data that never change. Each remote machine uses a persistent storage subsystem to read data from and write data to the persistent store .

The data stored by the persistent store may be replicated for reliability purposes physically or logically. For example physical redundancy may be provided using a set of redundant mirrored disks each providing a copy of the data. In other embodiments the database itself may be replicated using standard database techniques to provide multiple copies of the database. In further embodiments both physical and logical replication may be used concurrently.

The dynamic store i.e. the collection of all record tables can be embodied in various ways. In one embodiment the dynamic store is centralized that is all runtime data are stored in the memory of one remote machine in the farm . That remote machine operates as a master network node with which all other remote machines in the farm communicate when seeking access to that runtime data. In another embodiment each remote machine in the farm keeps a full copy of the dynamic store . Here each remote machine communicates with every other remote machine to keep its copy of the dynamic store up to date.

In another embodiment each remote machine maintains its own runtime data and communicates with every other remote machine when seeking to obtain runtime data from them. Thus for example a remote machine attempting to find an application program requested by the local machine may communicate directly with every other remote machine in the farm to find one or more remote machines hosting the requested application.

For farms having a large number of remote machines the network traffic produced by these embodiments can become heavy. One embodiment alleviates heavy network traffic by designating a subset of the remote machines in a farm typically two or more as collector points. Generally a collector point is a remote machine that collects run time data. Each collector point stores runtime data collected from certain other remote machines in the farm . Each remote machine in the farm is capable of operating as and consequently is capable of being designated as a collector point. In one embodiment each collector point stores a copy of the entire dynamic store . In another embodiment each collector point stores a portion of the dynamic store i.e. it maintains runtime data of a particular data type. The type of data stored by a remote machine may be predetermined according to one or more criteria. For example remote machines may store different types of data based on their boot order. Alternatively the type of data stored by a remote machine may be configured by an administrator using administration tool . In these embodiments the dynamic store is distributed among two or more remote machines in the farm .

In another embodiment an appliance may alleviate heavy network traffic by accelerating data passed between the remote machines the dynamic store and the persistent store . Such acceleration may be provided by any of the techniques discussed herein further in Section C. For example the appliance may be used to alleviate heavy network traffic.

Remote machines not designated as collector points know the remote machines in a farm that are designated as collector points. A remote machine not designated as a collector point may communicate with a particular collector point when delivering and requesting runtime data. Consequently collector points lighten network traffic because each remote machine in the farm communicates with a single collector point remote machine rather than with every other remote machine when seeking to access the runtime data.

Each remote machine can operate as a collector point for more than one type of data. For example remote machine can operate as a collector point for licensing information and for loading information. In these embodiments each collector point may amass a different type of run time data. For example to illustrate this case the remote machine can collect licensing information while the remote machine collects loading information.

In some embodiments each collector point stores data that is shared between all remote machines in a farm . In these embodiments each collector point of a particular type of data exchanges the data collected by that collector point with every other collector point for that type of data in the farm . Thus upon completion of the exchange of such data each collector point and possesses the same data. Also in these embodiments each collector point and also keeps every other collector point abreast of any updates to the runtime data.

Browsing enables a local machine to view farms remote machines and applications in the farms and to access available information such as sessions throughout the farm . Each remote machine includes an ICA browsing subsystem to provide the local machine with browsing capability. After the local machine establishes a connection with the ICA browser subsystem of any of the remote machines that browser subsystem supports a variety of local machine requests. Such local machine requests include 1 enumerating names of remote machines in the farm 2 enumerating names of applications published in the farm 3 resolving a remote machine name and or application name to a remote machine address that is useful the local machine . The ICA browser subsystem also supports requests made by local machines running a program neighborhood application that provides the local machine upon request with a view of those applications within the farm for which the user is authorized. The ICA browser subsystem forwards all of the above mentioned local machine requests to the appropriate subsystem in the remote machine .

In one embodiment each remote machine in the farm that has a program neighborhood subsystem can provide the user of a local machine with a view of applications within the farm . The program neighborhood subsystem may limit the view to those applications for which the user of the local machine has authorization to access. Typically this program neighborhood service presents the applications to the user as a list or a group of icons.

The functionality provided by the program neighborhood subsystem is available to two types of local machines 1 program neighborhood enabled local machines that can access the functionality directly from a local machine desktop and 2 non program neighborhood enabled local machines e.g. legacy local machines that can access the functionality by running a program neighborhood enabled desktop on the remote machine.

Communication between a program neighborhood enabled local machine and the program neighborhood subsystem may occur over a dedicated virtual channel that is established on top of an ICA virtual channel. In other embodiments the communication occurs using an XML service. In one of these embodiments the program neighborhood enabled local machine communicates with an XML subsystem such as the XML service described in connection with below providing program neighborhood functionality on a remote machine .

In one embodiment the program neighborhood enabled local machine does not have a connection with the remote machine with a program neighborhood subsystem . For this embodiment the local machine sends a request to the ICA browser subsystem to establish an ICA connection to the remote machine in order to identify applications available to the local machine . The local machine then runs a client side dialog that acquires the credentials of a user. The credentials are received by the ICA browser subsystem and sent to the program neighborhood subsystem . In one embodiment the program neighborhood subsystem sends the credentials to a user management subsystem for authentication. The user management subsystem may return a set of distinguished names representing the list of accounts to which the user belongs. Upon authentication the program neighborhood subsystem establishes the program neighborhood virtual channel. This channel remains open until the application filtering is complete. In some embodiments an acceleration program as described in section C may also be transmitted to the local machine in response to a local machine request.

The program neighborhood subsystem then requests the program neighborhood information from the common application subsystem associated with those accounts. The common application subsystem obtains the program neighborhood information from the persistent store . On receiving the program neighborhood information the program neighborhood subsystem formats and returns the program neighborhood information to the local machine over the program neighborhood virtual channel. Then the partial ICA connection is closed.

For another example in which the program neighborhood enabled local machine establishes a partial ICA connection with a remote machine consider the user of the local machine who selects a farm . The selection of the farm sends a request from the local machine to the ICA browser subsystem to establish an ICA connection with one of the remote machines in the selected farm . The ICA browser subsystem sends the request to the program neighborhood subsystem which selects a remote machine in the farm . Address information associated with the remote machine is identified and returned to the local machine by way of the ICA browser subsystem . The local machine can then subsequently connect to the remote machine corresponding to the received address information.

In another embodiment the program neighborhood enabled local machine an ICA connection upon which the program neighborhood virtual channel is established and remains open for as long as the ICA connection persists. Over this program neighborhood virtual channel the program neighborhood subsystem pushes program neighborhood information updates to the local machine . This pushing of updates to a local machine may be accelerated according to any of the accelerating techniques discussed herein. To obtain updates the program neighborhood subsystem subscribes to events from the common application subsystem to allow the program neighborhood subsystem to detect changes to published applications.

Referring to a block diagram depicts another embodiment of a system architecture for providing a plurality of application programs available to the local machine via publishing of GUIs in a web service directory. The system includes the local machine and a plurality of remote machines . One remote machine functions as a content server. A remote machine provides web server functionality. A remote machine provides functionality for providing access to application files and acts as an application server or a file server. The local machine can download content from the content server the web server and the application server over the network . In one embodiment the local machine can download content e.g. an application from the application server over the client application server communication channel .

In one embodiment the web browser on the local machine uses Secure Socket Layer SSL support for communications to the content server and or the web server . SSL is a secure protocol developed by Netscape Communication Corporation of Mountain View Calif. and is now a standard promulgated by the Internet Engineering Task Force IETF . The web browser can alternatively connect to the content server and or the web server using other security protocols such as but not limited to Secure Hypertext Transfer Protocol SHTTP developed by Terisa Systems of Los Altos Calif. HTTP over SSL HTTPS Private Communication Technology PCT developed by Microsoft Corporation of Redmond Wash. and the Transport Level Security TLS standard promulgated by the IETF. In other embodiments the web browser communicates with the servers using a communications protocol without encryption such as the HyperText Transfer Protocol HTTP .

Additionally the local machine includes an application client for establishing and exchanging communications with the application server over the client application server communication channel . In one embodiment the application client is a GUI application. In some embodiments the application client is an Independent Computing Architecture ICA client developed by Citrix Systems Inc. of Fort Lauderdale Fla. and is also referred to below as ICA client . Other embodiments of the application client include a Remote Display Protocol RDP client developed by Microsoft Corporation of Redmond Wash. an X Windows client a client side player interpreter or simulator capable of executing multimedia applications email Java or .NET code. Moreover in one embodiment the output of an application executing on the application server can be displayed at the local machine via the ICA client . In some embodiments the application client is an application client such as the application streaming client described in greater detail in connection with . In some embodiments the application client comprises an acceleration program in accordance with any of the embodiments described herein for accelerating communications between client and server .

The local machine searches the web service directory for a web service. In one embodiment the search is a manual search. Alternatively the search is an automatic search. The web service directory may also provide a service based view such as white and yellow pages to search for web services in the web service directory. In another embodiment the web service directory supports a hierarchical browsing based on a structured service name and service kind for GUI applications. In one embodiment the web service directory executes on a remote machine independent of the content server such as a directory server. In other embodiments the web service directory executes on multiple servers.

In some embodiments the content server enables the local machine to select web services based on additional analysis or information by providing this information or analysis in the web service directory . Examples of service information that the web service directory can list includes but is not limited to the name of the business offering the service the service type a textual description of the service one or more service access points SAPs the network type the path to use e.g. TCP or HTTPS and quality of service QoS information. Moreover service information can be client device type or user e.g. role specific. Thus service selection can be based on one or more of the above attributes.

In one embodiment the service type denotes a programming interface that the local machine must use to access the web service. For instance the service type can state that the service is encoded by an interface description language such as Web Services Description Language WSDL .

The service access point or SAP is a unique address for an application. The SAPs enable the computer system to support multiple applications at the local machine and each remote machine . For example the application server may support an electronic mail i.e. e mail application a file transfer application and or a GUI application. In one embodiment these applications would each have a SAP that is unique within the application server . In one embodiment the SAP is a web or Internet address e.g. Domain Name System DNS name IP port or Uniform Resource Locator URL . Thus in one embodiment the SAP identifies the address of the web server as part of the address for an application stored on the web server . In some embodiments the SAP identifies the address of a publishing server plug in as part of the address for an application stored on the web server as described below. In one embodiment the SAP is an accessPoint from the UDDI registry.

To prepare an item for publishing in the web service directory the content server includes a web publishing tool . In one embodiment the web publishing tool is a software module. Alternatively the web publishing tool is another server that may be externally located from or internally located in the content server .

In one embodiment the web server delivers web pages to the local machine . The web server can be any remote machine capable of providing web pages to the local machine . In another embodiment the web server is an Enterprise Information Portal e.g. corporate Intranet or secured business to business extranet . Enterprise portals are company web sites that aggregate personalize and serve applications data and content to users while offering management tools for organizing and using information more efficiently. In some companies portals have replaced traditional desktop software with browser based access to a virtual workplace. In some embodiments an appliance accelerates delivery of the provision of web pages is accelerated using any of the acceleration techniques discussed herein. In other embodiments an acceleration program accelerates delivery of the web pages.

The web server also includes a publishing server plug in to enable the publishing of graphical user interface GUI applications. More specifically the publishing server plug in translates a new web service entry URL into a GUI application service so that the GUI can be accessed via the web service directory . In one embodiment the publishing server plug in is a Common Gateway Interface CGI script which is a program designed to accept and return data that conforms to the CGI specification. The program can be written in any programming language such as C Perl Java or Visual Basic. In another embodiment the publishing server plug in is a Java Server Page JSP . Using the publishing server plug in to facilitate the publishing of remote GUI applications the local machine can thereby access the web service not through a programming interface or a web page but through a full GUI interface such as with Citrix s ICA or Microsoft s RDP. In some embodiments an appliance or acceleration program accelerates the delivery of said GUI to the client is accelerated using any of the acceleration techniques discussed herein in Section C.

The application server hosts one or more applications that are available for the local machine . Examples of such applications include word processing programs such as MICROSOFT WORD and spreadsheet programs such as MICROSOFT EXCEL both manufactured by Microsoft Corporation of Redmond Wash. financial reporting programs customer registration programs programs providing technical support information customer database applications or application set managers.

In one embodiment the web publishing tool stores information about an application that the web publishing tool is publishing in the web service directory in a persistent mass storage . In one embodiment the information is a URL for the dynamic publishing server plug in . The persistent mass storage may be a magnetic disk or magneto optical drive. In one embodiment the persistent mass storage is a database server which stores data related to the published application in one or more local service databases. The persistent mass storage may be a component internally located in or externally located from any or all of the remote machines .

In other embodiments the content server or the web server communicate with a remote machine in the farm to retrieve the list of applications. In one of these embodiments the content server or the web server communicate with the farm instead of with the persistent mass storage .

Referring now to a flow diagram depicts one embodiment of the steps taken to select a method of execution of an application program. In brief overview credentials associated with the local machine or with a user of the local machine are received with a request for an enumeration of applications available for execution by the local machine step . An enumeration of a plurality of application programs available to the local machine is provided responsive to the received credentials step . A request is received to execute an enumerated application step . One of a predetermined number of methods for executing the enumerated application is selected responsive to a policy the predetermined number of methods including a method for application streaming of the enumerated application step .

Credentials associated with the local machine or with a user of the local machine are received with a request for an enumeration of applications available for execution by the local machine step . In one embodiment the remote machine receives a request for enumeration of available applications from the local machine with the credentials. In another embodiment an XML service on the remote machine receives the request and the credentials and transmits the request and credentials to a management service on the remote machine .

In some embodiments a remote machine functioning as a web server receives communications from the local machine and forwards the communications to a remote machine . In one of these embodiments the web server forwards the communications to an XML service on the remote machine . In another of these embodiments the web server resides on the local machine. In other embodiments where communications from the local machine are routed to a remote machine by the web server the remote machine may be selected responsive to an Internet Protocol IP address of the local machine .

In some embodiments a local machine requests access to an application residing on a remote machine . In one of these embodiments the local machine requests execution by the remote machine of the application residing on the remote machine . In another of these embodiments the local machine requests retrieval of a plurality of application files that comprise the application.

In some embodiments the user provides credentials to the remote machine via a graphical user interface presented to the local machine by the remote machine . In other embodiments a remote machine having the functionality of a web server provides the graphical user interface to the local machine . In still other embodiments a collection agent transmitted to the local machine by the remote machine gathers the credentials from the local machine . In one embodiment a credential refers to a username and password. In another embodiment a credential is not limited to a username and password but includes without limitation a machine ID of the local machine operating system type existence of a patch to an operating system MAC addresses of installed network cards a digital watermark on the client device membership in an Active Directory existence of a virus scanner existence of a personal firewall an HTTP header browser type device type network connection information such as internet protocol address or range of addresses machine ID of the remote machine date or time of access request including adjustments for varying time zones and authorization credentials.

In some embodiments a credential associated with a local machine is associated with a user of the local machine. In one of these embodiments the credential is information possessed by the user. In another of these embodiments the credential is user authentication information. In other embodiments a credential associated with a local machine is associated with a network. In one of these embodiments the credential is information associated with a network to which the local machine may connect. In another of these embodiments the credential is information associated with a network collecting information about the local machine. In still other embodiments a credential associated with a local machine is a characteristic of the local machine.

An enumeration of a plurality of application programs available to the local machine is provided responsive to the received credentials step . In one embodiment a user of a local machine may learn of the availability of application programs hosted by the remote machines in the network without knowing where to find such applications and without technical information necessary to link to such applications. These available application programs comprise the program neighborhood of the user. A system for determining a program neighborhood for a local machine includes an application program hereafter referred to as the Program Neighborhood application memory for storing components of the application program and a processor for executing the application program. The Program Neighborhood PN application can be installed in memory of the local machine and or on a remote machine as described below.

A remote machine operating according to the Program Neighborhood application collects application related information from each of the remote machines in a farm . The application related information for each hosted application can be a variety of information including for example an address of the remote machine hosting that application the application name the users or groups of users who are authorized to use that application and the minimum capabilities required of the local machine before establishing a connection to run the application. For example the application may stream video data and therefore a required minimum capability may be that the local machine supports video data. Other examples are requirements that the local machine support audio data or have the capacity to process encrypted data. The application related information can be stored in a database.

When a local machine connects to the network the user of the local machine provides user credentials. User credentials may include the username of a user of the local machine the password of the user and the domain name for which the user is authorized. Alternatively the user credentials may be obtained from smart cards time based tokens social security numbers user passwords personal identification PIN numbers digital certificates based on symmetric key or elliptic curve cryptography biometric characteristics of the user or any other means by which the identification of the user of the local machine can be obtained and submitted for authentication. The remote machine responding to the local machine can authenticate the user based on the user credentials. The user credentials can be stored wherever the Program Neighborhood application is executing. For embodiments in which the local machine executes the Program Neighborhood application the user credentials may be stored at the local machine . For embodiments in which a remote machine executes the Program Neighborhood the user credentials can be stored at that remote machine .

From the user credentials and the application related information the remote machine can also determine which application programs hosted by remote machines are available for use by the user of the local machine . The remote machine transmits information representing the available application programs to the local machine . This process eliminates the need for a user of the local machine to establish application connections. Additionally an administrator of the remote machine may control access to applications among multiple users of a local machine .

In some embodiments the user authentication performed by the remote machine may suffice to authorize the use of each hosted application program presented to the local machine although such applications may reside at another remote machine . Accordingly when the local machine launches i.e. initiates execution of one of the hosted applications additional input of user credentials by the local machine may be unnecessary to authenticate use of that application. Thus a single entry of the user credentials may serve to determine the available applications and to authorize the launching of such applications without an additional manual log on authentication process by the user.

Either a local machine or remote machine can launch the Program Neighborhood application. The results are displayed on the display screen of the local machine . In a graphical windows based implementation the results can be displayed in a Program Neighborhood graphical window and each authorized application program can be represented by a graphical icon in that window.

In one embodiment the Program Neighborhood application filters out application programs that the local machine is unauthorized to execute and displays only authorized i.e. available programs. In other embodiments the Program Neighborhood application can display authorized and unauthorized applications. When unauthorized applications are not filtered from the display a notice can be provided indicating that such applications are unavailable. Alternatively the Program Neighborhood application can report all applications hosted by the remote machines to the user of a local machine without identifying which applications the local machine is authorized or unauthorized to execute. Authorization can be subsequently determined when the local machine attempts to run one of those applications.

The local machine may request application enumeration from a remote machine . Application enumeration enables a user of the local machine to view the names of every published application. In one embodiment the user of the local machine can view the application names regardless of whether the user has authorization to execute the application. In another embodiment the user views only those application names that the user is authorized to execute.

Requests for application enumeration pass to the ICA browser subsystem to the program neighborhood subsystem or to a common application subsystem depending upon the particular process being run by the local machine . For example when the local machine is running program neighborhood application the requests for application enumeration are sent to the program neighborhood subsystem on a remote machine . When the local machine submits the enumeration request through a web page the requests pass to the common access point subsystem . For these embodiments the common application subsystem serves as an initial access point for the program neighborhood subsystem ICA browser subsystem and common application subsystems when the local machine wants to enumerate applications. In some embodiments when the local machine submits the enumeration request through a web page an intermediate remote machine hosting a web server receives the request and forwards the request to a remote machine .

Upon receiving the enumeration requests a common application subsystem queries the persistent store for a list of all applications. For requests received from the program neighborhood subsystem and common access point subsystems this list of applications is filtered according to the credentials of the user of the local machine i.e. the user views only those applications for which the user is authorized .

The local machine can also request remote machine enumeration. Remote machine enumeration enables a user of the local machine to view a list of remote machines in the farm . In one embodiment the list of remote machines can be filtered according to the type of remote machine as determined by the specialized remote machine subsystem on that remote machine.

Requests for remote machine enumeration pass to the ICA browser subsystem or to the common access point subsystem depending upon the particular process being run by the local machine . For example when the local machine submits the remote machine enumeration request through a web page the requests pass to the common access point subsystem . For these embodiments the common remote machine subsystem serves as an initial access point for the ICA browser subsystem and common access point subsystems. Upon receiving the remote machine enumeration requests the common remote machine subsystem queries the persistent store for a list of all remote machines. Optionally the list of remote machines is filtered according to the remote machine type.

The local machine via the web browser transmits a request to access a Uniform Resource Locator URL address corresponding to an HTML page residing on remote machine . In some embodiments the first HTML page returned to the local machine by the remote machine is an authentication page that seeks to identify the local machine .

Still referring to once the local machine is authenticated by the remote machine the remote machine prepares and transmits to the local machine an HTML page that includes a Program Neighborhood window in which appears graphical icons representing application programs to which the local machine has access. A user of local machine invokes execution of an application represented by icon by clicking that icon .

In some embodiments the remote machine executes the Program Neighborhood application on behalf of a user of the local machine . In one of these embodiments the remote machine is an intermediate remote machine residing between the local machine and a remote machine .

Referring to a flow diagram depicts one embodiment of the steps taken to provide a plurality of application programs available to the local machine via publishing of GUIs in a web service directory. The web publishing tool receives a web service description and access information for an application e.g. GUI application for publishing step . In one embodiment the web service description includes the service information described above e.g. the name of the business offering the web service the service type a textual description of the service and a SAP . The access information may include for example a published application name a Transmission Control Protocol TCP browsing server farm address and a MetaFrame server IP address. In some embodiments the access information specifies the address to use and a ticket to use to traverse network or security gateways or bridge devices.

The web publishing tool then constructs a service publishing request to request the publication of the web service i.e. GUI application step . In one embodiment the service publishing request includes a SAP. In some embodiments the SAP is a URL including the web address of the web server and the publishing server plug in . Further the web address can be a Uniform Resource Identifier URI which is the generic term for the types of names and addresses that refer to objects on the web. A URL is one kind of URI. An example of the URI is the name of the web server e.g. web server and the CGI script name e.g. dynamic component for the publishing server plug in .

The web publishing tool stores a SAP entry associated with the SAP in the persistent mass storage step . In some embodiments the web publishing tool also associates published application information e.g. ICA published app info with the GUI application. In further embodiments the web publishing tool also includes a key in the service publishing request to identify the SAP entry that the content server stores in the persistent mass storage . For instance the key can have the value of 123456677. An example of a SAP identifying the web server the CGI script name of the publishing server plug in and the key described above is http web server dynamic component app 123456677. 

An example of the SAP entry associated with the SAP described above is key 123456677 value ICA published app info. The key can be any length e.g. 56 bit key 128 bit key . In one embodiment the key is a cryptographic random number. The key may also provides an access right to the key holder. Although illustrated with a key any means can be used to provide a form of security to the SAP entry stored in the persistent mass storage .

The web publishing tool provides the service publishing request to the content server for publishing in the web service directory step . Moreover in one embodiment the content server transmits the key of the SAP to the local machine requesting the particular web service for subsequent use in locating the SAP entry. In one embodiment the publishing of the service publishing request enables users of the local machine to access the service. In one embodiment GUI applications are published on the web service directory using NFUSE developed by Citrix Systems Inc. of Fort Lauderdale Fla. In some embodiments a publisher of a GUI application customizes the publication of the GUI application on the web service directory using Application Launching And Embedding ALE also developed by Citrix Systems Inc. ALE enables the launching of a GUI application from or the embedding of the application into an HTML page.

The local machine then queries a service name from the web service directory step . The content server receives the query from the local machine step and finds the requested service name in the web service directory . In another embodiment the user of the local machine navigates the web service directory until locating a particular service name that the user of the local machine was attempting to find. Although illustrated with the local machine any web service directory client e.g. UDDI client or LDAP browser can query or navigate the web service directory to discover published web services.

Upon location of the SAP associated with the received query the content server transmits the SAP to the local machine step . The local machine receives the SAP step and determines the address of the publishing server plug in from the SAP. The local machine subsequently transmits a request for the GUI application to the web server step . In some embodiments the request from the local machine is an HTTP request transmitted from the web browser to the web server . In other embodiments an application e.g. general directory browser or HTML UI executing on the local machine receives the SAP from the content server and provides the SAP as an argument to the web browser . The web browser may then automatically transmit an HTTP request for the GUI application to the web server . Following along the lines of the previous examples a particular example of the application request to the web server is http web server dynamic component app 123456677 .

The web server and more particularly the publishing server plug in receives the application request associated the SAP step and determines the SAP entry associated with the request step . In one embodiment the publishing server plug in receives the request from the local machine and retrieves the published application information associated with the request that had been stored as part of the SAP entry in the persistent mass storage . In some embodiments the publishing server plug in uses the SAP or part of the SAP that the local machine received from the content server as the key to access the proper service entry e.g. the published application information stored in the persistent mass storage .

The publishing server plug in then constructs a file or document having the published application information e.g. HTTP address of the application server step and transmits this document to the local machine step . The publishing server plug in constructs the file so that the file has a format compatible with the application client . In one embodiment the document is a Multipurpose Internet Mail Extensions MIME or a secure MIME S MIME document. In another embodiment the document is an HTML document containing an ICA web client embedded object HTML tag. In still another embodiment the document is an HTML document containing an application streaming client embedded object HTML tag.

The web browser subsequently receives the document and attempts to open the document. In one embodiment if the application client is not installed on the local machine the local machine communicates with the application server to download and install the application client . Upon installation of the application client or alternatively if the application client has already been installed on the local machine the local machine launches the application client to view the document received from the web server step .

Once the application client is installed and executing on the local machine the application server then executes the application and displays the application on the application client step . In an alternative embodiment the application server transmits a plurality of application files comprising the application to the application client for execution on the local machine as described in further detail below in connection with . In another embodiment the local machine views the document even before launching the application client and uses the information in the document to obtain the GUI application from the application server . In this embodiment the display of the GUI application includes the installation and execution of the application client . Moreover the viewing of the document may be transparent to the user of the local machine . For example the local machine may receive the document from the web server and interpret the document before automatically requesting the GUI application from the application server .

Thus the application client provides service based access to published applications desktops desktop documents and any other application that is supported by the application client . Examples of applications that the application client can provide access to include but are not limited to the WINDOWS desktops WINDOWS documents such as MICROSOFT EXCEL WORD and POWERPOINT all of which were developed by Microsoft Corporation of Redmond Wash. Unix desktops such as SUN SOLARIS developed by Sun Microsystems of Palo Alto Calif. and GNU Linux distributed by Red Hat Inc. of Durham N.C. among others.

In some embodiments an enumeration of a plurality of application programs available to the local machine is provided step responsive to a determination by a policy engine regarding whether and how a local machine may access an application. The policy engine may collect information about the local machine prior to making the determination. Referring now to one embodiment of a computer network is depicted which includes a local machine a collection agent a policy engine a policy database a farm and an application server . In one embodiment the policy engine is a remote machine . In another embodiment the application server is a remote machine . Although only one local machine collection agent policy engine farm and application server are depicted in the embodiment shown in it should be understood that the system may provide multiple ones of any or each of those components.

In brief overview when the local machine transmits a request to the policy engine for access to an application the collection agent communicates with local machine retrieving information about the local machine and transmits the local machine information to the policy engine . The policy engine makes an access control decision by applying a policy from the policy database to the received information .

In more detail the local machine transmits a request for a resource to the policy engine . In one embodiment the policy engine resides on an application server . In another embodiment the policy engine is a remote machine . In still another embodiment an application server receives the request from the local machine and transmits the request to the policy engine . In yet another embodiment the local machine transmits a request for a resource to a remote machine which transmits the request to the policy engine .

Upon receiving the request the policy engine initiates information gathering by the collection agent . The collection agent gathers information regarding the local machine and transmits the information to the policy engine .

In some embodiments the collection agent gathers and transmits the information over a network connection. In some embodiments the collection agent comprises bytecode such as an application written in the bytecode programming language JAVA. In some embodiments the collection agent comprises at least one script. In those embodiments the collection agent gathers information by running at least one script on the local machine . In some embodiments the collection agent comprises an Active X control on the local machine . An Active X control is a specialized Component Object Model COM object that implements a set of interfaces that enable it to look and act like a control.

In one embodiment the policy engine transmits the collection agent to the local machine . In another embodiment an appliance may store or cache the collection agent. The appliance may then transmit the collection agent to a local machine . In other embodiments an appliance may intercept the transmission of a collection agent . In still another embodiment an appliance may accelerate the delivery of a collection agent. In one embodiment the policy engine requires a second execution of the collection agent after the collection agent has transmitted information to the policy engine . In this embodiment the policy engine may have insufficient information to determine whether the local machine satisfies a particular condition. In other embodiments the policy engine requires a plurality of executions of the collection agent in response to received information .

In some embodiments the policy engine transmits instructions to the collection agent determining the type of information the collection agent gathers. In those embodiments a system administrator may configure the instructions transmitted to the collection agent from the policy engine . This provides greater control over the type of information collected. This also expands the types of access control decisions that the policy engine can make due to the greater control over the type of information collected. The collection agent gathers information including without limitation machine ID of the local machine operating system type existence of a patch to an operating system MAC addresses of installed network cards a digital watermark on the client device membership in an Active Directory existence of a virus scanner existence of a personal firewall an HTTP header browser type device type network connection information such as internet protocol address or range of addresses machine ID of the remote machine date or time of access request including adjustments for varying time zones and authorization credentials. In some embodiments a collection agent gathers information to determine whether an application can be accelerated on the client using an acceleration program .

In some embodiments the device type is a personal digital assistant. In other embodiments the device type is a cellular telephone. In other embodiments the device type is a laptop computer. In other embodiments the device type is a desktop computer. In other embodiments the device type is an Internet kiosk.

In some embodiments the digital watermark includes data embedding. In some embodiments the watermark comprises a pattern of data inserted into a file to provide source information about the file. In other embodiments the watermark comprises data hashing files to provide tamper detection. In other embodiments the watermark provides copyright information about the file.

In some embodiments the network connection information pertains to bandwidth capabilities. In other embodiments the network connection information pertains to Internet Protocol address. In still other embodiments the network connection information consists of an Internet Protocol address. In one embodiment the network connection information comprises a network zone identifying the logon agent to which the local machine provided authentication credentials.

In some embodiments the authorization credentials include a number of types of authentication information including without limitation user names client names client addresses passwords PINs voice samples one time passcodes biometric data digital certificates tickets etc. and combinations thereof. After receiving the gathered information the policy engine makes an access control decision based on the received information .

Referring now to a block diagram depicts one embodiment of a policy engine including a first component comprising a condition database and a logon agent and including a second component comprising a policy database . The first component applies a condition from the condition database to information received about local machine and determines whether the received information satisfies the condition.

In some embodiments a condition may require that the local machine execute a particular operating system to satisfy the condition. In some embodiments a condition may require that the local machine execute a particular operating system patch to satisfy the condition. In still other embodiments a condition may require that the local machine provide a MAC address for each installed network card to satisfy the condition. In some embodiments a condition may require that the local machine indicate membership in a particular Active Directory to satisfy the condition. In another embodiment a condition may require that the local machine execute a virus scanner to satisfy the condition. In other embodiments a condition may require that the local machine execute a personal firewall to satisfy the condition. In some embodiments a condition may require that the local machine comprise a particular device type to satisfy the condition. In other embodiments a condition may require that the local machine establish a particular type of network connection to satisfy the condition.

If the received information satisfies a condition the first component stores an identifier for that condition in a data set . In one embodiment the received information satisfies a condition if the information makes the condition true. For example a condition may require that a particular operating system be installed. If the local machine has that operating system the condition is true and satisfied. In another embodiment the received information satisfies a condition if the information makes the condition false. For example a condition may address whether spyware exists on the local machine . If the local machine does not contain spyware the condition is false and satisfied.

In some embodiments the logon agent resides outside of the policy engine . In other embodiments the logon agent resides on the policy engine . In one embodiment the first component includes a logon agent which initiates the information gathering about local machine . In some embodiments the logon agent further comprises a data store. In these embodiments the data store includes the conditions for which the collection agent may gather information. This data store is distinct from the condition database .

In some embodiments the logon agent initiates information gathering by executing the collection agent . In other embodiments the logon agent initiates information gathering by transmitting the collection agent to the local machine for execution on the local machine . In still other embodiments the logon agent initiates additional information gathering after receiving information . In one embodiment the logon agent also receives the information . In this embodiment the logon agent generates the data set based upon the received information . In some embodiments the logon agent generates the data set by applying a condition from the database to the information received from the collection agent .

In another embodiment the first component includes a plurality of logon agents . In this embodiment at least one of the plurality of logon agents resides on each network domain from which a local machine may transmit a resource request. In this embodiment the local machine transmits the resource request to a particular logon agent . In some embodiments the logon agent transmits to the policy engine the network domain from which the local machine accessed the logon agent . In one embodiment the network domain from which the local machine accesses a logon agent is referred to as the network zone of the local machine .

The condition database stores the conditions that the first component applies to received information. The policy database stores the policies that the second component applies to the received data set . In some embodiments the condition database and the policy database store data in an ODBC compliant database. For example the condition database and the policy database may be provided as an ORACLE database manufactured by Oracle Corporation of Redwood Shores Calif. In other embodiments the condition database and the policy database can be a Microsoft ACCESS database or a Microsoft SQL server database manufactured by Microsoft Corporation of Redmond Wash.

After the first component applies the received information to each condition in the condition database the first component transmits the data set to second component . In one embodiment the first component transmits only the data set to the second component . Therefore in this embodiment the second component does not receive information only identifiers for satisfied conditions. The second component receives the data set and makes an access control decision by applying a policy from the policy database based upon the conditions identified within data set .

In one embodiment policy database stores the policies applied to the received information . In one embodiment the policies stored in the policy database are specified at least in part by the system administrator. In another embodiment a user specifies at least some of the policies stored in the policy database . The user specified policy or policies are stored as preferences. The policy database can be stored in volatile or non volatile memory or for example distributed through multiple servers.

In one embodiment a policy allows access to a resource only if one or more conditions are satisfied. In another embodiment a policy allows access to a resource but prohibits transmission of the resource to the local machine . Another policy might make connection contingent on the local machine that requests access being within a secure network. In some embodiments the resource is an application program and the local machine has requested execution of the application program. In one of these embodiments a policy may allow execution of the application program on the local machine . In another of these embodiments a policy may enable the local machine to receive a stream of files comprising the application program. In this embodiment the stream of files may be stored and executed in an isolation environment. In still another of these embodiments a policy may allow only execution of the application program on a remote machine such as an application server and require the remote machine to transmit application output data to the local machine .

Referring now to a flow diagram depicts one embodiment of the steps taken by the policy engine to make an access control decision based upon information received about a local machine . Upon receiving gathered information about the local machine Step the policy engine generates a data set based upon the information Step . The data set contains identifiers for each condition satisfied by the received information . The policy engine applies a policy to each identified condition within the data set . That application yields an enumeration of resources which the local machine may access Step . The policy engine then presents that enumeration to the local machine . In some embodiments the policy engine creates a Hypertext Markup Language HTML document used to present the enumeration to the local machine.

Referring to one embodiment of a network is depicted which includes a local machine a collection agent a policy engine a policy database a condition database a local machine a session server a stored application database a remote machine a first database a remote machine and a second database . In brief overview when the local machine transmits to the access control server a request for access to an application program the collection agent communicates with local machine retrieves information about local machine and transmits local machine information to the policy engine . The policy engine makes an access control decision as discussed above in and . The local machine receives an enumeration of available applications associated with the local machine .

In some embodiments the session server establishes a connection between the local machine and a plurality of application sessions associated with the local machine . In other embodiments the policy engine determines that the local machine has authorization to retrieve a plurality of application files comprising the application and to execute the application program locally. In some embodiments the policy engine determines whether to accelerate delivery of the application files by transmitting an acceleration program to the local machine . In one of these embodiments the remote machine stores application session data and a plurality of application files comprising the application program. In another of these embodiments the local machine establishes an application streaming session with a remote machine storing the application session data and the plurality of application files comprising the application program. In some embodiments the policy engine determines whether to accelerate delivery of the streaming session by transmitting an acceleration program to the local machine . In some embodiments the policy engine determines whether to accelerate delivery of data files by transmitting an acceleration program to the local machine .

Referring now to a flow diagram depicts one embodiment of the steps taken by the session server to provide access for the local machine to its associated application sessions. The session server receives information about the local machine from the policy engine containing access control decision the policy engine made step . The session server generates an enumeration of associated applications step . The session server may connect the local machine to an associated application step . In one embodiment the information also includes the local machine information . In another embodiment the information includes authorization to execute the application program locally.

The session server generates an enumeration of associated applications step . In some embodiments the policy engine identifies a plurality of application sessions already associated with the local machine . In other embodiments the session server identifies stored application sessions associated with the local machine . In some of these embodiments the session server automatically identifies the stored application sessions upon receiving the information from the policy engine . In one embodiment the stored application database resides on the session server . In another embodiment the stored application database resides on the policy engine .

The stored application database contains data associated with a plurality of remote machines in the farm executing application sessions or providing access to application session data and application files comprising application programs. In some embodiments identifying the application sessions associated with the local machine requires consulting stored data associated with one or more remote machines. In some of these embodiments the session store consults the stored data associated with one or more remote machines. In others of these embodiments the policy engine consults the stored data associated with one or more remote machines. In some embodiments a first application session runs on a remote machine and a second application session runs on a remote machine . In other embodiments all application sessions run on a single remote machine within the farm .

The session server includes information related to application sessions initiated by users. The session server can be stored in volatile or non volatile memory or for example distributed through multiple servers. Table 1 shows the data included in a portion of an illustrative session server 

The illustrative session server in Table 1 includes data associating each application session with the user that initiated the application session an identification of the client computer or if any from which the user is currently connected to the remote machine and the IP address of that client computer or . The illustrative session server also includes the status of each application session. An application session status can be for example active meaning a user is connected to the application session or disconnected meaning a user is not connected to the application session . In an alternative embodiment an application session status can also be set to executing disconnected meaning the user has disconnected from the application session but the applications in the application session are still executing or stalled disconnected meaning the user is disconnected and the applications in the application session are not executing but their operational state immediately prior to the disconnection has been stored . The session server further stores information indicating the applications that are executing within each application session and data indicating each application s process on the server. In embodiments in which the remote machine is part of the farm the session server is at least a part of the dynamic store and also includes the data in the last two rows of Table 1 that indicate on which remote machine in the farm each application is was executing and the IP address of that remote machine . In alternative embodiments the session server includes a status indicator for each application in each application session.

For example in the example of Table 1 three application sessions exist App Session App Session and App Session . App Session is associated with User who is currently using terminal . Terminal one s IP address is 152.16.2.50. The status of App Session is active and in App Session a word processing program is being executed. The word processing program is executing on Server A as process number . Server A s IP address is 152.16.2.55. App Session in Table 1 is an example of a disconnected application session . App Session is associated with User but App Session is not connected to a local machine or . App Session includes a database program that is executing on Server A at IP address 152.16.2.55 as process number . App Session is an example of how a user can interact with application sessions operating on different remote machines . App Session is associated with User as is App Session . App Session includes a spreadsheet program that is executing on Server B at IP address 152.16.2.56 as process number whereas the application session included in App Session is executing on Server A.

In another example a user may access a first application program through an application session executing on a remote machine such as Server A while communicating across an application streaming session with a second remote machine such as Server B to retrieve a second application program from the second remote machine for local execution. The user of the local machine may have acquired authorization to execute the second application program locally while failing to satisfy the execution pre requisites of the first application program.

In one embodiment the session server is configured to receive a disconnect request to disconnect the application sessions associated with the local machine and disconnects the application sessions in response to the request. The session server continues to execute an application session after disconnecting the local machine from the application session. In this embodiment the session server accesses the stored application database and updates a data record associated with each disconnected application session so that the record indicates that the application session associated with the local machine is disconnected.

After receiving authentication information associated with a local machine connecting to the network the session server consults the stored applications database to identify any active application sessions that are associated with a user of the local machine but that are connected to a different local machine such as the local machine if the authentication information is associated with local machine for example. In one embodiment if the session server identifies any such active application sessions the session server automatically disconnects the application session s from the local machine and connects the application session s to the current local machine . In some embodiments the received authentication information will restrict the application sessions to which the local machine may reconnect. In other embodiments the received authentication information authorizes execution of an application program on the local machine where the authorization may have been denied to local machine . In one of these embodiments the session server may provide the local machine access information for retrieving the application program for local execution.

A request is received to execute an enumerated application step . In one embodiment a user of the local machine selects an application for execution from a received enumeration of available applications. In another embodiment the user selects an application for execution independent of the received enumeration. In some embodiments the user selects an application for execution by selecting a graphical representation of the application presented on the local machine by a client agent. In other embodiments the user selects an application for execution by selecting a graphical representation of the application presented to the user on a web server or other remote machine . In some embodiments an appliance or acceleration program accelerates delivery of the graphical representation. In some embodiments an appliance caches or stores the graphical representation. In some embodiments an appliance may cache or store any and all of the associated applications or portions of the associated applications.

In still other embodiments the user requests access a file. In one of these embodiments execution of an application is required to provide the user with access to the file. In another of these embodiments the application is automatically selected for execution upon selection of the file for access. In still another of these embodiments prior to the request for access to the file the application is associated with a type of file enabling automatic selection of the application upon identification of a type of file associated with the requested file. In some embodiments an appliance or an acceleration program may be used to accelerate delivery of one or more files. In some embodiments an appliance may cache or store some or all of a file.

In one embodiment the enumerated application comprises a plurality of application files. In some embodiments the plurality of application files reside on the remote machine . In other embodiments the plurality of application files reside on a separate file server or remote machine . In still other embodiments the plurality of application files may be transmitted to a local machine . In yet other embodiments a file in the plurality of application files may be executed prior to transmission of a second file in the plurality of application files to the local machine . In some embodiments an appliance or an acceleration program may be used to accelerate delivery of one or more application files.

In some embodiments the remote machine retrieves information about the enumerated application from a remote machine . In one of these embodiments the remote machine receives an identification of a remote machine hosting a plurality of application files. In another of these embodiments the remote machine receives identification of a location of a plurality of application files the identification conforming to a Universal Naming Convention UNC . In still another of these embodiments the identification includes a network location and a socket for an application streaming protocol.

In one embodiment the remote machine retrieves a file containing information about the enumerated application. The file may include an identification of a location of a server hosting the enumerated application. The file may include an identification of a plurality of versions of the enumerated application. The file may include an enumeration of a plurality of application files comprising the enumerated application. The file may include an identification of a compressed file comprising a plurality of applications files comprising the enumerated application. The file may include an identification of pre requisites to be satisfied by a machine executing the enumerated application. The file may include an enumeration of data files associated with the enumerated application. The file may include an enumeration of scripts to be executed on a machine executing the enumerated application. The file may include an enumeration of registry data associated with the enumerated application. The file may include an enumeration of rules for use in an embodiment where the enumerated application executes within an isolation environment. In one embodiment the file may be referred to as a manifest file. The information that the file may contain is described in further detail in connection with below.

In some embodiments the remote machine applies a policy to an identified characteristic of the local machine . In one of these embodiments the remote machine identifies a version of the enumerated application for execution responsive to the identified characteristic. In another of these embodiments the remote machine makes a determination to execute a version of the enumerated application compatible with a characteristic of the local machine . In still another of these embodiments the remote machine makes a determination to execute a version of the enumerated application compatible with an operating system executing on the local machine . In yet another of these embodiments the remote machine makes a determination to execute a version of the enumerated application compatible with a revision level of an operating system on the local machine . In one of these embodiments the remote machine makes a determination to execute a version of the enumerated application compatible with a language specified by an operating system on the local machine .

One of a predetermined number of methods for executing the enumerated application is selected responsive to a policy the predetermined number of methods including a method for application streaming of the enumerated application step . In one embodiment the selection is made responsive to an application of a policy to the received credentials associated with the local machine . In some embodiments the selection is made by a policy engine such as the policy engine described above in and . In other embodiments the remote machine receiving the credentials and the request to execute the enumerated application further comprises such a policy engine .

In one embodiment the predetermined number of methods includes a method for executing the enumerated application on a remote machine . In another embodiment the predetermined number of methods includes a method for executing the enumerated application on the local machine . In still another embodiment the predetermined number of methods includes a method for executing the enumerated application on a second remote machine .

In some embodiments the predetermined number of methods includes a method for providing the enumerated application to the local machine across an application streaming session. In one of these embodiments the local machine comprises a streaming service agent capable of initiating a connection with a remote machine and receiving from the remote machine a stream of transmitted data packets.

The stream of data packets may include application files comprising the enumerated application. In some embodiments application files include data files associated with an application program. In other embodiments application files include executable files required for execution of the application program. In still other embodiments the application files include metadata including information about the files such as location compatibility requirements configuration data registry data identification of execution scripts rules for use in isolation environments or authorization requirements. In one embodiment the stream of data packets are transmitted via a transport layer connection such as a payload of a TCP IP packet.

In some embodiments the streamed application executes prior to the transmission of each application file in a plurality of application files comprising the streamed application. In one of these embodiments execution of the streamed application begins upon receipt by a local machine of one application file in the plurality of applications. In another of these embodiments execution of the streamed application begins upon receipt by a local machine of an executable application file in the plurality of application files. In still another of these embodiments the local machine executes a first received application file in a plurality of application files and the first received application file requests access to a second application file in the plurality of application files.

In one embodiment the streamed application executes on the local machine without permanently residing on the local machine . In this embodiment the streamed application may execute on the local machine and be removed from the local machine upon termination of the streamed application. In another embodiment the streamed application executes on the local machine after a pre deployed copy of each application file is stored on the local machine . In still another embodiment the streamed application executes on the local machine after a copy of each application file is stored in an isolation environment on the local machine. In yet another embodiment the streamed application executes on the local machine after a copy of each application file is stored in a cache on the local machine .

In one embodiment the method for streaming the application to the local machine is selected from the predetermined number of methods responsive to a determination that the local machine may receive the streamed application files. In another embodiment the method for streaming the application to the local machine is selected from the predetermined number of methods responsive to a determination that the local machine has authority to execute the streamed application files locally.

In other embodiments the predetermined number of methods includes a method for providing application output data to the local machine the application output data generated from an execution of the enumerated application on a remote machine . In one of these embodiments the remote machine is the remote machine receiving the request for execution of the enumerated application. In another of these embodiments the remote machine is a second remote machine such as a file server or an application server. In some embodiments the enumerated application resides on the remote machine executing the enumerated application. In other embodiments the remote machine executing the enumerated application first receives the enumerated application from a second remote machine across an application streaming session. In one of these embodiments the remote machine comprises a streaming service agent capable of initiating a connection with a second remote machine and receiving from the second remote machine a stream of transmitted data. In another of these embodiments the second remote machine may be identified using a load balancing technique. In still another of these embodiments the second remote machine may be identified based upon proximity to the remote machine . These embodiments will be described in greater detail in connection with below.

In some embodiments the remote machine selects from the predetermined number of methods for executing the enumerated application a method for streaming the enumerated application to the remote machine executing the enumerated application on the remote machine and providing to the local machine application output data generated by the execution of the enumerated application. In one of these embodiments the remote machine selects the method responsive to an evaluation of the local machine . In another of these embodiments the determination is made responsive to an application of a policy to the evaluation of the local machine . In still another of these embodiments the determination is made responsive to an evaluation of the received credentials. In one embodiment the remote machine receives a plurality of application files comprising the enumerated application. In another embodiment the remote machine provides the application output data via a presentation level protocol such as an ICA presentation level protocol or a Remote Desktop Windows presentation level protocol or an X Windows presentation level protocol.

In some embodiments the remote machine also provides access information associated with the enumerated application the access information generated responsive to the selected method. In one of these embodiments the access information provides an indication to the local machine of the selected method for execution of the enumerated application program. In another of these embodiments the access information includes an identification of a location of the enumerated application the identification conforming to a Universal Naming Convention UNC . In still another of these embodiments the access information includes an identification of a session management server.

In some embodiments the access information includes a launch ticket comprising authentication information. In one of these embodiments the local machine may use the launch ticket to authenticate the access information received from the remote machine . In another of these embodiments the local machine may use the launch ticket to authenticate itself to a second remote machine hosting the enumerated application. In still another of these embodiments the remote machine includes the launch ticket in the access information responsive to a request from the local machine for the launch ticket.

Referring now to a block diagram depicts an embodiment in which a local machine requests execution of an application program and an application delivery system comprising a remote machine selects a method of executing the application program. In one embodiment the remote machine receives credentials from the local machine . In another embodiment the remote machine receives a request for an enumeration of available applications from the local machine .

In some embodiments multiple redundant remote machines and are provided. In one of these embodiments there may be for example multiple file servers multiple session management servers multiple staging machines multiple web interfaces or multiple access suite consoles. In another of these embodiments if a remote machine fails a redundant remote machine is selected to provide the functionality of the failed machine. In other embodiments although the remote machines and and the web interface and access suite console are described as separate remote machines having the separate functionalities of a management server a session management server a staging machine a file server a web server and an access suite console a single remote machine may be provided having the functionality of all of these machines. In still other embodiments a remote machine may provide the functionality and services of one or more of the other remote machines.

Referring now to in greater detail a block diagram depicts one embodiment of an application delivery system providing access to an application program. The application delivery system may comprise one or more remote machines an appliance or any combination thereof. In addition to the interfaces and subsystems described above in connection with the remote machine may further include a management communication service an XML service and a management service . The management service may comprise an application management subsystem a server management subsystem a session management subsystem and a license management subsystem . The remote machine may be in communication with an access suite console .

In one embodiment the management service further comprises a specialized remote procedure call subsystem the MetaFrame Remote Procedure Call MFRPC subsystem . In some embodiments the MFRPC subsystem routes communications between subsystems on the remote machine such as the XML service and the management service . In other embodiments the MFRPC subsystem provides a remote procedure call RPC interface for calling management functions delivers RPC calls to the management service and returns the results to the subsystem making the call.

In some embodiments the remote machine is in communication with a protocol engine such as the protocol engine described above in . In one of these embodiments the remote machine is in communication with a protocol engine residing on a remote machine . In other embodiments the remote machine further comprises a protocol engine .

The remote machine may be in communication with an access suite console . The access suite console may host management tools to an administrator of a remote machine or of a farm . In some embodiments the remote machine communicates with the access suite console using XML. In other embodiments the remote machine communicates with the access suite console using the Simple Object Access Protocol SOAP .

For embodiments such as those described in and in in which the remote machine comprises a subset of subsystems the management service may comprise a plurality of subsystems. In one embodiment each subsystem is either a single threaded or a multi threaded subsystem. A thread is an independent stream of execution running in a multi tasking environment. A single threaded subsystem is capable of executing only one thread at a time. A multi threaded subsystem can support multiple concurrently executing threads i.e. a multi threaded subsystem can perform multiple tasks simultaneously.

The application management subsystem manages information associated with a plurality of applications capable of being streamed. In one embodiment the application management subsystem handles requests from other components such as requests for storing deleting updating enumerating or resolving applications. In another embodiment the application management subsystem handles requests sent by components related to an application capable of being streamed. These events can be classified into three types of events application publishing application enumeration and application launching each of which will be described in further detail below. In other embodiments the application management subsystem further comprises support for application resolution application publication and application publishing. In other embodiments the application management subsystem uses a data store to store application properties and policies.

The server management subsystem handles configurations specific to application streaming in server farm configurations. In some embodiments the server management subsystem also handles events that require retrieval of information associated with a configuration of a farm . In other embodiments the server management subsystem handles events sent by other components related to remote machines providing access to applications across application streams and properties of those remote machines. In one embodiment the server management subsystem stores remote machine properties and farm properties.

In some embodiments the remote machine further comprises one or more common application subsystems providing services for one or more specialized application subsystems. These remote machines may also have one or more common remote machine subsystem providing services for one or more specialized remote machine subsystems. In other embodiments no common application subsystems are provided and each specialized application and remote machine subsystem implements all required functionality.

In one embodiment in which the remote machine comprises a common application subsystem the common application subsystem manages common properties for published applications. In some embodiments the common application subsystem handles events that require retrieval of information associated with published applications or with common properties. In other embodiments the common application subsystem handles all events sent by other components related to common applications and their properties.

A common application subsystem can publish applications to the farm which makes each application available for enumeration and launching by a local machine . Generally an application is installed on each remote machine on which availability of that application is desired. In one embodiment to publish an application an administrator runs an administration tool specifying information such as the remote machines hosting the application the name of the executable file on each remote machine the required capabilities of a local machine for executing the application e.g. audio video encryption etc. and a list of users that can use the application. This specified information is categorized into application specific information and common information. Examples of application specific information are the path name for accessing the application and the name of the executable file for running the application. Common information i.e. common application data includes for example the user friendly name of the application e.g. Microsoft WORD 2000 a unique identification of the application and the users of the application.

The application specific information and common information may be sent to a specialized application subsystem controlling the application on each remote machine hosting the application. The specialized application subsystem may write the application specific information and the common information into a persistent store .

When provided a common application subsystem also provides a facility for managing the published applications in the farm . Through a common application subsystem an administrator can manage the applications of the farm using an administration tool such as the access suite console to configure application groups and produce an application tree hierarchy of those application groups. Each application group may be represented as a folder in the application tree hierarchy. Each application folder in the application tree hierarchy can include one or more other application folders and specific instances of remote machines. The common application subsystem provides functions to create move rename delete and enumerate application folders.

In one embodiment the common application subsystem supports the application management subsystem in handling application enumeration and application resolution requests. In some embodiments the common application subsystem provides functionality for identifying an application for execution responsive to a mapping between a type of data file and an application for processing the type of data file. In other embodiments a second application subsystem provides the functionality for file type association.

In some embodiments the remote machine may further comprise a policy subsystem. A policy subsystem includes a policy rule for determining whether an application may be streamed to a local machine upon a request by the local machine for execution of the application. In some embodiments the policy subsystem identifies a server access option associated with a streamed application published in the access suite console . In one of these embodiments the policy subsystem uses the server access option as a policy in place of the policy rule.

The session monitoring subsystem maintains and updates session status of an application streaming session associated with a local machine and enforces license requirements for application streaming sessions. In one embodiment the session management subsystem monitors sessions and logs events such as the launching of an application or the termination of an application streaming session. In another embodiment the session monitoring subsystem receives communications such as heartbeat messages transmitted from the local machine to the remote machine . In still another embodiment the session management subsystem responds to queries about sessions from management tools such as tools within the access suite console . In some embodiments the management service further comprises a license management subsystem communicating with the session management subsystem to provide and maintain licenses to local machines for execution of applications.

In one embodiment the management service provides functionality for application enumeration and application resolution. In some embodiments the management service also provides functionality for application launching session monitoring and tracking application publishing and license enforcement.

Referring now to a block diagram depicts one embodiment of a remote machine comprising a management service providing an application enumeration. The management service may provide application enumeration through the use of a web interface interacting with an XML service . In one embodiment XML service enumerates applications for a user of a local machine . In another embodiment the XML service implements the functionality of the ICA browser subsystem and the program neighborhood subsystem described above. The XML service may interact with a management communications service . In one embodiment the XML service generates an application enumeration request using the management communications service . The application enumeration request may include a client type indicating a method of execution to be used when executing the enumerated application. The application enumeration request is sent to a common application subsystem . In one embodiment the common application subsystem returns an enumeration of applications associated with the client type of the application enumeration request. In another embodiment the common application subsystem returns an enumeration of applications available to the user of the local machine the enumeration selected responsive to an application of a policy to a credential associated with the local machine . In this embodiment a policy engine may apply the policy to credentials gathered by a collection agent as described in connection with above. In still another embodiment the enumeration of applications is returned and an application of a policy to the local machine is deferred until an execution of an enumerated application is requested.

The management service may provide application resolution service for identifying a second remote machine hosting an application. In one embodiment the second remote machine is a file server or an application server. In some embodiments the management service consults a file including identifiers for a plurality of remote machines hosting applications. In one embodiment the management service provides the application resolution service responsive to a request from a local machine for execution of an application. In another embodiment the management service identifies a second remote machine capable of implementing a different method of executing the application than a first remote machine . In some embodiments the management service identifies a first remote machine capable of streaming an application program to a local machine and a second remote machine capable of executing the application program and providing application output data generated responsive to the execution of the application program to the local machine .

In one embodiment a web interface transmits an application resolution request to the XML service . In another embodiment the XML service receives a application resolution request and transmits the request to the MFRPC subsystem .

In one embodiment the MFRPC subsystem identifies a client type included with a received application resolution request. In another embodiment the MFRPC subsystem applies a policy to the client type and determines to stream the application to the local machine . In this embodiment the MFRPC subsystem may forward the application resolution request to an application management subsystem . In one embodiment upon receiving the application resolution request from the MFRPC subsystem the application management subsystem may identify a remote machine functioning as a session management server for the local machine . In some embodiments the local machine transmits a heartbeat message to the session management server . In another embodiment the application management subsystem may identify a remote machine hosting a plurality of application files comprising the application to be streamed to the local machine .

In some embodiments the application management subsystem use a file enumerating a plurality of remote machines hosting the plurality of application files to identify the remote machine . In other embodiments the application management subsystem identifies a remote machine having an IP address similar to an IP address of the local machine . In still other embodiments the application management subsystem identifies a remote machine having an IP address in a range of IP addresses accessible to the local machine .

In still another embodiment the MFRPC subsystem applies a policy to the client type and determines that the application may be executed on a remote machine the remote machine transmitting application output data generated by an execution of the application to the local machine . In this embodiment the MFRPC subsystem may forward the application resolution request to a common application subsystem to retrieve an identifier of a host address for a remote machine . In one embodiment the identified remote machine may transmit the application output data to the local machine using a presentation level protocol such as ICA or RDP or X Windows. In some embodiments the remote machine receives the application from a second remote machine across an application streaming session.

In one embodiment upon completion of application enumeration and application resolution access information is transmitted to the local machine that includes an identification of a method of execution for an enumerated application and an identifier of a remote machine hosting the enumerated application. In one embodiment where the management service determines that the enumerated application will execute on the local machine a web interface creates and transmits to the local machine a file containing name resolved information about the enumerated application. In some embodiments the file may be identified using a .rad extension. The local machine may execute the enumerated application responsive to the contents of the received file. Table 2 depicts one embodiment of information contained in the file 

The file may also contain a launch ticket for use by the local machine in executing the application as shown in Table 2. In some embodiments the launch ticket expires after a predetermined period of time. In one embodiment the local machine provides the launch ticket to a remote machine hosting the enumerated application to be executed. Use of the launch ticket to authorize access to the enumerated application by a user of the local machine assists in preventing the user from reusing the file or generating an unauthorized version of the file to inappropriately access to applications. In one embodiment the launch ticket comprises a large randomly generated number.

As described above in connection with a method for selecting a method of execution of an application program begins when credentials associated with the local machine or with a user of the local machine are received step and an enumeration of a plurality of application programs available to the local machine is provided responsive to the received credentials step . A request is received to execute an enumerated application step and one of a predetermined number of methods for executing the enumerated application is selected responsive to a policy the predetermined number of methods including a method for application streaming of the enumerated application step .

Referring now to a flow diagram depicts one embodiment of the steps taken to access a plurality of files comprising an application program. A local machine performs a pre launch analysis of the local machine step . In one embodiment the local machine performs the pre launch analysis prior to retrieving and executing a plurality of application files comprising an application program. In another embodiment the local machine performs the pre launch analysis responsive to a received indication that the pre launch analysis is a requirement for authorization to access the plurality of application files comprising an application program.

In some embodiments the local machine receives from a remote machine access information associated with the plurality of application files. In one of these embodiments the access information includes an identification of a location of a remote machine hosting the plurality of application files. In another of these embodiments the local machine receives an identification of a plurality of applications comprising one or more versions of the application program. In still another of these embodiments the local machine receives an identification of a plurality of application files comprising one or more application programs. In other embodiments the local machine receives an enumeration of application programs available to the local machine for retrieval and execution. In one of these embodiments the enumeration results from an evaluation of the local machine . Instill other embodiments the local machine retrieves the at least one characteristic responsive to the retrieved identification of the plurality of application files comprising an application program.

In some embodiments the access information includes a launch ticket capable of authorizing the local machine to access the plurality of application files. In one of these embodiments the launch ticket is provided to the local machine responsive to an evaluation of the local machine . In another of these embodiments the launch ticket is provided to the local machine subsequent to a pre launch analysis of the local machine by the local machine .

In other embodiments the local machine retrieves at least one characteristic required for execution of the plurality of application files. In one of these embodiments the access information includes the at least one characteristic. In another of these embodiments the access information indicates a location of a file for retrieval by the local machine the file enumerating the at least one characteristic. In still another of these embodiments the file enumerating the at least one characteristic further comprises an enumeration of the plurality of application files and an identification of a remote machine hosting the plurality of application files.

The local machine determines the existence of the at least one characteristic on the local machine. In one embodiment the local machine makes this determination as part of the pre launch analysis. In another embodiment the local machine determines whether the local machine has the at least one characteristic.

In one embodiment determining the existence of the at least one characteristic on the local machine includes determining whether a device driver is installed on the local machine. In another embodiment determining the existence of the at least one characteristic on the local machine includes determining whether an operating system is installed on the local machine . In still another embodiment determining the existence of the at least one characteristic on the local machine includes determining whether a particular operating system is installed on the local machine . In yet another embodiment determining the existence of the at least one characteristic on the local machine includes determining whether a particular revision level of an operating system is installed on the local machine .

In some embodiments determining the existence of the at least one characteristic on the local machine includes determining whether the local machine has acquired authorization to execute an enumerated application. In one of these embodiments a determination is made by the local machine as to whether the local machine has received a license to execute the enumerated application. In another of these embodiments a determination is made by the local machine as to whether the local machine has received a license to receive across an application streaming session a plurality of application files comprising the enumerated application. In other embodiments determining the existence of the at least one characteristic on the local machine includes determining whether the local machine has sufficient bandwidth available to retrieve and execute an enumerated application.

In some embodiments determining the existence of the at least one characteristic on the local machine includes execution of a script on the local machine . In other embodiments determining the existence of the at least one characteristic on the local machine includes installation of software on the local machine . In still other embodiments determining the existence of the at least one characteristic on the local machine includes modification of a registry on the local machine . In yet other embodiments determining the existence of the at least one characteristic on the local machine includes transmission of a collection agent to the local machine for execution on the local machine to gather credentials associated with the local machine .

The local machine requests from a remote machine authorization for execution of the plurality of application files the request including a launch ticket step . In some embodiments the local machine makes the request responsive to a determination that at least one characteristic exists on the local machine . In one of these embodiments the local machine determines that a plurality of characteristics exist on the local machine the plurality of characteristics associated with an enumerated application and received responsive to a request to execute the enumerated application. In another of these embodiments whether the local machine receives an indication that authorization for execution of the enumerated application files depends upon existence of the at least one characteristic on the local machine . In one embodiment the local machine received an enumeration of application programs requested execution of an enumerated application and received access information including the at least one characteristic and a launch ticket authorizing the execution of the enumerated application upon the determination of the existence of the at least one characteristic on the local machine .

In one embodiment the local machine receives from the remote machine a license authorizing execution of the plurality of application files. In some embodiments the license authorizes execution for a specified time period. In one of these embodiments the license requires transmission of a heart beat message to maintain authorization for execution of the plurality of application files.

In another embodiment the local machine receives from the remote machine the license and an identifier associated with a remote machine monitoring execution of the plurality of application files. In some embodiments the remote machine is a session management server as depicted above in . In one of these embodiments the session management server includes a session management subsystem that monitors the session associated with the local machine . In other embodiments a separate remote machine is the session management server .

The local machine receives and executes the plurality of application files step . In one embodiment the local machine receives the plurality of application files across an application streaming session. In another embodiment the local machine stores the plurality of application files in an isolation environment on the local machine . In still another embodiment the local machine executes one of the plurality of application files prior to receiving a second of the plurality of application files. In some embodiments a remote machine transmits the plurality of application files to a plurality of local machines each local machine in the plurality having established a separate application streaming session with the remote machine.

In some embodiments the local machine stores the plurality of application files in a cache and delays execution of the application files. In one of these embodiments the local machine receives authorization to execute the application files during a pre defined period of time. In another of these embodiments the local machine receives authorization to execute the application files during the pre defined period of time when the local machine lacks access to a network. In other embodiments the local machine stores the plurality of application files in a cache. In one of these embodiments the application streaming client establishes an internal application streaming session to retrieve the plurality of application files from the cache. In another of these embodiments the local machine receives authorization to execute the application files during a pre defined period of time when the local machine lacks access to a network.

The local machine transmits at least one heartbeat message to a remote machine step . In some embodiments the local machine transmits the at least one heartbeat message to retain authorization to execute the plurality of application files comprising the enumerated application. In other embodiments the local machine transmits the at least one heartbeat message to retain authorization retrieve an application file in the plurality of application files. In still other embodiments the local machine receives a license authorizing execution of the plurality of application files during a pre determined period of time.

In some embodiments the local machine transmits the heartbeat message to a second remote machine . In one of these embodiments the second remote machine may comprise a session management server monitoring the retrieval and execution of the plurality of application files. In another of these embodiments the second remote machine may renew a license authorizing execution of the plurality of application files responsive to the transmitted heartbeat message. In still another of these embodiments the second remote machine may transmit to the local machine a command responsive to the transmitted heartbeat message.

Referring back to the local machine may include an application streaming client a streaming service and an isolation environment . The application streaming client may be an executable program. In some embodiments the application streaming client may be able to launch another executable program. In other embodiments the application streaming client may initiate the streaming service . In one of these embodiments the application streaming client may provide the streaming service with a parameter associated with executing an application program. In another of these embodiments the application streaming client may initiate the streaming service using a remote procedure call.

In one embodiment the local machine requests execution of an application program and receives access information from a remote machine regarding execution. In another embodiment the application streaming client receives the access information. In still another embodiment the application streaming client provides the access information to the streaming service . In yet another embodiment the access information includes an identification of a location of a file associated with a plurality of application files comprising the application program.

In one embodiment the streaming service retrieves a file associated with a plurality of application files. In some embodiments the retrieved file includes an identification of a location of the plurality of application files. In one of these embodiments the streaming service retrieves the plurality of application files. In another of these embodiments the streaming service executes the retrieved plurality of application files on the local machine . In other embodiments the streaming service transmits heartbeat messages to a remote machine to maintain authorization to retrieve and execute a plurality of application files.

In some embodiments the retrieved file includes an identification of a location of more than one plurality of application files each plurality of application files comprising a different application program. In one of these embodiments the streaming service retrieves the plurality of application files comprising the application program compatible with the local machine . In another of these embodiments the streaming service receives authorization to retrieve a particular plurality of application files responsive to an evaluation of the local machine .

In some embodiments the plurality of application files are compressed and stored on a file server within an archive file such as a CAB ZIP SIT TAR JAR or other archive file. In one embodiment a plurality of application files stored in an archive file comprise an application program. In another embodiment multiple pluralities of application files stored in an archive file each comprise different versions of an application program. In still another embodiment multiple pluralities of application files stored in an archive file each comprise different application programs. In some embodiments an archive file includes metadata associated with each file in the plurality of application files. In one of these embodiments the streaming service generates a directory structure responsive to the included metadata. As will be described in greater detail in connection with below the metadata may be used to satisfy requests by application programs for directory enumeration.

In one embodiment the streaming service decompresses an archive file to acquire the plurality of application files. In another embodiment the streaming service determines whether a local copy of a file within the plurality of application files exists in a cache on the local machine prior to retrieving the file from the plurality of application files. In still another embodiment the file system filter driver determines whether the local copy exists in the cache. In some embodiments the streaming service modifies a registry entry prior to retrieving a file within the plurality of application files.

In some embodiments the streaming service stores a plurality of application files in a cache on the local machine . In one of these embodiments the streaming service may provide functionality for caching a plurality of application files upon receiving a request to cache the plurality of application files. In another of these embodiments the streaming service may provide functionality for securing a cache on the local machine . In another of these embodiments the streaming service may use an algorithm to adjust a size and a location of the cache.

In some embodiments the streaming service creates an isolation environment on the local machine . In one of these embodiments the streaming service uses an isolation environment application programming interface to create the isolation environment . In another of these embodiments the streaming service stores the plurality of application files in the isolation environment . In still another of these embodiments the streaming service executes a file in the plurality of application files within the isolation environment. In yet another of these embodiments the streaming service executes the application program in the isolation environment.

For embodiments in which authorization is received to execute an application on the local machine the execution of the application may occur within an isolation environment . In some embodiments a plurality of application files comprising the application are stored on the local machine prior to execution of the application. In other embodiments a subset of the plurality of application files are stored on the local machine prior to execution of the application. In still other embodiments the plurality of application files do not reside in the isolation environment . In yet other embodiments a subset of the plurality of applications files do not reside on the local machine . Regardless of whether a subset of the plurality of application files or each application file in the plurality of application files reside on the local machine or in isolation environment in some embodiments an application file in the plurality of application files may be executed within an isolation environment .

The isolation environment may consist of a core system able to provide File System Virtualization Registry System Virtualization and Named Object Virtualization to reduce application compatibility issues without requiring any change to the application source code. The isolation environment may redirect application resource requests using hooking both in the user mode for registry and named object virtualization and in the kernel using a file system filter driver for file system virtualization. The following is a description of some embodiments of an isolation environment .

Referring now to one embodiment of a computer running under control of an operating system that has reduced application compatibility and application sociability problems is shown. The operating system makes available various native resources to application programs via its system layer . The view of resources embodied by the system layer will be termed the system scope . In order to avoid conflicting access to native resources by the application programs an isolation environment is provided. As shown in the isolation environment includes an application isolation layer and a user isolation layer . Conceptually the isolation environment provides via the application isolation layer an application program with a unique view of native resources such as the file system the registry objects and window names . Each isolation layer modifies the view of native resources provided to an application. The modified view of native resources provided by a layer will be referred to as that layer s isolation scope . As shown in the application isolation layer includes two application isolation scopes . Scope represents the view of native resources provided to application and scope represents the view of native resources provided to application . Thus in the embodiment shown in APP is provided with a specific view of the file system while APP is provided with another view of the file system which is specific to it. In some embodiments the application isolation layer provides a specific view of native resources to each individual application program executing on top of the operating system . In other embodiments application programs may be grouped into sets and in these embodiments the application isolation layer provides a specific view of native resources for each set of application programs. Conflicting application programs may be put into separate groups to enhance the compatibility and sociability of applications. In still further embodiments the applications belonging to a set may be configured by an administrator. In some embodiments a passthrough isolation scope can be defined which corresponds exactly to the system scope. In other words applications executing within a passthrough isolation scope operate directly on the system scope.

In some embodiments the application isolation scope is further divided into layered sub scopes. The main sub scope contains the base application isolation scope and additional sub scopes contain various modifications to this scope that may be visible to multiple executing instances of the application. For example a sub scope may contain modifications to the scope that embody a change in the patch level of the application or the installation or removal of additional features. In some embodiments the set of additional sub scopes that are made visible to an instance of the executing application is configurable. In some embodiments that set of visible sub scopes is the same for all instances of the executing application regardless of the user on behalf of which the application is executing. In others the set of visible sub scopes may vary for different users executing the application. In still other embodiments various sets of sub scopes may be defined and the user may have a choice as to which set to use. In some embodiments sub scopes may be discarded when no longer needed. In some embodiments the modifications contained in a set of sub scopes may be merged together to form a single sub scope.

Referring now to a multi user computer having reduced application compatibility and application sociability problems is depicted. The multi user computer includes native resources in the system layer as well as the isolation environment discussed immediately above. The application isolation layer functions as discussed above providing an application or group of applications with a modified view of native resources. The user isolation layer conceptually provides an application program with a view of native resources that is further altered based on user identity of the user on whose behalf the application is executed. As shown in the user isolation layer may be considered to comprise a number of user isolation scopes generally . A user isolation scope provides a user specific view of application specific views of native resources. For example APP executing in user session on behalf of user a is provided with a file system view a that is altered or modified by both the user isolation scope and the application isolation scope .

Put another way the user isolation layer alters the view of native resources for each individual user by layering a user specific view modification provided by a user isolation scope on top of an application specific view modification provided by an application isolation scope which is in turn layered on top of the system wide view of native resources provided by the system layer. For example when the first instance of APP accesses an entry in the registry database the view of the registry database specific to the first user session and the application a is consulted. If the requested registry key is found in the user specific view of the registry a that registry key is returned to APP . If not the view of the registry database specific to the application is consulted. If the requested registry key is found in the application specific view of the registry that registry key is returned to APP . If not then the registry key stored in the registry database in the system layer i.e. the native registry key is returned to APP .

In some embodiments the user isolation layer provides an isolation scope for each individual user. In other embodiments the user isolation layer provides an isolation scope for a group of users which may be defined by roles within the organization or may be predetermined by an administrator. In still other embodiments no user isolation layer is provided. In these embodiments the view of native resources seen by an application program is that provided by the application isolation layer . The isolation environment although described in relation to multi user computers supporting concurrent execution of application programs by various users may also be used on single user computers to address application compatibility and sociability problems resulting from sequential execution of application programs on the same computer system by different users and those problems resulting from installation and execution of incompatible programs by the same user.

In some embodiments the user isolation scope is further divided into sub scopes. The modifications by the user isolation scope to the view presented to an application executing in that scope is the aggregate of the modifications contained within each sub scope in the scope. Sub scopes are layered on top of each other and in the aggregate view modifications to a resource in a higher sub scope override modifications to the same resource in lower layers.

In some of these embodiments one or more of these sub scopes may contain modifications to the view that are specific to the user. In some of these embodiments one or more sub scopes may contain modifications to the view that are specific to sets of users which may be defined by the system administrators or defined as a group of users in the operating system. In some of these embodiments one of these sub scopes may contain modifications to the view that are specific to the particular login session and hence that are discarded when the session ends. In some of these embodiments changes to native resources by application instances associated with the user isolation scope always affects one of these sub scopes and in other embodiments those changes may affect different sub scopes depending on the particular resource changed.

The conceptual architecture described above allows an application executing on behalf of a user to be presented with an aggregate or unified virtualized view of native resources specific to that combination of application and user. This aggregated view may be referred to as the virtual scope . The application instance executing on behalf of a user is presented with a single view of native resources reflecting all operative virtualized instances of the native resources. Conceptually this aggregated view consists firstly of the set of native resources provided by the operating system in the system scope overlaid with the modifications embodied in the application isolation scope applicable to the executing application further overlaid with the modifications embodied in the user isolation scope applicable to the application executing on behalf of the user. The native resources in the system scope are characterized by being common to all users and applications on the system except where operating system permissions deny access to specific users or applications. The modifications to the resource view embodied in an application isolation scope are characterized as being common to all instances of applications associated with that application isolation scope. The modifications to the resource view embodied in the user isolation scope are characterized as being common to all applications associated with the applicable application isolation scope that are executing on behalf of the user associated with the user isolation scope.

This concept can be extended to sub scopes the modifications to the resource view embodied in a user sub scope are common to all applications associated with the applicable isolation sub scope executing on behalf of a user or group of users associated with a user isolation sub scope. Throughout this description it should be understood that whenever general reference is made to scope it is intended to also refer to sub scopes where those exist.

When an application requests enumeration of a native resource such as a portion of the file system or registry database a virtualized enumeration is constructed by first enumerating the system scoped instance of the native resource that is the instance found in the system layer if any. Next the application scoped instance of the requested resource that is the instance found in the appropriate application isolation scope if any is enumerated. Any enumerated resources encountered in the application isolation scope are added to the view. If the enumerated resource already exists in the view because it was present in the system scope as well it is replaced with the instance of the resource encountered in the application isolation scope. Similarly the user scoped instance of the requested resource that is the instance found in the appropriate user isolation scope if any is enumerated. Again any enumerated resources encountered in the user isolation scope are added to the view. If the native resource already exists in the view because it was present in the system scope or in the appropriate application isolation scope it is replaced with the instance of the resource encountered in the user isolation scope. In this manner any enumeration of native resources will properly reflect virtualization of the enumerated native resources. Conceptually the same approach applies to enumerating an isolation scope that comprises multiple sub scopes. The individual sub scopes are enumerated with resources from higher sub scopes replacing matching instances from lower sub scopes in the aggregate view.

In other embodiments enumeration may be performed from the user isolation scope layer down to the system layer rather than the reverse. In these embodiments the user isolation scope is enumerated. Then the application isolation scope is enumerated and any resource instances appearing in the application isolation scope that were not enumerated in the user isolation scope are added to the aggregate view that is under construction. A similar process can be repeated for resources appearing only in the system scope.

In still other embodiments all isolation scopes may be simultaneously enumerated and the respective enumerations combined.

If an application attempts to open an existing instance of a native resource with no intent to modify that resource the specific instance that is returned to the application is the one that is found in the virtual scope or equivalently the instance that would appear in the virtualized enumeration of the parent of the requested resource. From the point of view of the isolation environment the application is said to be requesting to open a virtual resource and the particular instance of native resource used to satisfy that request is said to be the literal resource corresponding to the requested resource.

If an application executing on behalf of a user attempts to open a resource and indicates that it is doing so with the intent to modify that resource that application instance is normally given a private copy of that resource to modify as resources in the application isolation scope and system scope are common to applications executing on behalf of other users. Typically a user scoped copy of the resource is made unless the user scoped instance already exists. The definition of the aggregate view provided by a virtual scope means that the act of copying an application scoped or system scoped resource to a user isolation scope does not change the aggregate view provided by the virtual scope for the user and application in question nor for any other user nor for any other application instance. Subsequent modifications to the copied resource by the application instance executing on behalf of the user do not affect the aggregate view of any other application instance that does not share the same user isolation scope. In other words those modifications do not change the aggregate view of native resources for other users or for application instances not associated with the same application isolation scope.

Applications may be installed into a particular isolation scope described below in more detail . Applications that are installed into an isolation scope are always associated with that scope. Alternatively applications may be launched into a particular isolation scope or into a number of isolation scopes. In effect an application is launched and associated with one or more isolation scopes. The associated isolation scope or scopes provide the process with a particular view of native resources. Applications may also be launched into the system scope that is they may be associated with no isolation scope. This allows for the selective execution of operating system applications such as Internet Explorer as well as third party applications within an isolation environment.

This ability to launch applications within an isolation scope regardless of where the application is installed mitigates application compatibility and sociability issues without requiring a separate installation of the application within the isolation scope. The ability to selectively launch installed applications in different isolation scopes provides the ability to have applications which need helper applications such as Word Notepad etc. to have those helper applications launched with the same rule sets.

Further the ability to launch an application within multiple isolated environments allows for better integration between isolated applications and common applications.

Referring now to and in brief overview a method for associating a process with an isolation scope includes the steps of launching the process in a suspended state step . The rules associated with the desired isolation scope are retrieved step and an identifier for the process and the retrieved rules are stored in a memory element step and the suspended process is resumed step . Subsequent calls to access native resources made by the process are intercepted or hooked step and the rules associated with the process identifier if any are used to virtualize access to the requested resource step .

Still referring to and in more detail a process is launched in a suspended state step . In some embodiments a custom launcher program is used to accomplish this task. In some of these embodiments the launcher is specifically designed to launch a process into a selected isolation scope. In other embodiments the launcher accepts as input a specification of the desired isolation scope for example by a command line option.

The rules associated with the desired isolation scope are retrieved step . In some embodiments the rules are retrieved from a persistent storage element such as a hard disk drive or other solid state memory element. The rules may be stored as a relational database flat file database tree structured database binary tree structure or other persistent data structure. In other embodiments the rules may be stored in a data structure specifically configured to store them.

An identifier for the process such as a process id PID and the retrieved rules are stored in a memory element step . In some embodiments a kernel mode driver is provided that receives operating system messages concerning new process creation. In these embodiments the PID and the retrieved rules may be stored in the context of the driver. In other embodiments a file system filter driver or mini filter is provided that intercepts native resource requests. In these embodiments the PID and the retrieved rules may be stored in the filter. In other embodiments still all interception is performed by user mode hooking and no PID is stored at all. The rules are loaded by the user mode hooking apparatus during the process initialization and no other component needs to know the rules that apply to the PID because rule association is performed entirely in process.

The suspended process is resumed step and subsequent calls to access native resources made by the process are intercepted or hooked step and the rules associated with the process identifier if any are used to virtualize access to the requested resource step . In some embodiments a file system filter driver or mini filter or file system driver intercepts requests to access native resources and determines if the process identifier associated with the intercepted request has been associated with a set of rules. If so the rules associated with the stored process identifier are used to virtualize the request to access native resources. If not the request to access native resources is passed through unmodified. In other embodiments a dynamically linked library is loaded into the newly created process and the library loads the isolation rules. In still other embodiments both kernel mode techniques hooking filter driver mini filter and user mode techniques are used to intercept calls to access native resources. For embodiments in which a file system filter driver stores the rules the library may load the rules from the file system filter driver.

Processes that are children of processes associated with isolation scopes are associated with the isolation scopes of their parent process. In some embodiments this is accomplished by a kernel mode driver notifying the file system filter driver when a child process is created. In these embodiments the file system filter driver determines if the process identifier of the parent process is associated with an isolation scope. If so file system filter driver stores an association between the process identifier for the newly created child process and the isolation scope of the parent process. In other embodiments the file system filter driver can be called directly from the system without use of a kernel mode driver. In other embodiments in processes that are associated with isolation scopes operating system functions that create new processes are hooked or intercepted. When request to create a new process are received from such a process the association between the new child process and the isolation scope of the parent is stored.

In some embodiments a scope or sub scope may be associated with an individual thread instead of an entire process allowing isolation to be performed on a per thread basis. In some embodiments per thread isolation may be used for Services and COM servers.

In some embodiments isolation environments are used to provide additional functionality to the application streaming client . In one of these embodiments an application program is executed within an isolation environment. In another of these embodiments a retrieved plurality of application files resides within the isolation environment. In still another of these embodiments changes to a registry on the local machine are made within the isolation environment.

In one embodiment the application streaming client includes an isolation environment . In some embodiments the application streaming client includes a file system filter driver intercepting application requests for files. In one of these embodiments the file system filter driver intercepts an application request to open an existing file and determines that the file does not reside in the isolation environment . In another of these embodiments the file system filter driver redirects the request to the streaming service responsive to a determination that the file does not reside in the isolation environment . The streaming service may extract the file from the plurality of application files and store the file in the isolation environment . The file system filter driver may then respond to the request for the file with the stored copy of the file. In some embodiments the file system filter driver may redirect the request for the file to a file server responsive to an indication that the streaming service has not retrieved the file or the plurality of application files and a determination the file does not reside in the isolation environment . In some embodiments the streaming service may include comprise an acceleration program to perform some or all of the acceleration techniques discussed below to accelerate the storage or delivery of files and applications.

In some embodiments the file system filter driver uses a strict isolation rule to prevent conflicting or inconsistent data from appearing in the isolation environment . In one of these embodiments the file system filter driver intercepting a request for a resource in a user isolation environment may redirect the request to an application isolation environment. In another of these embodiments the file system filter driver does not redirect the request to a system scope.

In one embodiment the streaming service uses IOCTL commands to communicate with the filter driver. In another embodiment communications to the file server are received with the Microsoft SMB streaming protocol.

In some embodiments the packaging mechanism stores in a manifest file a list of file types published as available applications and makes this information available to application publishing software. In one of these embodiments the packaging mechanism receives this information from monitoring an installation of an application program into the isolation environment on the staging machine. In another of these embodiments a user of the packaging mechanism provides this information to the packaging mechanism . In other embodiments application publishing software within the access suite console consults the manifest file to present to a user of the access suite console the possible file types that can be associated with the requested application being published. The user selects a file type to associate with a particular published application. The file type is presented to the local machine at the time of application enumeration.

The local machine may include a client agent . The client agent provides functionality for associating a file type with an application program and selecting a method of execution of the application program responsive to the association. In one embodiment the client agent is a program neighborhood application.

When an application program is selected for execution the local machine makes a determination as to a method of execution associated with a file type of the application program. In one embodiment the local machine determines that the file type is associated with a method of execution requiring an application streaming session for retrieval of the application files and execution within an isolation environment. In this embodiment the local machine may redirect the request to the application streaming client instead of launching a local version of the application program. In another embodiment the client agent makes the determination. In still another embodiment the client agent redirects the request to the application streaming client .

In one embodiment the application streaming client requests access information associated with the application program from the remote machine . In some embodiments the application streaming client receives an executable program containing the access information. In one of these embodiments the application streaming client receives an executable program capable of displaying on the local machine application output data generated from an execution of the application program on a remote machine. In another of these embodiments the application streaming client receives an executable program capable of retrieving the application program across an application streaming session and executing the application program in an isolation environment on the local machine . In this embodiment the application streaming client may execute the received executable program. In still another of these embodiments the remote machine selects an executable program to provide to the local machine responsive to performing an application resolution as described above.

Referring now to a flow diagram depicts one embodiment of steps taken in a method for executing an application. As described above in regarding step a local machine receives and executes the plurality of application files. In brief overview the local machine receives a file including access information for accessing a plurality of application files and for executing a first client capable of receiving an application stream step . The local machine retrieves an identification of the plurality of application files responsive to the file step . The local machine retrieves at least one characteristic required for execution of the plurality of application files responsive to the file step . The local machine determines whether the local machine includes the at least one characteristic step . The local machine executes a second client the second client requesting execution of the plurality of application files on a remote machine responsive to a determination that the local machine lacks the at least one characteristic step .

Referring to and in greater detail the local machine receives a file including access information for accessing a plurality of application files and for executing a first client capable of receiving an application stream step . In one embodiment the local machine receives access information including an identification of a location of a plurality of application files comprising an application program. In another embodiment the local machine receives the file responsive to requesting execution of the application program. In still another embodiment the access information includes an indication that the plurality of application files reside on a remote machine such as an application server or a file server. In yet another embodiment the access information indicates that the local machine may retrieve the plurality of application files from the remote machine over an application streaming session.

The local machine retrieves an identification of the plurality of application files responsive to the file step . In one embodiment the local machine identifies a remote machine on which the plurality of application files reside responsive to the file including access information. In another embodiment the local machine retrieves from the remote machine a file identifying the plurality of application files. In some embodiments the plurality of application files comprise an application program. In other embodiments the plurality of application files comprise multiple application programs. In still other embodiments the plurality of application files comprise multiple versions of a single application program.

Referring ahead to a flow diagram depicts one embodiment of a plurality of application files residing on a remote machine such as file server . In a plurality of application files referred to as a package includes application files comprising three different versions of one or more application programs.

In one embodiment each subset of application files comprising a version of one or more application programs and stored within the package is referred to as a target. Target 1 for example includes a version of a word processing application program and of a spreadsheet program the version compatible with the English language version of the Microsoft Windows 2000 operating system. Target 2 includes a version of a word processing application program and of a spreadsheet program the version compatible with the English language version of the Microsoft XP operating system. Target 3 a version of a word processing application program and of a spreadsheet program the version compatible with the Japanese language version of the Microsoft Windows 2000 operating system with service pack .

Returning now to in some embodiments the file retrieved from the remote machine hosting the plurality of application files includes a description of the package and the targets included in the plurality of application files. In other embodiments the file retrieved from the remote machine identifies the plurality of application files comprising an application program requested for execution by the local machine .

The local machine retrieves at least one characteristic required for execution of the plurality of application files responsive to the file step . In some embodiments the local machine may not execute an application program unless the local machine includes certain characteristics. In one of these embodiments different application programs require local machines to include different characteristics from the characteristics required by other application programs. In another of these embodiments the local machine receives an identification of the at least one characteristic required for execution of the plurality of application files comprising the application program requested by the local machine .

The local machine determines whether the local machine includes the at least one characteristic step . In one embodiment the local machine evaluates an operating system on the local machine to determine whether the local machine includes the at least one characteristic. In another embodiment the local machine identifies a language used by an operating system on the local machine to determine whether the local machine includes the at least one characteristic. In still another embodiment the local machine identifies a revision level of an operating system on the local machine to determine whether the local machine includes the at least one characteristic. In yet another embodiment the local machine identifies an application version of an application program residing on the local machine to determine whether the local machine includes the at least one characteristic. In some embodiments the local machine determines whether the local machine includes a device driver to determine whether the local machine includes the at least one characteristic. In other embodiments the local machine determines whether the local machine includes an operating system to determine whether the local machine includes the at least one characteristic. In still other embodiments the local machine determines whether the local machine includes a license to execute the plurality of application files to determine whether the local machine includes the at least one characteristic.

The local machine executes a second client the second client requesting execution of the plurality of application files on a remote machine responsive to a determination that the local machine lacks the at least one characteristic step . In one embodiment when the local machine determines that the local machine lacks the at least one characteristic the local machine does not execute the first client capable of receiving an application stream. In another embodiment a policy prohibits the local machine from receiving the plurality of application files over an application stream when the local machine lacks the at least one characteristic. In some embodiments the local machine determines that the local machine does include the at least one characteristic. In one of these embodiments the local machine executes the first client the first client receiving an application stream comprising the plurality of application files from a remote machine for execution on the local machine.

In some embodiments the local machine executes the second client requesting execution of the plurality of application files on a remote machine upon determining that the local machine lacks the at least one characteristic. In one of these embodiments the second client transmits the request to a remote machine hosting the plurality of application files. In another of these embodiments the remote machine executes the plurality of application files comprising the application program and generates application output data. In still another of these embodiments the second client receives application output data generated by execution of the plurality of application files on the remote machine. In some embodiments the second client receives the application output data via an Independent Computing Architecture presentation level protocol or a Remote Desktop Windows presentation level protocol or an X Windows presentation level protocol. In yet another of these embodiments the second client displays the application output on the local machine .

In some embodiments the second client transmits the request to a remote machine that does not host the plurality of application files. In one of these embodiments the remote machine may request the plurality of application files from a second remote machine hosting the plurality of application files. In another of these embodiments the remote machine may receive the plurality of application files from the second remote machine across an application streaming session. In still another of these embodiments the remote machine stores the received plurality of application files in an isolation environment and executes the application program within the isolation environment. In yet another of these embodiments the remote machine transmits the generated application output data to the second client on the local machine.

Referring back to in one embodiment the first client capable of receiving the application stream is an application streaming client . The application streaming client receiving the file retrieving an identification of a plurality of application files and at least one characteristic required for execution of the plurality of application files responsive to the file and determining whether the local machine includes the at least one characteristic. In another embodiment the second client is a client agent . In some embodiments the client agent receives the file from the application streaming client responsive to a determination by the application streaming client that the local machine lacks the at least one characteristic.

In some embodiments an application executing on the local machine enumerates files associated with the application using the Win32 FindFirstFile and FindNextFile API calls. In one of these embodiments a plurality of application files comprise the application . In another of these embodiments not all files in the plurality of application files reside on the local machine . In still another of these embodiments the streaming service retrieved the plurality of application file in an archived files but extracted only a subset of the plurality of application files. In yet another of these embodiments the streaming service and the file system filter driver provide functionality for satisfying the enumeration request even when the requested file does not reside on the local machine .

In one embodiment the functionality is provided by intercepting the enumeration requests and providing the data as if all files in the plurality of application files reside on the local machine . In another embodiment the functionality is provided by intercepting by the file system filter driver an enumeration request transmitted as an IOCTL command such as IRP MJ DIRECTORY CONTROL IOCTL. When the file system filter driver intercepts the call the file system filter driver redirects the request to the streaming service . In one embodiment the file system filter driver determines that the requested enumeration resides in an isolation environment on the local machine prior to redirecting the request to the streaming service . In another embodiment the streaming service fulfills the request using a file in the plurality of application files the file including an enumeration of a directory structure associated with the plurality of application files. In still another embodiment the streaming service provides the response to the request to the file system filter driver for satisfaction of the enumeration request.

Referring now to a flow diagram depicts one embodiment of the steps taken in a method for responding locally to requests for file metadata associated with files stored remotely. In brief overview i a directory structure representing an application program stored by the remote machine and ii metadata associated with each file comprising the stored application program are received from a remote machine step . The directory structure and the metadata are stored step . At least one request to access metadata associated with a specific file in the directory structure is received step . The at least one request is responded to using the stored metadata step .

Referring to in greater detail a directory structure representing an application program stored by the remote machine and metadata associated with each file comprising the stored application program are received from a remote machine step . In one embodiment the streaming service receives the directory structure and the metadata. In another embodiment the streaming service receives the directory structure and the metadata when the streaming service retrieves a plurality of application files comprising the stored application program. In still another embodiment the directory structure and the metadata are stored in a file in the plurality of application files.

In one embodiment the metadata associated with each file comprises an alternate name for the at least one file. In another embodiment the metadata associated with each file includes a short name for the at least one file the name having a length of eight characters a dot and a three character extension. In still another embodiment the metadata associated with each file includes a mapping between the alternate name for the at least one file and the short name for the at least one file. In some embodiments a file in the plurality of application files has an alternate filename. In one of these embodiments when the file is retrieved by a streaming service to a local machine the file is associated with a short name responsive to the mapping between the alternate name for the file and the short name for the at least one file.

The directory structure and the metadata are stored step . In one embodiment the directory structure and the metadata are stored in an isolation environment . In another embodiment the directory structure and the metadata are stored in a cache memory element. In still another embodiment the directory structure representing an application program stored by the remote machine is used to generate an enumeration of a directory structure representing an application program executing on the local machine.

At least one request to access metadata associated with a specific file in the directory structure is received step . In one embodiment the request is a request for enumeration of the file. In another embodiment the request is a request to determine whether a copy of the file comprising the stored application program resides locally.

In one embodiment the request is made by an application executing in an isolation environment on a local machine. In another embodiment the request is made by the application streaming client . In still another embodiment the request is made on behalf of the application .

In one embodiment the request is intercepted by a file system filter driver . In another embodiment the request is forwarded to the application streaming client by the file system filter driver . In still another embodiment the request is forwarded to the streaming service by the file system filter driver .

In some embodiments the request is hooked by a function that replaces the operating system function or functions for enumerating a directory. In another embodiment a hooking dynamically linked library is used to intercept the request. The hooking function may execute in user mode or in kernel mode. For embodiments in which the hooking function executes in user mode the hooking function may be loaded into the address space of a process when that process is created. For embodiments in which the hooking function executes in kernel mode the hooking function may be associated with an operating system resource that is used in dispatching requests for file operations. For embodiments in which a separate operating system function is provided for each type of file operation each function may be hooked separately. Alternatively a single hooking function may be provided which intercepts create or open calls for several types of file operations.

The at least one request is responded to using the stored metadata step . In one embodiment the file system filter driver responds to the request. In another embodiment the application streaming client responds to the request. In still another embodiment the streaming service responds to the request. In one embodiment the stored metadata is accessed to respond to the at least one request. In another embodiment the request is responded to with a false indication that a remote copy of the file resides locally.

In one embodiment a Windows Operating System FindFirst operation is satisfied responsive to the received metadata. In another embodiment a Windows Operating System FindNext operation is satisfied responsive to the received metadata. In still another embodiment an operation for identifying a root node in a directory structure is satisfied responsive to the received metadata. In some embodiments an application layer API such as WIN32 FIND DATA API is used to respond to the operation. In other embodiments a kernel layer API such as FILE BOTH DIR INFORMATION is used to respond to the operation.

In one embodiment the metadata satisfies an operation for identifying a time of access associated with a node in a directory structure. In another embodiment the metadata satisfies an operation for identifying a time of modification associated with a node in a directory structure. In still another embodiment the metadata satisfies an operation for identifying a modified node in a directory structure.

Referring now to a block diagram depicts one embodiment of a system for responding locally to requests for file metadata associated with files stored remotely including a streaming service a file system filter driver a directory structure a plurality of application files metadata and a cache memory element . In brief overview the directory structure identifies a plurality of files associated with at least one application program. The metadata is associated with at least one of the plurality of files at least one of the plurality of files residing on a remote machine. In one embodiment the directory structure includes the metadata . The cache memory element stores the directory structure . The file system filter driver intercepts a request to access metadata associated with the at least one remotely stored file accesses the cache memory element and responds to the at least one request using the stored directory structure.

In some embodiments the streaming service receives the directory structure and metadata . In one of these embodiments the directory structure represents a plurality of application files associated with an application program the plurality of application files residing on a remote machine such as the remote machine . In another of these embodiments the metadata comprises information for responding to a Windows Operating System FindFirst request. In still another of these embodiments the metadata comprises information for responding to a Windows Operating System FindNext request. In yet another of these embodiments the metadata comprises information for responding to a request for identification of a root node in a directory structure. In another of these embodiments the metadata comprises information for responding to a request for identification of a node in a directory structure. In some embodiments an application layer API such as WIN32 FIND DATA API is used to respond to the operation. In other embodiments a kernel layer API such as FILE BOTH DIR INFORMATION is used to respond to the operation.

In some embodiments small amounts of metadata about a file may be stored directly in the literal filename such as by suffixing the virtual name with a metadata indicator where a metadata indicator is a string uniquely associated with a particular metadata state. The metadata indicator may indicate or encode one or several bits of metadata. Requests to access the file by virtual filename check for possible variations of the literal filename due to the presence of a metadata indicator and requests to retrieve the name of the file itself are hooked or intercepted in order to respond with the literal name. In other embodiments one or more alternate names for the file may be formed from the virtual file name and a metadata indicator and may be created using hard link or soft link facilities provided by the file system. The existence of these links may be hidden from applications by the isolation environment by indicating that the file is not found if a request is given to access a file using the name of a link. A particular link s presence or absence may indicate one bit of metadata for each metadata indicator or there may be a link with a metadata indicator that can take on multiple states to indicate several bits of metadata. In still other embodiments where the file system supports alternate file streams an alternate file stream may be created to embody metadata with the size of the stream indicating several bits of metadata. In still other embodiments a file system may directly provide the ability to store some 3rd party metadata for each file in the file system. In yet other embodiment a separate sub scope may be used to record deleted files and existence of a file not marked as a placeholder in that sub scope is taken to mean that the file is deleted.

In one embodiment data in a user isolation environment an application isolation environment and a system scope is combined to form a local enumeration of a directory structure representing an application. In another embodiment the streaming service accesses metadata and the directory structure to populate the application isolation environment. In still another embodiment the file system filter driver generates the local enumeration of the directory structure. In yet another embodiment the local enumeration of the directory structure identifies at least one file in the plurality of application files the at least one file residing on a remote machine and not on the local machine. In some embodiments the local enumeration of the directory structure is stored on the cache memory element . In other embodiments the streaming service generates the application isolation environment and the local enumeration of the directory structure.

In one embodiment the file system filter driver intercepts a request transmitted to a system scope for access to the local enumeration of the directory structure. In another embodiment file system filter driver generates the local enumeration after intercepting the request. In still another embodiment the file system filter driver redirects the request for the local enumeration to the user isolation environment. In yet another embodiment the file system filter driver redirects the request for the local enumeration to the application isolation environment.

In some embodiments the file system filter driver intercepts a request for access to a file identifies in the local enumeration of the directory the file residing on a remote machine. In one of these embodiments the file system filter driver requests retrieval of the file by the streaming service as described in greater detail in connection with below.

As applications running in an isolation environment make requests for files a filter driver intercepts these requests. If the request is to open a file the filter driver will first redirect the request to an isolation environment to determine whether the request may be satisfied by the isolation environment. If the call is successful the filter driver will respond to the request with the instance of the file located in the isolation environment.

However if the requested file does not reside in the isolation environment the filter driver sends a request to streaming service to retrieve the file from the plurality of application files blocks until the request is complete and then retries the original open. In some embodiments the functionality of the streaming service for retrieving files from the plurality of application files upon receipt of a request from the filter driver is referred to as on demand caching. 

Referring now to a flow diagram depicts one embodiment of the steps taken in a method for accessing a remote file in a directory structure associated with an application program executing locally. In brief overview a request by an application for access to a file is intercepted step . The request is redirected to a first isolation environment step . A determination is made that the requested file does not exist in the first isolation environment step . The request is redirected to a second isolation environment responsive to a determination that the file is identified in an enumeration of a directory structure associated with a plurality of application files residing on a remote machine step . The requested file is retrieved from the remote machine responsive to a determination that the second isolation environment does not contain the file and that the file is identified in the enumeration step .

Referring to and in greater detail a request by an application for access to a file is intercepted step . In one embodiment the request is intercepted by a file system filter driver. In another embodiment the file system filter driver intercepts all requests for access to files. In still another embodiment an application streaming client intercepts the request. In some embodiments a request by an application for access to an executable file is intercepted. In other embodiments a request by an application for access to a file a portion of the application executing on a local machine is intercepted.

The request is redirected to a first isolation environment step . In one embodiment the application executes within the first isolation environment. In one embodiment the application is an application program such as a word processing program or spreadsheet program. In another embodiment the application is the application streaming client . In still another embodiment the application is a component within the application streaming client attempting to launch an application program on behalf of a user of the local machine . In another embodiment the file system filter driver redirects the request to the first isolation environment.

A determination is made that the requested file does not exist in the first isolation environment step . In one embodiment the file system filter driver receives an indication that the requested file does not exist in the first isolation environment.

The request is redirected to a second isolation environment responsive to a determination that the file is identified in an enumeration of a directory structure associated with a plurality of application files residing on a remote machine step . In one embodiment the enumeration of the directory structure is received with access information regarding execution of the first application. In another embodiment the enumeration identifies a plurality of application files comprising a second application. In this embodiment the first application is a local copy of the second application.

The requested file is retrieved from the remote machine responsive to a determination that the second isolation environment does not contain the file and that the file is identified in the enumeration step . In one embodiment the requested file is retrieved from a second remote machine. In another embodiment the requested file is retrieved from a file server. In some embodiments the enumeration of the directory structure identifies a plurality of application files residing on the local machine. In other embodiments the enumeration of the directory structure indicates that the plurality of application files resides on the local machine. In one of these embodiments when the application requests access to the file in the plurality of application files which the enumeration of the directory structure has indicated resides on the local machine the file is acquired from the file server upon interception of the access request. In another of these embodiments the file server streams the requested file to the local machine. In still another of these embodiments upon receiving the requested file the requested file is stored in the second isolation environment. In still other embodiments when the application requests access to the file in the plurality of application files which the enumeration of the directory structure has indicated resides on the local machine a copy of the file is provided to the application from a local cache.

In some embodiments the requested file is encrypted. In other embodiments the requested file is stored in an encrypted form. In still other embodiments the application requesting the file may be prevented from decrypting the requested file if the application lacks authorization to access the requested file.

In one embodiment a determination is made that the enumeration of the directory structure does not identify the file. In this embodiment the request to access the file may be redirected to an environment outside the first isolation environment and outside the second isolation environment.

In some embodiments a second request to access the file is intercepted. In one of these embodiments the request to access the file is made by a second application. In another of these embodiments the second application executes in a third isolation environment. In still another of these embodiments the request is redirected to the second isolation environment responsive to a determination that the file is enumerated in the enumeration and that the second isolation environment does contain the file. The determination may be made that the local machine stored the file in the second isolation environment upon receipt of the file from the file server. In yet another embodiment the file is stored in the third isolation environment.

Referring now to a block diagram depicts one embodiment of a system for accessing a file in a directory structure associated with an application. In brief overview a local machine includes an application streaming client a streaming service an isolation environment a file system filter driver and a first application . The local machine may interact with a file server a remote machine a web interface and a second application .

The local machine initializes the application streaming client to execute the first application . In one embodiment the application streaming client initializes a streaming service to retrieve and execute the first application . In some embodiments a plurality of application files comprise the first application . in one of these embodiments the streaming service retrieves the plurality of application files and stores them in the isolation environment . In another of these embodiments the streaming service identifies a location of a remote machine on which the plurality of application files resides but does not retrieve the plurality of application files. In still another of these embodiments the streaming service retrieves a subset of the files in the plurality of application files. In yet another of these embodiments the streaming service retrieves an archive file containing the plurality of application files.

In one embodiment the first application comprises a local copy of a second application residing on a remote machine . In another embodiment the plurality of application files reside on the remote machine and comprise the second application residing on a remote machine . In still another embodiment to execute the second application the local machine retrieves the plurality of application files creating the first application on the local machine and executes the first application . In some embodiments the applications and are user applications such as word processing applications or spreadsheet applications or presentation applications.

In some embodiments the plurality of application files include a file identifying a directory structure associated with the plurality of application files on the remote machine . In one of these embodiments the file includes metadata about each application file in the plurality of application files. In another of these embodiments the streaming service retrieves the metadata from the file to generate an enumeration of the directory structure associated with the plurality of application files as described in connection with above. In still another of these embodiments the streaming service stores the enumeration of the directory structure associated with the plurality of application files comprising the second application . In some embodiments the streaming service stores the enumeration in a second isolation environment.

In one embodiment the streaming service retrieves an initial executable file associated with the first application . In another embodiment the streaming service executes the first application on the local machine upon retrieval of the initial executable file. In still another embodiment the first application requests access to other files in the plurality of application files as the files are needed for continued execution of the first application . In some embodiments the first application executes in the isolation environment .

The file system filter driver intercepts requests by the first application executing within the isolation environment for access to a file in the plurality of application files. The file system filter driver redirects the request to the isolation environment . If the requested file resides in the isolation environment access to the requested file is provided to the first application .

If the requested file does not reside in the isolation environment the file system filter driver redirects the request to a second isolation environment. In one embodiment the second isolation environment includes the enumeration of the directory structure generated by the streaming service and associated with the plurality of application files comprising the second application . In another embodiment a determination is made that the requested file is identified in the enumeration of the directory structure.

In some embodiments the streaming service provides a semaphore to the isolation environment . In one of these embodiments the file system filter driver using the semaphore indicates to the streaming service that access to a file in the plurality of application files is required. In other embodiments the file system filter driver uses a thread to indicate to the streaming service that access to the file is required.

Upon receiving the notification from the file system filter driver the streaming service retrieves the requested file from the plurality of application files. In still another of these embodiments the streaming service stores the requested file in the second application isolation environment. In one embodiment the request for access to the file is satisfied with the instance of the file retrieved from the plurality of application files and stored in the second isolation environment. In another embodiment the requested file is also stored in the first isolation environment.

In some embodiments a determination is made that the second isolation environment does not contain the file and that the file is identified in the enumeration. In one of these embodiments the file is identified in the enumeration of the directory structure associated with the plurality of application files comprising the second application and the file is a file in the plurality of application files. In another of these embodiments the streaming service did not retrieve the file from the remote machine. In still another of these embodiments the streaming service did not retrieve a plurality of application files including the requested file. In yet another of these embodiments the streaming service retrieved the plurality of application files in an archived file but did not retrieve the requested file from the archive file.

In one embodiment the streaming service includes a transceiver in communication with the file system filter driver. In another embodiment the transceiver receives the redirected request from the file system filter driver. In still another embodiment the transceiver forwards the request for the file to a remote machine hosting the requested file. In one embodiment the remote machine is a file server . In another embodiment the request is forwarded to a remote machine which routes the request to a file server . In some embodiments the file server streams the requested file to the transceiver on the local machine . In other embodiments the remote machine streams the requested file to the transceiver on the local machine . In still other embodiments upon receiving the requested file from the file server the transceiver stores the received file in the second isolation environment.

In one embodiment the file system filter driver intercepts a second request for access to the file made by a third application executing on the local machine in a third isolation environment. In another embodiment the file system filter driver redirects the request for access to the file to the second isolation environment. In still another embodiment the file system filter driver determines that the streaming service stored the received file in the second isolation environment prior to the interception of the request for access by the third application .

In some embodiments upon initialization the streaming service may populate a cache in an isolation environment prior to execution of an application program. In one of these embodiments the streaming service installs a registry file into the isolation environment. In another of these embodiments the streaming service stores a mapping between a long name of a file and a short file name.

In one embodiment to save space on the local machine the size of the cache may be limited. In some embodiments when the cache nears its size limit the oldest files in the cache will automatically be purged to make room for new files. In one of these embodiments the age of a file is determined by a timestamp maintained by the operating system indicating a time of last access timestamp. In addition to the age of a file the file type may be taken into account binary executable files .EXE .DLL etc may be kept longer than similarly aged files of other types.

Upon initialization the streaming service may enumerate files currently in a cache and determine the total size of the cache. After a file is added to the cache either by an isolation environment or by the streaming service the streaming service calls a function to inform the cache system of the new file its location and its size. The size of each newly cached file is added to the running total of the current cache size. This new total is then compared against the cache size limit and if the limit has been exceeded the code fires off a thread to age the cache. There can only ever be one instance of this thread running at any given time.

The thread generates a list of all files currently in the cache sorts this list by last access timestamp and then starts walking down the list deleting files until we have freed enough disk space to satisfy the exit criteria for the thread. The exit criteria is based on dropping to cache size down to a level below the limit that is determined as a percentage of the limit the default value is 10 . Deleting more than is needed to prevent exceeding the limit prevents the cache from thrashing each time a new file is added.

In some embodiments the streaming service provides the ability to copy every file in a plurality of application files comprising an application program in a compressed file format to the local machine . This ability may be referred to as pre caching. In one of these embodiments when the application program is subsequently executed all the package requests go to the local copy rather than traversing the network. These embodiments may enable a user of the local machine to execute the application program at a time when the user has no access to the network.

A remote machine includes functionality for monitoring application usage by a local machine . The remote machine may monitor the status of each application used by the local machine for example when execution or termination of an application. In one embodiment the remote machine requires the local machine to transmit messages about the status of an application executed by the local machine . In another embodiment when a local machine connects to a network on which the remote machine resides the local machine transmits a message indicating that the local machine has connected to the network.

In one embodiment the local machine is said to have a session when the local machine interacts with the remote machine and executes one or more applications. In another embodiment the remote machine requires the local machine to maintain for the duration of a session a license authorizing execution of applications received from a remote machine. In still another embodiment sessions have unique session identifiers assigned by the remote machine.

In one embodiment the local machine transmits the messages to the remote machine with which is interacted to receive and execute the application program. In another embodiment the local machine receives from the remote machine an identifier of a second remote machine such as a session management server the second remote machine receiving and storing all transmitted messages associated with the session on the local machine .

In some embodiments the session management server is a remote machine providing license management and session monitoring services. In one of these embodiments the session management server includes a server management subsystem providing these services.

In one embodiment the local machine transmits messages directly to the session management server . In another embodiment the local machine transmits messages to a remote machine the remote machine forwarding the messages to the session management server with an identification of the local machine .

A local machine may transmit a heartbeat message to the remote machine . In one embodiment the heartbeat message includes a request for a license. In this embodiment the local machine may transmit the heartbeat message after receiving access information associated with an application program which the local machine requested authorization to execute. The local machine may transmit the heartbeat message prior to executing the application. In one embodiment the local machine includes with the heartbeat message a launch ticket received with the access information. In this embodiment the remote machine may grant the local machine a license upon successful verification of the launch ticket.

In another embodiment the heartbeat message includes an indication that the local machine has initiated execution of an application. In still another embodiment the heartbeat message includes an indication that the local machine has terminated execution of an application. In yet another embodiment the heartbeat message includes an indication of a failure to execute an application.

In one embodiment the heartbeat message includes a request for an identification of a second session management server such as a session management server . In another embodiment the heartbeat message includes an indication that the local machine has connected to a network on which the remote machine resides.

In some embodiments the heartbeat message includes a request to reset an application streaming session. In one of these embodiments the local machine transmits this heartbeat message when an error has occurred and a connection is terminated between a network on which the remote machine resides and the local machine . In another of these embodiments the local machine transmits with the heartbeat message information associated with the session. In still another of these embodiments the remote machine may transmit to the local machine session related data if the session has not expired.

In another of these embodiments if a remote machine disconnects from a network on which it replies the local machine may not receive a reply to a heartbeat message transmitted to the remote machine . In one embodiment the local machine may re establish a session by transmitting a message requesting a session reset to the remote machine . In another embodiment the local machine may re establish a session by transmitting a message requesting a session reset to a second remote machine . In some embodiments when the remote machine reconnects to the network it will create a new session for each session reset request received while the remote machine was disconnected. In one of these embodiments the new session will be associated with the reconnected and unlicensed state. In another of these embodiments no new license will be acquired for the new session. In still another of these embodiments when the local machine executes an application a new license will be acquired and all sessions associated with the local machine will be associated with an active and licensed state.

In some embodiments an application streaming client on the local machine generates the heartbeat message. In one of these embodiments the application streaming client forwards the heartbeat message to a web interface for transmission to the local machine for transmission to the remote machine . In other embodiments the management service on the remote machine receives the heartbeat message from the local machine via the web interface . In still other embodiments a remote machine comprising a collector point described above in connection with receives and stores the heartbeat messages.

In some embodiments the application streaming client requests a license from the remote machine . In one of these embodiments the license authorizes execution of an application program on the local machine . In another of these embodiments the remote machine may access a second remote machine to provide the license. In still another of these embodiments the remote machine may provide the license to the local machine. In yet another of these embodiments the remote machine may provide a license acceptable for authorization purposes to a second remote machine. In some embodiments the license is revoked upon termination of execution of an application program.

In some embodiments a remote machine in the farm includes a license management subsystem for configuring and maintaining licenses for those subsystems that require a license to operate and for controlling the number of connections to such subsystems. In other embodiments the remote machine incorporates functionality of a license management subsystem within other subsystems such as the application management subsystem and the session management subsystem. In one embodiment each remote machine includes a license management subsystem or the functionality associated with a license management subsystem. The license management subsystem manages two types of licenses 1 feature licenses and 2 connection licenses. In brief overview the license management subsystem uses feature licenses to control access to features of licensed software products such as load management and connection licenses to control the number of user connections allowed by those licensed software products. A feature can be some aspect or particular functionality of the software product or the feature can be the entire product that will not work without a feature license.

The license management subsystem communicates with the group subsystem over an event bus to form and maintain a logical grouping of licenses hereafter license groups to facilitate license pools assignments and groups. A license group includes a collection of license strings described below and or other license groups. License groups collect licenses of similar features and consequently enable pooling of licenses. A pooled license is a license that is available for use by any remote machine in the farm . Each license group holds the collective capabilities of the licenses in the license group and the other license subgroups i.e. other license groups within a license group . Information relating to license pools is in one embodiment maintained in the dynamic store . In this embodiment each license management subsystem stores locally the total number of licenses and the number of license assigned to a remote machine in the farm . Upon granting a pooled license the granting license management subsystem makes an entry in the dynamic store indicating that a pooled license is in use. Every other license management subsystem recognizes that such pooled license is unavailable for granting. In one particular embodiment the dynamic store store remote machine ID client ID pairs associated with each license group to identify pooled licenses that are in use.

The relationship subsystem maintains associations between licenses and remote machines and between license groups and remote machines . The associations define the number of licenses for each license and license group that only the associated remote machine may obtain i.e. local licenses . A local license is a license that is assigned to one remote machine in the farm and is not shared by other remote machines . The license management subsystem communicates with the relationship subsystem to create delete query and update such associations. The common access point subsystem provides remote procedure calls RPCs for use by software products residing on the remote machine . These RPC interfaces enable such software products to communicate through the common access subsystem to access licensing information.

Still referring to the specialized remote machine subsystem communicates with the license management subsystem to obtain a feature license for each capability of the specialized remote machine subsystem for which a license is required. This occurs at initialization of specialized remote machine subsystem and after any license event. If unable to obtain the feature license the specialized remote machine subsystem restricts the functionality that the subsystem would provide with a license. Also the specialized remote machine subsystem uses the license management subsystem to obtain client connection licenses whenever a client session is initiated with the remote machine .

The license management subsystem communicates with the persistent store system service module to store feature and connection licenses in a license repository as license strings formed in accordance with a naming convention. The license repository resides in the persistent store . Cyclical redundancy checks CRC prevent tampering of the licenses while such licenses are stored in the license repository . The license management subsystem also stores information related to the license strings in the license repository . For example the information may indicate which licenses are assigned to which remote machines of the farm and in some embodiments the activation status of each license. In one embodiment a connection license table stores identifiers of those local machines that have obtained a connection license.

In one embodiment the license management subsystem supports events from subsystems requesting use of a licensed capability such as a request for an available pooled license. The event includes the UID of the subsystem requesting the license and the UID of the remote machine upon which that subsystem resides. The event also contains the license type requested i.e. feature or connection license in the form of a license group ID. The actual license group ID stored in the persistent store is arbitrary but adherence to the naming convention provides flexibility for the future addition of new software products i.e. subsystems to the remote machine .

The event sent by a requesting subsystem seeking a license includes 1 an indication of the license group type the identity of the local machine and remote machine requesting the license and a force acquire flag. An indication of license group type may include identification of a feature license such as a load management or a connection type license such as a software application product. The field identifying the local machine and remote machine seeking the license may include the unique identifier associated with the remote machine and the local machine. The force acquire flag may be used for example to reacquire connection licenses after a license change event. A license change event indicates that licensing information in the persistent store has changed for example a license has been deleted added or assigned. Upon a license change event each remote machine attempts to reacquire all connection licenses that it possessed before the license change event because the particular cause of the license change event is unknown to that remote machine. This flag if set indicates that a connection license must be acquired even if doing so increases the number of connections to the remote machine in excess of the predetermined maximum number of allowable connections. No new connection licenses are subsequently granted until the number of connection licenses in use drops below this predetermined maximum number. In this manner a local machine connection will not be terminated in mid session due to a license change event.

Referring now to a block diagram depicts one embodiment of the components involved in licensing enforcement. A remote machine includes a server management subsystem and a license management subsystem . In some embodiments the server management subsystem and the license management subsystem provide the functionality of the license management subsystem described above. In other embodiments an application management subsystem and a session management subsystem provide the functionality of the license management subsystem described above. In still other embodiments other subsystems provide the functionality of the license management subsystem described above.

In one embodiment the server management subsystem may include a licensing component used to request issuance and revocation of licenses. In another embodiment the license management subsystem may apply a policy to a request for issuance or revocation of a license received from the server management subsystem . In still another embodiment the license management subsystem may transmit the request to a remote machine providing license enforcement functionality. In some embodiments the management service may maintain a connection with a second remote machine providing license enforcement functionality. In other embodiments the remote machine provides the license enforcement functionality.

In some embodiments a license expires and ceases to be valid upon a failure of the local machine to transmit a predetermined number of heartbeat messages to the remote machine. In one of these embodiments expiration of the license revokes authorization for execution of an application program by the local machine .

In other embodiments a session times out upon the expiration of a predetermined period of time. In one embodiment the management service maintains session related data after the expiration of a license until an expiration of a session. In some embodiments the session related data may include information such as session name session id client id client name session start time server name UNC Path of File Server application name Unique name generated by local machine based on browser name alias name session state active licensed active unlicensed reconnected unlicensed . In another embodiment the local machine ceases transmission of heartbeat messages and restarts transmission of heartbeat messages at a later point in time. In still another embodiment the management service may reissue a license and make the maintained session related data available to the local machine if the local machine restarts transmission of heartbeat messages prior to the expiration of the session.

Referring now to a flow diagram depicts one embodiment of the steps taken to request and maintain a license from a remote machine for the duration of a session on a local machine . In brief overview an application streaming client requests a license step . A remote machine receives the request for the license verifies a ticket associated with the request and generates a license step . The remote machine provides the license and information associated with the license to the local machine step . The local machine executes the application as described above in connection to step in . The local machine transmits a heartbeat message indicating that the local machine has executed an application step . The remote machine receives the heartbeat message and verifies identifying information transmitted with the heartbeat message step . The remote machine creates a session associated with the executed application and with the local machine step . A result of creating the session is transmitted to the local machine step . The local machine transmits heartbeat messages throughout the execution of the application as described above in connection with step of . The local machine receives a response to a transmitted heartbeat message step . The local machine transmits a heartbeat message indicating a termination of an execution of the application step . The remote machine receives the heartbeat message and determines whether to remove session related data and whether to release the license associated with the local machine and the terminated application step . A result of the determination made by the remote machine is transmitted to the local machine step .

Referring now to and in greater detail an application streaming client on a local machine requests a license step . In some embodiments the local machine requests the license upon receiving access information associated with an application program. In one of these embodiments the local machine requests a license from the remote machine granting authorization for execution of the application program by the local machine . In some embodiments the request for the license includes a launch ticket received from the remote machine with the access information. In other embodiments an application streaming client on the local machine transmits the request to a web interface and the web interface transmits the request to the remote machine . In still other embodiments a session management subsystem on the remote machine receives and processes the request for the license.

A remote machine receives the request for the license verifies a ticket associated with the request and generates a license step . In one embodiment the remote machine verifies that the local machine is authorized to execute the application. In another embodiment the remote machine determines whether the local machine is already associated with an existing license. In still another embodiment the remote machine determines that the local machine is associated with an existing license and provides the local machine with an identifier for a session management server managing the existing license. In yet another embodiment the remote machine generates and provides to the local machine a new license a session identifier and an identification of a session management server managing the new license.

In some embodiments the remote machine uses a license management subsystem to respond to a license request in an embodiment in which. The license management subsystem receives a license request. The request can be for a feature license or for a connection license. The license management subsystem determines if the license has already been granted i.e. the feature has already been started or a connection for a local machine already exists. If the license is already granted the license management subsystem sends a grant event to the license requestor. If the license has not been previously granted the license management subsystem determines if a local license i.e. a license that has been permanently assigned to the remote machine is available. In some embodiments the license management subsystem performs this determination by checking local memory. If a local license is available i.e. the remote machine has more licenses permanently assigned than currently granted the license management subsystem sends a grant event to the license requestor.

The remote machine provides the license and information associated with the license to the local machine step . In one embodiment upon receiving the license the session identifier and the identification of the session management server from the remote machine the local machine executes the application. The local machine may execute the application as described above in connection to step in . The local machine transmits a heartbeat message indicating that the local machine has executed an application step . In one embodiment the local machine transmits the heartbeat message to the remote machine for transmission of the heartbeat message to a session management server . In another embodiment the local machine transmits a heartbeat message directly to a session management server responsive to an identifier of the session management server received from the remote machine .

The remote machine receives the heartbeat message and verifies identifying information transmitted with the heartbeat message step . In one embodiment a remote machine is the session management server . In another embodiment the session management server verifies a server identifier provided with the heartbeat message by the local machine . In still another embodiment the server identifier is the identifier provided to the local machine by a remote machine .

The remote machine creates a session associated with the executed application and with the local machine step . In one embodiment the session management server creates a new session associated with the executing application upon receiving the heartbeat message. In another embodiment a third remote machine creates the new session. In some embodiments the session management server stores session related information upon the creation of the new session.

A result of creating the session is transmitted to the local machine step . In some embodiments the result confirms the creation of the session. In other embodiments the result identifies the application or applications associated with the session. The local machine transmits heartbeat messages throughout the execution of the application as described above in connection with step of . In one embodiment the local machine continues to transmit heartbeat messages at regular intervals to the session management server at periodic intervals throughout the execution of the application program. The local machine receives a response to a transmitted heartbeat message step . In one embodiment the local machine receives a confirmation of receipt of the heartbeat messages from the session management server . In another embodiment the local machine receives a command for execution from the session management server responsive to the receipt of a heartbeat message by the session management server .

The local machine transmits a heartbeat message indicating a termination of an execution of the application step . The remote machine receives the heartbeat message and determines whether to remove session related data and whether to release the license associated with the local machine and the terminated application step . A result of the determination made by the remote machine is transmitted to the local machine step .

Referring now to a block diagram depicts one embodiment of states that may be associated with a session monitored by a management service . In one embodiment a session maintenance subsystem on the management service monitors a session of a local machine and assigns a state to the session. In another embodiment the session maintenance subsystem maintains a list of license related data which may include an identifier associated with the local machine an identifier associated with the session a session state and a timestamp indicating the last time the remote machine received a message from the local machine . In some embodiments the session maintenance subsystem includes a session monitoring thread. In one of these embodiments the session monitoring thread awakens at a periodic license timeout interval to scan the list of license related data and update the session status of a session.

A first state that a session may be in is an active and licensed state. In one embodiment when in this state the local machine has maintained a valid license authorizing execution of an application. In another embodiment a session management server maintains session related data. In some embodiments the session management server stores the session related data on a second remote machine. In one embodiment when a local machine initially executes an application the session for the local machine is in the active and licensed state.

A second state that a session may be in is an active and unlicensed state. In one embodiment a session is in this state when the local machine fails to transmit heartbeat messages and a license to the local machine has expired. In another embodiment if a session is in this state then while the license has expired insufficient time has elapsed for the session to expire and the session is considered active. In some embodiments while a session is in this state a remote machine or a session management server may store session related data on behalf of the local machine . In other embodiments if a local machine transmits a heartbeat message prior to the expiration of the session session related data is transmitted to the local machine with a new license and the session returns to the active and licensed state. In one embodiment a remote machine uses session identifiers and identifiers associated with the local machine to verify that the session has not expired and to provide the local machine with the appropriate session related data.

A third state that a session may be in is a disconnected and non existent state. When a session expires session related data is deleted.

A fourth state that a session may be in is a reconnected and unlicensed state. In one embodiment when a session on a local machine expires session related data is deleted. In another embodiment when the local machine transmits a new heartbeat message a new session identifier and local machine identifier are generated for the local machine . In some embodiments the local machine re authenticates to the remote machine receives a new license and enters the active and licensed state.

In some embodiments a packaging mechanism enables creation of a plurality of application files associated with an application program. In one of these embodiments the packaging mechanism enables identification of a plurality of application files. In another of these embodiments the packaging mechanism enables grouping of individual application files into the plurality of application files. In still another of these embodiments the packaging mechanism enables hosting of the plurality of application files on a remote machine such as a file server or application server.

In one embodiment the packaging mechanism executes on a remote machine described as a staging machine. In another embodiment the packaging mechanism executes on a clean machine. A clean machine may be a remote machine having only an operating system installed on it without additional software drivers registry entries or other files. In still another embodiment the packaging machine executes on a remote machine the remote machine resembling a local machine on which an application program may execute. In some embodiments the remote machine on which the packaging mechanism executes includes an isolation environment providing a clean machine environment into which an application may be installed even where the remote machine is not itself a clean machine.

In one embodiment the plurality of application files is referred to as a package. In another embodiment the package may be an archive file storing the plurality of application files. In still another embodiment the package may be an archive file storing the plurality of application files and a file including metadata associated with at least one file in the plurality of application files. In some embodiments a package includes a plurality of application files comprising an application program. In other embodiments a package includes a plurality of application files comprising a suite of application programs. In yet other embodiments a package includes a plurality of application files comprising an application program and a prerequisite required for execution of the application program.

In one embodiment the packaging mechanism initiates execution of an installation program in an isolation environment. In another embodiment the packaging mechanism monitors a change to the isolation environment generated by the installation program. In still another embodiment the packaging mechanism monitors a creation by the installation program of a file in the isolation environment. In yet another embodiment the packaging mechanism monitors a modification by the installation program of a file in the isolation environment. In some embodiments the plurality of application files includes a file created or modified by the installation program. In other embodiments the packaging mechanism implements a file system filter driver to monitor the isolation environment.

In some embodiments a packaging mechanism may generate multiple pluralities of application files each comprising a different version of an application program configured for execution in a different target environment. In one of these embodiments a plurality of application files is configured to execute on a local machine having a particular operating system revision level language configurations and master drive e.g. one plurality of application files may be configured to execute on a local machine having the Windows XP Professional operating system with revision level SP2 and above using English and having a master Drive C . In another of these embodiments more than one plurality of application files may be combined in a single archive file. In still another of these embodiments each plurality of application files may be referred to as a target. In yet another of these embodiments an archive file containing one or more pluralities of application files may be referred to as a package. 

Referring now to a block diagram depicts a package including two targets each target comprising a plurality of application files comprising an application. In the application program Foo is packaged in two targets. The difference between the two targets is Target Language . Specifically target 1 supports English and target 2 supports German . In one embodiment an enumeration of available application programs may list the application program Foo. In another embodiment the appropriate plurality of files is transmitted to a local machine requesting access to the application program. In still another embodiment a determination is made to transmit a particular target to a local machine responsive to an evaluation of the local machine. In yet another embodiment a file associated with the package identifies at least one characteristic associated with a target in the package and required for execution on a local machine.

In some embodiments the packaging mechanism prepares an application program for streaming by executing an installation program associated with the application program. In one of these embodiments the packaging mechanism generates an isolation environment on the remote machine on which the packaging mechanism executes. In another of these embodiments the packaging mechanism executes the application program in the isolation environment. In still another of these embodiment the packaging mechanism identifies a plurality of application files generated or modified by the installation program. In yet another of these embodiment the packaging mechanism creates an archive file including the plurality of application files. In one of these embodiments the packaging mechanism creates a .CAB file including the plurality of application files. In another of these embodiments the packaging mechanism creates a directory and stores the plurality of application files in the directory. In some embodiments the packaging mechanism stores the plurality of application files on a file server or other remote machine . In other embodiments the packaging mechanism stores the plurality of application files on multiple remote machines.

Referring now to a flow diagram depicts one embodiment of the steps taken in a policy based method for effectively installing an application program without rebooting an operating system. In brief overview a packaging mechanism executes an installer program within an isolation environment the installer program installing at least one application file associated with a second application into the isolation environment step . A call by the installer program to at least one application programming interface API is intercepted the call requiring performance of an action after a reboot of an operating system step . The action of the at least one intercepted call is executed without reboot of the operating system step . An identification of a file type of the at least one application file is received step . At least one execution method is associated with the at least one installed application file responsive to the identified file type step . The at least one installed application file is stored on at least one server step . An enumeration is generated of the second application the at least one installed application file a location of the at least one server and the at least one execution method step .

Referring now to and in greater detail a packaging mechanism executes an installer program within an isolation environment the installer program installing at least one application file associated with a second application into the isolation environment step . In one embodiment executing the installer program within the isolation environment enables the packaging mechanism to isolate changes made by the installer program to a file or registry on the local machine. In another embodiment the packaging mechanism intercepts a change requested by the installer program and redirects the change to the isolation environment to prevent the change from occurring on the local machine. In still another embodiments the packaging mechanism executes a second installer program within the isolation environment the second application installing at least one application file associated with a third application into the isolation environment.

In some embodiments the packaging mechanism executes the installer program within the isolation environment the installer program executing at least one executable application associated with an application inside the isolation environment. In one embodiment in which the installer executes an application execution of the application enables installation of a second application.

In another of these embodiments installation of an application requires execution of the at least one executable application in addition to the execution of the installer program. In still another of these embodiments installation of an application requires execution of an Internet browser application in addition to the execution of the installer program. In some embodiments an installer program is executed to install a program and execution of the installer program includes execution of a second program required to install the program. In one of these embodiments the program is a plug in. In another of these embodiments the program is an Active X component. In still another of these embodiments the program is a Flash component. In yet another of these embodiments the program is a customized toolbar such as a Yahoo or Google toolbar. In other embodiments the program is a component installed into the second program and not executable independent of the second program.

A call by the installer program to at least one application programming interface API is intercepted the call requiring performance of an action after a reboot of an operating system step . The action of the at least one intercepted call is executed without reboot of the operating system step . In some embodiments execution of the action comprises executing an action of a registry entry modified during installation. Further details regarding the execution of the at least one intercepted call without reboot of the operating system are provided in connection with below.

An identification of a file type of the at least one application file is received step . At least one execution method is associated with the at least one installed application file responsive to the identified file type step . In one embodiment the at least one execution method enables streaming of the at least one application file to a client. In another embodiment the at least one execution method enables execution of the at least one installed application file on a client. In still another embodiment the at least one execution method enables execution of the at least one installed application file on a server. In yet another embodiment the at least one execution method enables streaming of the at least one application file to a server.

The at least one installed application file is stored on at least one server step . In some embodiments the installed application program is executed within the isolation environment prior to storing the at least one installed application file on at least one server. In one of these embodiments an additional application file is generated responsive to the execution of the installed application program. In another of these embodiments a data file is generated. In still another of these embodiments the installed application program requires information to complete installation the information being required after an initial installation process. In yet another of these embodiments information such as software product identifiers license identifiers or other credentials is required.

In some embodiments an identifier is provided identifying a location of the at least one installed application file on the at least one server. In one of these embodiments the identifier conforms to a Universal Naming Convention UNC . In other embodiments the at least one installed application file is placed in an archive file such as a .CAB file. In one of these embodiments a plurality of application files are stored in an archive file and the archive file is stored on the at least one server. In still another of these embodiments the at least one installed application file is stored on multiple servers. In still other embodiments the at least one application file is placed in a directory storing application files.

An enumeration is generated of the second application the at least one installed application file a location of the at least one server and the at least one execution method step . In some embodiments the enumeration is stored in a file. In other embodiments the enumeration is stored in a manifest file. In still other embodiments the enumeration is stored in an XML file.

In one embodiment an enumeration is generated of multiple applications a plurality of installed application files associated with each of the multiple application and a location of at least one server storing the plurality of installed application files. In another embodiment a enumeration is generated including an association between the second application and a plurality of installed application files. In still another embodiment an enumeration is generated including an association between the second application and a compressed file containing the at least one installed application file

Referring now to a flow diagram depicts one embodiment of the steps taken in a policy based method for installing an application program without rebooting an operating system. In brief overview a packaging mechanism executes an installer program within an isolation environment the installer program installing at least one application file associated with a second application into the isolation environment step . A call by the installer program to at least one application programming interface API is intercepted the call requiring performance of an action after a reboot of an operating system step . The action of the at least one intercepted call is executed without reboot of the operating system step . An identification of a characteristic of the at least one application file is received step . At least one execution pre requisite is associated with the at least one installed application file responsive to the identified characteristic step . The at least one installed application file is stored on at least one server step . An enumeration is generated of the second application the at least one installed application file a location of the at least one server and the at least one execution pre requisite step .

Referring now to and in greater detail a packaging mechanism executes an installer program within an isolation environment the installer program installing at least one application file associated with a second application into the isolation environment step . In one embodiment executing the installer program within the isolation environment enables the packaging mechanism to isolate changes made by the installer program to a file or registry on the local machine. In another embodiment the packaging mechanism intercepts a change requested by the installer program and redirects the change to the isolation environment to prevent the change from occurring on the local machine. In still another embodiments the packaging mechanism executes a second installer program within the isolation environment the second application installing at least one application file associated with a third application into the isolation environment.

In some embodiments the packaging mechanism executes the installer program within the isolation environment the installer program executing at least one executable application associated with an application inside the isolation environment. In one embodiment in which the installer executes an application execution of the application enables installation of a second application. In another of these embodiments installation of an application requires execution of the at least one executable application in addition to the execution of the installer program. In still another of these embodiments installation of an application requires execution of an Internet browser application in addition to the execution of the installer program.

Referring ahead to a block diagram depicts one embodiment of a system including a packaging mechanism executing an installer program into an isolation environment and a file system filter driver in communication with the packaging mechanism and the isolation environment .

In one embodiment the packaging mechanism generates a package as described above in connection with by installing an application program into an isolation environment . In another embodiment the packaging mechanism installs the application program into the isolation environment by executing the installer program . In some embodiments the packaging mechanism includes a graphical user interface. In one of these embodiments the graphical user interface enables a user of the packaging mechanism to customize the generation of a package by the packaging mechanism . In another of these embodiments the packaging mechanism is in communication with a graphical user interface on the access control suite enabling a user of the access control suite to customize the generation of a package by the packaging mechanism .

In some embodiments the file system filter driver enables the installation of the application program in an isolation environment . In one of these embodiments the file system filter driver intercepts a request by the installer program . In another of these embodiments the file system filter driver redirects the request by the installer program to the isolation environment . In still another of these embodiments the file system filter driver stores a record of the request made by the installer program . In yet another of these embodiments the file system filter driver stores a copy of a file created or modified by the installer program . In some embodiments the stored records generated by the file system filter driver are stored together as a plurality of application files comprising an application program. In other embodiments the plurality of application files is stored on a file server .

Referring back to a call by the installer program to at least one application programming interface API is intercepted the call requiring performance of an action after a reboot of an operating system step . The action of the at least one intercepted call is executed without reboot of the operating system step . In some embodiments execution of the action comprises installation of a driver configured to be started upon the boot of the computer system. In other embodiments execution of the action comprises executing an action of a registry entry modified during installation.

An identification of a characteristic of the at least one application file is received step . In some embodiments an identification of an operating system type is received. In other embodiments an identification of a language used by operating system is received. In still other embodiments an identification of a version of the second application is received.

At least one execution pre requisite is associated with the at least one installed application file responsive to the identified characteristic step . In one embodiment the at least one execution pre requisite is associated with the at least one installed application file responsive to an application of a policy to the characteristic. In another embodiment a script is associated with the at least one installed application file the script comprising an executable program determining the existence of the at least one execution pre requisite on a client. Referring ahead to a screen shot depicts one embodiment of an enumeration of scripts to be executed on the local machine. A type of script indicates when the script should be executed for example either before the execution of the application or after termination of execution of the application. An isolation indicator indicates whether the script should be executed in an isolation environment on the local machine . As shown in in some embodiments the script was associated with the application program at the time the plurality of application files were packaged together and stored on the remote machine hosting the plurality of application files.

In some embodiments the at least one execution pre requisite requires installation of a version of an operating system on a system executing the at least one installed application file. In other embodiments the at least one execution pre requisite requires installation of a version of the second application on a system executing the at least one installed application file. In still other embodiments an instruction is associated with the at least one installed application file the instruction indicating a second installed application file for use by a client failing to satisfy the at least one execution pre requisite. In yet other embodiments an instruction is associated with the at least one installed application file the instruction indicating a second execution method for execution of the at least one installed application file on a client failing to satisfy the at least one execution pre requisite. In one of these embodiments an execution method is associated with the at least one installed application file the execution method authorizing streaming of a plurality of application files comprising the second application to a local machine for execution on the local machine. In another of these embodiments an evaluation of a local machine identifies at least one characteristic associated with the at least one installed application file not included on the local machine. In still another of these embodiments authorization for execution of the plurality of application files is revoked. In yet another of these embodiments a second execution method is provided for executing the plurality of application files the second execution method enabling execution of the plurality of application files on a remote machine and transmission of application output data from the remote machine to the local machine.

The at least one installed application file is stored on at least one server step . In some embodiments the installed application program is executed within the isolation environment prior to storing the at least one installed application file on at least one server. In one of these embodiments an additional application file is generated responsive to the execution of the installed application program. In another of these embodiments a data file is generated. In still another of these embodiments the installed application program requires information to complete installation the information being required after an initial installation process. In yet another of these embodiments information such as software product identifiers license identifiers or other credentials is required.

In some embodiments an identifier is provided identifying a location of the at least one installed application file on the at least one server. In one of these embodiments the identifier conforms to a Universal Naming Convention UNC . In other embodiments the at least one installed application file is placed in an archive file such as a .CAB file. In one of these embodiments a plurality of application files are stored in an archive file and the archive file is stored on the at least one server. In still another of these embodiments the at least one installed application file is stored on multiple servers. In still other embodiments the at least one installed application file is placed in a directory storing application files.

An enumeration is generated of the second application the at least one installed application file a location of the at least one server and the at least one execution pre requisite step . In some embodiments the enumeration is stored in a file. In other embodiments the enumeration is stored in a manifest file. In still other embodiments the enumeration is stored in an XML file.

In one embodiment an enumeration is generated of multiple applications a plurality of installed application files associated with each of the multiple application and a location of at least one server storing the plurality of installed application files. In another embodiment a enumeration is generated including an association between the second application and a plurality of installed application files. In still another embodiment an enumeration is generated including an association between the second application and a compressed file containing the at least one installed application file

Referring back to step where an action of the at least one intercepted call is executed without reboot of the operating system in some embodiments a virtualized installation and execution environment is provided that removes the requirement of rebooting the system before executing an installed application.

Referring now to a flow chart depicts an embodiment in which execution of an installer program requires rebooting of an operating system on a local machine on which the installer program executes. A conventional application installer copies files onto a remote machine where the application is being installed step . In some embodiments copying the files may cause a reboot of the remote machine. The application installer attempts to copy at least one of the files to locked files step . In one embodiment a locked file may only be written to when an operating system is executed or rebooted . The MOVE FILE DELAY UNTIL REBOOT option is set in the MoveFileEx Win32 API step and the application installer calls system shutdown reboot function step . Following a reboot the originally locked files are then installed upon reboot step .

Referring now to a block diagram depicts one embodiment of a remote machine onto which a packaging mechanism installs an application program. The remote machine includes system resources system APIs and an application installer used to install an application. The remote machine also includes a function hooking mechanism a post install processor module and an application isolation environment . In some embodiments installing an application program into an isolation environment enables installation without reboot of the remote machine . In one of these embodiments a change made to a system resource virtualized in an isolation environment does not change a corresponding system resource on the remote machine . Since the system resource on the remote machine is not changed rebooting the machine to protect the system resource from inappropriate changes is not required.

Referring now to and in greater detail the system resources may include registry entries system DLLs and other locked files that the operating system prevents from being written to while the remote machine is executing. The system APIs include APIs used to reboot the system that are called by the application installer and hooked by the function hooking mechanism to prevent the rebooting of the remote machine .

The application isolation environment provides an environment with a view of operating system resources to an application installer . In one embodiment the application isolation environment is an isolation environment . In some embodiments the application isolation environment provides virtualization of operating system resources such as the file system registry and named objects. In one embodiment the application installer executes within the application isolation environment . In another embodiment the application installer installs the application program into the application isolation environment . In still another embodiment the application installer executes outside the application isolation environment and installs the application program inside the application isolation environment .

In some embodiments the application isolation environment circumvents the requirement for rebooting the remote machine when the application installer installs an application into the application isolation environment . In one embodiment the application isolation environment intercepts a request to copy an application file to a locked file. In another embodiment the application isolation environment redirects the request to copy the application file to an unlocked file. In still another embodiment the application isolation environment redirects the request to copy the application file to a virtualized file. In yet another embodiment redirecting the request to copy the application file enables installation of application files without requiring a reboot of the remote machine . As an example if an application installer attempts to write to a locked file such as c windows system32 mfc40.dll the application isolation environment intercepts the request and redirect the file to another unlocked location. This ability to avoid locked files means the file can be installed without having to make use of the MoveFileEx API and MOVE FILE DELAY UNTIL REBOOT flag. This ability in removes the need for a reboot of the remote machine .

In one embodiment the function hooking mechanism is a file system filter driver . In another embodiment a file system filter driver includes the function hooking mechanism . In still another embodiment the function hooking mechanism intercepts requests from the application installer to restart the remote machine . In some embodiments the application isolation environment provides for copying of application files to unlocked files. However the application isolation environment does not address a request by the application installer for reboot of the remote machine . The function hooking mechanism intercepts the request for reboot and responds to the application installer .

The application isolation environment enables copying of application files to unlocked files. However in some embodiments other actions are required for installation of an application and these actions may occur upon the reboot. Preventing the reboot does not prevent the need to complete these actions in the installation process. The function hooking mechanism may provide functionality for carrying out an action associated with an installation of an application

For example during the installation of an application registry entries such as HKLM SYSTEM CurrentControlSet Control Session Manager Pending FileRenameOperations may be written. Other applications may install services or drivers which need to be started upon boot of a machine. The Post Install Processor Module identifies application files that have been modified during installation and carries out the actions associated with the application files.

Referring now to a flow diagram depicts one embodiment of the steps followed to install an application in an application isolation environment . The application isolation environment provides a virtualized view of the server operating system to the application installer step . The APIs on the server relating to system reboots and shutdowns are hooked step to prevent the application installer from causing a reboot. The application installer requests file copying operations to locked files the request being intercepted and redirected to non conflicting locations step . When the application installer attempts to reboot by calling a system API the request is intercepted and the reboot is prevented step . The post install processor module performs actions that ordinarily occur after reboot step and the application may then be executed in the application isolation environment without reboot of a remote machine step .

In some embodiments following installation of the application program into the application isolation environment a packaging mechanism identifies a plurality of application files created or modified during installation of an application program. In one of these embodiments the plurality of application files are stored on a remote machine. In another of these embodiments a local machine retrieving the plurality of application files may execute the application program.

In some embodiments the packaging mechanism executes on a remote machine including an isolation environment and a file system filter driver and installs an application program into the isolation environment . In one of these embodiments the remote machine is referred to as a clean machine or a staging machine. In another of these embodiments the isolation environment includes an application isolation scope providing a modifiable virtualized instance of a native resource provided by an operating system on the clean machine. In still another of these embodiments the isolation environment includes a system isolation scope providing a read only view of the native resource. In yet another of these embodiments the read only view of the native resource comprises a snapshot of a file system and registry residing on the clean machine.

In one embodiment a redirector intercepts a request for a change to the native resource. In some embodiments the redirector is a file system filter driver . In another embodiment an installer program executed by the packaging mechanism makes the request for the change. In still another embodiment the change to the native resource is required to install an application program on to the clean machine. In yet another embodiment the redirector redirects the request to the isolation environment .

In some embodiments redirecting requests to change native resources to the isolation environment results in isolation of changes associated with installation of an application program. In other embodiments the requests to change native resources are recorded and stored in a storage element. In one of these embodiments all changes associated with installation of an application program reside in the storage element. In another of these embodiments a local machine retrieving the contents of the storage element and implementing the changes to native resources residing in an isolation environment on the local machine result in installation of the application program on the local machine .

In some embodiments a pre launch analysis of the local machine may be required. In one of these embodiments the local machine verifies that at least one characteristic is included in the local machine . In another of these embodiments the at least one characteristic is added to the local machine after the pre launch analysis determines that the local machine lacks the at least one characteristic. In still another of these embodiments the at least one characteristic is included in a remote machine hosting an application program and failure of the local machine to include the at least one characteristic will prevent execution of the application program. In yet another embodiment the application program requires existence of the at least one characteristic on the local machine for execution.

In some embodiments the packaging mechanism enables identification of at least one characteristic for use in a pre launch analysis on the local machine. In other embodiments the packaging mechanism enables association of at least one characteristic with an application program available for execution on the local machine. In still other embodiments the packaging mechanism enables association of an executable script with an application program the local machine executing the executable script to complete the pre launch analysis. In yet other embodiments the at least one characteristic is required to exist on the local machine after the execution of the application program.

The packaging mechanism may provided functionality for signing a plurality of application files. In one embodiment signing the plurality of application files enables a local machine to verify integrity of the plurality of application files. In another embodiment signing the plurality of application files prevents a local machine from executing a corrupted application program. In some embodiments a cryptographic checksum such as an MD4 hash an MD5 hash or a SHA 1 hash of a file in the plurality of application files is computed.

In other embodiments a cryptographic checksum of every file in the plurality of application files is computed. In one of these embodiments the cryptographic checksum is stored in a second file. In another of these embodiments the second file is associated with the plurality of application files. In some embodiments the second file is added to the plurality of application files. In other embodiments the second file is signed using a certificate such as an X.509 certificate. In still other embodiments a local machine retrieving the plurality of application files verifies the signature using a public portion of the certificate. In yet other embodiments the local machine receives the public portion of the certificate and an identification of a certificate trust list for verification of the signature. In one of these embodiments local machine receives a registry key containing the identification of a certificate trust list.

In one embodiment the packaging mechanism provides functionality for customizing an isolation environment. In another embodiment the packaging mechanism provides functionality for generating a file storing a definition of an isolation environment. In still another embodiment the packaging mechanism includes the file with the plurality of application files comprising an application program. In yet another embodiment a local machine receives the file with access information from a remote machine.

In some embodiments a plurality of application files are stored in an archive file. In one of these embodiments the archive file is in a CAB file format. In another of these embodiments the archive file format does not provide support for specification by an application program of a short file names of a file. In still another of these embodiments an operating system such as WINDOWS 2000 may not provide support for specification by an application program of a short file names of a file. In other embodiments an operating system such as WINDOWS XP provides support for specification by an application program of a short file name of a file. In one of these embodiments a request to execute the file must include the correct short file name of the file.

In one embodiment a mapping may be generated to associate a long file name of a file in the plurality of application files with a short name of the file. In another embodiment the mapping is stored in a file in the plurality of application files. In still another embodiment a file has a short file name only if the long file name of the file is longer than twelve characters. In some embodiments the short file name is a virtual file name associated with the file. In one of these embodiments the file is transmitted to a local machine for execution where it is stored with a long file name. In another of these embodiments an application file on the local machine requests execution of the file using the short file name. In still another of these embodiments the mapping enables execution of the file although the request for execution of the file did not use the name of the file on the local machine the long file name .

In some embodiments the packager mechanism generates the mapping. In one of these embodiments the packager mechanism selects a short file name for a file having a long file name. In another of these embodiments an operating system on the remote machine on which the packager mechanism is executing selects a short file name for a file having a long file name. In still another of these embodiments a unique short file name is selected that does not conflict with a second short file name on the remote machine . In yet another of these embodiments the installer program executed by the packager mechanism generates a file including a mapping between a long file name with a short file name. In other embodiments the mapping is transmitted to a local machine retrieving the file. In one of these embodiments the local machine refers to the file when executing the file.

The following illustrative examples show how the methods and systems discussed above can be used for selecting streaming to a local machine and executing on the local machine a plurality of files comprising an application program. These examples are meant to illustrate and not to limit.

In one embodiment a user of a local machine requests access to an application program such as a word processing program a web browsing application or a spreadsheet program identified in an enumeration of application programs. In one example of this embodiment the local machine executes a program neighborhood application that receives from a remote machine an enumeration of applications available to the local machine . In another example of this embodiment the local machine communicates with a web server such as remote machine to receive the enumeration of applications. The user of the local machine may request access to an enumerated application program by selecting a graphical depiction representing the enumerated application program. The user of the local machine may request access to an application program not previously installed on the local machine .

The local machine transmits the request to access the application program to a remote machine . The local machine receives an identification of a remote machine providing access to a plurality of application files comprising the application program. The local machine identifies at least one characteristic required for execution of the application program. In one example of this embodiment the local machine receives the at least one characteristic with the identification of the remote machine transmitted to the local machine by the remote machine . In another example of this embodiment the local machine retrieves the at least one characteristic from the remote machine after receiving the identification of the remote machine . The local machine may be required to comprise the at least one characteristic prior to receiving authorization to retrieve the plurality of application files. Alternatively the local machine may be required to comprise the at least one characteristic prior to executing the plurality of application files. In one example of this embodiment the local machine may be required to comprise the at least one characteristic throughout the execution of the plurality of application files.

Upon verification by the local machine that the local machine includes the at least one characteristic the local machine retrieves a least one application file in the plurality of application files and executes the retrieved application file to execute the application program.

A remote machine receives a request to access an application program from a local machine . The remote machine authenticates the local machine . In one example of this embodiment the remote machine requests credentials such as a user name and password from the local machine . In another example of this embodiment the remote machine transmits a collection agent to the local machine . The collection agent gathers information about the local machine and transmits the information to the remote machine for use in authenticating the local machine . In still another example of this embodiment the remote machine provides information about the local machine to a policy engine for authentication of the local machine . The remote machine may comprise the policy engine . Alternatively the remote machine may be in communication with a remote machine comprising the policy engine .

The remote machine selects a method of execution of the application program. The remote machine may make the selection responsive to the authentication of the local machine . In one example of this embodiment the remote machine applies a policy to information gathered about the local machine . In another example of this embodiment the remote machine makes the selection responsive to a policy applied to the application program. In still another example of this embodiment the remote machine makes the selection responsive to a policy applied to a file type associated with the application program. The remote machine may consult a file to make the selection of the method of execution of the application program.

The remote machine may select a method of execution of the application program enabling the local machine to receive application output data generated by execution of the application program on a remote machine . The remote machine may select a method of execution of the application program enabling the local machine to execute the application program locally after retrieving a plurality of application files comprising the application program.

In one embodiment the remote machine selects a method of execution of the application program enabling the local machine to execute the application program locally while retrieving a plurality of application files comprising the application program across an application streaming session. In one example of this embodiment the local machine establishes an application streaming session with a remote machine hosting a plurality of application files the local machine initiates retrieval of the plurality of application files across the application streaming session and the local machine executes a retrieved first application file in the plurality of application files while retrieving a second application file in the plurality of application files. In another example of this embodiment the local machine executes a first application file in the plurality of application files and retrieves a second application file in the plurality of applications upon receiving a request from the first application file for access to the second application file.

For embodiments in which the selected method of execution enables the local machine to retrieve at least one application file in a plurality of application files comprising an application program the remote machine identifies a remote machine hosting the application program available for access by the local machine . The remote machine hosts a plurality of application files comprising the application program. The remote machine may host multiple pluralities of application files comprising various application programs. In one example of this embodiment the remote machine hosts a plurality of application files for each of several different versions of an application program.

The remote machine hosts a file associating a plurality of application files comprising a particular application program with a description of the application program. The file may also identify one or more execution pre requisites to be identified on a machine prior to the transmission of the plurality of application files to the machine. The file may further include an identification of a location on a network of the remote machine . In one example of this embodiment the remote machine consults the file to identify the location on the network of the remote machine .

The remote machine selects a remote machine . The remote machine may select a remote machine having a location on a network accessible to the local machine . The remote machine may select a remote machine hosting a version of the application program compatible with the local machine . The remote machine transmits an identification of the selected method of execution of the application program and an identification of the remote machine to the local machine in response to receiving the request for access to the application program. The remote machine may also transmit the file to the local machine .

In one embodiment the local machine receives an identification of a selected method of execution of an application program and an identification of a remote machine providing access to a plurality of application files comprising the application program. The local machine verifies authorization of access to the application program. In one example of this embodiment the local machine performs a pre launch analysis of itself. The local machine identifies at least one characteristic and verifies the existence of the at least one characteristic on the local machine . The at least one characteristic may be a pre requisite to maintaining authorization to access and execute the application program. Verifying the existence of the at least one characteristic on the local machine may ensure compatibility between characteristics of the local machine and the system requirements of the application program and may additionally ensure compliance with security policies or licensing agreements.

Upon successful completion of a pre launch analysis the local machine establishes an application streaming session with the remote machine providing access to the plurality of application files. The application streaming session may be any connection over which the local machine may request and receive a file in the plurality of application files. Establishment of the application streaming session may enable the local machine to execute a first application file in the plurality of application files prior to retrieval of all files in the plurality of application files. The local machine may initiate execution of the application program while continuing retrieval of additional application files in the plurality of application files. Alternatively the local machine may retrieve the plurality of application files in an archive file and execute a first extracted application file while extracting a second application file from the archive file.

In one embodiment an application streaming client on a local machine retrieves a plurality of application files from a remote machine . The application streaming client includes a streaming service an isolation environment and a file system filter driver . The streaming service establishes an application streaming session with the remote machine for requesting and retrieving the plurality of application files. The streaming service executes the application files within the isolation environment . The file system filter driver enables execution of application files within the isolation environment by intercepting requests from the execution application files and redirecting the requests to the isolation environment .

In one example of this embodiment the streaming service retrieves an archive file including the plurality of application files comprising an application program. The streaming service extracts from the archive file a first application file from the plurality of application files. The first application file may be an executable file. The streaming service may execute the first application file within the isolation environment . Execution of the first application file may initiate execution of the application program.

In another embodiment a first application file executing within the isolation environment requests from the local machine an enumeration of the plurality of application files. The file system filter driver intercepts the request for the enumeration and redirects the request to the streaming service . In embodiments where the streaming service retrieved the plurality of application files the streaming service may generate an enumeration of the plurality of application files. In embodiments where the streaming service retrieved an archive file including the plurality of application files the streaming service may generate the enumeration of the plurality of application files responsive to an enumeration included in the retrieved archive file. In other embodiments the streaming service retrieves only the enumeration of the plurality of application files while at least one application file in the plurality of application files resides on a remote machine and has not yet been retrieved to the local machine by the streaming service . In these embodiments the streaming service may generate an enumeration of the plurality of application files responsive to the retrieved enumeration. In one example of these embodiments the streaming service indicates to the first application file that the plurality of application files resides on the local machine although only the enumeration resides on the local machine .

In one embodiment a first application file executing within the isolation environment requests from the local machine access to a file identified by the enumeration of the plurality of application files. If the requested file resides in a user scope within the isolation environment accessible to the first application file the first application file accesses the requested file.

If the requested file does not reside in the user scope or in the isolation environment the file system filter driver intercepts the request and redirects the request to the streaming service . If the requested file is a file within the archive file containing the plurality of application files the streaming service extracts the requested file and stores the requested file on the local machine . The streaming service may store the file within the isolation environment . The request for the file is satisfied when the file is stored in the isolation environment .

If the requested file does not reside in the isolation environment or in the archive file including the plurality of application files the streaming service requests the file from the remote machine . The streaming service may receive the file from the remote machine across an application streaming session. The streaming service stores the received file in the isolation environment . The request for the file is satisfied when the file is stored in the isolation environment .

In one example of this embodiment a second application file executes in a second user scope in the isolation environment . The second application file requests access to the file originally requested by the first application file. If a copy of the requested file does not reside in the second user scope the copy of the requested file stored in the isolation environment is used to satisfy the request for the application file.

In one embodiment a local machine receives from a remote machine an identification of a selected method of execution of an application program and an identification of a remote machine providing access to a plurality of application files comprising the application program. The local machine successfully completes a pre launch analysis of the local machine . The local machine receives a license from the remote machine authorizing execution of the application program. In one example of this embodiment the license requires the local machine to transmit heartbeat messages to a session management server to maintain authorization to execute the application program. Heartbeat messages may include messages indicating initiation of execution of an application program termination of execution of an application program and messages sent on a periodic basis throughout the execution of the application program. Heartbeat messages may also include messages about the status of the local machine such as when the local machine connects to a network or when the local machine terminates a connection to a network. In another example of this embodiment the license specifies a pre determined period of time during which the local machine has authorization to execute the application program.

The local machine establishes an application streaming session with the remote machine and retrieves at least one of the application files in the plurality of application files. During execution of the at least one application file in embodiments where the received license requires transmission of heartbeat messages the local machine sends heartbeat messages to the session management server to maintain authorization to execute the at least one application file.

In one embodiment the local machine receives an identification of a selected method of execution of an application program and an identification of a remote machine providing access to a plurality of application files comprising the application program. The local machine successfully completes a pre launch analysis of the local machine . The local machine receives a license specifying a pre determined period of time during which the local machine has authorization to execute the application program.

The local machine establishes an application streaming session with the remote machine and retrieves at least one of the application files in the plurality of application files. In one example of this embodiment the local machine retrieves a subset of the plurality of application files the subset comprising each file necessary to execute the application program when the local machine is not connected to a network. The local machine stores the subset in a cache on the local machine .

At a point in time within the pre determined period of time the local machine is disconnected from a network and receives from a user of the local machine a request for access to the application program. In one example of this embodiment the local machine is a device such as a laptop and the user of the local machine is in an environment prohibiting connections to networks such as an airplane. Upon receiving the request from the user the local machine may retrieve from the cache an application file from the plurality of application files and execute the application program.

In another embodiment the local machine receives an identification of a selected method of execution of an application program and an identification of a remote machine providing access to a plurality of application files comprising the application program. The local machine may receive an identification of a first client agent residing on the local machine to execute to retrieve the plurality of application files such as an application streaming client.

In one example of this embodiment the local machine fails to successfully complete a pre launch analysis of itself. The local machine may lack a characteristic required for compatibility with a requirement of the application program such as a particular device driver or operating system. The local machine may lack a characteristic required for compliance with a security policy for example membership in a particular Active Directory or authorization for access to a private network. The local machine may be a type of machine incompatible with a requirement of the application program such as a personal digital assistant attempting to access a computationally intensive application program or a public machine at a kiosk attempting to execute a secure application hosted by a remote machine on a private network.

The local machine makes a determination not to retrieve the plurality of application files across the application streaming session responsive to the determination that the local machine lacks the at least one characteristic required for access to the application program. The local machine executes a second client agent residing on the local machine instead of executing the identified first client agent. In one example of this embodiment the local machine receives an identification of the second client agent to execute in the event of failure to successfully complete the pre launch analysis. The local machine requests execution of the application program on a remote machine . The second client agent receives application output data generated by the execution of the application program on the remote machine . The second client agent displays the application output data on the local machine .

In one embodiment an administrator of a network provides access to an application program for users of local machines . The administrator executes an application on a remote machine to generate a plurality of application files comprising the application program. The application may include a graphical user interface. The administrator may use the graphical user interface to identify the application program and an installer program associated with the application program define policies to be applied in authorizing access to the application program and specify characteristics about the type of access provided including requirements to be satisfied by a local machine attempting to access or execute the application program. The administrator may identify an installer program installing an entire application program or a portion of an application program such as an upgrade or patch.

In one example of this embodiment a remote machine includes a packaging mechanism . The packaging mechanism executes the installer program within an isolation environment on the remote machine . Execution of the installer program results in installation into the isolation environment of at least one application file associated with the application program. The remote machine may include a file system filter driver which ensures the installation of the application file into the isolation environment by intercepting a request by the installer program to install the application file on the local machine and redirecting the request to the isolation environment . The packaging mechanism may use the file system filter driver to maintain a record of each application file installed into the isolation environment .

The installer program may install a plurality of application files into the isolation environment . The packaging mechanism generates a file including an enumeration of application files in the plurality of application files. The file may include information associated with the plurality of application files such as the type of application program the plurality of application files comprise the version of the application program execution pre requisites associated with the application program and policy requirements such as a method of execution required for a particular application program. The packaging mechanism stores on a remote machine the plurality of application files and the file.

In one embodiment the administrator of the network identifies an application program comprising an updated version of an existing application program or application file in a plurality of application files comprising an application program.

An embodiment of the present invention is directed towards systems and methods for accelerating client server communications. These systems and methods may be used alone or in concert and may be used in conjunction with any of the systems and methods for delivering a computing environment discussed above. In particular four general categories of acceleration techniques will be discussed.

1. Caching of Dynamically Generated Objects In some embodiments client server communications are accelerated by an appliance performing caching of dynamically generated objects in a data communication network.

2. Connection Pooling In some embodiments client server communications are accelerated by an appliance performing connection pooling techniques.

3. Integrated Caching In another embodiment client server communications are accelerated by an appliance performing caching integrated with a plurality of acceleration techniques.

4. Client side Acceleration In yet another embodiment client server communications are accelerated by a program executing on a client performing one or more acceleration techniques.

As will be described in more detail herein in one embodiment an appliance may integrate caching functionality at the kernel level of the operating system with one or more other processing tasks including but not limited to decryption decompression or authentication and or authorization. Such an example architecture is described herein in accordance with but other architectures may be used in practicing the operations described herein.

Hardware layer provides the hardware elements upon which programs and services within kernel space and user space are executed. Hardware layer also provides the structures and elements which allow programs and services within kernel space and user space to communicate data both internally and externally with respect to appliance . As shown in the hardware layer includes a processing unit for executing software programs and services a memory for storing software and data network ports for transmitting and receiving data over a network and an encryption processor for performing functions related to Secure Sockets Layer processing of data transmitted and received over the network. In some embodiments the central processing unit may perform the functions of the encryption processor in a single processor. Additionally the hardware layer may comprise multiple processors for each of the processing unit and the encryption processor . Although the hardware layer of appliance is generally illustrated with an encryption processor processor may be a processor for performing functions related to any encryption protocol such as the Secure Socket Layer SSL or Transport Layer Security TLS protocol. In some embodiments the processor may be a general purpose processor GPP and in further embodiments may be have executable instructions for performing processing of any security related protocol.

Although the hardware layer of appliance is illustrated with certain elements in the hardware portions or components of appliance may comprise any type and form of elements hardware or software of a computing device such as the computing device illustrated and discussed in conjunction with herein. In some embodiments the appliance may comprise a server gateway router switch bridge or other type of computing or network device and have any hardware and or software elements associated therewith.

The operating system of appliance allocates manages or otherwise segregates the available system memory into kernel space and user space . In example software architecture the operating system may be any type and or form of Unix operating system. As such the appliance can be running any operating system such as any of the versions of the Microsoft Windows operating systems the different releases of the Unix and Linux operating systems any version of the Mac OS for Macintosh computers any embedded operating system any network operating system any real time operating system any open source operating system any proprietary operating system any operating systems for mobile computing devices or network devices or any other operating system capable of running on the appliance and performing the operations described herein.

The kernel space is reserved for running the kernel including any device drivers kernel extensions or other kernel related software. As known to those skilled in the art the kernel is the core of the operating system and provides access control and management of resources and hardware related elements of the application . In accordance with an embodiment the kernel space also includes a number of network services or processes working in conjunction with a cache manager . sometimes also referred to as the integrated cache the benefits of which are described in detail further herein. Additionally the embodiment of the kernel will depend on the embodiment of the operating system installed configured or otherwise used by the device .

In one embodiment the device comprises one network stack such as a TCP IP based stack for communicating with the client and or the server . In one embodiment the network stack is used to communicate with a first network such as network and a second network . In some embodiments the device terminates a first transport layer connection such as a TCP connection of a client and establishes a second transport layer connection to a server for use by the client e.g. the second transport layer connection is terminated at the appliance and the server . The first and second transport layer connections may be established via a single network stack . In other embodiments the device may comprise multiple network stacks for example and and the first transport layer connection may be established or terminated at one network stack and the second transport layer connection on the second network stack . For example one network stack may be for receiving and transmitting network packet on a first network and another network stack for receiving and transmitting network packets on a second network. In one embodiment the network stack comprises a buffer for queuing one or more network packets for transmission by the appliance .

As shown in the kernel space includes the cache manager a high speed layer 2 7 integrated packet engine an encryption engine a policy engine and multi protocol compression logic . Running these components or processes and in kernel space or kernel mode instead of the user space improves the performance of each of these components alone and in combination. Kernel operation means that these components or processes and run in the core address space of the operating system of the device . For example running the encryption engine in kernel mode improves encryption performance by moving encryption and decryption operations to the kernel thereby reducing the number of transitions between the memory space or a kernel thread in kernel mode and the memory space or a thread in user mode. For example data obtained in kernel mode may not need to be passed or copied to a process or thread running in user mode such as from a kernel level data structure to a user level data structure. In another aspect the number of context switches between kernel mode and user mode are also reduced. Additionally synchronization of and communications between any of the components or processes and can be performed more efficiently in the kernel space .

In some embodiments any portion of the components and may run or operate in the kernel space while other portions of these components and may run or operate in user space . In one embodiment a kernel level data structure is used to provide access to any portion of one or more network packets for example a network packet comprising a request from a client or a response from a server . In some embodiments the kernel level data structure may be obtained by the packet engine via a transport layer driver interface or filter to the network stack . The kernel level data structure may comprise any interface and or data accessible via the kernel space related to the network stack network traffic or packets received or transmitted by the network stack . In other embodiments the kernel level data structure may be used by any of the components or processes and to perform the desired operation of the component or process. In one embodiment a component and is running in kernel mode when using the kernel level data structure while in another embodiment the component and is running in user mode when using the kernel level data structure. In some embodiments the kernel level data structure may be copied or passed to a second kernel level data structure or any desired user level data structure.

The cache manager may comprise software hardware or any combination of software and hardware to provide cache access control and management of any type and form of content such as objects or dynamically generated objects served by the originating servers . The data objects or content processed and stored by the cache manager may comprise data in any format such as a markup language or communicated via any protocol. In some embodiments the cache manager duplicates original data stored elsewhere or data previously computed generated or transmitted in which the original data may require longer access time to fetch compute or otherwise obtain relative to reading a cache memory element. Once the data is stored in the cache memory element future use can be made by accessing the cached copy rather than refetching or recomputing the original data thereby reducing the access time. In some embodiments the cache memory element nat comprise a data object in memory of device . In other embodiments the cache memory element may comprise memory having a faster access time than memory . In another embodiment the cache memory element may comprise any type and form of storage element of the device such as a portion of a hard disk. In some embodiments the processing unit may provide cache memory for use by the cache manager . In yet further embodiments the cache manager may use any portion and combination of memory storage or the processing unit for caching data objects and other content.

Furthermore the cache manager includes any logic functions rules or operations to perform any embodiments of the techniques described herein. For example the cache manager includes logic or functionality to invalidate objects based on the expiration of an invalidation time period or upon receipt of an invalidation command from a client or server . In some embodiments the cache manager may operate as a program service process or task executing in the kernel space and in other embodiments in the user space . In one embodiment a first portion of the cache manager executes in the user space while a second portion executes in the kernel space . In some embodiments the cache manager can comprise any type of general purpose processor GPP or any other type of integrated circuit such as a Field Programmable Gate Array FPGA Programmable Logic Device PLD or Application Specific Integrated Circuit ASIC .

The policy engine may include for example an intelligent statistical engine or other programmable application s . In one embodiment the policy engine provides a configuration mechanism to allow a user to identifying specify define or configure a caching policy. Policy engine in some embodiments also has access to memory to support data structures such as lookup tables or hash tables to enable user selected caching policy decisions. In other embodiments the policy engine may comprise any logic rules functions or operations to determine and provide access control and management of objects data or content being cached by the appliance in addition to access control and management of security network traffic network access compression or any other function or operation performed by the appliance . In some embodiments the policy engine may be integrated with functionality of the policy engine . In one embodiment the policy engine may determine caching policy decisions based on information provided by a collection agent . In some embodiments the policy engine may determine caching policy decisions based on a type of application execution. In one embodiment the policy engine may determine caching policy decisions based on whether an application is being streamed to a client . Further examples of specific caching policies are further described herein.

The encryption engine comprises any logic business rules functions or operations for handling the processing of any security related protocol such as SSL or TLS or any function related thereto. For example the encryption engine encrypts and decrypts network packets or any portion thereof communicated via the appliance . The encryption engine may also setup or establish SSL or TLS connections on behalf of the client server or appliance . As such the encryption engine provides offloading and acceleration of SSL processing. In one embodiment the encryption engine uses a tunneling protocol to provide a virtual private network between a client and a server . In some embodiments the encryption engine is in communication with the Encryption processor . In other embodiments the encryption engine comprises executable instructions running on the Encryption processor .

The multi protocol compression engine comprises any logic business rules function or operations for compressing one or more protocols of a network packet such as any of the protocols used by the network stack of the device . In one embodiment multi protocol compression engine compresses bi directionally between clients and servers any TCP IP based protocol including Messaging Application Programming Interface MAPI email File Transfer Protocol FTP HyperText Transfer Protocol HTTP Common Internet File System CIFS protocol file transfer Independent Computing Architecture ICA protocol Remote Desktop Protocol RDP Wireless Application Protocol WAP Mobile IP protocol and Voice Over IP VoIP protocol. In other embodiments multi protocol compression engine provides compression of Hypertext Markup Language HTML based protocols and in some embodiments provides compression of any markup languages such as the Extensible Markup Language XML . In one embodiment the multi protocol compression engine provides compression of any high performance protocol such as any protocol designed for appliance to appliance communications. In another embodiment the multi protocol compression engine compresses any payload of or any communication using a modified transport control protocol such as Transaction TCP T TCP TCP with selection acknowledgements TCP SACK TCP with large windows TCP LW a congestion prediction protocol such as the TCP Vegas protocol and a TCP spoofing protocol.

As such the multi protocol compression engine accelerates performance for users accessing applications via desktop clients e.g. Microsoft Outlook and non Web thin clients such as any client launched by popular enterprise applications like Oracle SAP and Siebel and even mobile clients such as the Pocket PC. In some embodiments the multi protocol compression engine by executing in the kernel mode and integrating with packet processing engine accessing the network stack is able to compress any of the protocols carried by the TCP IP protocol such as any application layer protocol.

High speed layer 2 7 integrated packet engine also generally referred to as a packet processing engine or packet engine is responsible for managing the kernel level processing of packets received and transmitted by appliance via network ports . The high speed layer 2 7 integrated packet engine may comprise a buffer for queuing one or more network packets during processing such as for receipt of a network packet or transmission of a network packer. Additionally the high speed layer 2 7 integrated packet engine is in communication with one or more network stacks to send and receive network packets via network ports . The high speed layer 2 7 integrated packet engine works in conjunction with encryption engine cache manager policy engine and multi protocol compression logic . In particular encryption engine is configured to perform SSL processing of packets policy engine is configured to perform functions related to traffic management such as request level content switching and request level cache redirection and multi protocol compression logic is configured to perform functions related to compression and decompression of data.

The high speed layer 2 7 integrated packet engine includes a packet processing timer . In one embodiment the packet processing timer provides one or more time intervals to trigger the processing of incoming i.e. received or outgoing i.e. transmitted network packets. In some embodiments the high speed layer 2 7 integrated packet engine processes network packets responsive to the timer . The packet processing timer provides any type and form of signal to the packet engine to notify trigger or communicate a time related event interval or occurrence. In many embodiments the packet processing timer operates in the order of milliseconds such as for example 100 ms 50 ms or 25 ms. For example in some embodiments the packet processing timer provides time intervals or otherwise causes a network packet to be processed by the high speed layer 2 7 integrated packet engine at a 10 ms time interval while in other embodiments at a 5 ms time interval and still yet in further embodiments as short as a 3 2 or 1 ms time interval. The high speed layer 2 7 integrated packet engine may be interfaced integrated or in communication with the encryption engine cache manager policy engine and multi protocol compression engine during operation. As such any of the logic functions or operations of the encryption engine cache manager policy engine and multi protocol compression logic may be performed responsive to the packet processing timer and or the packet engine . Therefore any of the logic functions or operations of the encryption engine cache manager policy engine and multi protocol compression logic may be performed at the granularity of time intervals provided via the packet processing timer for example at a time interval of less than or equal to 10 ms. For example in one embodiment the cache manager may perform invalidation of any cached objects responsive to the high speed layer 2 7 integrated packet engine and or the packet processing timer . In another embodiment the expiry or invalidation time of a cached object can be set to the same order of granularity as the time interval of the packet processing timer such as at every 10 ms

In contrast to kernel space user space is the memory area or portion of the operating system used by user mode applications or programs otherwise running in user mode. A user mode application may not access kernel space directly and uses service calls in order to access kernel services. As shown in user space of appliance includes a graphical user interface GUI a command line interface CLI shell services health monitoring program and daemon services . GUI and CLI provide a means by which a system administrator or other user can interact with and control the operation of appliance such as via the operating system of the appliance and either is user space or kernel space . The GUI may be any type and form of graphical user interface and may be presented via text graphical or otherwise by any type of program or application such as a browser. The CLI may be any type and form of command line or text based interface such as a command line provided by the operating system. For example the CLI may comprise a shell which is a tool to enable users to interact with the operating system. In some embodiments the CLI may be provided via a bash csh tcsh or ksh type shell. The shell services comprises the programs services tasks processes or executable instructions to support interaction with the appliance or operating system by a user via the GUI and or CLI .

Health monitoring program is used to monitor check report and ensure that network systems are functioning properly and that users are receiving requested content over a network. Health monitoring program comprises one or more programs services tasks processes or executable instructions to provide logic rules functions or operations for monitoring any activity of the appliance . In some embodiments the health monitoring program intercepts and inspects any network traffic passed via the appliance . In other embodiments the health monitoring program interfaces by any suitable means and or mechanisms with one or more of the following the encryption engine cache manager policy engine multi protocol compression logic packet engine daemon services and shell services . As such the health monitoring program may call any application programming interface API to determine a state status or health of any portion of the appliance . For example the health monitoring program may ping or send a status inquiry on a periodic basis to check if a program process service or task is active and currently running. In another example the health monitoring program may check any status error or history logs provided by any program process service or task to determine any condition status or error with any portion of the appliance .

Daemon services are programs that run continuously or in the background and handle periodic service requests received by appliance . In some embodiments a daemon service may forward the requests to other programs or processes such as another daemon service as appropriate. As known to those skilled in the art a daemon service may run unattended to perform continuous or periodic system wide functions such as network control or to perform any desired task. In some embodiments one or more daemon services run in the user space while in other embodiments one or more daemon services run in the kernel space.

Dynamic content such as one or more dynamically generated objects may be generated by servers referred to as application or originating servers and or back end databases that process object requests from one or more clients local or remote as depicted in . As those applications or databases process data including data related to inputs received from clients the response objects served by these databases and applications may change. Prior objects generated by those applications or databases in an originating server will no longer be fresh and therefore should no longer be stored by a cache. For example given the same set of inputs a dynamically generated object of a first instance may be different than a dynamically generated object of a second instance. In another example the same object may be dynamically generated with a different set of inputs such that a first instance of the object is generated differently from a second instance of the object.

In order to achieve improved network performance the appliance is designed and configured to addresses the problems that arise in caching dynamically generated content through a variety of methods as described in detail below. In some embodiments described herein the appliance incorporates a set of one or more techniques for making the invalidation of dynamically generated content stored in the cache more efficient and effective. Furthermore the appliance may incorporate techniques for performing control and caching for flash crowds. Cache memories typically store every response to a request for an object as long as such response is not marked as non cacheable. As described herein efficient caching of dynamically generated contents requires techniques that enable the timely invalidation of objects in the cache memory that have undergone a change at the originating server. Timely invalidation allows the cache to avoid serving stale content a task of particular concern with dynamically generated content especially where changes to the content occur irregularly. Set forth below are a number of techniques to ensure timely invalidation of dynamically generated content.

In one aspect caching of dynamically generated objects is related to techniques of integrating functions logic or operations of the cache manager policy engine encryption engine and or the multi protocol compression engine with packet processing operations of the high speed layer 2 7 integrated packet engine responsive to the packet processing timer . For example the operations of the cache manager can be performed within the time intervals of the packet processing timer used for packet processing operations such as on a receipt or transmit of a network packet. In one embodiment by integrating with the packet processing operations and or using the packet processing timer the cache manager can cache objects with expiry times down to very small intervals of time as will be described in further detail below. In other embodiments the cache manager responsive to the packet processing timer can also receive an invalidation command to invalidate an object within a very short time period of caching the object.

The method depicted in illustrates one embodiment of a technique for requesting the cache manager policy engine encryption engine and or the multi protocol compression engine to perform an operation during processing or in association with the time intervals for processing a network packet by the high speed layer 2 7 integrated packet engine or packet processing engine . In brief overview at step of method the device receives a network packet or is requested to transmit a network packet. At step the device requests the packet processing engine to process the network packet responsive to the packet processing timer . As part of or associated with packet processing operations at step the packet processing engine requests the cache manager policy engine encryption engine and or the multi protocol compression engine to perform an operation on a cached object. At step the cache manager policy engine encryption engine and or the multi protocol compression engine performs the requested operation which may include any one or combination of the techniques described herein. In one embodiment the cache manager determines invalidation of a cached object and marks the cached object invalid. In some embodiments the cache manager flushes the invalid object in response to a request by the packet processing engine . As the cache manager is performing these operations responsive to the packet processing timer invalidation of objects can occur within time periods in the order of milliseconds and with objects having an expiry in the order of the time intervals provided by the packet processing timer such as 10 ms.

In further detail of method at step the appliance receives one or more network packets and or transmits one or more network packets. In some embodiments the appliance requests to transmit one or more network packets over the network or network . In another embodiment the appliance receives a network packet on one port and transmits a network packet on the same port or a different port . In some embodiments the packet engine of the appliance transmits or requests to transmit one or more network packets. In one embodiment the appliance receives or transmits a packet on a first network while in another embodiment the appliance receives or transmits a packet on a second network . In other embodiments the appliance receives and transmits packets on the same network . In some embodiments the appliance receives and or transmits networks packets to one or more clients . In other embodiments the appliance receives and or transmits networks packets to one or more servers .

At step the device may request or trigger packet processing operations of the packet processing engine upon receipt of a network packet at the network port of the device or upon request to transmit a network packet from the device or upon any combination of receipt and or transmit of one or more network packets. In some embodiments the packet processing operations of the packet processing engine are triggered via a signal provided by a packet processing timer . In one embodiment the packet processing timer may provide interrupt driven or event driven timer functionality related to the receipt and or transmission of one or more network packets. In some embodiments the packet processing timer is driven by a rate of receipt and or transmit of network packets via the device or by the rate by which each packet or a batch of packets are processed. As such the packet processing timer may be triggered and reset after each set of one or more packet processing operations. In another embodiment the packet processing timer provides time intervals either equal or variable time intervals to trigger wake up or signal the packet processing engine to perform a function or operation such as handling a received packet or transmitting a submitted packet. As discussed above in connection with the device of the packet processing timer may operate in the order of milliseconds such as causing time intervals or triggering of packet processing operations at intervals of 10 ms or less. The granular timer functionality of the packet processing timer may be provided in various ways and used in operations of the packet processing operations of the packet processing engine .

At step of method the packet processing engine requests one or more of the cache manager policy engine encryption engine and or the multi protocol compression engine to perform an operation. In one embodiment the packet processing engine or packet processing timer generates a signal or signals to one or more of the cache manager policy engine encryption engine and or the multi protocol compression engine . The packet processing engine may request or signal the operation at any point before during or after a packet processing operation of a network packet or one or more packets. In one embodiment the packet processing engine makes the request upon trigger of the packet processing timer or expiration of a time interval provided by the packet processing timer and before performing a packet processing operation on a network packet. In another embodiment during the course of performing one or more packet processing operations the packet processing engine makes the request. For example during execution of an operation such as within a function call the packet processing engine may make an application programming interface API call to one of the cache manager policy engine encryption engine and or the multi protocol compression engine . In other embodiments the packet processing engine makes the request upon completion of a network packet processing operation.

At step the requested operation is performed by one or more of the cache manager policy engine encryption engine and or the multi protocol compression engine . In some embodiments any functionality or operation provided via the kernel may be requested to be executed such as via a kernel application programming interface API . As such any of the functions of the device may be performed in conjunction with the timing or timing intervals of packet processing via the packet processing timer . In some embodiments the requested operation is performed synchronously and in conjunction with the packet processing operations of the packet processing engine . For example the packet processing operations wait and continue upon a completion of or response from the requested operation. In other embodiments the requested operation is performed asynchronously with the packet processing operations. For example the packet processing engine sends a request to perform the operation but does not block or wait to receive a response from the operation. As will be discussed in further detail in conjunction with method depicted in the packet processing engine may request the cache manager to perform any cache management function such as checking for expiry or invalidation of objects marking objects as invalid or flushing invalid or expired objects.

In some embodiments the packet processing engine at step sends multiple requests such as a first request to the cache manager and a second request to the encryption engine . In other embodiments the packet processing engine at step sends a single request comprising multiple requests to be distributed by the device such as via the kernel to the intended component of the device . In one embodiment the requests are communicated subsequent to each other. In another embodiment requests may be dependent on the status result success or completion of a previous request. For example a first request to the policy engine may be used to determine a policy for processing a network packet from another device or a user associated with the network packet. Based on a policy of the policy engine a second request to the cache may be made or not made depending on a result of the first request. With the cache manager policy engine encryption engine and or the multi protocol compression engine integrated in the kernel space of the device with the packet processing engine there are various operations of the device as described herein that may be triggered by and integrated with packet processing operations.

In another aspect caching of dynamically generated objects is related to and incorporates the ability to configure the expiration time of objects stored by the cache to fine granular time intervals such as the granularity of time intervals provided by the packet processing timer. This characteristic is referred to as invalidation granularity. As such in one embodiment objects with expiry times down to very small intervals of time can be cached. In other embodiments the cache manager responsive to a packet processing timer can also receive an invalidation command to invalidate an object within a very short time period of caching the object. By providing this fine granularity in expiry time the cache can cache and serve objects that frequently change sometimes even many times within a second. One technique is to leverage the packet processing timer used by the device in one embodiment that is able operate at time increments on the order of milliseconds to permit invalidation or expiry granularity down to 10 ms or less. Traditional caches by contrast typically do not set expiry or invalidation granularity of less than one second.

Referring now to an embodiment of a method is depicted for invalidating or expiring a cached object responsive to the packet processing timer and or packet processing engine . As such in some embodiments cached objects can be invalidated or expired in the order of milliseconds such as 10 ms or less. In overview at step of method the cache manager receives a signal or request to perform an operation via the packet processing engine in response to the packet processing timer . At step the cache manager determines if a cached object such as a dynamically generated object is invalid or expired. At step if the object is invalid the cache manager marks the object as invalid and at step flushes the invalid object from the cache manager .

In further detail of step in some embodiments the cache manager may be signaled or requested to perform a cache related operation at any point of time during network packet processing. In one embodiment at step the cache manager receives an operation request prior to the processing of a network packet received or to be transmitted by the device . In another embodiment the cache manager receives an operation request upon the completion of processing of a network packet. For example the packet processing engine completes processing of a network packet and before either waiting for the next time interval of the timer or before processing the next packet requests the cache to perform an operation. In other embodiments during an operation of packet processing the packet processing engine communicates an operation request to the cache manager . In another embodiment the cache manager receives a signal such as from the packet processing engine or packet processing timer to trigger the cache manager to perform an operation. In some embodiments the signal indicates to invalidate a cached object or to expire an expiry of a cached object.

In some embodiments the cache manager may receive a request to perform a cache operation from an entity external to the cache manager such as a request to invalidate an object communicated by a server and processed by the packet processing engine . In one embodiment the cache manager may receive an invalidation request within 10 ms or less of caching the object while in another embodiment as short as 5 ms 2 ms or 1 ms. In other embodiments the cache manager may perform a cache operation responsive to the operations or functionality of the cache manager such as the expiration of a timer to cause an object to be invalidated or during the processing of any cache command. In other embodiments the cache manager uses the packet processing timer of the device to trigger cache operations. For example the timer may trigger or signal the cache to check for invalidation or expiry of a cached object at any time interval capable of being set by the timer . In one embodiment the timer may be set to trigger or signal the cache within 10 ms or less of being set or in another embodiment as short as 5 ms 2 ms or 1 ms of being set. In some embodiments the originating server may set the expiry time of the object. In other embodiments the appliance or client may set the expiry time of the object.

At step the cache manager determines the invalidation or expiry of an object stored in cache. In some embodiments an object in cache is invalidated based on the expiration of a timer. In one embodiment the cache manager may issue an invalidation command on an object based on the expiration of a timer. In another embodiment the object stored in cache is automatically invalidated by the cache manager responsive to the expiration of a timer such as a timer set with the packet processing timer . In some embodiments responsive to the packet processing timer the cache manager checks for the expiration of any timers for cached objects. In one embodiment the cache manager determines an object timer has expired while in another embodiment the cache manager determines the object timer has not expired. In a further embodiment the cache manager responsive to a second trigger or second timer interval of the packer processing timer will check a second time if a previously checked object timer has expired.

In some embodiments the cache manager parses interprets accesses reads or otherwise processes an invalidation command or request to identify the object to invalidate in the cache. In one embodiment an entity external to the cache manager issues an invalidation command to the cache manager to invalidate the object. In another embodiment the external entity may issue the invalidation command responsive to a packet processing timer . If the object is valid and or has not been invalidated the cache manager invalidates the object responsive to the request. In some embodiments the invalidation request processed by the cache manager is responsive to the packet processing operations of the packet processing engine processing the request which in turn may also be responsive to the packet processing timer .

At step the cache manager marks the object as invalid. The cache manager may mark each object as invalid in any suitable or desired manner. In one embodiment an object is marked as invalid by setting a flag attribute or property of the stored object. For example a flag may be set to any value identifying to the cache manager the object is invalid. In another embodiment an object may be marked as invalid by moving the object to an area or portion of the cache for storing invalid objects. In other embodiments the cache manager may identify or track the invalid and or valid state of a stored object by a database or a linked list or any type and form of data structure. In some embodiments the cache manager uses one or more objects to identify or track the validity or invalidity of one or more objects stored in cache. In another embodiment the object is marked as invalid by changing modifying or altering the stored object for example deleting or removing a portion of the object so that is may not be used or by changing or mangling the name of the object.

At step the cache manager in some embodiments flushes from the cache those objects marked as invalid. In another embodiment the cache manager flushes the invalid object from cache upon request for the object such as by a client . In some embodiments the cache manager overwrites the invalid object with an updated copy or version of the object received after invalidation or expiration of the object. In another embodiment the cache manager reuses the cache memory occupied by the invalid object by storing another to the same portion of cache memory. In yet another embodiment the cache manager does not flush the object marked as invalid but keeps the object stored in memory or storage of the cache.

Although method describes invalidation and flushing of cached objects responsive to a packet processing timer and or in conjunction with packet processing operations to provide invalidation granularity any operation of the cache and any techniques of cache management as well as any other operation of the device described herein may be executed at fine granular time intervals provided by the packet processing timer. In some embodiments the invalidation or expiration of cached objects can occur as short as a 100 ms time interval while in another embodiment as short as a 50 ms time interval. In some embodiments the invalidation or expiration of cached objects can occur as short as 25 ms time interval and in other embodiments as short as a 10 ms time interval. While in other embodiments the invalidation or expiration of cached objects can occur as short as a 5 ms time interval and still yet in further embodiments as short as a 3 2 or 1 ms time interval.

By incorporating the capacity to invalidate objects after the elapse of very small increments of time as described in methods and in conjunction with above improved caching of dynamically generated content is enabled. Some dynamic content is in fact amenable to being stored and served from a cache for very short periods of time. To successfully cache such content however an approach in accordance with one embodiment provides caching objects for very short periods of time before the object is invalidated and flushed from the cache memory. For example certain dynamically generated objects may be cacheable for as long as 1 second but anything longer is frequently unacceptable for content that is constantly changing. In an embodiment the approach included invalidating or expiring cached content after small fractions of a second. As an example if an application takes 100 milliseconds to generate a dynamic response then the cache can store and serve that response for a duration of less than or equal to the period of 100 milliseconds without compromising the freshness of the data. There will not be a new object generated during that 100 millisecond period because it is shorter than the time it takes to generate a new object. The appliance can thus be set up to serve the prior object during that duration. The ability of the appliance to invalidate down to very small increments of time is frequently very useful for application environments where the database transaction isolation level is set to allow Repeatable Reads or Serialized Reads.

Traditional caching technology invalidates stored content based on a pre defined expiry time for the content which is typically configured either by the administrator or is received from the server that served the object. Described below is another technique for invalidating content in order to more efficiently cache dynamically generated content. A technique includes the ability to receive at the appliance an invalidation command that identifies one or more of the previously stored objects in the cache as invalid in real time. For example the invalidation command may be communicated via a network packet transmitted to the client or an application programming interface API call made by a server to the appliance. This differs from the traditional approach by which the server simply sets a cache expiry time that it includes in the object header at the time the object is served.

A technique is more specifically illustrated in . is a flow chart illustrating a method for maintaining a cache such as a computer memory cache. In brief overview and according to step dynamically generated objects previously served from an originating server are stored in the cache. For example the dynamically generated object may not be identified as cacheable or otherwise include any cache or cache control information. At step an invalidation command is received at the cache or cache manager . The invalidation command identifies one or more previously served objects as invalid. As step in response to the invalidation command the cache or cache manager marks the identified object as invalid.

In further detail at step the cache manager stores in a cache memory element a dynamically generated object received obtained or communicate from any source. In some embodiments the dynamically generated object may be generated and served from a server . In other embodiments the dynamically generated object may be generated and communicated by a client . In some embodiments another portion component or process of the appliance generates the object and stores the object in the cache. In further embodiments the dynamically generated object may be generated by another appliance or another computing device on the network and transmitted or communicated to the appliance . In some embodiments the dynamically generated object is not identified as cacheable or identified as non cacheable. In other embodiments the dynamically generated object is identified as cacheable or is under cache control.

At step the cache manager receives an invalidation command identifying an object to invalidate such a dynamically generated object stored in the cache. In one embodiment the invalidation command may comprise any type of directive or instruction indicating to the cache that an object in invalid or otherwise may be stale. In some embodiments the invalidation command identifies the object and may also identify the time at which the object is invalid as well as what portions of the object may be invalid. In one embodiment the cache manager provides an application programming interface API that may be called remotely by an originating server . In some embodiments the cache manager may provide any type and form of protocol for receiving commands and replying to commands via one or more network packets. In one embodiment the cache manager or device provides an Extensible Markup Language XML API interface for receiving and processing invalidation commands. For example the cache manager may provide a web service interface. In some embodiments the cache manager replies to the invalidation command by sending an acknowledgement status or other response to the originating server . In other embodiments the cache manager does not reply to the invalidation command. In one embodiment an object is marked as invalid if an application running in an originating server performed an action that made the stored object stale such as by generated a new or updated version of the object. This could occur for example when news editors make changes to a fast developing news story and therefore want to be assured the most recent version of the story is being served to clients.

Invalidation commands may be issued from an originating server by the application that generated the object by another server or another appliance . In one embodiment the originating server issues or communicates an invalidation command to the cache automatically in response to a change to the dynamically generated object on the originating server . The invalidation command can also be generated by an administrative control outside or external to the server and the appliance . For example the administrative control may be any type and form of program or application running on the network and in communication with the appliance such as administrator console. Furthermore a client could issue or communicate an invalidation command to the appliance or cache manager . For example if the client were to take action that the client recognizes would cause a change to the requested objects at the originating server the client may communicate the invalidation command. Any object stored in the cache can be invalidated by the transmission to the cache of a user command executed locally at the cache or invoked remotely using the XML API infrastructure.

According to step an object stored in cache e.g. a previously served dynamically generated object that has been identified as invalid is marked as such in response to the invalidation command. An invalid object will not be provided to a requesting client from the cache but instead would be served directly from the originating server. The cache manager may mark each object as invalid in any suitable or desired manner. In one embodiment an object is marked as invalid by setting a flag attribute or property of the stored object. For example a flag may be set to any value identifying to the cache manager the object is invalid. In another embodiment an object may be marked as invalid by moving the object to an area or portion of the cache for storing invalid objects. In other embodiments the cache manager may identify or track the invalid and or valid state of a stored object by a database or a linked list or any type and form of data structure. In some embodiments the cache manager uses one or more objects to identify or track the validity or invalidity of one or more objects stored in cache. In another embodiment the object is marked as invalid by changing modifying or altering the stored object for example deleting or removing a portion of the object so that is may not be used or by changing or mangling the name of the object.

In some embodiments the appliance subsequently flushes from the cache those objects marked as invalid. In another embodiment the appliance flushes the invalid object from cache upon request for the object such as by a client . In some embodiments the appliance overwrites the invalid object with an updated copy or version of the object. In another embodiment the appliance reuses the cache memory occupied by the invalid object by storing another dynamically generated object to the same portion of cache memory.

With the command invalidation API of the cache manager any computing device or user in communication with the appliance may request to invalidate an object such as a dynamically generated object stored in the cache. As such the invalidation of objects stored in cache can be controlled real time instead of using pre determined configuration expiry or invalidation time periods. Thus using these techniques the longevity of the cached objects can be controlled from external application processing nodes such as databases or originating application servers. For example the appliance can be configured to work with a database such that a change to the database automatically triggers an invalidation command from the database or application to the appliance to flush a particular object or objects.

In a further embodiment the appliance identifies and invalidates at the same time a group of objects stored by the cache. Objects stored in a traditional cache memory are each treated individually and separately by the cache in determining whether the object is stale. As each object reaches its specified expiry time generally as set by the server and stored by the cache in a table that item is flushed from cache memory. This traditional approach is inefficient and ultimately insufficient however to successfully handle the challenges that arise in attempting to cache dynamically generated content.

Step is the same as in wherein an object is stored in the cache of the appliance such as dynamically generated objects previously served from an originating server . In some embodiments one or more of the objects may not be identified as cacheable or otherwise may not have any cache or cache control information. For example the server may assume the dynamically generated objects will not be cached.

According to step the appliance forms a group out of a set of the objects previously served from the originating server and stored in the cache. Any suitable or desired set of objects may be associated with each other to form a group. For example any dynamically generated objects generated for or associated with serving a web page may form a group. In some embodiments an object may be associated with multiple groups. In other embodiments one group of objects may form a subset of another groups of objects. In some embodiments the formed group of objects have objects served from the same server while in other embodiments the formed group of objects have objects served from different servers . In further embodiments the formed group of objects may comprise objects from a client objects from a server or objects generated by or served from both clients and servers . In one embodiment one object in the group is static while another object in the group is dynamically generated. In some cases one object in the group is not identified as cacheable while another object in the group is identified as cacheable. In other cases the objects in the group may be logically related in accordance with functionality or application provided by a server . In another case the objects in the group may be related as associated with the same client or the same user.

In step a record of the group of objects is maintained. Various techniques for recording and maintaining a record of a group of objects or otherwise associating objects may be used in practicing some embodiments of the operations described herein. In one embodiment the record may be maintained directly in for example a look up table. In another embodiments the records could be represented in a hash table format. In some embodiments the cache manager maintains the association of objects in a database or a data structure or object in memory. In further embodiments a flag property or attribute of each object in the group is assigned or set to a value identifying the group such as a value equal to identifying or referencing the name or identifier of the group such as a group s object determinant that will be described in more detail below. In some embodiments a group of objects is arranged placed or located in a portion of cache memory identified as holding the group

In step an invalidation command is received at the appliance or cache manager . According to the embodiment described in the invalidation command identifies that one or more objects are invalid or otherwise are stale. In some embodiments the invalidation command references identifies or specifies a name or identifier of the group of objects. In one embodiment the invalidation command comprises a single invalidation request to invalidate all the objects in the group. In another embodiment the invalidation command identifies one object in the group to invalidate. In other embodiments the invalidation command comprises a plurality of invalidation request to invalidate a plurality of objects in the group

According to step the group of previously served objects is marked as invalid if the invalidation command references identifies or specifies an object of the group as invalid each object in the group as invalid or the group as invalid. In some embodiments if the invalidation command identifies an object in the group as invalid the cache manager marks the object as invalid. In other embodiments if the invalidation command identifies an object in the group as invalid the cache manager marks the group of objects as invalid or each object in the group as invalid. In yet further embodiments the cache manager may only invalidate the group of objects when a plurality of objects are identified as invalid via one or more invalidation commands. In another embodiment the invalidation command may specify a name or identifier of the group and the cache manager marks the group as invalid or each object in the group as invalid.

In one embodiment the appliance or cache manager flushes from the cache memory a group of objects that has been marked as invalid. In some embodiments the objects in the group may be flushed from cache memory only when each object in the group is marked as invalid. In other embodiments if one object of the group has been marked as invalid then the entire group is flushed. In another embodiment the group of objects or any object in the group marked as invalid may be flushed upon receipt of a request for the group of objects or any object in group by a client . In other embodiments the group of objects or any object in the group marked as invalid may be flushed upon receipt of a response from a server provide one or more new objects in the group.

An example of the above described embodiments follows. Customer resource management CRM applications are used by many businesses to track and evaluate all aspects of resource management. Often CRM applications are implemented and accessed over private and public networks including the Internet. These applications which provide access to large amounts of data that is frequently being accessed thus benefit from caching the data generated by such applications. For example sales reports are frequently generated and served to remotely connected users. These sales reports are built by the relevant application through compiling data from sales information that is posted to such application servers and or their underlying databases. As many users request the same document i.e. a certain sales report without caching the application server must re generate the object for each request. If however such objects can be stored in the cache then application and database processing is conserved including potentially valuable bandwidth as the cache is placed closer to the requesting clients.

The challenge for caching such objects arises because each time a new sale is posted to the application running at the originating server or to its underlying database the information in the sales report needs to be updated. As a result all sales reports that may have been stored in any caches supporting these application servers must be invalidated and the content flushed out of cache memory. The traditional approach to caching however has no way of accurately determining when the change to the underlying database or application is going to occur and therefore cannot reasonably evaluate the freshness of dynamic content. Every time a change occurs in database or application or originating server the cache has to be able to identify that the change has been made and which group of objects should be invalidated as a consequence of such change. Generation of invalidation commands that contain object determinants linked to groups of previously served objects as described above can meet this need.

Multiple groups of related objects may be formed at a single hierarchical level. Alternatively sub groups of objects may be formed to create multiple hierarchical levels. In an embodiment the groups or sub groups of objects may be pre designated by a user. In another embodiment a user may establish rules by which the appliance automatically forms groups of related objects and associates object determinants therewith.

An embodiment also addresses the need to be able to identify all objects affected by a state change at the originating application server and or underlying database by generating groupings of objects and implementing parameterized invalidation. In this embodiment any object or pre defined group of objects can be invalidated by an intercepted HTTP request for example from a client that the cache parses in order to identify an object determinant. The term object determinant refers to any information data data structure parameter value data pattern request reply or command that references identifies or specifies one object or a set of objects uniquely or otherwise. In some embodiments an object determination is a pattern of bytes or characters in a communication that may be associated with an object or used to uniquely identify that the communication is associated with or referencing the object. In one embodiment an object determinant indicates whether change has occurred or will occur in the originating server to a group of previously served objects stored in the cache manager with which the object determinant is associated. In some embodiments the objects in a group of objects are related in that they are associated with at least one object determinant. Specific non limiting examples of object determinants and further illustrations of their use are described more fully below.

In some embodiments of the present embodiment object determinants are certain pre defined parameters or data structures included or embedded in a client request or response. In other embodiments the client server or appliance embeds in a communication one or more object determinants such as pre defined strings or sets of characters representing the object determinant. The object determinants indicate whether such request will have the effect of causing a change in the state of objects stored in the originating server or databases linked thereto. In one embodiment the existence of the object determinant in a request indicates a change has or will occur to an object. In another embodiment the syntax structure parameter or value of the object determinant indicates a change has or will occur to an object. In an embodiment the cache receives an object request from a client . The request may include certain parameters or values object determinants that the cache recognizes will change the state of the originating server or application server which will as a consequence make stale certain related objects stored by the cache manager that had been previously generated by such originating server or application server . Depending on the invalidation policy set by the user the parameters object determinants may require invalidation of one or more previously served objects or group of objects by the originating server that have been stored by the cache. The cache is configured to identify the relevant objects that will be effected by this state change i.e. those objects or groups of objects linked to the object determinant and invalidate these objects via the method marking each of the objects as invalid and or flushing such objects from the cache memory.

The above described technique is illustrated in . As with other embodiments described herein step comprises storing in the cache objects such as dynamically generated objects previously served from an originating server. The objects could be generated by an application running on the originating server or could be drawn for example from a database accessed by the originating server . In some embodiments the dynamically generated objects are identified as not cacheable or otherwise not identified as cacheable.

According to step the cache intercepts or otherwise receives a communication between the client and the server such as a request from a client or a response from a server. In some embodiments the request is for a specified object the object having been previously served and stored in the cache. In another embodiment the communication includes a response from a server having a requested object. In one embodiment such receipt or interception occurs according to established caching protocol and communications standards. Although the cache manager or appliance may be generally described as receiving a request response or communication in receiving such request response or communication the cache or appliance may intercept or obtain by any suitable means and or mechanisms the request response or communication even though not communicated directly or explicitly to the cache.

In step an object determinant is identified in the intercepted communication. The cache manager may extract interpret parse access read or otherwise process the intercepted communication to determine or identify one or more objects determinants in the communications. Any parameter value syntax data structure or set of one or more characters of the communication may be used to identify an object determinant. In one embodiment the cache manager may identify the name or identifier of an object in a request from the client to the server in which the client requests the object. In another embodiment the cache manager may identify the name or identifier of a first object in the request of the client or response from the server that indicates a change has occurred or will occur to a second object stored in the cache. In other embodiments the cache manager determines if any patterns of characters in the request match any object determinants associated with an object or group of objects in the cache. In some embodiments an object determinant may be determined for an object not currently stored in cache. In other embodiments an object determinant may be determined for an object currently marked as invalid. In other embodiments an object determinant for a requested object is determined to be associated with an object determinant of a cached object. In yet another embodiment upon the first reference request or response for an object in a communication the cache manager establishes the identified object determinant as the object determinant for the object.

By receiving and parsing the communication such as a client request or server response to identify an object determinant the cache manager or appliance may effectively determine whether to mark as invalid a cached object that has been associated with the identified object determinant. Thus according to step a determination is made as to whether the object determinant indicates a change to the cached object. In some embodiments the identified object determinant may be part of a communication that does not alter modify or generate an object. In other embodiments the identified object determinant is a part of a communication that indicates a change has occurred or will occur to the object associated with the object determinant. For example the communication may be a get request for a dynamically generated object or a submit request that will change the data used for one or more dynamically generated objects. In some embodiments the existence of the object determinant in the communication indicates a change has or will occur on one or more objects. In another embodiment the type or name of a command directive or instruction in the communication along with the object determinant indicates a change has or will occur on one or more objects. In yet a further embodiment the existence value or setting of a parameter or variable of a command directive or instruction indicates a change has or will occur on one or more objects associated with an object determinant.

In other embodiments the cache manager performs a hash function algorithm or operation on the intercepted communication or object determinant to determine if a change has occurred in the object. In some embodiments the hash value is compared with a previous stored hash value for the object and if different then the cache manager recognizes the object has changed. In yet another embodiment a hash value for the object may be included in the communication or object determinant. In one embodiment the communication indicates the object has changed by the value or setting of a parameter such as with a Boolean flag. In other embodiments an entity tag control and validation mechanism as will be described in more detail below may be used to identify the object and determine if the object has changed.

If a change is indicated then at step then the object associated with or identified by the object determinant is marked as invalid. In some embodiments an object requested by the intercepted communication is marked as invalid in accordance with step and retrieved from the originating server in accordance with step . Otherwise in other embodiments the requested object is retrieved from the cache in accordance with step . In one embodiment any object marked as invalid will be flushed from the cache.

The above embodiment describes the case of invalidating a previously served object in the cache manager based on identification of an object determinant in the client request. This general concept may also be used in another embodiment to identify and invalidate a group of objects with which one or more object determinants have been associated. This embodiment is illustrated in .

The method described in begins in the same fashion as the method of . Step comprises storing in the cache objects such as dynamically generated objects previously served from an originating server. In some embodiments one or more of the objects are not identified as cacheable. According to step and similar to previously served objects are formed into groups. In one embodiment and in accordance with the object determinant technique a group of objects is associated with or identified by at least one object determinant. As described more fully below in some embodiments the association of groups with object determinants depends on the nature and details of the users caching policy such as a policy defined controlled or used by the policy engine . In other embodiment the one or more object determinant of the group comprises the one or more object determinants of the objects in the group. In another embodiment the object determinant of the group comprises a combination of object determinants of objects in the group.

According to step a record is maintained of the group along with its associated object determinants if applicable. This step is similar to step illustrated in . In one embodiment the record and or any object determinants of the group is maintained in a look up table. In other embodiments the record and or any object determinants of the group may be maintained in a hash table format. The hash table may be designed to efficiently store non contiguous keys that may have wide gaps in their alphabetic and numeric sequences. In another embodiment an indexing system can be built on top of a hash table. In some embodiments the cache manager maintains the association of objects as a group with one or more object determinants in a database or a data structure or object in memory. In further embodiments a flag property or attribute of each object in the group is assigned or set to a value identifying the group such as a value equal to identifying or referencing the name or identifier of the group or a group s object determinant. In some embodiments a group of objects is arranged placed or located in a portion of cache memory identified as holding the group. In another embodiment the one or more object determinants are stored in association with the group of objects.

Steps and are similar to steps and as illustrated in . According to step the cache manager or appliance intercepts or otherwise receives a communication between the client and server such as a request from a client for an object previously served and stored in the cache. In one embodiment the cache manager intercepts a request from the client to the server . In some embodiments the request is for an object stored in cache. In other embodiments the request is an instruction command or directive to the server that will cause a change to an object stored in cache such as to cause an object to be dynamically generated. In another embodiment the cache manager intercepts a response from a server to the client comprising or identifying an object stored in cache.

In step an object determinant is identified in the intercepted communication. As noted above the object determinant indicates whether a change has occurred or will occur in the requested object at the originating server . However in the embodiment of the object determinant may be associated with a group of objects. This enables efficient invalidation of all objects stored in the cache that may be affected by a particular object determinant. In some embodiments an object determinant of an object in the group is identified. In other embodiments an object determinant for example a group object determinant for the group of objects is identified. In another embodiment a combination of object determinants of one or more objects in the group are identified.

Thus according to step a determination is made as to whether the object determinant indicates a change in the group of previously served objects. In some embodiments the existence of the object determinant of the group in the intercepted communication indicates a change has occurred or will occur to one or more or all of the objects in the group. In other embodiments the name and type of a command directive or instruction in the intercepted communication indicates such changes. In yet another embodiment the existence value or setting of any parameters or variables in the communication may also indicate such changes.

If at step the object determinant indicates a change in the group then the group of previously served objects is marked as invalid in the cache in accordance with step . In some embodiments one or more or all of the objects of the group are requested and retrieved from the originating server in accordance with step . If at step the object determinant does not indicate a change in the group then in some embodiments any objects requested as part of intercepted communication and previously served and stored in the cache is retrieved from the cache manager in accordance with step . In an embodiment any object or group of objects marked as invalid may be flushed by the cache manager from the cache.

The cache administrator may specifically designate which objects get included into a particular group. Whenever an object is stored in the cache the administrator may make that object a member of one of the configured or implicit groups depending on the configuration. The configured groups can be based on configurations that an administrator has previously established or alternatively based on application behavior and other data related to object invalidation. An object may also be part of an implicit group if its configured group is dynamic. Objects in the implicit group are grouped by the value of the significant invalidation parameters.

By permitting very flexible grouping of objects a cache can achieve a level of flexibility and coordination in invalidation that is necessary to effectively cache dynamically generated content. The cache can invalidate a very specific group of objects simultaneously thereby making the cache more responsive to the frequent need to invalidate dynamically generated content. At the time the cache assigns an object to a group the group determines a number of things relative to that object including the invalidation parameters and the hit determinants in order to associate one or more object determinants therewith.

In the customer resource management CRM example the cache administrator may pre designate each of the groupings. For example the administrator configures the cache to group each of the sales departments by name. Thus the administrator can designate an auto department a motorcycle department etc. and each time an object determinant is recognized in a request coming to the cache the cache can then invalidate all objects stored in a designated group linked to an appropriate department via the object determinant.

Alternatively the cache administrator may establish rules that allow the cache appliance to determine on the run which objects to include in a particular group or groups. Such rules based groupings may rely on the designation of groups by virtue of established rules that link the object to significant object determinants that the cache utilizes to create the relevant groups. An example of this approach may involve configuring the cache with rules that the cache uses to recognize what objects to put in each group.

Again turning to the CRM example a rule may state that each subdivision of the Sales Department that is set up on the application should be recognized by the cache as its own grouping. In this way the groupings can be created without the cache administrator having to specifically identify each grouping but allows the cache to determine based on the relevant rules. This technique creates a more flexible and often less work intensive way to designate groupings. The cache administrator could configure a rule that states that every subdivision department of Sales i.e. sales auto sales motorcycle etc. should generated a new grouping by the cache. As a request from the Auto Sales Department is processed and returned by the application via the cache the cache can recognize each subgrouping of sales and automatically create a grouping for it based on the pre configured rule.

The rule may be implemented by the cache each time it sees a new request for an object of the type report sales auto or report sales motorcycle etc. This process can then be repeated when a Motorcycle Sales Department request showing that it is a subgrouping of the Sales Department then the Bicycle Sales Department and so forth as the cache recognizes these subgroups and establishes an object grouping for each of them. When a known invalidation request comes to the cache linked to one of these groupings or if a relevant object determinant is identified in a client request for example a post of a sales report to the Motorcycle Sales Department sales motorcycle found in the parsing the request the cache knows to invalidate all the cached objects in the Motorcycle Sales Department Grouping.

In this way when a cache recognizes that a change has occurred or will occur to data served by the application either because the cache recognizes that contents of a request received by the cache will trigger a change at the application or because of the occurrence of some outside change the above technique enables the cache to quickly and simply identify which objects require invalidation through the process of grouping. In this way the cache is able to invalidate large numbers of dynamically generated objects that are no longer fresh because of changes in the application or database state.

The ability of the cache to successfully store and serve out of its cache memory dynamically generated content can also be enhanced with an intelligent statistical engine that examines the pattern of request and response traffic in order to determine over a period of time the set of objects that would provide the most caching benefit. The engine can either be integrated into the cache appliance itself or run in a separate computer as a heuristic to select some subset of objects for further investigation to determine suitability for dynamic caching.

As described above object determinants may be any data structure that indicates whether a change has occurred or will occur in the originating server to the group of previously served objects stored in the cache with which the object determinant is associated. Object determinants could be set up on the basis of predefined string values embedded in the request. For example when a request comes in with a certain USERID the USERID can be linked to a group of objects in the cache memory that should be invalidated each time a post or other request comes from that certain USERID. Potential candidates for object determinants could also include using service identifiers of the server that originally served the object. The service identifier contains service IP address TCP port and service identifier present in the HTTP request.

Another potential object determinant present in the request the request uniform resource locator URL . In the case of caching of static objects the request URL is typically sufficient to uniquely identify the object. For requests for dynamically generated content however the information present in the URL may not be sufficient to identify the cached object. The cache must therefore inspect other information in the request to find object determinants including in HTTP headers cookie header or in other custom HTTP headers. The cache can additionally look for a subset of relevant parameter information in a variety of other places in the client request including without limitation in the URL query string in the POST body in a cookie header or in any other request or response headers.

The problem in parsing a URL for object determinants is that the URL and other headers may contain a lot of information in addition to what is relevant for the cache s decision. The cache must therefore be able to parse through quite a lot of information to be able to identify the appropriate object determinants. In addition the data in the header is often arbitrarily ordered meaning there are no standardized ways that such data is placed into the HTTP header and therefore a simple comparison is often insufficient to locate the relevant object determinants in such string.

If there is no pre configured policy to match a particular object determinant to a relevant object or group of objects stored in cache memory the cache may still in another embodiment make such a determination. For example the cache may examine and parse various aspects of the request to discover whether any other object determinants may be found in such request and used to link such request to particular objects stored in the cache memory that should be invalidated. Alternatively one could also enable the cache to examine a request for certain object determinants that the cache determines based on certain pre defined heuristics may meaningfully linked to particular objects or group of objects. For example when the request comes into the cache for an update of a calendar associated with a particular USERID an embodiment could be set up to recognize that all cached objects with USERID equal to the USERID of the request updating the calendar and that contains the user s calendar for any one particular day will need to be invalidated.

The cache may also assume that the object determinants are present as a group of name value or similar pairs in a non specified order in the URL Stem in the queries present in the URL in the POST body or in a Cookie header. In an embodiment it is assumed that the query is formatted as a list of name value pairs. The user can therefore configure which parameter names are significant. Every cached object is keyed using first its access URL. The URL may look like site application special file.ext p1 v1 p2 v2 p3 v3. The site application special file.ext part is the URL stem. The p1 v1 p2 v2 p3 v3 part is the URL query and contains parameter value pairs. These parameter value pairs may also be present in the POST body or in the Cookie headers.

In an embodiment the user or administrator establishes that p1 and p2 shall be the invalidation parameters or object determinants. The cache will thereafter automatically group objects that have matching p1 and p2 values. One way of implementing this grouping is to map p1 and p2 to primary keys in database tables i.e. to uniquely identifiable objects in the table that the cache will know how to reference in order to determine validation status. To update something in those database tables in order to reflect the fact that data stored in the cache is no longer valid the cache will specify new values for p1 and p2 and when the cache recognizes such new values the next time it goes to serve such content it will know to invalidate the linked objects stored in its memory. The cache when it encounters such a request on seeing the update request knows that it has to invalidate the group with matching p1 and p2 values because the cache understands that data in the origin will change thereby affecting all objects that are related to those p1 and p2 object determinants.

To address the more complex case where the administrator has not pre configured specific parameters embedded in the request as object determinants the cache can deploy user configured policies to extract the relevant object determinants from the request to assist in identifying when to invalidate groupings of objects. The determinant string is then used to locate the group of objects stored in the cache and invalidate such objects. These object determinants can be used to configure the cache to generate lists of significant parameter values. If an incoming write request has matching values for the significant parameters then the objects tied to those parameter names should be invalidated. Alternatively a user could specify the policy framework action that can extract the object determinant string from the request. The object determinant string is extracted from the write request and all objects with matching determinant strings are invalidated. In this alternative approach a request arrives at the cache the cache makes a determination whether the request string matches an invalidation policy. The invalidation policy specifies objects in which content group should be invalidated.

Alternatively the cache could use any other user information that may be present in the client request. As noted above the authentication and authorization integration allows the cache access to the user information. The USERID or the GROUPID could be one of the determinants in the event the relevant grouping of cached objects are linked to a user or a group of users. Although user information is often an important object determinant the user information often may not be present in the HTTP request. In a further embodiment the dynamic caching aspects can be combined with a system and method for integrating the cache with a variety of other networking elements including the ability to perform certain kinds of authentication access control and audit AAA infrastructure. Thus the level of security accorded to data that is generated by the applications is applied to data that is instead served from a cache. This technique allows the applications to cache sensitive access controlled information that could not otherwise be cached.

This approach allows the cache to identify users that do not include identifiable user information in the HTTP request but that may be identifiable via the AAA approach described in the Integrated Caching patent. Such an approach enables the cache to identify the relevant user to a particular request through examining the authorization state information that can be shared from the AAA processing. In a further embodiment the integration enables the application of security policies to information stored in the cache to prevent unauthorized users from accessing information stored at the cache.

This approach also address the challenge posed by the fact that a significant portion of dynamically generated data requires that the client requesting such data be authorized and authenticated before the cache can respond to the relevant request from the client. The cache must have the ability to authorize requests made by authenticated users so that applications can cache access controlled objects and by integrating such dynamic caching technology with authentication and authorization information this security can be achieved. The USERID or the GROUPID will be one of the object determinants if the objects are personalized to a user or a group of users. Thus the level of security accorded to data that is generated by the applications is applied to cached information as well. This technique allows the applications to cache sensitive access controlled information that could not otherwise be cached.

Finally other information like time of day state of the database at the origin etc. may be parsed from the request and used as object determinants to determine whether objects stored in the cache are still valid. The cache may take care of this situation by configuring appropriate expiration behavior in groupings of objects that are configured to be sensitive to such external variables.

To further address the challenge presented by the fact that requests for dynamic content must be parsed and interpreted by the cache the cache in accordance with an embodiment can limit which parameters are deemed to be relevant object determinants for the cache. In this way the success rate for serving objects from the cache rather than forwarding such requests to the applicable application server can be enhanced. By way of example a request query from a client may contain both a city and a state parameter. However the cache may be configured to comply with the requirements of the application for which the cache is storing content to recognize that the response can be served to requests coming from clients that the query shows come from all clients in a given state without regard to the city value. For this purpose the city parameter is not relevant and the cache could recognize this fact. An alternate embodiment involves configuring the cache so that a response can be served from the cache if just the city parameter makes a match regardless of what is specified for the state parameter.

In summary the cache implements generalized parameterized object matching. In this approach the cache is configured to recognize the subset of information in the request that will be useful as object determinants and that are linked to a particular object so that when such object determinants are recognized the cache can utilize the presence or conversely the absence of such determinants in evaluating whether the object or group of objects remains fresh and capable of being served from the cache. The cache maintains a table that it consults each time a request comes in to check against the configured parameters to determine if the requested data remains fresh and which also allows the cache to match the relevant data to the proper object stored in the cache memory.

In yet another embodiment the cache can utilize incarnation numbers to invalidate a group of objects. Where a cache needs to change the state of each of a group of objects at one time because of a change in the state at the origin incarnation numbers provides a simple technique for effecting this invalidation. Whereas identifying each object and changing the state individually is an inefficient approach to assuring freshness of data stored in a cache use of incarnation numbers enables a much more simple and effective approach to invalidating groups of objects. The present embodiment describes how each object points to a data structure that represents the group and therefore the server need only send a command that changes the state in the data structure for the group. When a subsequent request for a cached object arrives from a client the cache must first figure out whether the state has changed. To do so it looks up the data structure to reference whether the state has changed for the group.

In order to implement the data structure effectively the cache must be able to determine whether to look up for a state change. Therefore the cache must be able to determine whether it has already looked at the state change in the group or not. This is where the incarnation numbers are helpful. The cache associates dynamically generated objects into content groups. Each of these content groups may be represented through a hash table look up process with a particular index value or incarnation number contained in a data structure. Thereafter whenever the cache receives a client request that the cache recognizes as causing a state change the client parses the client request for the relevant parameters performs the hash look up based on the recognized object determinants and increments the index or incarnation number in the data structure. Each time an object stored within a designated grouping is requested by a client the cache performs the hash algorithm on the object and compares it to the original stored value in the data structure for such content group. If the stored value is the same as the number calculated by the cache for such object then the cache knows the content remains fresh and can be served to the requestor. In the event the cache detects a discrepancy between the current incarnation number calculated for such object in and the number stored for such content group in the data structure the cache knows that the stored object is no longer fresh. The cache then invalidates the stored object and sends the request along to the application server. When the response comes back the cache appliance will store the new response in the cache memory and link such response again to the new data structure. Thereafter each time the cache receives a request for an object in that grouping the cache can make the comparison and assuming no further changes have been made to the data structure the cache can serve the newly stored object.

By utilizing invalidation of a group of objects in this fashion the cache is able to invalidate very quickly and the time taken is constant regardless of the number of objects invalidated. Through this faster and more efficient process of invalidation the techniques enable the cache to more effectively handle dynamically generated objects. The approach allows cache appliances that sit in front of applications to more aggressively store and serve dynamically generated objects without serving invalid or stale content because of rapid changes in such data. The embodiment enables the cache to serve data that frequently or unpredictably changes thereby improving the performance of the cache. The cache is also able to invalidate objects and group of objects stored in the cache memory using user commands and also by examining and grouping various kinds of web traffic.

In one embodiment a network appliance also referred to herein as interface unit relieves servers of much of the processing load caused by repeatedly opening and closing connections to clients by opening one or more connections with each server and maintaining these connections to allow repeated data accesses by clients via the Internet. This technique is referred to herein as connection pooling .

For completeness the operation of connection pooling is briefly described next with reference to . The process begins in when a client requests access to one of the servers in the server farm tended by interface unit . A connection is opened between interface unit and the requesting client and interface unit receives the client request to access the server as shown in step . Interface unit determines the identity of the requested server as shown in step . In one embodiment this is accomplished by examining the destination network address specified by the client request. In another embodiment this is accomplished by examining the network address and path name specified by the client request.

After determining the identity of the server to which the client request should be directed interface unit determines whether a free connection that is one that is not in use to the server is already open as shown in step . If so processing resumes at step . If not interface unit opens a connection to the server as shown in step . Interface unit then translates the client request and passes it to the server as shown in step and as more fully described with respect to below. After server processing interface unit receives a response from the server as shown in step . The server response is translated and passed to the requesting client as shown in step and described further below. Finally interface unit closes the connection with the client as shown in step . However the connection between interface unit and server is not disconnected. By maintaining open connections with the servers and by opening and closing connections with the client as needed interface unit frees the servers of nearly all of the connection loading problems associated with serving clients over the Internet.

As will be discussed further below some embodiments are related to step where interface unit closes the connection with the client . There are a number of scenarios that result in interface unit closing the connection with the client. For example the client may initiate a FIN finish command or a RST reset command. In both of these scenarios interface unit waits until it receives one of these commands before it loses the connection between itself and the client. Inefficiencies with connection pooling occur when the client is not using or finished with the connection but does not relay this information to interface unit for a period of time. Because interface unit is waiting for a command from the client in order to reuse the connection for another client the connection is tied up unnecessarily.

As will be explained in more detail below Hyper Text Transfer Protocol HTTP 1.1 by default and HTTP 1.0 with the Connection Keep Alive Technique enable the client and or interface unit to keep the connection open with the server even after receiving a server response to a request. The client and or interface unit may then issue other requests via the same connection either immediately or after considerable time or think time . A client is in think time when the human operator of the client is deciding the next link on the browser to click and so forth. This can result in connections being maintained by the server even though the server is not processing any requests via the connections. Here server administrators may be forced to guard against too many simultaneous connections on the server by setting a Keep Alive timeout after which the connection which has been idle or in think time is closed. One embodiment allows the connection to the server to be used by client while the client is thinking . Of course if client makes a request when client is using the server connection then client must use a different connection to the server. However the efficiency of the connection pooling of one embodiment is realized when a very small number of connections is exceeded and moves into the general case. The general case being when n client connections may be statistically multiplexed onto m server connections where n is greater than m .

Each TCP packet includes a TCP header and an IP header. The IP header includes a 32 bit source IP address and a 32 bit destination IP address. The TCP header includes a 16 bit source port number and a 16 bit destination port number The source IP address and port number collectively referred to as the source network address uniquely identify the source interface of the packet. Likewise the destination IP address and port number collectively referred to as the destination network address uniquely identify the destination interface for the packet. The source and destination network addresses of the packet uniquely identify a connection. The TCP header also includes a 32 bit sequence number and a 32 bit acknowledgment number.

The TCP portion of the packet is referred to as a TCP segment. A TCP segment includes a TCP header and body. The body part of the TCP segment includes a HTTP header and the message. There are two mechanisms for determining the length of the message including one based on chunked transfer encoding and another based on content length. A content length header file is found in the HTTP header. If a content length header field is present its value in bytes represents the length of the message body. Alternatively if a chunked transfer encoding header is present in the HTTP header and indicates that the chunked transfer coding has been applied then the length of the message is defined by the chunked encoding. The chunked encoding modifies the body of a message in order to transfer the message as a series of chunks each with its own indicator contained in the chunk size field.

As will be discussed in detail below one embodiment utilizes the content length parameter and or the chunked transfer encoding header to increase the efficiency of connection pooling between servers and clients by avoiding the situation where the client is in think time . Without this embodiment interface unit either waits for a command from the client before it reuses the connection for another client or the connection times out when the connection has been idle for too long.

The 32 bit sequence number mentioned above identifies the byte in the string of data from the sending TCP to the receiving TCP that the first byte of data in the TCP segment represents. Since every byte that is exchanged is numbered the acknowledgment number contains the next sequence number that the sender of the acknowledgment expects to receive. This is therefore the sequence number plus one of the last successfully received bytes of data. The checksum covers the TCP segment i.e. the TCP header and the response data or body . This is a mandatory field that must be calculated and stored by the sender and then verified by the receiver.

In order to successfully route an inbound packet from a client to the intended server or to route an outbound packet from a server to a client interface unit employs a process known as network address translation . Network address translation is well known in the art and is specified by request for comments RFC 1631 which can be found at the URL http www.safety.net RFC1631.txt.

However in order to seamlessly splice the client and server connections a novel translation technique was described in detail in the commonly owned U.S. patent application Ser. No. 09 188 709 filed Nov. 10 1998 entitled Internet Client Server Multiplexer referred to herein as connection multiplexing . According to this technique a packet is translated by modifying its sequence number and acknowledgment number at the TCP protocol level. A significant advantage of this technique is that no application layer interaction is required.

Referring to the network address of the packet is translated as shown in step . In the case of an in bound packet that is a packet received from a client the source network address of the packet is changed to that of an output port of interface unit and the destination network address is changed to that of the intended server. In the case of an outbound packet that is one received from a server the source network address is changed from that of the server to that of an output port of interface unit and the destination address is changed from that of interface unit to that of the requesting client. The sequence numbers and acknowledgment numbers of the packet are also translated as shown in steps and and described in detail below. Finally the packet checksum is recalculated to account for these translations as shown in step .

As mentioned above an embodiment is related specifically to an apparatus method and computer program product for efficiently pooling network client server connections though the content length parameter and or the chunked transfer encoding header to increase the efficiency of connection pooling between servers and clients. The increase in efficiency is the result of avoiding occupying the connection while the client is in think time . In one embodiment the content length parameters is used to determine the length of the message. In another embodiment chunked transfer encoding is used to determine the length of the message. The two embodiments will be described next with reference to respectively.

The chunk size fields A G are linked together as illustrated in . The chunk size field A indicates the length of the message in the chunk message data A chunk size field C indicates the length of the message in the chunk message data C and so forth. The last chunk size field G always contains the length value zero indicating that there is no more message data to follow. This is an indication that all of the message has been sent to the client. How an embodiment utilizes the chunk size fields A G to provide more efficient connection pooling is described below with reference to . It is important to note that TCP segment in is for illustration purposes only.

Prior to describing the detail of how an embodiment utilizes the content length parameter to increase the efficiency of connection pooling connection pooling as it is described in U.S. patent application Ser. No. 09 188 709 filed Nov. 10 1998 entitled Internet Client Server Multiplexer will first be discussed for completeness. is a message flow diagram illustrating connection pooling. shows interface unit connecting two clients C and C to a server S. The two clients C and C may comprise any of the clients discussed herein and the server S may comprise any of the servers discussed herein. First interface unit opens a connection with client C using network address provided by client C as shown by flow . Flow line is shown as a two way flow because the TCP IP protocol employs a multi stage handshake to open connections.

Once the connection is opened interface unit receives a GET request from client C specifying a path name of sales forecast.html as shown by flow line . Because no free connection is open between interface unit and server S interface unit opens a connection with server S. Interface unit maps this request to network address which specifies server S as shown by flow line . Interface unit also passes the GET request to that server as shown by flow line . Server S responds with the requested web page as shown by flow line . Interface unit forwards the web page to client C as shown by flow line . Finally the connection between client C and interface unit is closed as shown by flow line . According to the TCP IP protocol closing a network connection can involve a multi stage process. Therefore flow line is shown as bidirectional. It is important to note that interface unit does not close the connection with server S but rather keeps it open to accommodate further data flows.

Next a connection is opened between interface unit and client C using network address provided by client C as shown by flow line Next interface unit receives a GET request from client C specifying the Web page sales forecast.html as shown by flow line . Because a free connection is already open between interface unit and server S it is unnecessary for interface unit to burden server S with the processing load of opening a further connection. Interface unit merely uses a free open connection. Interface unit maps the GET request to server S transfers it and forwards it to server S as shown by flow line . Interface unit receives the response from server S as shown by flow line and forwards it to client C as shown by flow line . Finally interface unit closes the connection with client C as shown in flow line . Once again interface unit does not close the connection with server S. Instead interface unit keeps the connection open to accommodate further data flows.

As discussed above there are a number of scenarios that result in interface unit closing the connection with client C as shown in flow line . For example the client may initiate a FIN finish command which occurs once the client has retrieved all requested data or message . The client may also initiate a RST reset command. In addition to closing the connection between interface unit and the client the RST command results in a number of housekeeping operations being performed to keep the server side connection in good order. In particular the TCP protocol guarantees that the RST command will have the right SEQ sequence number so that the server will accept the TCP segment however the RST command is not guaranteed to have the right ACK acknowledge number. To take care of this scenario interface unit keeps track of the bytes of data sent by the server and the bytes acknowledged by the client. If the client has not yet acknowledged all the data by the server interface unit calculates the unacknowledged bytes and sends an ACK to the server. Furthermore the server side PCB may be placed on a timeout queue to allow any pending server data transfers to drain.

Furthermore although not shown in the server can also close a connection between itself and interface unit . The server would send a FIN command to interface unit . In this case both the connection between the server and interface unit and the connection between interface unit and client will be closed.

Another aspect is to maximize offload of connection processing from the server by minimizing the occasions on which the server closes the connection. There are three cases 

 1 The protocol version HTTP 1.1 is used. In this case no explicit Keep Alive header is required. By default the server keeps the connection open it is up to the client to close the connection. An embodiment offloads the server by reusing the server side connection. Because it is up to the client to close the connection inefficiencies with connection pooling occur when the client is finished with the connection but does not relay this information to interface unit for a period of time. Because interface unit is waiting for a command from the client in order to reuse the connection for another client the connection is tied up unnecessarily.

 2 The protocol version HTTP 1.0 is used and the Connection Keep Alive header is provided by the client. In this case the server keeps the connection open it is up to the client to close the connection. An embodiment offloads the server by reusing the server side connection. As with protocol version HTTP 1.1 inefficiencies with connection pooling occur when the client is finished with the connection but does not relay this information to interface unit for a period of time.

 3 The protocol version HTTP 1.0 is used and the Connection Keep Alive header is not provided by the client. In this case the server will normally close the connection after fully satisfying one GET request. If the server closes the connection after each request this denies that interface unit the opportunity to reuse the server side connection. As it turns out much of the Internet still uses HTTP 1.0 without Connection Keep Alive . A novel technique for allowing the reuse of server side connections in this specific important case was described in detail in the commonly owned U.S. patent application Ser. No. 09 188 709 filed Nov. 10 1998 entitled Internet Client Server Multiplexer . Interface unit inspects the GET packet to detect this situation. When this case is detected interface unit inserts Connection Keep Alive into the GET packet. Since this is done invisibly to the client interface unit must keep track of the number of Bytes Added on the server side connection. The Bytes Added does not affect the Sequence numbers in the GET packet since the sequence number is that of the first byte. However interface unit must add Bytes Added to the sequence number of subsequent packets from the client to the server. Conversely the server will acknowledge the additional bytes but interface unit must subtract them before sending the acknowledgment to the client which does not know that these bytes were added.

As mentioned above connection multiplexing is achieved by manipulating sequence and acknowledgment numbers. Sequence and acknowledgment numbers of segments received by interface unit are modified and mapped to values expected by the recipient. To the client data appears to be coming from the server and vice versa. For example if Inflow denotes a segment received by interface unit and Outflow denotes the corresponding outbound segment the sequence and acknowledge numbers are changed in the following manner Outflow sequence number Inflow sequence number Inflow starting sequence number Outflow starting sequence number Outflow acknowledge number Inflow acknowledge number Inflow starting acknowledge number Outflow starting acknowledge number To address the addition of the Connection Keep Alive header for HTTP 1.0 packets interface unit keeps track of Bytes Added on the appropriate half of the connection in this case the server side. The sequence number and acknowledgment number formulas are changed as follows Outflow sequence number Inflow sequence number Inflow starting sequence number Outflow starting sequence number Outflow Bytes Added Outflow acknowledge number Inflow acknowledge number Inflow starting acknowledge number Outflow starting acknowledge number Inflow Bytes Added

Specific examples of translations accomplished using these equations while incorporating the content length parameter technique of an embodiment to provide more efficient connection pooling is described below with reference to relating to content length parameter and relating to chunk size fields .

Flows A C present one method of opening the connection between client C and interface unit . Each flow represents a TCP segment. In TCP segment A the SYN flag in the TCP header is set indicating a new connection request from client C. Client C has established a starting sequence number of 2000 and an acknowledgment number of 2000. Interface unit responds with a SYN ACK segment specifying a starting sequence number of 4000 and incrementing the acknowledgment number to 2001 as shown by flow B. Each entity e.g. client server interface unit within the network sets its own unique sequence number and or acknowledgment number as is well known in the art. Client C responds with an ACK segment specifying a sequence number of 2001 and incrementing the acknowledgment number to 4001 as shown by flow C. Client C then sends a GET segment specifying a length of 49 bytes as shown by flow .

Assume that interface unit determines that no free open connections exist with server S and therefore sends a SYN segment to server S specifying a starting sequence number of 1950 as shown in flow A. Server S responds with a SYN ACK segment specifying a starting sequence number of 6000 and incrementing the acknowledgment number to 1951 as shown in B. Interface unit responds with an ACK segment as shown by flow . Interface unit then forwards the GET segment from client C to server S after modifying the sequence and acknowledgment numbers according to the translation equations described above as shown by flow line .

Server S responds with the requested data specifying a sequence number of 6001 an acknowledgment number of 2000 and a content length parameter of 999 as shown by flow . Interface unit receives the RESP segment translates the sequence and acknowledgment numbers and forwards the RESP segment to client C as shown by flow line A.

At this point interface unit receives a request by client C to open a connection. As above flows A C present one method of opening the connection between client C and interface unit . Again each flow represents a TCP segment. In TCP segment A the SYN flag in the TCP header is set indicating a new connection request from client C. Client C has established a starting sequence number of 999 and an acknowledgment number of 999. Interface unit responds with a SYN ACK segment specifying a starting sequence number of 4999 and incrementing the acknowledgment number to 1000 as shown by flow B. Client C responds with an ACK segment specifying a sequence number of 1000 and incrementing the acknowledgment number to 5000 as shown by flow C. Client C then sends a GET segment specifying a length of 50 bytes as shown by flow .

Assume at this point that interface unit has no available connections to server S. The goal is to reuse the same connection to server S that was previous used for client C if client C is finished with the connection or is in think time . Instead of waiting for client C to initiate a FIN finish command or a RST reset command to free up the connection interface unit uses the content length parameter to confirm that all of the requested data has been received by client C. Here at flow B interface unit receives confirmation from client C that client C has in fact received all of the requested data. This indicates to interface unit that even though client C may be pausing for some reason before it sends a FIN or RST command client C is finished with the connection. Interface unit modifies the acknowledgment and sequence numbers and forwards the RESP ACK segment to server S as shown by flow C.

Using the same connection as used with client C interface unit then forwards the GET segment from client C to server S after modifying the sequence and acknowledgment numbers according to the translation equations described above as shown by flow line . Server S responds with the requested data specifying a sequence number of 7000 an acknowledgment number of 2050 and a content length parameter of 500 as shown by flow .

Interface unit receives the RESP segment translates the sequence and acknowledgment numbers and forwards the RESP segment to client C as shown by flow line A. Here at flow B interface unit gets confirmation from client C that client C has in fact received all of the requested data. Interface unit modifies the acknowledgment and sequence numbers and forwards the RESP ACK segment to server S as shown by flow C.

The connection between client C and interface unit is then closed or delinked once interface unit receives a FIN or RST command from client C as shown by flows A D. Likewise the connection between client C and interface unit is then closed or delinked once it receives a FIN or RST command from client C as shown by flows A D. It is important to note however that interface unit maintains the connection with server S It is also important to note that the sequence of events as they were described with reference to is for illustration purposes only.

Interface unit then selects the server hosting the content specified by the path name as shown in step . In alternative embodiments interface unit consults other predefined policies to select the appropriate server such as the load of the servers and the state of the servers. Interface unit manages and maintains a database of servers and server farms that it tends. Among other things information in this database includes currently active policies and rules that allow interface unit to direct incoming packets to the correct server. Depending on network conditions and services desired these policies and rules can change very quickly.

Interface unit then translates the request and passes the translated request to the selected server as shown in step . Interface unit receives the response from server S as shown in step . Interface unit then translates the response and passes the translated response on to client C as shown in step .

Assume for illustration purposes that at this point interface unit receives a request from client C to retrieve data. Interface unit in response to the client C request opens a connection to client C and receives a request from client C to retrieve data using a path name as shown in step . Interface unit then selects the server hosting the content specified by the path name as shown in step .

In step interface unit determines whether client C has selected the same server as client C. If the outcome to step is negative then interface unit proceeds in a fashion necessary to satisfy client C s request which is not important to this embodiment . At this point the flowchart in ends. Alternatively if the outcome to step is positive then interface unit determines whether there are any open connections to the selected server as shown in step .

If the outcome to step is positive then interface unit proceeds in a fashion necessary to satisfy client C s request which is not important to this embodiment . At this point the flowchart in ends. Alternatively if the outcome to step is negative then interface unit utilizes the content length parameter to confirm that client C received all of the data that client C requested as shown in step . It is important to note that interface unit does not wait for client C to send a FIN or RST command in order to determine that client C is finished with the connection or is in think time . This allows for more efficient connection pooling due to the fact that interface unit can utilize each connection quicker than if interface unit waited for the client to close the connection prior to reusing the connection for another client.

In step interface unit then translates the request and passes the translated request to the selected server using the same connection as client C used as shown in step . Interface unit receives the response from server S as shown in step . Interface unit then translates the response and passes the translated response on to client C as shown in step . Interface unit utilizes the content length parameter to confirm that client C received all of the data that client C requested as shown in step .

Next interface unit closes or delinks the connection with client C in step . Finally interface unit closes or delinks the connection with client C in step and the flowchart in ends. As stated above with reference to the sequence of events as they were described with reference to is for illustration purposes only.

For simplicity we assume that connections to both client C and client C have already been established. Client C then sends a GET segment specifying a length of 49 bytes as shown by flow . Interface unit determines that no free open connections exist with server S and therefore opens a connection with server S not shown in . Interface unit then forwards the GET segment from client C to server S after modifying the sequence and acknowledgment numbers according to the translation equations described above as shown by flow line .

For illustration purposes assume that the data in the response segment has a total content data length of 999. Further assume that the data will be transmitted in two 300 data chunks and one 399 data chunk. Note that this is for illustration purposes only and is not intended to limit. Therefore the server S first responds with a chunk of the requested data or message specifying a sequence number of 6001 an acknowledgment number of 2000 and a chunk size field of 300 as shown by flow A. Interface unit receives the RESP segment translates the sequence and acknowledgment numbers and forwards the RESP segment to client C as shown by flow line A. Client C acknowledges receipt of the data to interface unit as shown by flow line B. Interface unit in return passes this acknowledgment on to server S as shown by flow line B.

Server S next responds with the second chunk of the requested data specifying a sequence number of 6301 an acknowledgment number of 2001 and a chunk size field of 300 as shown by flow A. Interface unit receives the RESP segment translates the sequence and acknowledgment numbers and forwards the RESP segment to client C as shown by flow line A. Client C acknowledges receipt of the data to interface unit as shown by flow line B. Interface unit in return passes this acknowledgment on to server S as shown by flow line B.

Server S next responds with the third chunk of the requested data specifying a sequence number of 6601 an acknowledgment number of 2002 and a chunk size field of 399 as shown by flow A. Interface unit receives the RESP segment translates the sequence and acknowledgment numbers and forwards the RESP segment to client C as shown by flow line A. Client C acknowledges receipt of the data to interface unit as shown by flow line B. Interface unit in return passes this acknowledgment on to server S as shown by flow line B.

Finally server S responds with the final chunk of the zero data indicated by a chunk size field that equals zero specifying a sequence number of 7000 an acknowledgment number of 2003 and a chunk size field of 0 as shown by flow . Interface unit receives the RESP segment translates the sequence and acknowledgment numbers and forwards the RESP segment to client C as shown by flow line . This indicates to interface unit and client C that all of the requested data has been transmitted.

At this point client C then sends a GET segment specifying a length of 50 bytes as shown by flow . Assume at this point that interface unit has no available connections to server S. The goal is to reuse the same connection to server S that was previous used for client C if client C is finished with the connection or is in think time . Instead of waiting for client C to initiate a FIN finish command or a RST reset command to free up the connection the interface unit uses the chunk size field that equaled zero to confirm that all of the requested data has been received by client C. This indicates to interface unit that even though client C may be pausing for some reason before it sends a FIN or RST command client C is finished with the connection. Interface unit modifies the acknowledgment and sequence numbers and forwards the GET segment to server S as shown by flow .

For illustration purposes assume that the data in the response segment has a total content data length of 500. Further assume that the data will be transmitted in one 300 data chunk and one 200 data chunk. Note that this is for illustration purposes only and is not intended to limit. Therefore the server S first responds with a chunk of the requested data specifying a sequence number of 7000 an acknowledgment number of 2050 and a chunk size field of 300 as shown by flow A. Interface unit receives the RESP segment translates the sequence and acknowledgment numbers and forwards the RESP segment to client C as shown by flow line A. Client C acknowledges receipt of the data to interface unit as shown by flow line B. Interface unit in return passes this acknowledgment on to server S as shown by flow line B.

Server S next responds with the second chunk of the requested data specifying a sequence number of 7300 an acknowledgment number of 2051 and a chunk size field of 200 as shown by flow A. Interface unit receives the RESP segment translates the sequence and acknowledgment numbers and forwards the RESP segment to client C as shown by flow line A. Client C acknowledges receipt of the data to interface unit as shown by flow line B. Interface unit in return passes this information on to server S as shown by flow line B.

Finally server S responds with the final chunk of the zero data indicated by a chunk size field that equals zero specifying a sequence number of 7500 an acknowledgment number of 2052 and a chunk size field of 0 as shown by flow . Interface unit receives the RESP segment translates the sequence and acknowledgment numbers and forwards the RESP segment to client C as shown by flow line . This indicates to interface unit and client C that all of the requested data has been transmitted.

The connection between client C and interface unit is then closed or delinked once interface unit receives a FIN or RST command from client C as shown by flow . Likewise the connection between client C and interface unit is then closed or delinked once it receives a FIN or RST command from client C as shown by flow . It is important to note however that interface unit maintains the connection with server S. It is also important to note that the sequence of events as they were described with reference to is for illustration purposes only and does not limit.

Interface unit then selects the server hosting the content specified by the path name as shown in step . Interface unit then translates the request and passes the translated request to the selected server as shown in step . Interface unit receives the response from server S as shown in step . Interface unit then translates the response and passes the translated response on to client C until chunk size field is equal to zero as shown in step .

Assume for illustration purposes that at this point interface unit receives a request from client C to open a connection. Interface unit in response to a client C request opens a connection to client C and receives a request from client C to retrieve data using a path name as shown in step . Interface unit then selects the server hosting the content specified by the path name as shown in step .

In step interface unit determines whether client C has selected the same server as client C. If the outcome to step is negative then interface unit proceeds in a fashion necessary to satisfy client C s request. At this point the flowchart in ends. Alternatively if the outcome to step is positive then interface unit determines whether there are any open connections to the selected server as shown in step .

If the outcome to step is positive then interface unit proceeds in a fashion necessary to satisfy client C s request. At this point the flowchart in ends. Alternatively if the outcome to step is negative then interface unit utilizes the fact that chunk size field equaled zero in step to confirm that client C received all of the message data that client C requested. It is important to note that interface unit does not wait for client C to send a FIN or RST command in order to determine that client C is finished with the connection or is in think time .

In step interface unit then translates the request and passes the translated request to the selected server using the same connection as client C used. Interface unit receives the response from server S as shown in step . Interface unit then translates the response and passes the translated response on to client C until chunk size field equals zero as shown in step . Interface unit utilizes the chunk size field to confirm that client C received all of the message data that client C requested.

Next interface unit closes or delinks the connection with client C in step . Finally interface unit closes or delinks the connection with client C in step and the flowchart in ends. As stated above with reference to the sequence of events as they were described with reference to is for illustration purposes only and does not limit.

The previous embodiments are described specifically when implemented within an interface unit such as interface unit that is connected to servers in a farm for the purpose of offloading connection processing overhead from the servers. However they can also be applied within other kinds of devices that are in the network connection path between the client and the servers. As network traffic flows through such devices they all have the opportunity to offload connection processing. Some examples of such devices are 

Load Balancers which distribute client network connections between a set of servers in a server farm local or geographically distributed .

Routers and switches also lie in the path of the network traffic. The industry trend may be to integrate additional functionality such as load balancing bandwidth management and firewall functionality within these devices.

Embodiments can also be applied within computer systems which are the end points of network connections. In this case add on cards can be used to offload the main processing elements within the computer system.

The method of flowchart can be implemented in one or more device s that are communicatively coupled to a data communication network. For example the method of flowchart can be implemented in an appliance such as appliance described above in reference to having a software architecture as described above in reference to . The method of flowchart will be described with continued reference to this exemplary embodiment.

As shown in the method of flowchart begins at step in which appliance receives an encrypted packet from one of clients . In an embodiment appliance is configured to act as a proxy SSL endpoint for servers decrypting encrypted packets received from clients and then sending there on for further processing as necessary and ultimately on to an appropriate resource based on address information within the encrypted packets. The appropriate resource may be for example any of servers or the cache managed by appliance . At step appliance performs decryption processing on the packet.

At step appliance which is configured in accordance with an embodiment to carry out AAA policies for access control authenticates and or authorizes the client from which the encrypted packet was received.

At step appliance which is configured in accordance with an embodiment to perform certain types of packet processing carries out packet processing on the decrypted packets to reduce the connection overhead processing requirements generated by the applicable network protocols.

At step appliance which is configured in accordance with an embodiment to compress and decompress content decompresses a request associated with the packet. In an embodiment the request comprises a web object request.

At step appliance is then able to activate the cache functionality which receives a clear and or authorized and or decompressed and or packet processed request for an object. Because of the prior processing described in reference to steps and the cache management logic can make a decision as to whether the object has been cached or is cacheable based on a clear authorized decompressed packet processed request and is therefore able to process a much wider array of requests then traditional caches and to carry out the caching more efficiently than under traditional approaches. Furthermore because the cache management logic is working in the kernel space along with the other processes it relates to the relevant object as a data structure with equal status in relation to such data structure as each of the other applications and therefore the integration is earned out in an extremely efficient manner 

As shown at step if the object is not already in the cache memory appliance sends a request on to one or more servers . Before the request is sent however several additional processing steps may occur.

For example at step appliance optionally performs connection processing to ensure efficient transit of the request to the server s and at step appliance optionally makes a load balancing decision to ensure that the request is sent to the most appropriate server s . Also in an embodiment the request is encrypted before it is sent to the server s via a back end encryption process thereby providing end to end network security. At step the request is transmitted to the server s 

At step appliance receives a response back from one of the servers . If back end encryption is supported as discussed above appliance decrypts the response from the server.

At step appliance compresses an object associated with the response from the server. In an embodiment the object comprises a web object.

At step the cache management logic in appliance stores the object in the cache in compressed form. The cache management logic is able to store compressed objects in this fashion due to the processing abilities Once the object is stored in the cache future client requests for the object can be served from the cache without performance of steps and as described above. This is indicated by the line directly connecting decision step to step in flowchart .

At stop after the object has been received from a server or retrieved from the cache appliance performs packet processing on the connection to more efficiently service the original client request. At step the response object is then re encrypted and delivered back to the client.

Each of the processing steps described above occurs at the kernel OS level of appliance . By implementing the cache in the middle of and integrated with other processing steps in the kernel OS space an embodiment is able to bring out additional functionality and improve performance of the cache.

Such integration permits a cache implementation in accordance with an embodiment to perform additional functions that are traditionally beyond the functional abilities of a cache. For example an embodiment permits the cache to work with encrypted and or compressed objects.

Another example of additional functionality that may be achieved by an embodiment involves the caching of end to end encrypted HTTPS traffic. Typically caches only store unencrypted HTTP responses from servers. Certain caches may in some cases support SSL encrypted HTTPS delivery from the cache to the clients but in any case traditional caches are not able to cache responses that have been encrypted by the server and so are unable to support end to end i.e. server to client encryption. Typically when a response is encrypted by the server in the form of HTTPS the cache is not able to decrypt such a response and is therefore unable to store the response in its cache memory. For this reason traditional caches fail to provide any benefit in the face of end to end encrypted traffic in an embodiment the integrated caching appliance serves as a two way termination point for the SSL encrypted HTTPS traffic.

For example in a embodiment the integrated caching appliance acts as a termination point both to encrypted traffic between the server and the appliance and between the appliance and the clients. In this manner the appliance is able to decrypt and cache SSL encrypted responses received from servers and when serving such responses to a client re encrypt such response and securely deliver it to the requesting client thereby enabling end to end encryption and thus increasing the applicability of caching to a wider variety of web traffic.

In an embodiment the appliance can also serve as an endpoint in an SSL virtual private network SSL VPN . In particular the appliance can act as a proxy SSL endpoint for any resource in a private data communication network decrypting encrypted packets received from a client and then sending there on to the appropriate destination server resource based on address information within the encrypted packets. A data communication session established between client and a gateway may be encrypted with the gateway serving as an encryption endpoint as described in the preceding paragraphs of the present application. As described the client may use Secure Sockets Layer SSL IPSec or some other encryption method to establish the encrypted data communication session by which an interception mechanism on the client directs traffic to the gateway while making the client browser think it is communicating directly with the destination servers or destination networks In such an embodiment the encrypted data communication session can be terminated at the gateway which also includes an integrated cache as described herein. In this way caching functionality can be integrated into the SSL VPN functionality.

The gateway can also perform any applicable AAA. policies to the request and consequently the gateway will serve cached objects only to appropriately authenticated clients as well as permitting requests only for users authorized to access a particular cached object. This is possible because the cache is integrated in such a way that the access control policies of the gateway are enforced before the cache sees any particular request. Thus cached objects get the benefit of access control without the cache itself needing to perform the authentication and authorization. Through the integration of the cache with such other functions the cache itself becomes more efficient and more effective at handling the variety of data that passes across today s networks. An embodiment also is able to improve the efficiency of the overall network performance by introducing the benefits of cache functionality to a broader array of web traffic.

Some other unique results of the mode of integration described above in accordance with an embodiment are as follows. One result is the ability to cache pre compressed data and serve it to compression aware clients. Another result is the ability to cache access controlled data. Yet another result is the ability to work with external caches to provide scalability of the cache. Because the cache is integrated with redirection and traffic management capabilities at the gateway external caches can be deployed to provide a second tier of caching thereby extending the capacity and the benefits of caching significantly. Through an embodiment this capacity is created without the cache module itself having to explicitly perform cache redirection policies.

In terms of performance by integrating the cache as described above the processors of the cache are freed from performing the variety of connection processing tasks that caches acting as a nodes on a network are traditionally required to perform and are thus able to perform its caching functions at their highest performance levels. Indeed by enabling the caching of compressed data the cache is able to function even more efficiently and allow users to realize even higher performance.

As previously noted in this application the efficiency arises as a result of the way the cache is integrated with the other network services and technologies including load balancing technology encryption AAA compression and other types of acceleration and packet processing. As a result processing duplications and other inefficiencies introduced by traditional modes of integration are avoided. These inefficiencies caused by unnecessary copying and context switching arise because each object received by the device must be copied to a message and then into a processor memory prior to processing by the relevant application. The request must then be copied back to the object or packet level for processing by the cache introducing additional memory copies. In contrast an embodiment carries out the integration at the OS or kernel level thereby enabling the cache to operate on the object as a data structure where the cache has equal status as the other applications and or processes in relating to and processing such data structure and where the need for such additional memory copies is obviated as all processes are working with the same data structure. The result is a more efficient integration.

Because web objects can change over time each potentially cacheable object is said to have a useful life or freshness The concept of freshness refers to the fact that the application server that originally generated the content also determines the period of time that such object can be served by a cache that may store such object. Caches must be able to determine whether or not the copy of an object stored in its memory is still fresh or whether the cache needs to retrieve a new copy of the object from the origin server. An embodiment implements a novel approach to assuring object freshness. Many conventional cache implementations try to keep the cached content fresh by fetching the content from the origin on a pre determined schedule. The fetching of content from the origin occurs at times established by the cache administrator typically based on one or both of the following approaches either at i regular specified intervals or ii when the content is about to expire.

There are two problems typically associated with the above commonly employed approaches. First unnecessary processing loads are imposed upon the origin server because that server is required to provide content to the cache requesting the refreshment whether such refresh occurs at specified intervals or as the content is about to expire without regard to whether such content will ultimately be served to clients Second the cache incurs additional processor load based on the extra processing overhead generated because the cache needs to keep track of the elements that must be refreshed and the time at which they have to be refreshed.

A cache in accordance with an embodiment solves the above problems using a novel pre fetching approach. The prefetching of the content is not performed in accordance with a predefined schedule or Just prior to expiration of the content. Instead an embodiment performs pre fetching only when both of the following conditions have been met 1 a client has made a request for the specified content and 2 that content is about to expire .

This approach addresses both problems described above. Pro active revalidation is more likely to generate a request for refreshing of content from the origin server only where such content is being actively accessed. This minimizes the amount of unnecessary load on the origin server As discussed above where the cache requests refreshment of objects that are not ultimately served to clients or only rarely get served depending on the sensitivity of the cache the cache is inefficiently utilizing both its own resources as well as the resources of the origin server. An embodiment avoids the inefficient use of the cache and server resources by requesting only that content that is being actively accessed. The approach also for the same reason reduces the bandwidth used for pre fetching and therefore makes more efficient use of network resources than traditional approaches.

Furthermore an embodiment uses the expiry information included in the cached object itself to determines whether to request refreshment of the object from the origin server. Such expiry information is typically included in the headers of the relevant object. This embodiment thus avoids the inefficiencies of staring any additional information for fetching unlike many traditional approaches which require the cache to keep a table tracking the schedule for refreshment. Using a demand based pre fetching technique also enhances benefits that are inherent to pre fetching. This technique reduces the number of cache misses for frequently accessed objects since such objects are very likely to undergo pro active revalidation just before they expire. This technique can also prevent the surge of traffic to an origin server that can occur when a large response that is in great demand expires. In the traditional approach all of the requests for such content miss the cache and get sent to the origin server because the cache content has expired. By contrast in an embodiment the content of the cache memory will generally be refreshed just prior to expiration and therefore the situation where cache misses occur while the cache is refreshing are much less likely to arise.

In an embodiment the aggressiveness of pre fetching can be controlled through adjusting the length of the duration before the expiry where the content is determined to be about to expire and also the number of client requests required to trigger refreshment by the cache of the relevant object.

In accordance with an embodiment the cache recognizes and does not store objects that are above a specified size in order to improve the object hit ratio. Caches typically have limited memory space devoted to storing cached objects and therefore certain responses that exceed allocated memory space are ultimately rejected as non cacheable and not stored by the cache. With traditional caches the cache attempts to store the large response in its cache memory and only aborts storing the response once the cache recognizes that the response size exceeds a predefined maximum size. Traditional caches will repeatedly attempt to cache the large response each time a request for such response is received by the cache from the server In each case the cache will need to determine that the object is non cacheable as exceeding the memory space Thus this is a manifestly inefficient approach.

In accordance with an embodiment the cache employs an optimization to avoid expending effort in storing such responses. Whenever the cache detects a response that becomes non cacheable due to response size it stores a notation regarding the corresponding request in a data structure termed a negative cell. The notation indicates that the request is non cacheable In the fixture when a client requests the same object the request is matched to the notation regarded the first request stored in the data structure. Eased on the match the cache will not try to cache the response and instead the request will completely bypass the cache.

There is no user configuration required for specifying the duration for which a negative cell should remain in the cache In fact the users are not even aware that this particular mechanism is being employed. In an embodiment the cache uses the regular expiry information that it would have employed to cache the big response to cache the negative information about that response.

In one embodiment a client side acceleration program may perform one or more acceleration techniques to accelerate enhance or otherwise improve a client s communications with and or access to a server such as accessing an application provided by a server. Referring now to a client having an acceleration program is depicted. In brief overview the client operates on computing device having an operating system with a kernel mode and a user mode and a network stack with one or more layers . The client may comprise any and all of the clients previously discussed. Although only one client is shown any number of clients may comprise the client . The client may have installed and or execute one or more applications . In some embodiments one or more applications may communicate via the network stack to a network. One of the applications N may also include a first program for example a program which may be used in some embodiments to install and or execute the acceleration program .

The network stack of the client may comprise any type and form of software or hardware or any combinations thereof for providing connectivity to and communications with a network. In one embodiment the network stack comprises a software implementation for a network protocol suite. The network stack may comprise one or more network layers such as any networks layers of the Open Systems Interconnection OSI communications model as those skilled in the art recognize and appreciate. As such the network stack may comprise any type and form of protocols for any of the following layers of the OSI model 1 physical link layer 2 data link layer 3 network layer 4 transport layer 5 session layer 6 presentation layer and 7 application layer. In one embodiment the network stack may comprise a transport control protocol TCP over the network layer protocol of the internet protocol IP generally referred to as TCP IP. In some embodiments the TCP IP protocol may be carried over the Ethernet protocol which may comprise any of the family of IEEE wide area network WAN or local area network LAN protocols such as those protocols covered by the IEEE 802.3. In some embodiments the network stack comprises any type and form of a wireless protocol such as IEEE 802.11 and or mobile internet protocol.

In view of a TCP IP based network any TCP IP based protocol may be used including Messaging Application Programming Interface MAPI email File Transfer Protocol FTP HyperText Transfer Protocol HTTP Common Internet File System CIFS protocol file transfer Independent Computing Architecture ICA protocol Remote Desktop Protocol RDP Wireless Application Protocol WAP Mobile IP protocol and Voice Over IP VoIP protocol. In another embodiment the network stack comprises any type and form of transport control protocol such as a modified transport control protocol for example a Transaction TCP T TCP TCP with selection acknowledgements TCP SACK TCP with large windows TCP LW a congestion prediction protocol such as the TCP Vegas protocol and a TCP spoofing protocol. In other embodiments any type and form of user datagram protocol UDP such as UDP over IP may be used by the network stack such as for voice communications or real time data communications.

Furthermore the network stack may include one or more network drivers supporting the one or more layers such as a TCP driver or a network layer driver. The network drivers may be included as part of the operating system of the computing device or as part of any network interface cards or other network access components of the computing device . In some embodiments any of the network drivers of the network stack may be customized modified or adapted to provide a custom or modified portion of the network stack in support of any of the techniques described herein. In other embodiments the acceleration program is designed and constructed to operate with or work in conjunction with the network stack installed or otherwise provided by the operating system of the client .

The network stack comprises any type and form of interfaces for receiving obtaining providing or otherwise accessing any information and data related to network communications of the client . In one embodiment an interface to the network stack comprises an application programming interface API . The interface may also comprise any function call hooking or filtering mechanism event or call back mechanism or any type of interfacing technique. The network stack via the interface may receive or provide any type and form of data structure such as an object related to functionality or operation of the network stack . For example the data structure may comprise information and data related to a network packet or one or more network packets. In some embodiments the data structure comprises a portion of the network packet processed at a protocol layer of the network stack such as a network packet of the transport layer. In some embodiments the data structure comprises a kernel level data structure while in other embodiments the data structure comprises a user mode data structure. A kernel level data structure may comprise a data structure obtained or related to a portion of the network stack operating in kernel mode or a network driver or other software running in kernel mode or any data structure obtained or received by a service process task thread or other executable instructions running or operating in kernel mode of the operating system.

Additionally some portions of the network stack may execute or operate in kernel mode for example the data link or network layer while other portions execute or operate in user mode such as an application layer of the network stack . For example a first portion of the network stack may provide user mode access to the network stack to an application while a second portion of the network stack provides access to a network. In some embodiments a first portion of the network stack may comprise one or more upper layers of the network stack such as any of layers 5 7. In other embodiments a second portion of the network stack comprises one or more lower layers such as any of layers 1 4. Each of the first portion and second portion of the network stack may comprise any portion of the network stack at any one or more network layers in user mode kernel mode or combinations thereof or at any portion of a network layer or interface point to a network layer or any portion of or interface point to the user mode and kernel mode .

The acceleration program of the present may comprise software hardware or any combination of software and hardware. In some embodiments the acceleration program comprises any type and form of executable instructions constructed and designed to execute or provide the functionality and operations as described herein. In some embodiments the acceleration program comprises any type and form of application program service process task or thread. In one embodiment the acceleration program comprises a driver such as a network driver constructed and designed to interface and work with the network stack . The logic functions and or operations of the executable instructions of the acceleration program may perform one or more of the following acceleration techniques 1 multi protocol compression 2 transport control protocol pooling 3 transport control protocol multiplexing 4 transport control protocol buffering and 5 caching via a cache manager which will be described in further detail below. Additionally the acceleration program may perform encryption and or decryption of any communications received and or transmitted by the client . In some embodiments the acceleration program also performs tunneling between the client and another computing device such as a server . In other embodiments the acceleration program provides a virtual private network connection to a server .

In some embodiments the acceleration program operates at one or more layers of the network stack such as at the transport layer. In one embodiment the acceleration program comprises a filter driver hooking mechanism or any form and type of suitable network driver interface that interfaces to the transport layer of the network stack such as via the transport driver interface TDI . In some embodiments the acceleration program interfaces to a first protocol layer such as the transport layer and another protocol layer such as any layer above the transport protocol layer for example an application protocol layer. In one embodiment the acceleration program may comprise a driver complying with the Network Driver Interface Specification NDIS or a NDIS driver. In another embodiment the acceleration program may comprise a min filter or a mini port driver. In one embodiment the acceleration program or portion thereof operates in kernel mode . In another embodiment the acceleration program or portion thereof operates in user mode . In some embodiments a portion of the acceleration program operates in kernel mode while another portion of the acceleration program operates in user mode . In other embodiments the acceleration program operates in user mode but interfaces to a kernel mode driver process service task or portion of the operating system such as to obtain a kernel level data structure . In further embodiments the acceleration program is a user mode application or program such as application 

The acceleration program may operate at or interface with a protocol layer in a manner transparent to any other protocol layer of the network stack . For example in one embodiment the acceleration program operates or interfaces with the transport layer of the network stack transparently to any protocol layer below the transport layer such as the network layer and any protocol layer above the transport layer such as the session presentation or application layer protocols. This allows the other protocol layers of the network stack to operate as desired and without modification for using the acceleration program . As such the acceleration program can interface with the transport layer to accelerate any communications provided via any protocol carried by the transport layer such as any application layer protocol over TCP IP.

Furthermore the acceleration program may operate at or interface with the network stack in a manner transparent to any application a user of the client and any other computing device such as a server in communications with the client . The acceleration program may be installed and or executed on the client in a manner such as the acceleration program may accelerate any communications of an application without modification of the application . In some embodiments the user of the client or a computing device in communications with the client are not aware of the existence execution or operation of the acceleration program . As such in some embodiments the acceleration program is installed executed and or operated transparently to an application user of the client another computing device such as a server or any of the protocol layers above and or below the protocol layer interfaced to by the acceleration program .

In some embodiments the acceleration program performs one or more of the acceleration techniques in an integrated manner or fashion. In one embodiment the acceleration program comprises any type and form of mechanism to intercept hook filter or receive communications at the transport protocol layer of the network stack . By intercepting a network packet of the client at the transport layer and interfacing to the network stack at the transport layer via a data structure such as a kernel level data structure the acceleration program can perform transport layer related acceleration techniques on the network packet such as transport control protocol TCP buffering TCP pooling and TCP multiplexing. Additionally the acceleration program can perform compression on any of the protocols or multiple protocols carried as payload of network packet of the transport layer protocol

In one embodiment the acceleration program uses a kernel level data structure providing access to any portion of one or more network packets for example a network packet comprising a request from a client or a response from a server. In one embodiment the kernel level data structure may be used by the acceleration program to perform the desired acceleration technique. In one embodiment the acceleration program is running in kernel mode when using the kernel level data structure while in another embodiment the acceleration program is running in user mode when using the kernel level data structure . In some embodiments the kernel level data structure may be copied or passed to a second kernel level data structure or any desired user level data structure. Although the acceleration program is generally depicted in as having a first portion operating in user mode and a second portion operating in kernel mode in some embodiments any portion of the acceleration program may run in user mode or kernel mode . In some embodiments the acceleration program may operate only in user mode while in other embodiments the acceleration program may operate only in kernel mode .

Furthermore by intercepting at the transport layer of the network stack or obtaining access to the network packet via a kernel level data structure the acceleration program can perform or apply the plurality of acceleration techniques at a single interface point or at a single point of execution or time of executing any executable instructions of the acceleration program . For example in one embodiment in a function or set of instructions of the acceleration program a plurality of the acceleration techniques may be executed such as by calling a set of executable instructions constructed and designed to perform the acceleration technique. In some embodiments the acceleration program at one interface point place of execution or in a set of instructions call one or more application programming interfaces APIs to any program service process task thread or executable instructions designed and constructed to provide 1 multi protocol compression 2 transport control protocol pooling 3 transport control protocol multiplexing 4 transport control protocol buffering and 5 caching via a cache manager and in some embodiments encryption .

By executing the plurality of acceleration techniques at one place or location in executable instructions of the acceleration program or at one protocol layer of the network stack such as the transport layer the integration of these acceleration techniques is performed more efficiently and effectively. In one aspect the number of context switches between processes may be reduced as well as reducing the number of data structures used or copies of data structures in memory needed or otherwise used. Additionally synchronization of and communications between any of the acceleration techniques can be performed more efficiently such as in a tightly coupled manner in a set of executable instructions of the acceleration program . As such any logic rules functionality or operations regarding the order of acceleration techniques which techniques to perform and data and information to be shared or passed between techniques can be performed more efficiently. The acceleration program can intercept a TCP packet at the transport layer obtain the payload of the TCP packet via a kernel level data structure and then perform desired acceleration techniques in a desired order. For example the network packet may be first compressed and then cached. In another example the compressed cached data may be communicated via a buffered pooled and or multiplexed TCP connection to a server.

In some embodiments and still referring to a first program may be used to install and or execute the acceleration program automatically silently transparently or otherwise. In one embodiment the first program comprises a plugin component such an ActiveX control or Java control or script that is loaded into and executed by an application . For example the first program comprises an ActiveX control loaded and run by a web browser application such as in the memory space or context of the application . In another embodiment the first program comprises a set of executable instructions loaded into and run by the application such as a browser. In one embodiment the first program comprises a designed and constructed program to install the acceleration program . In some embodiments the first program obtains downloads or receives the acceleration program via the network from another computing device. In another embodiment the first program is an installer program or a plug and play manager for installing programs such as network drivers on the operating system of the client .

In other embodiments the first program may comprise any and all of the functionality described herein in Section B. In one embodiment the first program may comprise a collection agent . In another embodiment the first program may comprise a program for installing a collection agent. In another embodiment the first program may also comprise a computing environment . In one embodiment the first program may comprise means for installing a computer environment such as an execution environment or virtual execution environment. In one embodiment the first program may comprise an application streaming client as previously discussed. In another embodiment the first program may comprise an application to be executed on a client .

In other embodiments the first program may comprise a portion of the functionality operations and logic of the acceleration program to facilitate or perform any of the functionality operations and logic of the acceleration program described herein such as any of the acceleration techniques. In some embodiments the first program is used to establish a connection such as a transport layer connection or a communication session with an appliance or a server such as a Secure Socket Layer SSL communication session. In one embodiment the first program is used to establish or facilitate the establishment of a virtual private network connection and communication session.

The cache manager of the acceleration program or the client as depicted in may comprise software hardware or any combination of software and hardware to provide cache access control and management of any type and form of content such as objects or dynamically generated objects served by the servers . The data objects or content processed and stored by the cache manager may comprise data in any format such as a markup language or communicated via any protocol. In some embodiments the cache manager duplicates original data stored elsewhere or data previously computed generated or transmitted in which the original data may require longer access time to fetch compute or otherwise obtain relative to reading a cache memory element. Once the data is stored in the cache memory element future use can be made by accessing the cached copy rather than refetching or recomputing the original data thereby reducing the access time. In some embodiments the cache memory element may comprise a data object in memory of the client . In other embodiments the cache memory element may comprise memory having a faster access time than memory otherwise used by the client . In another embodiment the cache memory element may comprise any type and form of storage element of the client such as a portion of a hard disk. In yet another embodiment the cache manager may use any portion and combination of memory storage or the processing unit for caching data objects and other content.

Furthermore the cache manager may include any logic functions rules or operations to perform any embodiments of the techniques described herein. For example the cache manager includes logic or functionality to invalidate objects based on the expiration of an invalidation time period or upon receipt of an invalidation command from a client or server . In some embodiments the cache manager may operate as a program service process or task executing in the kernel space and in other embodiments in the user space . In one embodiment a first portion of the cache manager executes in the user space while a second portion executes in the kernel space . In some embodiments the cache manager can comprise any type of general purpose processor GPP or any other type of integrated circuit such as a Field Programmable Gate Array FPGA Programmable Logic Device PLD or Application Specific Integrated Circuit ASIC .

The encryption engine of the acceleration program or the client comprises any logic business rules functions or operations for handling the processing of any security related protocol such as SSL or TLS or any function related thereto. For example the encryption engine encrypts and decrypts network packets or any portion thereof communicated by the client . The encryption engine may also setup or establish SSL or TLS connections on behalf of the client . As such the encryption engine provides offloading and acceleration of SSL processing. In one embodiment the encryption engine uses a tunneling protocol to provide a virtual private network between a client and another computing device such as a server

Still referring to the multi protocol compression engine of the acceleration program or the client comprises any logic business rules function or operations for compressing one or more protocols of a network packet such as any of the protocols used by the network stack of the client . For example multi protocol compression may include compression and decompression utilities comprising GZip compression and decompression differential compression and UnCompression or any other proprietary or publicly available utility for compressing and decompressing data to be transmitted over a network. In one embodiment multi protocol compression engine compresses bi directionally between the client and another computing device such as a servers any TCP IP based protocol including Messaging Application Programming Interface MAPI email File Transfer Protocol FTP HyperText Transfer Protocol HTTP Common Internet File System CIFS protocol file transfer Independent Computing Architecture ICA protocol Remote Desktop Protocol RDP Wireless Application Protocol WAP Mobile IP protocol and Voice Over IP VoIP protocol. In other embodiments multi protocol compression engine provides compression of Hypertext Markup Language HTML based protocols and in some embodiments provides compression of any markup languages such as the Extensible Markup Language XML . As such the multi protocol compression engine accelerates performance for users accessing applications via desktop clients e.g. Microsoft Outlook and non Web thin clients such as any client launched by enterprise applications like Oracle SAP and Siebel and even mobile clients such as the Pocket PC.

The acceleration program also performs transport protocol layer acceleration techniques of buffering pooling and multiplexing as will be described in further detail below. As such the acceleration program comprises any type and form of executable instructions having logic rules functions and operations to perform any of these techniques as described herein. The acceleration program intercepts controls and manages at the transport layer of the network stack any transport layer application programming interface API calls made by an applications via the network stack . The acceleration program responds to any requests of the client in a transparent manner such that the client receives a response as expected from the transport protocol layer of the network stack . For example in one embodiment the acceleration program intercepts in the network stack of the client a request to establish a transport layer connection with another computing device such as a server and may use a pool of one or more transport layer connections established by the acceleration program to respond to the request. In another embodiment the acceleration program multiplexes a request from a first application via an established transport layer connection used by a second application

In some embodiments the acceleration program comprises a mechanism for buffering or holding communications of the client at the client before transmitting on a network. For example the rate of consumption by the client of received communications from a network such as from a server may be less than the rate of production of communications transmitted by the client on the network. As such the client may be sending more requests to a server at a rate greater than by which the client can consume and process responses from such requests. The acceleration program can intercept a communication and determine if a rate of consumption and or rate of production of the client is below a predetermined threshold such as a threshold configured by a user the client or another computing device. If the determined rate is below the desired threshold the acceleration program stores the intercepted communication to a memory element of the client until the performance of the client increases the rate of consumption and or production to a rate equal to or higher than the predetermined or desired threshold. At that point the acceleration program communicates the client s communications on the network. As such a client side mechanism is provided to throttle communications of the client based on performance of consumption and or production of communications by the client .

The application depicted in can be any type and or form of application such as any type and or form of web browser web based client client server application a thin client computing client an ActiveX control or a Java applet or any other type and or form of executable instructions capable of executing on client or communicating via a network . The application can use any type of protocol and it can be for example an HTTP client an FTP client an Oscar client or a Telnet client. In some embodiments the application uses a remote display or presentation level protocol. In one embodiment the application is an ICA client developed by Citrix Systems Inc. of Fort Lauderdale Fla. In other embodiments the application includes a Remote Desktop RDP client developed by Microsoft Corporation of Redmond Wash. In other embodiments the application comprises any type of software related to VoIP communications such as a soft IP telephone. In further embodiments the application comprises any application related to real time data communications such as applications for streaming video and or audio.

The appliance comprises an application acceleration determination mechanism and a client side acceleration program . The application acceleration determination mechanism comprises software hardware or any combination of hardware and software. In some embodiments the application acceleration determination mechanism comprises any type and form of executable instructions such as a program services process task or thread having logic function rules or operations for determining whether an application executing on a client and or server can be accelerated or whether access or communications between a client and a server can be accelerated. In one embodiment a database is used by the application acceleration determination mechanism to determine whether an application can be accelerated. For example the database may associate an application with one or more acceleration techniques capable of accelerating the application and may be further based on user type form location processing capability and other characteristics of the client and or server . In some embodiments the application acceleration determination mechanism uses a look up table file data structure or object in memory comprising information identifying if an application by name type or category can be accelerated by an acceleration technique. In other embodiments the appliance and or application acceleration determination mechanism includes a configuration mechanism such as a user interface graphical command line or otherwise to receive user input to identify specify or configure whether an application or access to a server can be accelerated.

In some embodiments the application acceleration determination mechanism requests from the server information identifying whether an application may be accelerated and in further embodiments by what acceleration technique s and for what type and form of clients . In yet another embodiment the application acceleration determination mechanism comprises a database of historical information regarding the performance of an application between a client and a server with and without one or more client side acceleration techniques to provide a database of comparative and heuristic information about where the application is accelerated or capable of being accelerated using any client side acceleration techniques. For example the appliance may capture network related performance information related to the performance of the application from the client . As such the determination of whether an application is capable of being accelerated may be adapted to based on or influenced by changing operational and performance characteristics of the network .

In one aspect an application may either not be capable of being accelerated or may be capable of being accelerated but the acceleration would not be effective or would otherwise be minimal. In one embodiment the type and form of application may not use a protocol or may not communicate in a manner suitable for use with an acceleration technique. In another embodiment the protocol or manner in which the application communicates may allow for performing an acceleration technique but based on any of the operational or performance characteristics of the client appliance or server the acceleration technique would not be effective or otherwise would provide minimal acceleration. As such the application acceleration determination mechanism may determine the application is not desired to be accelerated based on whether the application is able to be accelerated or whether the acceleration would meet a desired pre determined threshold of performance improvement.

In another aspect the appliance stores a client side acceleration program in a storage or memory element of the appliance such as storage or memory provided by the hardware layer of the appliance. In one embodiment the appliance dynamically determines via the application acceleration determination mechanism an application to be used or being used by the client can be accelerated by the acceleration program executing on the client and transmits or otherwise communicates the acceleration program from storage or memory of the appliance to the client . In another embodiment the appliance determines communications between the client and a server can be accelerated by the acceleration program executing on the client and communicates the acceleration program to the client . In some embodiments the appliance receives downloads or obtains the acceleration program from another computing device such as a server .

In some embodiments the acceleration program receives downloads or obtains policy information from the policy engine of the appliance . In other embodiments the acceleration program executes and operates a policy engine either independently of or in conjunction with the policy engine of the appliance . In other embodiments the packet engine or portion thereof may be operated on the client such as part of the acceleration program . As such the acceleration program may operate on the client in accordance with the packet processing timer as described above. In one embodiment the acceleration program may perform integrated acceleration techniques in one point in execution and responsive to the granular time intervals provided by the pack processing timer .

In some embodiments the health monitoring program may check and determine the status error or history of any client side acceleration program on any client in communication with the appliance or to which the appliance transmitted the acceleration program . In some embodiments the health monitoring program or a portion thereof executes on the client .

Referring now to an embodiment of a method for dynamically providing by the appliance an acceleration program and automatically installing and executing the acceleration program by the client is depicted. In brief overview at step the appliance intercepts a request from a client to establish a communication session with the server. At step the appliance transmits the acceleration program to the client for the client to automatically install and execute. At step upon receipt of the acceleration program the client automatically executes or performs a silent installation of the acceleration program . At step upon completion of installation of the acceleration program the client automatically executes the acceleration program in the network stack to intercept communications between the client and the server . At step the acceleration program performs any of the plurality of acceleration techniques and may encrypt and or decrypt communications.

In further detail at step the appliance may intercept or otherwise receive by any suitable means and mechanisms a request from the client to establish a communication session with the server . In one embodiment the packet engine of the appliance intercepts communications from the client . In other embodiments the appliance establishes a first transport layer connection with the client for example with the acceleration program and a second transport layer connection with the server on behalf of the client . As such the appliance may receive intercept or otherwise obtain any of the client s communications transmitted to the server . In some embodiments the appliance intercepts a request for the client to establish a transport layer connection with the server . In other embodiments the appliance intercepts a request to establish a communication session via any protocol layer above the transport layer connection such as an application layer protocol of HTTP. This embodiment of the method may be practiced with a request to establish a communication session at any protocol layer of the network stack of the client .

At step the appliance transmits the acceleration program to the client . The appliance may transmit the acceleration program at any point before during or after establishing the communication session requested by the client . In one embodiment the appliance transmits the acceleration program to the client in response to intercepting the client request. In another embodiment the appliance forwards the request to the server and transmits the acceleration program to the client . In some embodiments the appliance establishes the communication session with the server and upon establishment of the communication session the appliance transmits the acceleration program . In yet another embodiment the appliance performs authentication and or authorization of the client or the user of the client and if the authenticated user or client is so authorized the appliance transmits the acceleration program to the client . In one embodiment the appliance forwards the client s request to the server for authentication and or authorization and if the server authenticates and or authorizes the client s request the appliance transmits the acceleration program to the client .

In some embodiments the appliance transmits the acceleration program from storage or memory of the appliance . In other embodiments the appliance requests the acceleration program from the server and forwards the received acceleration program to the client . In another embodiment the server transmits the acceleration program to the client . In one embodiment the appliance transmits a Uniform Resource Locator URL to the client for the client to obtain download or receive the acceleration program. In some embodiments the URL identifies a location of the acceleration program in storage or memory of the appliance while in other embodiments the URL identifies the acceleration program on a server such as a web server providing the acceleration program for download. In one embodiment the acceleration program is stored on the client and the appliance transmits a key such as an encryption or license key to the client for the client to install and make use of the acceleration program stored on the client . In some embodiments the appliance transmits to the client any files configuration data or other information to be used to install and execute the acceleration program on the client .

In one embodiment the acceleration program is designed and constructed to be automatically installed and executed by the client . The acceleration program may include any files entries configuration data or instructions to cause the acceleration program to be registered or recognized by the operating system of the client in accordance with the type and form of operating system. In one embodiment another computing device such as a server or an appliance transmits the acceleration program to the client and the client automatically installs and executes the acceleration program . In one embodiment the acceleration program is designed and constructed to be a plug and play PnP device to be added to a running computing device . In some embodiments the acceleration program is a self installed executable such as an executable including an installer program and the acceleration program . In other embodiments the acceleration program may include a plurality of files for example an installation package or installation download such as files necessary to register and install the acceleration program in the operating system of the client . For example the acceleration program may comprise an .inf file and a .sys file. An .inf file provides Windows Setup in Microsoft Windows family of operating systems with the information required to set up a device such as a list of valid logical configurations for the device and the names of driver files associated with the device. In some embodiments the .inf file may comprise an autorun .inf file which is a configuration file that tells or informs the operating system which executable to start and any configuration information related to starting the executable. In one embodiment the .sys file is the driver file comprising the acceleration program or a portion thereof.

At step the client automatically installs the acceleration program . The acceleration program may be installed in any suitable manner in accordance with the operating system of the client . In one embodiment the client installs the acceleration program upon receipt of the acceleration program . In some embodiments the client automatically performs or executes a silent installation of the acceleration program . In one embodiment the silent installation is performed transparently to a user or application of the client . In other embodiments the silent installation of the acceleration program does not require a reboot or restart of the client . In another embodiment the silent installation does not require interaction by the user to start and or complete the installation. In other embodiments the silent installation of the acceleration program occurs while the client is running and transparently to a network layer session layer and or application layer of the network stack . In some embodiments the acceleration program is a self installed executable that is executed by the client . In other embodiments the client uses a plug and play manager to install the acceleration program . In one embodiment the client comprises an installation manager which receives and installs the acceleration program . In another embodiment the acceleration program transmitted by the appliance also includes an installation program that installs the acceleration program .

In another embodiment the acceleration program is automatically installed via a silent installation. In one embodiment a silent installation comprises an installation unattended by a user. In another embodiment a silent installation comprises an installation not requiring or having interaction by the user to start and or complete the installation. In some embodiments the installation is silent in that the installation process does not display information regarding a status or progress of the installation. In one embodiment the installation is silent in that it is transparent to the user. In other embodiments the installation is silent because the installation of the acceleration program does not require a reboot or restart of the client . In another embodiment the installation is silent in that the installation occurs seamlessly during operation of the client without interruption or disruption to the client s operation. As such the acceleration program can be installed in a manner that is transparent to the user or an application of the client by not requiring a reboot and not displaying any information to the user related to the installation.

In order to prevent or avoid a reboot or restart of the client in some embodiments the client such as the operating system of the client has a plug and play manager to install and configure drivers such as a network driver in one embodiment of the acceleration program for Plug and Play devices while the operating system is running. In one embodiment the plug and play manager is not instructed to reboot or restart the client based on the configuration of the installation package of the acceleration program . In another embodiment the .inf file does not comprise an instruction to reboot or restart the computer. In one embodiment the acceleration program can be implemented as a side by side component instead of replacing shared in use dynamic link libraries DLLs . In other specific embodiments for a network driver of the acceleration program the acceleration program uses the INetCfgPnpReconfigCallback network driver API so that a user will not be required to reboot the operating system to cause configuration changes to take effect in the driver. Additionally the acceleration program may have a notify object that calls the SendPnpReconfig API within its implementation of the ApplyPnpChanges method of the INetCfgComponentControl to send configuration information to the driver of the network component that owns the object. The SendPnpReconfig API provides the notify object with a mechanism to send data to the driver and in some embodiments is used to avoid requiring a user to reboot the operating system before configuration changes take effect.

At step upon completion of installation of the acceleration program automatically silently transparently or otherwise the acceleration program is automatically executed on the client . In some embodiments the installation program that installs the acceleration program starts or executes the acceleration program . In some embodiments the installer program for the acceleration program makes a system call to load or execute the acceleration program in memory of the client . In one embodiment the installation of the acceleration program comprises an instruction command or directive to start the acceleration program . In one embodiment the acceleration program includes an automatic run configuration such as an autorun.inf file that notifies the client to automatically run the acceleration program . In other embodiments a plug and play manager or the operating system of the client automatically executes the acceleration program upon installation. In one embodiment the acceleration program comprises a service process thread or task that is started by the client . In some embodiments the acceleration program is a service of the operating system that is configured to automatically start. In one embodiment the acceleration program comprises a network driver loaded in the memory of the network stack of the operating system of the client

In another embodiment the acceleration program comprises a network driver that is loaded into memory of the client . In some embodiments the acceleration program is loaded into memory allocated to the network stack . In some cases the acceleration program is loaded and executed in a memory area or space that allows the acceleration program to access a protocol layer of the network stack such as the transport layer. In other cases the acceleration program is loaded and executed in a memory that allows the acceleration program to access a kernel level data structure . In other embodiments the acceleration program is loaded into memory of an application . In another embodiment the acceleration program executes independently in its own memory space or context. In one embodiment the acceleration program runs in the memory space or context of an application . In some embodiments the acceleration program is loaded into user mode memory or memory allocated to the user mode while in other embodiments the acceleration program is loaded into kernel mode memory or memory allocated to the kernel mode

In some embodiments the acceleration program is loaded into memory and or executed on the client transparently to a user of the client an application of the client the appliance or the server . In other embodiments the acceleration program executes to interface with the transport layer of the network stack and executes transparently to any protocol layer above the transport layer such as a session or application layer and any protocol layer below the transport layer such as the network layer. In one embodiment the acceleration program executes transparently to any transport layer connection of the client or the transport layer itself.

At step the loaded started or otherwise executing acceleration program performs any of the plurality of acceleration techniques of the acceleration program such as any techniques provided by 1 multi protocol compression 2 transport control protocol pooling 3 transport control protocol multiplexing 4 transport control protocol buffering and 5 caching via a cache manager . The acceleration program may also perform any encryption and or decryption of communications between the client and the server . In one embodiment the acceleration program performs multi protocol compression. In another embodiment the acceleration program performs transport control protocol pooling and in a further embodiment the acceleration program performs multiplexing via the pooled transport layer connection. In one embodiment the acceleration program performs transport control protocol buffering. In some embodiments the acceleration program performs caching. In other embodiments the acceleration program performs caching and compression. In one embodiment the acceleration program performs caching with transport layer pooling and multiplexing. In another embodiment the acceleration program performs multi protocol compression with transport layer pooling and multiplexing. In another embodiment the acceleration program performs caching and or compression with TCP buffering and in a further embodiment with TCP pooling and multiplexing.

As such the client side acceleration program is dynamically provided by the appliance and automatically installed and executed on the client in a silent manner or transparent to the user or application of the client to perform one or more client side acceleration techniques to communications between the client and a server . The acceleration program may perform these acceleration techniques transparently to any protocol layer of the network stack and transparently to a user of the client application of the client appliance or server.

In another aspect the appliance may determine if an application requested to be accessed by the client can be accelerated and provide the acceleration program to the client if the application can be accelerated. Referring now to another embodiment of a method is depicted. The method may be practiced upon requests to establish a connection or communication session as well as requests to access an application on a server. In brief overview of method at step the appliance intercepts a request from a client requesting access to an application on a server . At step the appliance determines if the application is capable of being accelerated. At step if the application cannot be accelerated then the application forwards the request to the server at step . At step if the application can be accelerated then the appliance determines if the acceleration program is installed on the client or has been previously transmitted to the client . If the acceleration program has not yet been provided to the client then the method continues at step of the method described above to transmit install and execute the acceleration program. If the acceleration program has been installed and is executing on the client then the appliance at step sends a message to the acceleration program on the client to accelerate the application . At step of method the acceleration program performs a plurality of acceleration techniques on the communications for the application and may encrypt and or decrypt such communications.

In further detail at step the appliance may intercept by any suitable means and mechanisms a request from the client to access an application provided by the server . In one embodiment the packet engine of the appliance intercepts communications from the client . In other embodiments the appliance establishes a first transport layer connection with the client for example with the acceleration program and a second transport layer connection with the server on behalf of the client . As such the appliance may receive intercept or otherwise obtain any of the client s communications transmitted to the server . In some embodiments the appliance intercepts a request for the client to access an application via an established transport layer connection with the server . In other embodiments the appliance intercepts a request to establish a communication session via any protocol layer above the transport layer connection such as an application layer protocol of HTTP. In one embodiment the appliance intercepts a request from the client to display and provide an application from the server via a remote display protocol such as ICA or RDP.

At step the appliance determines whether the application requested by the client can be accelerated. In some embodiments the appliance identifies extracts or otherwise processes an application identifier from the intercepted client request that identifies the application by name type or category. In one embodiment the application acceleration determination mechanism is used by the appliance to determine if or whether the application can be accelerated. In some embodiments the application acceleration determination mechanism performs a query or lookup in a database lookup table or other structured source of data in memory or storage such as a data structure or object to determine if the application can be accelerated. In another embodiment the appliance sends a communication such as request to a server to determine whether the application can be accelerated.

In other embodiments the appliance has a performance log or history to determine if the application has been accelerated before and whether the acceleration had improvement on the performance and operation of the application . As such the appliance may determine that an application can be accelerated if such acceleration meets a predetermined threshold of improvement to performance or operations of the application . In yet another embodiment the appliance provides heuristic rules based on the current operation and performance of the network client or server . In one embodiment the application may be determined to be capable of being accelerated if the client has certain performance and operational characteristics or capabilities for example a certain speed processor or a minimum amount of memory. In some embodiments the application may be determined to be capable of being accelerated based on a configured policy or rule such as in the policy manager of the appliance . For example an application to be communicated between a remote user with a certain type of client accessing a certain type of application and or server may be accelerated. In other embodiments the application may be determined to be capable of acceleration based on an authentication and authorization of the user or the client . In yet another embodiment the application may be determined to not be desired to be accelerated. For example the application is of a type that is infrequently used.

At step if the application is determined not to be capable of being accelerated or otherwise it is desired not to apply acceleration techniques to the application on the client the appliance forwards the intercepted client request to the server at step and does not transmit or provide the acceleration program to the client . In one embodiment the appliance may perform or provide appliance based acceleration of the appliance . In other embodiments the appliance does not perform acceleration of the application on the appliance . In yet another embodiment the appliance may perform some acceleration techniques and not others for the application if the appliance determines the application is not capable of or otherwise desired to be accelerated.

At step if the application is determined to be capable of being accelerated or otherwise it is desired to apply acceleration techniques to the application on the client the appliance determines if the acceleration program has been provided to the client . In one embodiment the appliance determines if the acceleration program has been installed on the client or is executing on the client . In some embodiments the appliance sends a communication to the acceleration program on a client to determine if the acceleration program is running on the client . In other embodiments the appliance checks a log file or history file to determine if the acceleration program has been transmitted to the client . In another embodiment the appliance checks with a health monitoring program of the appliance or the client to determine if the acceleration program is executing on the client .

If the appliance determines the acceleration program has not been transmitted installed and or executed on the client the appliance will provide the acceleration program in accordance with the steps of method described in conjunction with . For example the appliance transmits the acceleration program to the client which the client upon receipt automatically installs and executes. In one embodiment upon performance of the suitable steps of the embodiment of method the appliance may communicate at step a message to the acceleration program to apply one or more of the accelerations techniques to the application . In other embodiments if the acceleration program is already installed and executing then at step the appliance communicates a message to the acceleration program to apply one or more of the accelerations techniques to the application .

In some embodiments the acceleration program performs any of the acceleration techniques available by the acceleration program to the identified application . In other embodiments the appliance indicates to the acceleration program which of the acceleration techniques to perform for the application . In one embodiment the acceleration program may apply the desired acceleration techniques for the application on a per session basis. That is the message from the appliance to the acceleration program only informs the acceleration program to perform acceleration techniques for this instance or session of the application . In other embodiments once the acceleration program receives a message from the appliance to apply acceleration techniques for the identified application the acceleration program applies the acceleration techniques for any instances or sessions of the application or until the client is rebooted or restarted or the appliance is rebooted or restarted.

In one embodiment the message from the appliance at step is not application specific. For example the message informs the acceleration program to execute one or more of the acceleration techniques for any application of the client . In some embodiments the message sent to the client informs the acceleration program to stop using any one or more of the acceleration techniques for the application or for all applications . In another embodiment the appliance communicates a message to the acceleration program to ignore certain applications . In yet another embodiment the appliance communicates a message to the acceleration program to provide configuration data or information to the acceleration program such as an update to an acceleration technique or application of a new acceleration technique.

At step the acceleration program performs any of the plurality of acceleration techniques of the acceleration program for the application such as any techniques provided by 1 multi protocol compression 2 transport control protocol pooling 3 transport control protocol multiplexing 4 transport control protocol buffering and 5 caching via a cache manager . The acceleration program may also perform any encryption and or decryption of communications of the application between the client and the server . In one embodiment the acceleration program performs multi protocol compression of application related data. In another embodiment the acceleration program performs transport control protocol pooling and in a further embodiment the acceleration program performs multiplexing via the pooled transport layer connection. In one embodiment the acceleration program performs transport control protocol buffering. In some embodiments the acceleration program performs caching. In other embodiments the acceleration program performs caching and compression. In one embodiment the acceleration program performs caching with transport layer pooling and in a further embodiment also with multiplexing. In another embodiment the acceleration program performs multi protocol compression with TCP buffering and in a further embodiment with transport layer pooling and in yet a further embodiment also with multiplexing. In another embodiment the acceleration program performs caching with compression and in a further embodiment with TCP pooling and in yet a further embodiment with multiplexing.

As such an appliance dynamically determines whether to the accelerate an application or whether the application can be accelerated and communicates to the client side acceleration program to perform on the client any one or more of the acceleration techniques for the application . Furthermore in some embodiments a plurality of acceleration programs may be dynamically delivered to the client by the appliance and automatically installed and executed by the client . For example an acceleration program may be provided in accordance with the techniques and methods for each connection to a server or each communication session with an application . As such the client may automatically install and execute a plurality of acceleration programs to handle and perform acceleration for each server or each application 

Referring now to an embodiment of a method for performing a plurality of acceleration techniques in an integrated manner is depicted. In brief overview at step the acceleration program intercepts at the transport layer a network packet of a communication between the client and server via a transport layer connection. At step the acceleration program accesses at the transport layer the network packet via a kernel level data structure for example a data structure provided via an API to the network stack of the client . At step the acceleration program performs a plurality of the acceleration techniques in an integrated manner using the kernel level data structure at an interface point or point of execution in the acceleration program .

In further detail at step the acceleration program intercepts by any suitable means and mechanism a network packet of a communication between the client and the server via a transport layer connection. In one embodiment the acceleration program intercepts a network packet of or related to a request by the client or a response thereto to establish a transport layer connection between the client and the server . In another embodiment the acceleration program intercepts a network packet of or related to a request or a response thereto to access or use an application via the transport layer connection between the client and the server . In one embodiment the acceleration program intercepts the network packet at the transport protocol layer via a transport driver interface or otherwise a network driver interfaced at a transport protocol layer of the network stack . In another embodiment the acceleration program intercepts the network packet at the transport protocol layer or any other protocol layer of the network stack via a Network Driver Interface Specification NDIS driver or a mini port driver or a mini filter driver. In some embodiments the acceleration program intercepts the network packet at the transport layer via a hooking or filtering mechanism.

At step the acceleration program accesses or otherwise obtains information and data of the network packet intercepted at the transport layer via a kernel level data structure . By using the kernel level data structure the acceleration program can obtain information and data on the payload s or the one or more protocols carried or transported by the network packet at the transport layer. In some embodiments using a kernel level data structure to represent the network packet at the layers of the network stack at and or above the transport layer enables the acceleration program to perform or operate the plurality of acceleration techniques at the transport layer and for protocol layers carried by the transport layer network packet. In one embodiment using a single kernel level data structure prevents or avoids copying and memory allocation along with context switching from using multiple data structures at various protocol layers of the network stack . In one embodiment the acceleration program copies the kernel level data structure to a second data structure which may comprise another kernel level data structure or a user level data structure.

At step the acceleration program performs executes or operates the plurality of acceleration techniques at single interface point or location in the program or in a set of executable instructions or one point of execution of the program . The acceleration program performs any of the plurality of acceleration techniques of the acceleration program such as any techniques provided by 1 multi protocol compression 2 transport control protocol pooling 3 transport control protocol multiplexing 4 transport control protocol buffering and 5 caching via a cache manager . The acceleration program may also perform any encryption and or decryption of communications of the application between the client and the server at the same point in execution of the acceleration techniques of the acceleration program .

In one embodiment the acceleration program performs in a set of executable instructions such as function call or one place or location any desired plurality of the acceleration techniques subsequent to each other. For example the acceleration program obtains the intercepted network packet via a kernel level data structure and then executes instructions representing the logic function rules or operation of the acceleration techniques subsequent to each other. As such information and data of the network packet can be extracted or obtained once via the kernel level data structure and used as input parameters arguments and conditions for any of instructions of the acceleration program representing the acceleration techniques. Although the network packet carries higher level protocol data and information the acceleration program in some embodiments processes the network packet and the higher level protocol data and information at one point and at one time during execution. Additionally the acceleration program may perform each of a plurality of acceleration techniques in any desired order in an integrated manner such as compression data stored to the cache manager or compressing uncompressing data retrieved from the cache.

In one embodiment the acceleration program performs multi protocol compression and caching subsequently to each other. In another embodiment the acceleration program performs subsequent to each other operations related transport control protocol pooling and multiplexing via the pooled transport layer connection. In one embodiment the acceleration program performs transport control protocol buffering subsequently to compression and caching or to TCP pooling and or multiplexing. In some embodiments the acceleration program performs caching. In one embodiment the acceleration program performs caching subsequently with transport layer pooling and multiplexing. In another embodiment the acceleration program performs multi protocol compression subsequently with transport layer pooling and multiplexing. In another embodiment the acceleration program performs caching and or compression subsequently with TCP buffering and in a further embodiment subsequently with TCP pooling and multiplexing.

Although the acceleration program is generally described as subsequently performing the acceleration techniques subsequent execution may also include other logic functions and operations not related to acceleration but integrated and executed in between each acceleration technique. The acceleration program still obtains operational and performance efficiency with such integration as the executable instructions for the acceleration techniques and any other operations or function are executed at a single interface point or point of execution in the acceleration program. Furthermore the acceleration techniques for protocol layers carried or above the transport protocol layer are processed at one time and or at one location at the transport layer. As such acceleration techniques for these higher level protocols do not need to be applied again as the network packet traverses and gets processed in these higher levels of the network stack or at a later point in the network stack .

In other aspects a first program and the acceleration program or also referred to as the second program in this embodiment can be used. In one embodiment the first program along with the second program can be used to facilitate and establish a virtual private network connection with a server such as via appliance over which the client side acceleration techniques may be applied. In another embodiment the first program is used to install and execute the second program or the acceleration program .

Referring now to an embodiment of a method for practicing this aspect is depicted. In brief overview at step the client logs in and establishes a communication session with the appliance At step the appliance sends the first program to the client . At step the client installs and executes the first program which in turns installs and executes the acceleration program i.e. the second program. At step the client communicates with and accesses resources on a private network via an established encrypted data communication session. At step the client logs out from the appliance and terminates the communication session with the appliance .

At step of method the client performs a log in procedure and establishes an encrypted data communication session with appliance via network . In one embodiment the encrypted data communication session is used as a tunnel to bridge traffic from client to any of servers which reside behind appliance in private data communication network. In an embodiment client uses a web browser such as Microsoft Internet Explorer or Netscape Navigator to log in and establish a data communication session with appliance using Secure Sockets Layer SSL or other encryption methods such as IPSec and Transport Layer Security TLS . In another embodiment a protocol such as Hypertext Transfer Protocol over Secure Sockets Layer HTTPS may be used to initiate the encrypted data communication session.

At step in response to log in and establishment of the encrypted data communication session appliance sends a first program to client over network . The first program is designed and constructed or otherwise configured to act as a tunnel endpoint for communication over the encrypted data communication session. In one embodiment the first program comprises a plug in application that is automatically installed and executed by the browser of the client . For example the first program may comprise an ActiveX control that is provided as a plug in to be executed by a Microsoft Internet Explorer Web browser. In another embodiment the first program may comprise a Java applet that is provided as a plug in to be executed by a Netscape Navigator Web browser or another control or programming component that works across network environments.

At step client installs and executes the first program wherein executing the first program comprises installing a second program on client . In one embodiment the first program may be automatically installed and executed such as using any of the techniques discussed in conjunction with method and . In some embodiments the first program obtains downloads or receives the second program or the acceleration program from the appliance . In another embodiment the first program comprises a installer or install manager for the second program such as the acceleration program to automatically install and execute the second program such as by way of a silent installation or an installation transparent to a user of the client application of the client the appliance or the server .

In one embodiment the second program is configured in part to intercept communications from applications running on client that are destined for resources on network and to provide the intercepted communications to the first program for sending to appliance via the encrypted data communication session. The second program may also be configured to provide intranet network name resolution service and optionally split network traffic. By splitting the traffic an embodiment is able to determine what traffic is channeled to an SSL tunnel or encryption tunnel of the first program and what traffic is permitted or allows to continue along for processing by the transport layer of the network stack under normal routine or typical operations of the client . In an embodiment the second program comprises a dynamic interceptor for instance a filter device driver that is inserted as a hook into an operating system of client . For example the second program may comprise a filter device driver that is attached to the transport layer stack of the client operating system such as the transport layer stack of a Microsoft Windows operating system.

At step once the first and second programs have been installed applications running on client may communicate with and access resources such as applications and data on private data communication network via the established encrypted data communication session. The manner in which this communication occurs will be discussed in more detail below with respect to . Note that in an one embodiment the functions of the first program and second program as described above are performed by a single control or programming component that is automatically installed and executed by client such as the acceleration program . In addition to providing a virtual private network connection and communications the first program and or second program such as the acceleration program may perform any of the acceleration techniques described herein on communications of the client via the virtual private network connection e.g. the encrypted tunnel or bridge to appliance .

At step client performs a log out procedure to disconnect from network which terminates the encrypted data communication session with appliance . In one embodiment at time of logging out the first program automatically cleans up the modifications made to the operating system of the client to return the operating system to a state prior to the installation of the first program and or second program. In one embodiment the first program and or second program also includes an uninstaller or uninstall instructions to remove the first and second programs from the operating system of the client or from further operation on the client in a non intrusive manner to the continued operations of the client . In yet another embodiment the first program and or the acceleration program removes any files such an temporary files or cookies used by applications of the client during any communication connections or sessions provided.

At step an application of a client makes a new connection or resolves a domain name via the transport protocol layer of the network stack of the client . In one embodiment the application may request to establish a transport layer connection between the client and a server or between the client and the appliance . In another embodiment the application or the client may request access to an application provided by the server . For example the server may provide for server based computing or thin client computing by transmitting a remote display protocol of ICA or RDP representing output of an application executing on the server . In another embodiment the client may request access to resources of a server such as files or directories or email services. In some embodiments the client may be on a public network and the server on a private network . In other embodiments the client and server may be on different private networks.

At step the second program executes one or more functions automatically or otherwise before any transport layer functions are initiated. In some embodiments the second program is or otherwise comprises the acceleration program . In one embodiment the second program intercepts or otherwise receives the client request of step . In some embodiments the application of the client makes API calls to the network stack which are intercepted by the second program. Prior to any API calls being processed by the transport layer of the network stack the second program is hooked into or otherwise interfaced to the network stack to execute logic rules functions or operations prior to the communication being transmitted or processed for transmission via a transport layer connection.

At step the second program intercepts communications from the client such as by any application on client that are destined for resources on a network and re routes them to the first program which in an embodiment comprises an ActiveX control plug in a Java applet or other control or programming component that works across network environments. The second program may access read or otherwise obtain destination information from the network packet or packets providing the intercepted communications to determine the communication is destined for a network such as a private network behind appliance . For example the second program may extract or interpret the destination IP address and or port from the network packet. Upon determination an intercepted communication is destined for network the second program communicates the intercepted communication to the first program via any suitable interface means and mechanism such as via any inter process communication interface or an API call. In one embodiment the intercepted communication is sent to the first program as is or in other embodiments the intercepted communication is pre processed by the second program prior to sending to the first program . For example the second program may remove the payload from the intercepted communication and forward the payload to the first program .

At step each intercepted communication is terminated or proxied by the first program and the first program prepares the intercepted communication for transmission via the established encrypted data communication session. In one embodiment the first program separates out the payload and encapsulates the payload for delivery via the established encrypted data communication session. In another embodiment the first program encapsulates the intercepted communicated as received from the second program. In some embodiment the payload is a TCP payload and is encapsulated into a new TCP connection between the client and the server such as via appliance .

At step the first program sends the intercepted communications over network to appliance via the pre established encrypted data communication session. In some embodiments the first program encrypts the intercepted communications and sends the encrypted intercepted communications to appliance . In one embodiment encryption is carried out in accordance with SSL protocols. In another embodiment encryption is TLS based. Any type and form of encryption and or decryption may be used by either first program or the acceleration program .

At step appliance acts as a proxy terminating the connection sent by the first program . The appliance decrypts the communications received from the first program and forwards the decrypted communications onto the appropriate destination resource on network via a second connection that the appliance has established with the destination resource on network . In one embodiment decryption is carried out in accordance with SSL protocols or other applicable encryption and decryption protocols. In some embodiments the appliance performs one or more acceleration techniques on the communication forwarded to the destination resource such as one or more of the following techniques provided by 1 multi protocol compression 2 transport control protocol pooling 3 transport control protocol multiplexing 4 transport control protocol buffering and 5 caching via a cache manager .

At step the destination resource processes the decrypted communications. In one embodiment the decrypted communications is a request to establish a connection or communication session. In another embodiment the decrypted communications is a request to start or access an application on behalf of the client . In other embodiments the decrypted communications is a request for a web page such as a HTTP request to receive a web page from a web server .

At step if the decrypted communications include a request for which there is a response then the destination resource sends out responsive communications to appliance . In some embodiments the response includes an acknowledgement of establishing a connection or communication session as requested by the client . In other embodiments the response includes an error message. In one embodiment the response includes an authentication request or a challenge response mechanism. In some embodiments the response includes an acceleration program to be used by the client . In another embodiment the response includes HTML such as a web page to be displayed by the client . In other embodiments the response includes an object such as a dynamically generated object.

At step appliance sends the responsive communications over network to the first program on client via the pre established encrypted data communication session. In one embodiment the appliance encrypts the responsive communications and sends the encrypted responsive communications to the first program . In some embodiments encryption is carried out in accordance with SSL protocols or other applicable encryption and decryption protocols. Furthermore the appliance may perform any of the acceleration techniques on communications to the client such as multi protocol compression caching or TCP buffering .

At step the first program decrypts the responsive communications and forwards the communication to the appropriate application via the second program. The first program may use any suitable interface means and mechanism to communicate to the second program such as via any type and form of inter process communication mechanism or an API call. The second program provides the responsive communication via the network stack of the client to the application . As such the application transparently receives the responsive communication without any changes or modification to the application .

In accordance with another embodiment client performs additional processing of the intercepted communications before sending the communications over the network at step . Because an embodiment provides a VPN solution that acts as a proxy terminating connections at the client before encrypting such data the additional processing can be performed more effectively. Such processing can include Domain Name Service DNS name resolution of the intercepted communications in order to enable client applications to use whatever IP addresses they choose as well as dynamically change those addresses at run time. Such additional processing permits embodiments to be effectively integrated with other technologies such as global service load balancing to achieve greater availability and greater efficiency among distributed gateways or servers. The additional connection processing can also enable the keeping of detailed logs and statistics regarding the intercepted communications.

In another embodiment an appliance terminates communications received from the first program on client and further processes one or more requests included therein rather than forwarding the communications to a destination on network as shown at step . This further processing can include back end encryption wherein communications are re encrypted by appliance before delivery to the appropriate destination on network thereby providing end to end network security. The destination will thereafter decrypt the traffic and respond appropriately. Further such processing can permit appliance to serve responses out of a cache rather than requiring additional work by a destination server perform local network load balancing global service load balancing and or compression on the communications to enhance the efficiency and responsiveness of network .

In accordance with the above described methods a VPN based on an encrypted data communication session is established between client and network . For example in an embodiment a secure VPN is established via HTTPS. Thereafter all communications from client to network are routed via the first program to appliance and vice versa through this encrypted data communication session. It should be noted that although the encrypted data communication session may be established using HTTPS the communications that are passed through the encrypted data communication session need not be HTTPS packet data or even HTTP packet data. For example the communications may also comprise Transmission Control Protocol User Datagram Protocol TCP UDP or Internet Control Message Protocol ICMP packet data although these examples are not intended to be limiting. Furthermore although the method described in reference to describes a request response type communication between an application on client and a resource on network encrypted communications need not be request response based. Rather the communications can be of any type. Thus any client application that can establish a connection or communication session such as a UDP session can send and receive encrypted communications

In another aspect the acceleration program may dynamically bypass from the client any intermediary device to connect or communicate with a server . For example a client may connection with a server via one or more intermediaries such as the appliance . For one reason or another an intermediary may no longer be available for use by the client to communicate with the server for example the appliance may be down for maintenance or may be in the process of rebooting or restarting. The acceleration program determines the intermediary is not available and automatically establishes a different connection or communication session path with the server . This may occur transparently to the user or application of the client such that the connection and or communication session does not appear to have changed or otherwise has been disrupted.

Referring now to an embodiment of a method for automatically bypassing an intermediary is depicted. In brief overview at step the acceleration program establishes a transport layer connection between the client and server via an intermediary such as appliance . At step the acceleration program determines the intermediary is not useable for communicating by the client to the server via the established transport layer connection. At step the acceleration program intercepts on the client a communication from the client to the serve . At step the acceleration program establishes a second transport layer connection between the client and the server and as a result bypasses the intermediary determines as not useable for the client s communications to the server . At step the acceleration program transmits the intercepted communication of the client to the server via the second transport layer connection.

In further detail at step the acceleration program establishes a transport layer connection between the client and the server via an intermediary. In one embodiment the intermediary comprises an appliance . In other embodiments the intermediary comprises one of the following a cache a server a gateway a firewall a bridge a router a switch a hub a proxy or any software application or program acting as or providing the functionality and operations of any of these types and forms of intermediaries. In one embodiment the intermediary may operate on the server . In some embodiments the transport layer connection is established via a plurality of intermediaries of the same type and form or of a different types and forms. In another embodiment the transport layer connection comprises of the connection of a pool of transport layer connection either established as the client or at the appliance .

At step the acceleration program determines the intermediary is not available or otherwise is not useable for communicating by the client to the server via the established transport layer connection. The acceleration program may determine the status or availability of the intermediary by any suitable means and or mechanism. In one embodiment the acceleration program determines the intermediary is not available by receiving an error message or failure reply associated with a transmission to the intermediary. For example the acceleration program may receive a failed transport layer communication response when transmitting a communication from the client via the established transport layer connection. In another embodiment the acceleration program may transmit a ping command to the intermediary on a predetermined frequency to monitor the status and availability of the intermediary. If the acceleration program does not receive a reply from the intermediary or in some embodiments receives a delayed reply or a reply with a longer than desired latency the acceleration program may determine the intermediary is not available or useable by the client . In other embodiments a server appliance or the intermediary may send a message to the client or acceleration program providing information identifying the intermediary is not available or otherwise is not useable by the client . In some embodiments the established transport layer connection is disrupted or interrupted or in other embodiments is closed.

At step the acceleration program intercepts a communication from the client to the server destined to travel via the intermediary through the established transport layer connection. The acceleration program may intercept the communication at any point and at any protocol layer in the network stack . In one embodiment the acceleration program intercepts the communication at the transport protocol layer prior to transmission on the established transport layer connection. For example in some embodiments the acceleration program comprises a network driver having a transport driver interface or otherwise interfaced to the transport protocol layer. Other embodiments may include a first program and the acceleration program as a second program as discussed in conjunction with in which either the first program or the acceleration program intercepts the communication.

At step the acceleration program establishes a second transport layer connection to the server for the client in order to bypass the intermediary determined to be unavailable or not useable by the client at step . In one embodiment the acceleration program establishes a second transport layer connection directly to the server for example when the client and server are on the same network or on different networks routable between the client and the server . In another embodiment the acceleration program establishes the second transport layer connection with a second intermediary such as a second appliance . In some embodiments the acceleration program requests the appliance to establish another transport layer connection with the server . In one embodiment the appliance uses a second transport layer connection of a pool of transport layer connections to the server . In another embodiment the acceleration program request the server to establish the second transport layer connection. In some embodiments the acceleration program uses a second transport layer connection from a pool of transport layer connections established by the acceleration program with the server .

In one embodiment the acceleration program establishes the second transport layer connection at step transparently to a user or application of the client or in some embodiments transparently to any protocol layer above or below the transport layer. In some aspects the second transport layer connection is established automatically for the client upon determination at step that the intermediary is not available or should not be used by the client . In other embodiments the second transport layer connection is established automatically upon failure of transmission of the intercepted communication to the server e.g. the first attempt to transmit the communication. In some embodiments the second transport layer connection is established automatically upon failure of one or more retried transmissions of the communication or upon exhausting a predetermined number of retries. In another embodiment the second transport layer connection is established upon determination the intermediary is delaying the rate of transmit or receipt of network packets causing latency or otherwise affecting the use of the transport layer connection in an undesired manner. In one embodiment the acceleration program performs load balancing and establishes a second transport layer connection bypassing the intermediary to offload any processing or operations of the intermediary to the client and or second intermediary.

At step the acceleration program transmits the intercepted communication of the client to the server via the second transport layer connection. In one embodiment the acceleration program transmits the intercepted communication directly to the server . In other embodiments the acceleration program transmits the intercepted communication via a second intermediary such as a second appliance . By using the second transport layer connection the acceleration program bypasses the intermediary and continues the operations of an application of the client with the server . In one embodiment an application of the client continues with operations and communications with the server as if the application was continuing to use the previously or first established transport layer connection. As such the acceleration program prevents avoids or circumvents any communication interruption disruption latencies delays or other operational or performance issues that may occur if the intermediary was not bypassed by the acceleration program . In another aspect this technique automatically provides the client continuous access to a server or remotely accessed application even if there is an issue with or disruption in access from an intermediate device.

Moreover the redirection and bypassing techniques described above can be used to perform load balancing and traffic management on the client to access one or more servers providing applications or other content and functionality to the client . For example in one embodiment an intermediary or appliance used by the client to access a server may be overloading with increasing transport layer connections and decreasing rate of responses performance or other operations. Upon determination of decreasing performance of the intermediary or appliance the acceleration program can redirect the client to another intermediary or appliance or server to bypass any performance bottlenecks in the client s end to end connectivity to the server.

In other aspects client side acceleration techniques may be related to or performed at the transport protocol layer of the network stack of the client. The acceleration program may comprises executable instructions to perform any one or more of 1 transport control protocol TCP buffering 2 TCP connection pooling and 3 TCP multiplexing . In some embodiments as the acceleration program transparently processes communications intercepted at the transport protocol layer of the client s network stack the acceleration program can control and manage the TCP connections of the client and the use and transmission over the connections by applications of the client . depicts an embodiment of method of practicing the TCP buffering techniques while depicts an embodiment of the TCP connection pooling technique and and the TCP multiplexing technique.

In brief overview of an embodiment of method depicted in at step the acceleration program intercepts a communication from the client to the server such as a request to access the server by the client . At step the acceleration program determines whether a difference between a rate of consumption of received server responses and a rate of production of requests transmitted by the client falls below a predetermined threshold. If at step the difference in product and consumption rates does not fall below the predetermined threshold the acceleration program forwards the communication to the server at step . If at step the difference in rates is below the predetermined threshold then at step the acceleration program stores the communication in memory of the client . At step the acceleration program determines if the difference in rates has changed to above the predetermined threshold and if so forwards the stored communication to the server . Otherwise the acceleration program maintains the communication in memory of the client until a point in time the difference in rates change at step to above the predetermined threshold. For example if the client is transmitting requests to the server at a greater rate than by which the client can consume the generated responses the acceleration program holds further transmission until a future point in time at which the difference in the rates haves changed.

In further detail at step the acceleration program intercepts a communication from the client to the server . The acceleration program may intercept the communication at any point and at any protocol layer in the network stack . In one embodiment the acceleration program intercepts the communication at the transport protocol layer prior to transmission on the established transport layer connection. For example in some embodiments the acceleration program comprises a network driver having a transport driver interface or otherwise interfaced to the transport protocol layer. Other embodiments may include a first program and the acceleration program as a second program as discussed in conjunction with in which either the first program or the acceleration program intercepts the communication. In one embodiment the communication comprises a request by the client to use or otherwise access a resource of the server such as an application .

At step the acceleration program determines whether a difference between a rate of consumption and a rate of production of the client falls below a predetermined threshold. In one embodiment the acceleration program counts and tracks the number of requests transmitted by the client to the server and in another embodiment the acceleration program counts and tracks number of responses received by the client from the server . In some embodiments the client tracks responses transmitted and requests received on a per application basis. The responses and requests may be tracked at any protocol layer of the network stack . In one embodiment the number of requests transmitted by the client or application is counted and tracked from the point of submission to the transport layer or to a transport layer connection between the client and server . Likewise in another embodiment the number of responses received by the client or application from the server is counted and tracked from the point of receipt at to the transport layer or from the transport layer connection between the client and server and or at the point the response is provided to a protocol layer such as an application layer above the transport layer of the network stack .

In some embodiments the acceleration program accesses inspects or otherwise obtains information and data about the send and receive TCP buffers of the transport layer connection established by the acceleration program between the client and server . For example the acceleration program may determine the default and maximum size of any TCP IP buffer and the currently used portions of the buffer to determine a difference in rates between sending and receiving of network packets from the client to the server . In other embodiments the acceleration program uses any type and form of congestion algorithm to determine if there is congestion causes by a difference in consumption and product of network packets from the client to the server . In another embodiment the acceleration program interfaces with or obtains information or data from a congestion algorithm uses by the transport layer connection such as by a network driver or TCP service provider. For example in one embodiment the acceleration program determines information and data regarding the congestion window used by the connection.

The predetermined threshold can be configured specified defined or identified by any suitable means and mechanism of the acceleration program . In one embodiment the threshold may be specified as a percentage relative absolute or otherwise between the production rate and consumption rate of the client and or application . The rates for consumption and or product may be identified by a number of consumed receipts and produced transmissions respectively over any time period at any granularity. In some embodiments the threshold may be specified as a quantity difference between the rate of production and consumption of the client and or application and in some embodiments a quantity difference over a time period. For example the threshold may be specified as the point in time the client has produced requests more than the client has consumed. In another example the threshold may be specified as the point in time when the client is producing requests per time period to the server more than the requests consumed by the client during the same time period.

At step if the difference in product and consumption rate of the client and or application is not below the predetermined threshold the acceleration program forwards the communication to the server at step . In some embodiments the acceleration program performs any of the acceleration techniques for the communication. For example the communication may be forwarded to the server via a pooled multiplexed transport layer connection and additionally may be compressed. In other embodiments the client may forward the communication to an appliance providing a connection for the client to the server .

At step if the difference in product and consumption rate of the client and or application is below the predetermined threshold the acceleration program at step stores the communication in memory of the client . In some embodiments the memory may be memory of the kernel mode of the client while in other embodiments the memory may be in user mode of the client . In one embodiment the acceleration program may store the communication in cache via the cache manager . In other embodiments the acceleration program may use an object data structure or other data element accessible by the acceleration program to buffer hold or otherwise store the intercepted communication. In one embodiment the intercepted communication may be stored in a compressed manner in memory. In another embodiment the acceleration program sends the intercepted communication to a first program to store or hold in memory for transmission at a later point in time.

At step the acceleration program determines when to transmit the stored communication to the server . In one embodiment the acceleration program performs steps and to determine if the difference in production and consumption rates of the client are above the threshold upon which the acceleration program forwards the stored communication to the server at step . In some embodiments the acceleration program compares the difference in production and consumption rates on a regular or predetermined frequency or on a polling or event basis and when the difference rises above the predetermined threshold the acceleration program forwards the communication to the server . In other embodiments the acceleration program sets or configures a timer to determine how long to store the intercepted communication. Upon expiration of the timer the acceleration program transmits the stored communication to the server . In another embodiment the acceleration program checks the number of server responses consumed by the client since storing the intercepted communication. If the number of consumed responses is greater than a predetermined number the acceleration program releases the intercepted communication from the memory buffer or storage and submits the communication for transmission to the server .

If at step the acceleration program determines the rates of production or consumption have not changed in a suitable manner the acceleration program holds or maintains the intercepted communication in memory until a suitable point of time is reached. In one embodiment the acceleration program forwards the communication to the server at step even if the production and or consumption rates do not change. For example after a period of time waiting for the production and or consumption rate to change and the rates do not change the acceleration program forward the communication to the server .

Although the TCP buffering technique is generally discussed in relation to an intercepted communication or request the embodiments of the method may be practiced subsequently nearly simultaneously or concurrently for multiple intercepted communications of the client to the server . Additionally in another embodiment the method may be practiced on the client regarding communications from the client to multiple servers . For example a first instance of method may be practiced between the client and a first server and a second instance of method may be practiced between the client and a second server . Furthermore in some embodiments the method may be practiced for a first application and also for a second application using the respective production and consumption rates of each application. In other embodiments the method may be practiced for a first application but not a second application

According to another aspect the client side acceleration program reduces the processing load of servers and or appliance caused by repeatedly opening and closing connections of the client clients by opening one or more connections with each server and maintaining these connections to allow repeated data accesses by applications of the client to the server . This technique is generally referred to herein as connection pooling. Referring now to in brief overview of method at step the acceleration program intercepts an application s request to access a server and at step determines the identity of the server associated with the request. At step the acceleration program determines if the acceleration program has an established transport layer connection to the server free for use by the application . If there is not a transport layer connection to the server free for use by the application the acceleration program establishes at step a transport layer connection to the server for use by the client . At step if there is a transport layer connection available for use by the application at step the acceleration program translates the application s request for transmission or communication via the available transport layer connection.

In further overview at step the acceleration program receives the response to the request from the server and at step translates the response into a response to the application . At step the acceleration program may maintain or keep the transport layer connection open for use by any of the applications of the client . By maintaining on the client open transport layer connections with the servers and by opening and closing connections with the applications as needed the acceleration program frees the servers of TCP connection loading problems associated with serving the client over the network such as the Internet. At step the acceleration program at some point closes the transport layer connection if the connection is determined no longer used by one or more application of the client to access the server .

In further detail at step the acceleration program intercepts a request by any application of the client to access a server . In some embodiments the request is intercepted at the transport protocol layer before establishing or transmitting the request via a transport layer connection. In other embodiments the request is intercepted at any protocol layer above the transport layer or a transport layer connection. In one embodiment the request of the application is a request to open or establish a transport layer connection with the server . In some embodiments in response to the request the acceleration program establishes a first transport layer connection of a pool of transport layer connections for use by applications of the client . In another embodiment the application request is a request to access the server via an established transport layer connection of the client .

At step the acceleration program determines the identity of the server from the request by any suitable means and mechanism. In some embodiments the domain name or internet protocol address of the server is identified or otherwise referenced by the contents of the request for example a text string of the request may identify the domain name of a server . In one embodiment the identity of the server is determined by the header information of a TCP packet such as the destination internet protocol address and port number. In another embodiment the server is associated with the application and the acceleration program looks up or queries the association in a database or other structured information storage.

At step the acceleration program determines if there is a transport layer connection available for use or is otherwise free to use by the application . In one embodiment the acceleration program may have not yet established a transport layer connection with the server and as such there is not a transport layer connection available for the application to use. In another embodiment the acceleration program may have a previously established transport layer connection with the server but determines that another application is currently actively using the connection. As will be discussed in further detail below the acceleration program determines if an established transport layer connection is available for use by another application or can be shared by applications based on the length of a message being received from the server for the application such as a response to a request and or if the communications between the server and application are currently idle.

At step if the acceleration program determines a transport layer connection is not available for use by the application the acceleration program establishes a transport layer connection with the server . In some embodiments the transport layer connection established at step is the first transport layer connection with the server and in other embodiments the transport layer connection is a second transport layer connection of a plurality of transport layer connections to the server . In yet another embodiment the acceleration program waits for an already established transport layer connection to become available or free to communicate the application s request to the server . For example the acceleration program may determine a first application may be shortly completing a transaction with the server via an established connection.

At step the acceleration program translates the application s request to be transmitted via the transport layer connection to the server . In some embodiments the acceleration program uses one port number for the transport layer connection communication for all applications of the client sharing the connection. In some cases the acceleration program tracks the requests and outstanding responses for the requests on an application by application basis. As such the acceleration program recognizes which application is transmitting and receiving network packets via the transport layer connection to the server at any given point in time. In one embodiment only one application at a time is sending and receiving on the transport layer connection and thus the acceleration program understands which application is using the connection. In some embodiments the acceleration program associates a process id of the application with the request. In other embodiments the acceleration program provides and associates a port number with the application and modifies the port number in the TCP network packet to be transmitted to application s assigned port number. In another embodiment the port number is provided by the application and the acceleration program changes or otherwise provides the port number accordingly in the TCP network packet.

At step the acceleration program receives a response to the application s request from the server . In one embodiment the server does not respond to the request. In another embodiment the server responds with an error or failure message. In some embodiments the server responds with multiple responses. In other embodiments the server responds with a response comprising multiple network packets or multiple TCP segments. In another embodiment the server responds with one or more network packets identifying the source port number associated with or assigned to the application . In one embodiment the server responds with one or more network packets identifying a source port number of the transport layer connection and used for multiple applications of the client .

At step the acceleration program translates or otherwise processes the response from the server in a manner responsive to the application . In one embodiment the acceleration program replaces the source port number of the received network packet or packets with the port number of the application . In another embodiment the acceleration program determines via a tracking mechanism the application currently using the transport layer connection and passes the response to the application via the network stack . In one embodiment the response is not altered and passed for processing via the protocol layers of the network stack above the transport layer of the connection. In some embodiments the acceleration program waits for multiple portions such as TCP segments of the response to be received before processing and forwarding the response to the application . In one embodiment the acceleration program passes the response to a first program which interfaces with and provides the response to the application .

At step the acceleration program maintains or keeps the transport layer connection open in a pool of one or more transport layer connections from the client to the server . In one embodiment the acceleration program or a transport layer driver of the network stack includes a keep alive mechanism that periodically probes the other end of a connection when the connection is otherwise idle for example where when there is no data to send. The keep alive mechanism may send this message in order to receive a response to confirm the connection is still active although the connection may be idle. The keep alive message and corresponding response. may include any type and form of format command directive or communication. As such in some embodiments the acceleration program transmits or causes to transmit via a transport layer driver a keep alive message to the transport layer connection. In some embodiments the acceleration program sets a frequency for the keep alive messages and in other embodiments changes the frequency of the keep alive messages based on the behavior or activity of the applications using the connection.

In some embodiments the acceleration program intercepts any RST and or FIN commands i.e. TCP IP commands to reset and or terminate the TCP connection received over the transport layer connection. In one embodiment the acceleration program ignores takes no action on or otherwise drops deletes or flushes the intercepted RST and or FIN command. In another embodiment the acceleration program intercepts and receives a RST and or FIN commands but sends a message to the other end of the connection to keep or maintain the connection open. In other embodiments the acceleration program establishes a new transport layer connection in response to a closing of an established transport layer connection due to processing of a RST and or FIN command.

In other embodiments the acceleration program inserts an instruction command or directive in an intercepted communication of the client to direct the server to keep the connection open or to otherwise not close the connection unless the client sends a command to do so. For example in one embodiment the acceleration program intercepts a communication of a GET request of the HTTP protocol such as protocol version 1.0 and inserts a keep alive header e.g. Connection Keep Alive into the communication to the server . In other embodiments a GET request or other HTTP command may include the keep alive header. In these embodiments the acceleration program may intercept the communication and check for the keep alive header and then forward the communication to the server . In some embodiments version 1.1 or greater of HTTP is used by which the keep alive mechanism is implicit such that the server keeps the connection open until the client requests to the close the connection. In other embodiments the acceleration program keeps the transport layer connection open to the server until the client is rebooted or restarted the network becomes unavailable or the client is disconnected from the network or the server is rebooted or restarted.

At step the acceleration program may close any one or more of the transport layer connections between a client and a server at any desired point in time. In some embodiments the acceleration program closes a transport layer connection upon the termination of the one or more applications on the client using the connection. In other embodiments the acceleration program closes a transport layer connection upon expiration of a time out period for any application to use the connection. For example the acceleration program may configure set or provide a timer to expire upon a predetermined time period and if the connection is or remains idle during the time period the acceleration program closes the connection. In some embodiments the server may be rebooted restarted or the connection disrupted or interrupted and the acceleration program closes the connection. In some embodiments the acceleration program transmits or causes to be transmitted a RST and or FIN command to close connection upon completion of sending requests to and receiving all the data of responses from the server . In other embodiments the transport layer connection or pool of transport layer connections are closed upon restart or reboot of the client disconnection to the network or unavailability of the network or restart or reboot of the server .

In some embodiments a first transport layer connection to the server is kept open while a second transport layer connection to the server is closed as the acceleration program determines only the first transport layer connection is needed for sharing a connection to the server by one or more applications of the client . In other embodiments the acceleration program maintains a pool of one transport layer connection to any server and establishes a second or a plurality of connections to a given server based on increased requests communications or transport layer connection usage of the applications on the client

Although an embodiment of method is generally discussed in relation to a pool of one or more transport layer connections from the client to a server the acceleration program may establish subsequently nearly simultaneously or concurrently a pool of transport layer connections between the client and each of a plurality of servers . As such a first application and a second application may be using a first pool of one or more transport layer connections to server and a third application and a fourth application using a second pool of one or more transport layer connection to server . Furthermore each of the steps of an embodiment of the method can be performed in different instances and at different frequencies. In some embodiments multiples instances of the acceleration program may be used to handle each pool of one or more transport layer connections to each server .

Now referring to a flow diagram is depicted of an acceleration program providing a transport layer connection for use by two applications and of a client to a server in one embodiment or to an appliance in another embodiment. The acceleration program on client opens a first transport layer connection between client and the server or appliance using network address provided by application as depicted by step . Step is shown as a two way step because the TCP IP protocol employs a multi stage handshake to open connections.

Once the transport layer connection is established the acceleration program intercepts a GET request from application specifying a path name of sales forecast.html as shown by step . Because no free transport layer connection is open between acceleration program and server or appliance acceleration program opens a transport layer connection. In one embodiment acceleration program maps the request of the application to a second network address of network address which specifies server as shown by step . For example the acceleration program performs network address translation to modify the destination IP address and or destination port to a server requested by the application or to another server that can also handle or respond to the request. In another embodiment the acceleration program sends the request to the server or appliance as received or as generated by the application

Acceleration program also passes the GET request to that server or appliance as shown by step . In one embodiment the appliance forwards the request to the server and in a further embodiment the appliance forwards the request via a pooled or pooled and multiplexed transport layer connections between the appliance and the server . In some embodiments the server responds with the requested web page as shown by step . Acceleration program forwards the web page to application as shown by step . In one embodiment the transport layer connection between the acceleration program and the server or appliance is closed as shown by step . In other embodiments the acceleration program intercepts the close request and ignores the request leaving the transport layer connection open. According to the TCP IP protocol closing a network connection can involve a multi stage process. Therefore the flow line of step is shown as bidirectional. In other embodiments and in accordance with the techniques of the pooling aspect the transport layer connection established for and used by the first application is kept open or otherwise maintained to accommodate further data steps from the same application or a different application such as the second application

At step the acceleration program intercepts a request from the second application to the server or appliance . If there is a free transport layer connection open and or useable by the second application such as the transport layer connection established at step for the first application the acceleration program uses this previously established transport layer connection. As such a second transport layer connection does not need to be opened at step . Otherwise the acceleration program establishes a second transport layer connection to the server or appliance . At step the acceleration program intercepts a request from the second application for example requesting the Web page sales forecast.html and transmits the request to the server or appliance at step . Because a free connection is already open between the acceleration program and server it is unnecessary for the acceleration program to burden the server with the processing load of opening a further connection. At step the acceleration program intercepts or receives a response from the server such as via appliance from the transport layer connection and forwards the response to second application . At step the acceleration program intercepts a close request from the second application and in some embodiments closes the connection while in other embodiments ignores the request and keeps the connection to accommodate further data requests from the first application the second application or yet another application of the client .

There are a number of scenarios that result in the acceleration program closing the connection with server or application at step . For example the client or acceleration program may initiate a FIN finish command upon determination that the client has retrieved all the requested data for applications and or upon termination shutting down or exiting applications and . In some embodiments the client or acceleration program may also initiate a RST reset command under similar conditions. In addition to closing the connection between the acceleration program and the server or the appliance the RST command results in a number of housekeeping operations being performed to keep the server side connection in good order. In particular the TCP protocol guarantees that the RST command will have the right SEQ sequence number so that the server will accept the segment. However the RST command is not guaranteed to have the right ACK acknowledge number. To take care of this scenario the acceleration program keeps track of the bytes of data sent by the server or appliance and the bytes acknowledged by the client . If the client has not yet acknowledged all the data by the server the acceleration program calculates the unacknowledged bytes and sends an ACK to the server .

Furthermore although not shown in the server or appliance can also close a connection between itself and the client . The server or appliance would send a FIN command to the client . In response in some embodiments the acceleration program closes the connection and a further embodiment re establishes another connection with the server or appliance .

Moreover although an embodiment of method of and the example flow diagram of are generally discussed as pooling one or more transport layer connections for use by a plurality of applications the pooling technique can be applied to a single application that requests or initiates a plurality of transport layer connections and requests via these connections. For example in an embodiment of HTTP protocol a transport layer connection may be established for each HTTP request from an application. Using the techniques a pool of one or more transport layer connections can be used by the application without opening and closing transport layer connections for each request.

In another aspect techniques for multiplexing application requests via the same or shared transport layer connection may be used such as a transport layer connection established via the pooling techniques described in conjunction with . In some embodiments the availability of an established transport layer connection is determined and requests may be multiplexed from a plurality of applications via the connection by checking whether the content of a response from the server to an application s requests has been completely received. As will be discussed in further detail below in one embodiment the content length parameter of a response is used and in another embodiment a chunked transfer encoding header of a response is used to check if all the data of a response has been received. In one aspect whether all the data from a response has been received is checked to determine if a pooled connection is currently free for use by an application and or whether to establish another transport layer connection to the pool of connections to the server such at steps and of method depicted in . In another embodiment the technique of checking the content length for a response is used as a technique for multiplexing requests from a plurality of applications via the same transport layer connection.

Referring now to an embodiment of a method for multiplexing requests via a single transport layer connection from the client to the server is depicted. In brief overview at step the acceleration program establishes a transport layer connection between the client and server . At step the acceleration program intercepts a first request of a first application to the server . At step the acceleration program determines whether the transport layer connection is currently being used by another application or is otherwise idle. At step if the transport layer connection is available to use by the application then at step the acceleration program transmits the request to the server. Otherwise at step if the transport layer connection is not available to use by the application then the acceleration program at step either waits for a time period and returns to step or establishes a second transport layer connection for use by the application . At step the acceleration program receives a response to the application s request from the server. At step the acceleration program intercepts a second request by a second application and proceeds at step to determine if the transport layer connection is available for use by the second application . In some embodiments the acceleration program intercepts the request of the second application at step prior to receiving the response of the first request at step or prior to receiving all of the data of the response. As discussed further herein in some embodiments the acceleration program uses content length checking technique to determine when the transport layer connection is idle or an application has received all the data to a response to a request.

In further detail at step the acceleration program establishes a transport layer connection between the client and server . In some embodiments the acceleration program establishes the transport layer connection with or via the appliance or an intermediary. In one embodiment the acceleration program establishes the transport layer connection as a pool of transport layer connection to the server . As such in some embodiments the transport layer connection may comprise a second or a third transport layer connection to the server . In other embodiments the acceleration program may establish the transport layer connection via a first program as previously discussed herein. In some embodiments the acceleration program established the transport layer connection in response to a request by a first application of the client .

At step the acceleration program intercepts a first request by a first application to access the server . In some embodiments the request is intercepted at the transport protocol layer before establishing or transmitting the request via the transport layer connection. In other embodiments the request is intercepted at any protocol layer above the transport layer or above the transport layer connection. In some embodiments the request is intercepted by a first program . In one embodiment the request of the application is a request to open or establish a transport layer connection with the server . In another embodiment the application request is a request to access the server via the established transport layer connection or via the appliance .

At step the acceleration program determines whether the transport layer connection is idle or available for use by the first application or to communicate the first request of the first application . In some embodiments the acceleration program determines from a pool of one or more transport layer connections which transport layer connection in the pool is idle or free to use by the first application . In one embodiment the acceleration program determines the transport layer connection is idle because the acceleration program established the transport layer connection in response to the request or immediately prior to the request. In some embodiments the acceleration program may have not received any requests from any application and recognizes this request as the first request to be intercepted and processed by the acceleration program . In another embodiment the acceleration program tracks the number of outstanding responses for any requests transmitted on the transport layer connection and if there are no outstanding responses the acceleration program recognizes the transport layer connection is available for use by the first application . In yet another embodiment the acceleration program recognizes the transport layer connection is currently idle. For example the acceleration program may be initiating keep alive requests to the server to keep the connection open. In some embodiments the transport layer connection is idle as the last transaction has been completed but the server and or client has not yet transmitted a RST and or FIN command.

In some embodiments the acceleration program may check the content length of a response to determine if the response from the server to the first request of the first application is complete or otherwise the acceleration program has received all the data to the response. As mentioned above these techniques in some embodiments are also used to determine to establish another connection for the pooling technique. In regards to this technique will be used to describe checking the content length parameter of a response in one embodiment or in another embodiment a chunked transfer encoding header of a response to determine whether all the data of a response has been received. depicts a TCP portion of a TCP packet referred to as a TCP segment . The TCP segment includes a TCP header and a body . The body comprises among other data and information a HTTP header and message in an embodiment wherein the TCP packet carries an application layer protocol of HTTP. In some embodiments a content length parameter is located found or referenced by or in the HTTP header. In one embodiment the acceleration program uses the content length parameter to determine if all the data for a response is received.

The chunk size field A G are linked together or otherwise referenced or associated as illustrated in . The chunk size field A indicates the length of the message in the chunk message data A the chunk size field C indicates the length of the message in the chunk message data C and so forth. The last chunk size field G comprises the length value zero indicating that there are no more chunks or any more of the message to follow. In another embodiment the acceleration program determines via the chunk size fields whether the client has received all the data to a response.

Although generally describes a technique for checking whether all the data for a response to a request has been received these techniques are applicable to a server or appliance sending an asynchronous message or communication to the client . Furthermore although these techniques are generally described in conjunction with for an HTTP protocol these techniques can be used for any protocol at any protocol layer that provided an indication of the length of data to be transmitted or received by the client . As such in some embodiment the acceleration program accesses extracts inspects analyzes or otherwise processes any portion of the network packet including at any protocol layer to determine if all the data has yet been received in association with a request response or communication between the client and the server or appliance. In yet another embodiment the acceleration program tracks the numbers of bytes transmitted received and acknowledged between the client and server to determine if any bytes are outstanding between the client and server for an application .

By using the content length techniques described above the acceleration program can reuse the same transport layer connection to the server previously used or in the process of use by any other application of the client . At step the acceleration program determines if the transport layer connection is available to transmit the first request and if so at step transits the request to the server . Otherwise at step the acceleration program may wait until all the data is received for an outstanding request of an application. For example the acceleration program may set a timer for example to a short time period and proceed to step . In some embodiments the acceleration program checks if the all the data has been received responsive to a packet processing timer of the network stack of the client . In another embodiments at step the acceleration program establishes another transport layer connection to transmit the first request of the first application

At step the acceleration program may track which application currently has an outstanding request or response on the connection or is currently using the connection. For example only one application at a time may transmit a request and receive a response on the connection. As such the acceleration program understands which application is using the connection. In some embodiments the acceleration program uses one port number for the transport layer connection communication for all applications of the client sharing the connection. In some cases the acceleration program tracks the requests and outstanding responses for the requests on an application by application basis. In some embodiments the acceleration program associates a process id of the application with the request. In yet another embodiment the acceleration program transmits the request of the first application with a request of the second application in the same network packet or packets TCP segment or segments. In other embodiments the acceleration program transmits a plurality of requests of applications via the same transport layer connection as part of a series of TCP segments of one or more TCP segment windows.

In other embodiments the acceleration program uses a port numbering mechanism and or scheme to track and recognize which response or message received is for which application . In other embodiments the acceleration program provides and associates a port number with the application and modifies the port number in the TCP network packet to be transmitted to the application s assigned port number. In another embodiment the port number is provided by the application and the acceleration program changes or otherwise provides the port number accordingly in the TCP network packet. As such in some embodiments the acceleration program may interweave requests from a plurality of applications of the client such that applications may use the transport layer connection at the same time.

At step the acceleration program receives a response to the first request of the first application from the server such as via appliance and provides the response to the first application . In some embodiments the acceleration program provides the response to the first application via the network stack such as allowing or initiating the processing of the response by the protocol layers above the transport layer of the connection. In another embodiment the first program provides the response to the first application . In other embodiments the acceleration program may provide the response to the first application via an inter process communication mechanism or an interface such as an API. In some embodiments the acceleration program only receives a portion of the response such as a first chunk in a multi chunk message as described in .

At step the acceleration program intercepts a request of a second application to access the server . In some embodiments the acceleration program intercepts the request of the second application prior to step . In other embodiments the acceleration program intercepts the request of the second application during receipt of the response at step . In another embodiment the acceleration program intercepts the request of the second application prior to the client or acceleration program receiving all the data for a response of the first request of the first application . Upon interception of the request of the second application the acceleration program proceeds to step in an embodiment to determine whether to multiplex the second request via the transport layer connection or whether to establish another transport layer connection such as another connection in a pool of connections. In other embodiments the acceleration program transmits the request of the second application via the same connection as the first application while the first application has an outstanding response or has not received all the data from the response of the first request. In another embodiment the acceleration program transmits the request of the second application after the first application has received the response and prior to any generated RST and or FIN commands are generated in connection with the first application

Although the acceleration program has generally been discussed in relation to the client side implementation and execution of acceleration techniques the acceleration program interfaces and works in conjunction with the appliance which also implements and executes appliance side acceleration techniques. In one embodiment the client side acceleration program and the appliance may work in conjunction with each other to perform a plurality of the acceleration techniques on communications between the clients and the servers . In some embodiments the client side acceleration program and the appliance both provide TCP pooling and multiplexing such as to provide a cascading or end to end pooling and multiplexing mechanism between clients and servers . For example the acceleration program may provide a first pooled transport layer connection to the appliance which in turns provides a second pooled transport layer connection to the server . In another example the acceleration program may multiplex an application request via a first pooled transport layer connection on the client which in turns is multiplexed by the appliance via the second pooled transport layer connection to the server . In some embodiments the acceleration program provides a throttling mechanism for transmitting requests from the client while the appliance provides a throttling mechanism for transmitting responses from the servers to the clients . In another embodiment the acceleration program performs client side caching for the client while the appliance provides caching of objects such as dynamically generated objects for the client along with other clients .

In some embodiments in addition to or in conjunction with performing acceleration techniques on the client and or appliance the acceleration program and the appliance may provide a virtual private network connection and communications between the client and a network access via the appliance . In another embodiment the acceleration program may compress data communicated from an application and the appliance may decompress the compressed data upon receipt thereof. Conversely appliance may compress data communicated from an application on the server on a private data communication network and the acceleration program may decompress the compress data upon receipt thereof. Also the acceleration program and appliance may act as endpoints in an encrypted data communication or tunneling session in which the acceleration program encrypts data communicated from an application and appliance decrypts the encrypted data upon receipt thereof. In a similar manner appliance encrypts data communicated from an application on private data communication network and the acceleration program may decrypt the data upon receipt thereof.

In view of the structure functions and operations described above in Sections B and C in some embodiments the delivery of a computing environment to a client may be accelerated. For example the embodiments described herein may be used to deliver a streaming application and data file processable by the application from a central corporate data center to a remote user location such as a branch office of the company. The appliance and acceleration program provide end to end acceleration techniques for accelerating any transport layer payload such as streamed applications and data files from a server to a remote client. The application delivery management system provides application delivery techniques to deliver a computing environment to a desktop of a remote user based on a plurality of execution methods and based on any authentication and authorization policies applied via a policy engine. With these techniques a remote user may obtain a computing environment and access to server stored applications and data files from any network connected device.

Referring now to an embodiment for practicing the systems and methods of acceleration and application delivery described above is depicted. In brief overview a client is in communication with a server via network and appliance . For example the client may reside in a remote office of a company e.g. a branch office and the server may reside at a corporate data center. The client comprises a client agent and a computing environment . The computing environment may execute or operate an application that accesses processes or uses a data file. The computing environment application and or data file may be delivered via the appliance and or the server . In some embodiments the client also includes an acceleration program a collection agent and a streaming client . The server includes an application delivery system and in some embodiments a policy engine .

In one embodiment the application delivery system may reside or execute on a server . In another embodiment the application delivery system may reside or execute on a plurality of servers . In some embodiments the application delivery system may execute in a server farm. In one embodiment the server executing the application delivery system may also store or provide the application and data file. In another embodiment a first set of one or more servers may execute the application delivery system and a different server may store or provide the application and data file. In some embodiments each of the application delivery system the application and data file may reside or be located on different servers. In one embodiment the application delivery system also includes the policy engine . In another embodiment the policy engine executes separately from the application delivery system . In some embodiments the policy engine is on the same server as the application delivery system . In other embodiments the policy engine executes on the appliance . In yet another embodiment any portion of the application delivery system and or policy engine may reside execute or be stored on or distributed to the appliance or a plurality of appliances.

In some embodiments the client agent includes any of the streaming client collection agent and or acceleration program as previously described above. In one embodiment the client agent streaming client collection agent and or acceleration program form or are incorporated into a single program or set of executable instructions providing the functionality logic and operations of each. In other embodiments each of the streaming client collection agent and acceleration program execute separately from the client agent . In one embodiment the client executes the client agent . In another embodiment the client executes the client executes the streaming client . In some embodiments the client executes the collection agent . In one embodiment the client executes the acceleration program . In some embodiments the client executes the client agent with one or more of the streaming client collection agent or acceleration program . In other embodiments the client executes the streaming client and acceleration program . In one embodiment the client executes the acceleration program and the collection agent .

In some embodiments the client obtains the client agent streaming client and or collection agent from the server . In other embodiments the client obtains the client agent streaming client and or collection agent from the appliance . In one embodiment any of the client agent streaming client and or collection agent may be stored on the appliance . For example in some embodiments the client agent streaming client and or collection agent may be cached in the appliance . In other embodiments upon determination by the appliance an application can be accelerated the appliance may transmit the client agent streaming client acceleration program and or collection agent to the client . In some embodiments the client may automatically install and execute any of the client agent streaming client acceleration program and or collection agent . In yet another embodiment any of the client agent streaming client acceleration program and or collection agent may execute transparently to a user or application of the client or to any portion of the network stack of the client.

In some embodiments the appliance establishes a VPN or SSL VPN connection for the client to the server or network . In other embodiments the appliance acts as a proxy access server or load balancer to provide access to the one or more servers . In one embodiment the appliance and or acceleration program accelerates the delivery of the streaming client collection agent and or client agent to the client . In one embodiment the appliance accelerates the delivery of the acceleration program to the client . In other embodiments the appliance and or acceleration program accelerates the delivery of the computing environment application and or data file to the client In one embodiment the client has a computing environment and the appliance and or acceleration program accelerates the delivery of the application and or data file. In one embodiment the appliance and or acceleration program accelerates the delivery of the application. In another embodiment the appliance and or acceleration program accelerates the delivery of the data file. In yet another embodiment the appliance and or acceleration program accelerates the delivery of a computing environment such as an execution environment or virtualized execution environment previously described herein.

In one embodiment the appliance uses information collected from the collection agent to determine if a computing environment application and or data file may be accelerated. In some embodiments the policy engine of the application comprises the policy engine . In other embodiments the appliance communicates or interfaces with the policy engine to determine authentication and or authorization of a remote user or a remote client to access the computing environment application and or data file from a server . In another embodiment the appliance communicates or interfaces with the policy engine to determine authentication and or authorization of a remote user or a remote client to have the application delivery system deliver one or more of the computing environment application and or data file. In yet another embodiment the appliance establishes a VPN or SSL VPN connection based on the policy engine s authentication and or authorization of a remote user or a remote client In one embodiment the appliance controls the flow of network traffic and communication sessions based on policies of the policy engine . For example the appliance may control the access to a computing environment application or data file based on the policy engine .

Referring now to an embodiment of a method for accelerating delivery of a computing environment to a remote user of a client at a remote location is depicted. In brief overview of method at step the server receives a request to execute an application on the client . At step the server streams to the client an application for execution. At step the appliance and or client side acceleration program accelerates the transmission or delivery of the application to the client . At step the client or application requests a data file from the server for use by the application. At step the server and or appliance transmits the data file to the client . At step the appliance and or client side acceleration program accelerates the transmission or delivery of the data file to the client

In further detail at step a server receives a request to execute an application on a client . In some embodiments the user of the client makes the request. In other embodiments an application operating system or computing environment transmits the request. In another embodiment the appliance intercepts the request from the client and forwards the request to the server . In one embodiment the appliance forwards the request to the server based on authentication and or authorization of the user or client . In another embodiment the appliance forwards the request to the server based on information provided by the collection agent . In one embodiment the request includes a request to execute the application by one method of a plurality of execution methods. For example the user of the client may request to execute the application as an application streamed from the server as a locally installed and executed application or as a server based application executing on the server and displaying remotely to the client . In some embodiments the request is based on a file type association. For example a user may select a file associated with an application that is used to read or access the file.

At step in response to the request of step the server transmits the application for execution to the client . In some embodiments the server streams the application to the client . For example by streaming the application in some embodiments the application operates on the client without installation. In other embodiments the server transmits to the client an application for local installation and execution. For example using the automatic installation and execution techniques described in conjunction with the acceleration program in Section C the client may automatically install and execute the application upon receipt. In another embodiment the server executes the application on a server on behalf of the client and transmits display out to the client via a remote display or presentation layer protocol. In yet another embodiment the appliance streams the application to the client or transmits the application to the client for installation and or execution. In some embodiments the appliance and or server transmit the computing environment comprising the application. In other embodiments the appliance and or server transmit the computing environment in response to a request.

At step the appliance and or acceleration program accelerates the delivery of the application for execution to the client . In one embodiment the appliance performs or applies one or more of the plurality of acceleration techniques described in Section C above. In another embodiment the acceleration program performs or applies one or more of the plurality of client side acceleration techniques also described in Section C above. In some embodiments the acceleration program and appliance work together or in conjunction with each other to perform a plurality of acceleration techniques both on the client and on the appliance . For example the acceleration program may perform a first set of one or more acceleration techniques while the appliance performs a second set of one or more acceleration techniques. In one embodiment the acceleration program and appliance perform the same acceleration techniques. In another embodiment the acceleration program and appliance perform different acceleration techniques.

In one embodiment the appliance and or acceleration program accelerates any payload communicated via a transport layer connection between the client and server . In some embodiments the server streams the application as one or more data files via a transport layer connection such as a payload of a TCP IP packet. In other embodiments the server streams the application via an application layer protocol or streaming protocol over a transport layer connection. In another embodiment the server transmits display output via an ICA or RDP protocol via the transport layer connection. In any of these embodiments the appliance and or acceleration program accelerates the delivery of the application via payloads of transport layer packets.

At step the client transmits a request for a data file for use by the application or the computing environment . In some embodiments the request for the data file is transmitted with the request to execute an application in step . In one embodiment the request to execute an application includes the request for the data file. In other embodiments the application or the computing environment requests the data file in the course of performing any functionality operations or logic of the application or computing environment. For example the application or computing environment may request any macros scripts configuration data profile templates or rules from a server . In some embodiments the application requests the data file as a background process or task of the application. In one embodiment the user of the application or computing environment requests the data file to read access or otherwise process the file with the application or computing environment. For example the user may open a file for edit via an application such as opening a document for edit via a word processing application. In some embodiments the user drags and drops a file into an application of the computing environment to request the data file. In other embodiments the user may request the data file via a file and directory interface e.g. file explorer in Windows operating system to a storage of a networked or remote storage system such as a network driver of a central server.

At step the server or appliance transmits the requested data file to the client . In some embodiments the server or appliance transmits the data file to the client in response to the request of step . In other embodiments the server or appliance transmits the data file to the client without a request from the client . For example the server may push an update to a data file to the client . In one embodiment the server transmits the requested data file to the client . In another embodiment the appliance transmits the requested data file to the client . For example in one embodiment the appliance intercepts a request for the data file checks the cache of the appliance for the data file and transmits the cached data file to the client . In yet another embodiment the acceleration program intercepts the data file request at the client and provides the data file to the client via a cache of the acceleration program . In some embodiments the appliance or server transmits the data file via a streaming protocol or a stream. In other embodiments the appliance or server transmits the data file via any type and form of caching protocol.

At step the appliance and or acceleration program accelerates the delivery or transmission of the data file to the client . In some embodiments the data file may be transmitted via any type and form of protocol such as an application layer protocol over a transport layer protocol. In one embodiment the appliance accelerates the transmission of the data file. In another embodiment the acceleration program accelerates the transmission of the data file. In some embodiments the appliance in conjunction with the acceleration program accelerates the transmission of the data file. As discussed herein the appliance and or acceleration program may perform one or more of a plurality of acceleration techniques on the client and appliance to accelerate the transmission of the data file. In some embodiments the appliance and or acceleration program may cache one or more data files on the client or appliance for use by the application or computing environment .

As an example embodiment a user may be located at a branch office working on a local machine . The user may desire to use a word processing application such as MICROSOFT Word to edit a company document both residing on remote machines located in a central office. The user may then navigate a web browser to a corporate web site hosted by remote machine . Once the user is authenticated by the remote machine the remote machine may prepare and transmit to the local machine an HTML page that includes a Program Neighborhood window as described herein in in which appears graphical icons representing application programs to which the local machine has access. The user of local machine may invoke execution of an application by clicking an icon. A policy engine as described in may then determine whether and how the local machine may access the word processing application. The application may then be locally installed and executed using the techniques described in . The user may then use the application to select a document on the remote machine for editing. An appliance may then accelerate delivery of the file to the local machine using any techniques described herein such as TCP multiplexing.

As another example a second user may be located at a branch office working on a local machine . The user may wish to access through the user s corporate account an email containing an attached file. The email application and the email data files may reside in a central office. Upon a user request to access the email application a policy engine as described in may determine to stream the email application to the user using the streaming techniques described herein. A policy engine may also determine to install an acceleration program as described herein on the local machine . The application streaming may be accelerated using techniques described herein such as dynamic caching. Upon local installation the user may then select the email and accompanying attachment to view. An appliance may accelerate the delivery of the file by using an acceleration technique such as TCP pooling as described herein. The appliance may also cache some or all of the data files delivered to the remote machine so as to accelerate later requests. The caching may be done either on the appliance or on the local machine in conjunction with the acceleration program.

As a third example a user located at a branch office may wish to access a spreadsheet program such as MICROSOFT Excel to update a spreadsheet. The user may use a local machine to establish an SSL connection to a remote machine at a central office and select the spreadsheet application from a program neighborhood as described in . A collection agent as described in may then collect information about the local machine to determine whether the spreadsheet application may be streamed to the local machine . The spreadsheet application may then be streamed to the local machine via the SSL connection. The SSL connection may be accelerated by an appliance providing SSL or TCP connection pooling and multiplexing as described herein. The application streaming may be also accelerated by an appliance providing any of the dynamic caching techniques described herein. The user may then select a file from within the spreadsheet application for editing. The local machine may transmit a request for the file to the remote machine. An appliance may then use the compression techniques described herein to accelerate delivery of the file to the user.

Although generally described above as an application delivery system and appliance accelerating delivery of a computing environment to a client the application delivery system and appliance may accelerate the delivery of a plurality of computing environments applications and or data files to a client. For example the application delivery system and appliance may accelerate delivery to the client of a first computing environment associated with one type of operating system and a second computing environment associated with a second type of operating system. Additionally the application delivery system and appliance may accelerate the delivery of a computing environment application and or data file to a plurality of clients. Furthermore although generally described above as an application delivery system and appliance accelerating delivery of a computing environment to a remote user or remote client the application delivery system and appliance may accelerate delivery of a computing environment application and or data file to any client local remote or otherwise such as a client on a LAN of the server.

Moreover although generally described above as an appliance between the client and the application delivery system a plurality of appliances may be used between one or more clients and one or more servers. In some embodiments a first appliance resides on the network of the client and a second appliance resided on the network of the server. In one embodiment the first appliance and second appliance communicate with each other in performing the operations described herein. For example the first appliance and second appliance may communicate via any internode high performance or appliance to appliance communication protocol. Additionally a plurality of application delivery systems may be used in conjunction with one appliance or a plurality of appliances. The application delivery system and appliance may be deployed in a wide variety of network environments and infrastructure architectures.

Embodiments may be provided as one or more computer readable programs embodied on or in one or more articles of manufacture. The article of manufacture may be a floppy disk a hard disk a compact disc a digital versatile disc a flash memory card a PROM a RAM a ROM or a magnetic tape. In general the computer readable programs may be implemented in any programming language. Some examples of languages that can be used include C C C or JAVA. The software programs may be stored on or in one or more articles of manufacture as object code.

