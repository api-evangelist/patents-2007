---

title: Methods and apparatus for providing a distinct perceptual location for an audio source within an audio mixture
abstract: In accordance with a method for providing a distinct perceptual location for an audio source within an audio mixture, a foreground signal may be processed to provide a foreground perceptual angle for the foreground signal. The foreground signal may also be processed to provide a desired attenuation level for the foreground signal. A background signal may be processed to provide a background perceptual angle for the background signal. The background signal may also be processed to provide a desired attenuation level for the background signal. The foreground signal and the background signal may be combined into an output audio source.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08660280&OS=08660280&RS=08660280
owner: QUALCOMM Incorporated
number: 08660280
owner_city: San Diego
owner_country: US
publication_date: 20071128
---
This application relates to co pending application Methods and apparatus for providing an interface to a processing engine that utilizes intelligent audio mixing techniques Ser. No. 11 946 319 co filed with this application.

The present disclosure relates generally to audio processing. More specifically the present disclosure relates to processing audio sources in an audio mixture.

The term audio processing may refer to the processing of audio signals. Audio signals are electrical signals that represent audio i.e. sounds that are within the range of human hearing. Audio signals may be either digital or analog.

Many different types of devices may utilize audio processing techniques. Examples of such devices include music players desktop and laptop computers workstations wireless communication devices wireless mobile devices radio telephones direct two way communication devices satellite radio devices intercom devices radio broadcasting devices on board computers used in automobiles watercraft and aircraft and a wide variety of other devices.

Many devices such as the ones just listed may utilize audio processing techniques for the purpose of delivering audio to users. Users may listen to the audio through audio output devices such as stereo headphones or speakers. Audio output devices may have multiple output channels. For example a stereo output device e.g. stereo headphones may have two output channels a left output channel and a right output channel.

Under some circumstances multiple audio signals may be summed together. The result of this summation may be referred to as an audio mixture. The audio signals before the summation occurs may be referred to as audio sources. As mentioned above the present disclosure relates generally to audio processing and more specifically to processing audio sources in an audio mixture.

A method for method for providing a distinct perceptual location for an audio source within an audio mixture is disclosed. In accordance with the method a foreground signal may be processed to provide a foreground perceptual angle for the foreground signal. The foreground signal may also be processed to provide a desired attenuation level for the foreground signal. A background signal may be processed to provide a background perceptual angle for the background signal. The background signal may also be processed to provide a desired attenuation level for the background signal. The foreground signal and the background signal may be combined into an output audio source.

An apparatus for providing a distinct perceptual location for an audio source within an audio mixture is also disclosed. The apparatus may include a foreground angle control component that is configured to process a foreground signal to provide a foreground perceptual angle for the foreground signal. The apparatus may also include a foreground attenuation component that is configured to process the foreground signal to provide a desired attenuation level for the foreground signal. The apparatus may also include a background angle control component that is configured to process a background signal to provide a background perceptual angle for the background signal. The apparatus may also include a background attenuation component that is configured to process the background signal to provide a desired attenuation level for the background signal. The apparatus may also include an adder that is configured to combine the foreground signal and the background signal into an output audio source.

A computer readable medium is also disclosed. The computer readable medium may include instructions providing a distinct perceptual location for an audio source within an audio mixture. When executed by a processor the instructions may cause the processor to process a foreground signal to provide a foreground perceptual angle for the foreground signal. The instructions may also cause the processor to process the foreground signal to provide a desired attenuation level for the foreground signal. The instructions may also cause the processor to process a background signal to provide a background perceptual angle for the background signal. The instructions may also cause the processor to process the background signal to provide a desired attenuation level for the background signal. The instructions may also cause the processor to combine the foreground signal and the background signal into an output audio source.

An apparatus for providing a distinct perceptual location for an audio source within an audio mixture is also disclosed. The apparatus may include means for processing a foreground signal to provide a foreground perceptual angle for the foreground signal. The apparatus may also include means for processing the foreground signal to provide a desired attenuation level for the foreground signal. The apparatus may also include means for processing a background signal to provide a background perceptual angle for the background signal. The apparatus may also include means for processing the background signal to provide a desired attenuation level for the background signal. The apparatus may also include means for combining the foreground signal and the background signal into an output audio source.

The present disclosure relates to intelligent audio mixing techniques. More specifically the present disclosure relates to techniques for providing the audio sources within an audio mixture with distinct perceptual locations so that a listener may be better able to distinguish between the different audio sources while listening to the audio mixture. To take a simple example a first audio source may be provided with a perceptual location that is in front of the listener while a second audio source may be provided with a perceptual location that is behind the listener. Thus the listener may perceive the first audio source as coming from a location that is in front of him her while the listener may perceive the second audio source as coming from a location that is in back of him her. In addition to providing ways for listeners to distinguish between locations in the front and back different audio sources may also be provided with different angles or degrees of skew. For example a first audio source may be provided with a perceptual location that is in front of the listener and to the left while a second audio source may be provided with a perceptual location that is in front of the listener and to the right. Providing the different audio sources in an audio mixture with different perceptual locations may help the user to better distinguish between the audio sources.

There are many situations in which the techniques described herein may be utilized. One example is when a user of a wireless communication device is listening to music on the wireless communication device when the user receives a phone call. It may be desirable for the user to continue listening to the music during the phone call without the music interfering with the phone call. Another example is when a user is participating in an instant messaging IM conversation on a computer while listening to music or to another type of audio program. It may be desirable for the user to be able to hear the sounds that are played by the IM client while still listening to the music or audio program. Of course there are many other examples that may be relevant to the present disclosure. The techniques described herein may be applied to any situation in which it may be desirable for a user to be able to perceptually distinguish between the audio sources within an audio mixture.

As indicated above under some circumstances multiple audio signals may be summed together. The result of this summation may be referred to as an audio mixture. The audio signals before the summation occurs may be referred to as audio sources.

Audio sources may be broadband audio signals and may have multiple frequency components with frequency analysis. As used herein the term mixing refers to combining the time domain value either analog or digital of two audio sources with addition.

The definition of a perceptual angle that was just described will be used throughout the present disclosure. However perceptual angles may be defined differently and still be consistent with the present disclosure.

The terms foreground region and background region should not be limited to the specific foreground region and background region shown in . Rather the term foreground region should be interpreted as referring generally to an area that is in front of the listener whereas the term background region should be interpreted as referring generally to an area that is in back of the listener . For example in the foreground region and the background region are both shown as being 180 . Alternatively however the foreground region may be greater than 180 and the background region may be less than 180 . Alternatively still the foreground region may be less than 180 and the background region may be greater than 180 . Alternatively still both the foreground region and the background region may be less than 180 .

The processing engine may be configured to utilize intelligent audio mixing techniques. The processing engine is also shown with several audio source processors . Each audio source processor may be configured to process an input audio source and to output an audio source that includes a distinct perceptual location relative to the listener . In particular the processing engine is shown with a first audio source processor that processes the first input audio source and that outputs a first audio source that includes a distinct perceptual location relative to the listener . The processing engine is also shown with a second audio source processor that processes the second input audio source and that outputs a second audio source that includes a distinct perceptual location relative to the listener . The processing engine is also shown with an Nth audio source processor that processes the Nth input audio source and that outputs an Nth audio source that includes a distinct perceptual location relative to the listener . An adder may combine the audio sources into the audio mixture that is output by the processing engine .

Each of the audio source processors may be configured to utilize methods that are described in the present disclosure for providing an audio source with a distinct perceptual location relative to a listener . Alternatively the audio source processors may be configured to utilize other methods for providing an audio source with a distinct perceptual location relative to a listener . For example the audio source processors may be configured to utilize methods that are based on head related transfer functions HRTFs .

The apparatus shown in also includes a control unit . The control unit may be configured to provide an interface to the processing engine . For example the control unit may be configured so that a requesting entity may change the perceptual location of one or more of the audio sources via the control unit .

In response to receiving the request the control unit may generate one or more control signals to provide to the processing engine . The control signal s may be configured to cause the processing engine to change the perceptual location of the applicable audio source from its current perceptual location to the new perceptual location that is specified in the request . The control unit may provide the control signal s to the processing engine . In response to receiving the control signal s the processing engine and more specifically the applicable audio source processor may change the perceptual location of the applicable audio source from its current perceptual location to the new perceptual location that is specified in the request .

In one possible implementation the control unit may be an ARM processor and the processing engine may be a digital signal processor DSP . With such an implementation the control signals may be control commands that the ARM processor sends to the DSP.

Alternatively the control unit may be an application programming interface API . The processing engine may be a software component e.g. an application module routine subroutine procedure function etc. that is being executed by a processor. With such an implementation the request may come from a software component either the software component that serves as the processing engine or another software component . The software component that sends the request may be part of a user interface.

In some implementations the processing engine and or the control unit may be implemented within a mobile device. Some examples of mobile devices include cellular telephones personal digital assistants PDAs laptop computers smartphones portable media players handheld game consoles etc.

The audio source unit engine A may be configured to utilize intelligent audio mixing techniques. The audio source unit engine A is also shown with several audio source units A. Each audio source unit A may be configured to process an input audio source A and to output an audio source A that includes a distinct perceptual location relative to the listener . In particular the audio source unit engine A is shown with a first audio source unit A that processes the first input audio source A and that outputs a first audio source A that includes a distinct perceptual location relative to the listener . The audio source unit engine A is also shown with a second audio source unit A that processes the second input audio source A and that outputs a second audio source A that includes a distinct perceptual location relative to the listener . The audio source unit engine A is also shown with an Nth audio source unit A N that processes the Nth input audio source A N and that outputs an Nth audio source A N that includes a distinct perceptual location relative to the listener . An adder A may combine the audio sources A into the audio mixture A that is output by the audio source unit engine A.

Each of the audio source units may be configured to utilize methods that are described in the present disclosure for providing an audio source A with a distinct perceptual location relative to a listener . Alternatively the audio source units A may be configured to utilize other methods for providing an audio source A with a distinct perceptual location relative to a listener . For example the audio source units A may be configured to utilize methods that are based on head related transfer functions HRTFs .

The processor A shown in also includes a control unit A. The control unit A may be configured to provide an interface to the audio source unit engine A. For example the control unit A may be configured so that a requesting entity may change the perceptual location of one or more of the audio sources A via the control unit A.

In response to receiving the request A the control unit A may generate one or more control signals A to provide to the audio source unit engine A. The control signal s A may be configured to cause the audio source unit engine A to change the perceptual location of the applicable audio source A from its current perceptual location to the new perceptual location that is specified in the request A. The control unit A may provide the control signal s A to the audio source unit engine A. In response to receiving the control signal s A the audio source unit engine A and more specifically the applicable audio source unit A may change the perceptual location of the applicable audio source A from its current perceptual location to the new perceptual location that is specified in the request A.

In accordance with the method a request to change the perceptual location of an audio source may be received . Values of parameters of the processing engine that are associated with the new perceptual location may be determined . Commands may be generated for setting the parameters to the new values. Control signal s may be generated . The control signal s may include the commands for setting the parameters to the new values and thus the control signal s may be configured to cause the processing engine to change the perceptual location of the audio source from its current perceptual location to the new perceptual location that is specified in the request . The control signal s may be provided to the processing engine . In response to receiving the control signal s the processing engine may change the perceptual location of the audio source to the new perceptual location.

The method of described above may be performed by corresponding means plus function blocks illustrated in . In other words blocks through illustrated in correspond to means plus function blocks through illustrated in .

The audio source processor is shown with a foreground angle control component and a foreground attenuation component for processing the foreground signal. The audio source processor is also shown with a background angle control component and a background attenuation component for processing the background signal.

The foreground angle control component may be configured to process the foreground signal so that the foreground signal includes a perceptual angle within the foreground region . This perceptual angle may be referred to as a foreground perceptual angle. The foreground attenuation component may be configured to process the foreground signal in order to provide a desired level of attenuation for the foreground signal.

The background angle control component may be configured to process the background signal so that the background signal includes a perceptual angle within the background region . This perceptual angle may be referred to as a background perceptual angle. The background attenuation component may be configured to process the background signal in order to provide a desired level of attenuation for the background signal.

The foreground angle control component foreground attenuation component background angle control component and background attenuation component may function together to provide a perceptual location for an audio source . For example to provide a perceptual location that is within the foreground region the background attenuation component may be configured to attenuate the background signal while the foreground attenuation component may be configured to allow the foreground signal to pass without being attenuated. The foreground angle control component may be configured to provide the appropriate perceptual angle within the foreground region . Conversely to provide a perceptual location that is within the background region the foreground attenuation component may be configured to attenuate the foreground signal while the background attenuation component may be configured to allow the background signal to pass without being attenuated. The background angle control component may be configured to provide the appropriate perceptual angle within the background region .

As indicated above the control unit may generate the control signals in response to receiving a request to change the perceptual location of an audio source . As part of generating the control signals the control unit may be configured to determine new values for parameters associated with the processing engine and more specifically with the audio source processor . The control signals may include commands for setting the parameters to the new values.

The control signals are shown with foreground angle control commands foreground attenuation commands background angle control commands and background attenuation commands . The foreground angle control commands may be commands for setting parameters associated with the foreground angle control component . The foreground attenuation commands may be commands for setting parameters associated with the foreground attenuation component . The background angle control commands may be commands for setting parameters associated with the background angle control component . The background attenuation commands may be commands for setting parameters associated with the background attenuation component .

The audio source processor is shown receiving an input audio source . The input audio source is a stereo audio source with two channels a left channel and a right channel . The input audio source is shown being split into two signals a foreground signal and a background signal . The foreground signal is shown with two channels a left channel and a right channel . Similarly the background signal is shown with two channels a left channel and a right channel . The foreground signal is shown being processed along a foreground path while the background signal is shown being processed along a background path.

The left channel and the right channel of the background signal are shown being processed by two low pass filters LPFs . The right channel of the background signal is then shown being processed by a delay line . The length of the delay line may be relatively short e.g. 10 milliseconds . Due to a precedence effect the interaural time difference ITD brought by the delay line could result in a sound image skew i.e. the sound is not perceived as centered when both channels are set to the same level. To counteract this the left channel of the background signal is then shown being processed by an interaural intensity difference IID attenuation component . The gain of the IID attenuation component may be tuned according to sampling rate and the length of the delay line . The processing that is done by the LPFs the delay line and the IID attenuation component may make the background signal sound more diffuse than the foreground signal .

The audio source processor is shown with a foreground angle control component . As indicated above the foreground angle control component may be configured to provide a foreground perceptual angle for the foreground signal . In addition because the input audio source is a stereo audio source the foreground angle control component may also be configured to balance the contents of the left channel and the right channel of the foreground signal . This may be done for the purpose of preserving contents of the left channel and the right channel of the foreground signal for any perceptual angle that the foreground signal may be set to.

The audio source processor is also shown with a background angle control component . As indicated above the background angle control component may be configured to provide a background perceptual angle for the background signal . In addition because the input audio source is a stereo audio source the background angle control component may also be configured to balance the contents of the left channel and the right channel of the background signal . This may be done for the purpose of preserving contents of the left channel and the right channel of the background signal for any perceptual angle that the background signal may be set to.

The audio source processor is also shown with a foreground attenuation component . As indicated above the foreground attenuation component may be configured to process the foreground signal in order to provide a desired level of attenuation for the foreground signal . The foreground attenuation component is shown with two scalars . Collectively these scalars may be referred to as foreground attenuation scalars .

The audio source processor is also shown with a background attenuation component . As indicated above the background attenuation component may be configured to process the background signal in order to provide a desired level of attenuation for the background signal . The background attenuation component is shown with two scalars . Collectively these scalars may be referred to as background attenuation scalars .

The values of the foreground attenuation scalars may be set to achieve the desired level of attenuation for the foreground signal . Similarly the values of the background attenuation scalars may be set to achieve the desired level of attenuation for the background signal . For example to completely attenuate the foreground signal the foreground attenuation scalars may be set to a minimum value e.g. zero . In contrast to allow the foreground signal to pass without being attenuated these scalars may be set to a maximum value e.g. unity .

An adder is shown combining the left channel of the foreground signal with the left channel of the background signal . The adder is shown outputting the left channel of the output audio source . Another adder is shown combining the right channel of the foreground signal with the right channel of the background signal . This adder is shown outputting the right channel of the output audio source .

The audio source processor illustrates how separate foreground processing and background processing may be implemented in order to change the perceptual location of an audio source . An input audio source is shown being split into two signals a foreground signal and a background signal . The foreground signal and the background signal are then processed separately. In other words there are differences between the way that the foreground signal is processed as compared to the way that the background signal is processed. The specific differences shown in are that the foreground signal is processed with a foreground angle control component and a foreground attenuation component whereas the background signal is processed with a background angle control component and a background attenuation component . In addition the background signal is processed with components i.e. low pass filters a delay line and an IID attenuation component that make the background signal sound more diffuse than the foreground signal whereas the foreground signal is not processed with these components.

The audio source processor of is just an example of one way that separate foreground processing and background processing may be implemented in order to change the perceptual location of an audio source . Separate foreground processing and background processing may be achieved using different components than those shown in . The phrase separate foreground and background processing should not be construed as being limited to the specific components and configuration shown in . Instead separate foreground and background processing means that an input audio source is split into a foreground signal and a background signal and there is at least one difference between the way that the foreground signal is processed as compared to the way that the background signal is processed.

As indicated above the foreground angle control component may be configured to balance contents of the left channel and the right channel of the foreground signal . This may be accomplished by redistributing the contents of the left channel and the right channel of the foreground signal to two signals . These signals may be referred to as content balanced signals . The content balanced signals may both include a substantially equal mixture of the contents of the left channel and the right channel of the foreground signal . To distinguish the content balanced signals from each other one content balanced signal may be referred to as a left content balanced signal while the other content balanced signal may be referred to as a right content balanced signal

Mixing scalars may be used to redistribute the contents of the left channel and the right channel of the foreground signal to the two content balanced signals . In these mixing scalars are labeled as the g L2L scalar the g R2L scalar the g L2R scalar and the g R2R scalar . The left content balanced signal may include the left channel multiplied by the g L2L scalar and the right channel multiplied by the g R2L scalar . The right content balanced signal may include the right channel multiplied by the g R2R scalar and the left channel multiplied by the g L2R scalar

As indicated above the foreground angle control component may also be configured to provide a perceptual angle within the foreground region for the foreground signal . This may be accomplished through the use of two scalars which may be referred to as foreground angle control scalars . In these foreground angle control scalars are labeled as the g L scalar and the g R scalar . The left content balanced signal may be multiplied by the g L scalar and the right content balanced signal may be multiplied by the g R scalar

To achieve a perceptual angle between 270 and 0 i.e. on the left side of the foreground region the values of the foreground angle control scalars may be set so that the right content balanced signal is more greatly attenuated than the left content balanced signal . Conversely to achieve a perceptual angle location between 0 and 90 i.e. on the right side of the foreground region the values of the foreground angle control scalars may be set so that the left content balanced signal is more greatly attenuated than the right content balanced signal . To achieve a perceptual location that is directly in front of the listener 0 the values of the foreground angle control scalars may be set so that the left content balanced signal and the right content balanced signal are equally attenuated.

As indicated above the background angle control component may be configured to balance contents of the left channel and the right channel of the background signal . This may be accomplished by redistributing the contents of the left channel and the right channel of the background signal to two content balanced signals which may be referred to as a left content balanced signal and a right content balanced signal . The content balanced signals may both include a substantially equal mixture of the contents of the left channel and the right channel of the background signal .

Mixing scalars may be used to redistribute the contents of the left channel and the right channel of the background signal to the two content balanced signals . In these mixing scalars are labeled as the g L2L scalar the g R2L scalar the g L2R scalar and the g R2R scalar . The left content balanced signal may include the left channel multiplied by the g L2L scalar and the right channel multiplied by the g R2L scalar . The right content balanced signal may include the right channel multiplied by the g R2R scalar and the left channel multiplied by the g L2R scalar

As indicated above the background angle control component may also be configured to provide a perceptual angle within the background region for the background signal . This may be accomplished by tuning the values of the four mixing scalars so that these scalars also perform the function of providing a perceptual angle for the background signal in addition to the function of redistributing contents of the left and right channels of the background signal . Thus the background angle control component is shown without any dedicated angle control scalars such as the g L scalar and the g R scalar in the foreground angle control component shown in . The mixing scalars may be referred to as mixing angle control scalars because they may perform both of these functions. The mixing angle control scalars may be able to perform both mixing and angle control functions because for processing in the background region the sound is diffused already so it is not necessary to provide as accurate of a sound image as in the foreground region .

As indicated above the control signals that the control unit sends to the audio source processor may include foreground attenuation commands and background attenuation commands . The foreground attenuation commands may include commands for setting the values of the foreground attenuation scalars in accordance with the values shown in . The foreground attenuation commands may cause the values of the foreground attenuation scalars to gradually decrease or to gradually increase as appropriate. The background attenuation commands may include commands for setting the values of the background attenuation scalars in accordance with the values shown in . The background attenuation commands may cause the values of the background attenuation scalars to gradually increase or to gradually decrease as appropriate.

The values of the foreground attenuation scalars and the background attenuation scalars shown in are examples only. Other values for these scalars may be used. For example the values for the foreground left scalar and the foreground right scalar could be switched and the values for the background left scalar and the background right scalar could be switched. This may cause the transition between foreground and background to appear to the opposite side i.e. a left side transition with the values as shown in may become a right side transition if the values were switched as described above. The sound as a whole may not be an exact left right mirror however because the control unit may be configured to automatically choose the arc that is less than 180 degrees to execute. For example consider a transition from 120 to 270 . For this type of transition the values shown in would make an arc like movement on the left side of a sonic space. If the values were switched as described above the arc would be along the right side instead but would still start from 120 and end at 270 .

The table includes a column that shows examples of values for the foreground attenuation scalars and the background attenuation scalars when the perceptual location of an audio source is changed from a current location in the foreground region to a new location that is also in the foreground region . Another column shows examples of values for the foreground attenuation scalars and the background attenuation scalars when the perceptual location of an audio source is changed from a current location in the background region to a new location that is also in the background region .

As indicated above the control signals that the control unit sends to the audio source processor may include foreground angle control commands . The foreground angle control commands may include commands for setting the values of the foreground angle control scalars in accordance with the values shown in . If the perceptual location is changing from the background region to the foreground region the foreground angle control commands may be configured to immediately set the foreground angle control scalars to values that correspond to the new perceptual location of the audio source in the foreground region . If the perceptual location is changing within the foreground region the foreground angle control commands may be configured to gradually transition the values of the foreground angle control scalars from values corresponding to the current perceptual location to values corresponding to the new perceptual location.

As indicated above the control signals that the control unit sends to the audio source processor may include foreground angle control commands . The foreground angle control commands may include commands for setting the values of the mixing scalars in accordance with the values shown in . If the perceptual location is changing from the background region to the foreground region the foreground angle control commands may be configured to immediately set the mixing scalars to values that correspond to the new perceptual location of the audio source in the foreground region . If the perceptual location is changing within the foreground region the foreground angle control commands may be configured to gradually transition the values of the mixing scalars from values corresponding to the current perceptual location to values corresponding to the new perceptual location.

As indicated above the control signals that the control unit sends to the audio source processor may include background angle control commands . The background angle control commands may include commands for setting the values of the mixing angle control scalars in accordance with the values shown in . If the perceptual location is changing from the foreground region to the background region the background angle control commands may be configured to immediately set the mixing angle control scalars to values that correspond to the new perceptual location of the audio source in the background region . If the perceptual location is changing within the background region the background angle control commands may be configured to gradually transition the values of the mixing angle control scalars from values corresponding to the current perceptual location to values corresponding to the new perceptual location.

In accordance with the method an input audio source may be split into a foreground signal and a background signal . The foreground signal may be processed differently than the background signal .

The processing of the foreground signal will be discussed first. If the input audio source is a stereo audio source the foreground signal may be processed to balance contents of the left channel and the right channel of the foreground signal . The foreground signal may also be processed to provide a foreground perceptual angle for the foreground signal . The foreground signal may also be processed to provide a desired level of attenuation for the foreground signal .

The processing of the background signal will now be discussed. The background signal may be processed so that the background signal sounds more diffuse than the foreground signal . If the input audio source is a stereo audio source the background signal may be processed to balance contents of the left channel and the right channel of the background signal . The background signal may also be processed to provide a background perceptual angle for the background signal . The background signal may also be processed to provide a desired level of attenuation for the background signal .

The foreground signal and the background signal may then be combined into an output audio source . The output audio source may then be combined with other output audio sources to create an audio mixture .

The method of illustrates how separate foreground processing and background processing of an input audio source may be implemented. The steps of balancing contents of the left channel and the right channel of the foreground signal providing a foreground perceptual angle for the foreground signal and providing a desired level of attenuation for the foreground signal correspond to foreground processing of the input audio source . The steps of processing the background signal to sound more diffuse than the foreground signal balancing contents of the left channel and the right channel of the background signal providing a background perceptual angle for the background signal and providing a desired level of attenuation for the background signal correspond to background processing of the input audio source . Because there is at least one difference between the way that the foreground signal is processed as compared to the way that the background signal is processed it may be said that the foreground signal is processed separately than the background signal .

Although the method of illustrates one way that separate foreground processing and background processing may be implemented in order to change the perceptual location of an audio source the phrase separate foreground and background processing should not be construed as being limited to the specific steps shown in . Instead as indicated above separate foreground and background processing means that an input audio source is split into a foreground signal and a background signal and there is at least one difference between the way that the foreground signal is processed as compared to the way that the background signal is processed.

The method of described above may be performed by corresponding means plus function blocks illustrated in . In other words blocks through illustrated in correspond to means plus function blocks through illustrated in .

In accordance with the method control signals may be received from a control unit . These control signals may include commands for setting various parameters of the audio source processor .

For example suppose that the perceptual location of an audio source is being changed from the foreground region to the background region . The control signals may include commands to immediately set the mixing angle control scalars within the background angle control component to values that correspond to the new perceptual location of the audio source . The values of the mixing angle control scalars may be changed in accordance with these commands .

The control signals may also include commands to gradually transition the values of the background attenuation scalars from values that result in complete attenuation of the background signal to values that result in no attenuation of the background signal . The values of the background attenuation scalars may be changed in accordance with these commands .

The control signals may also include commands to gradually transition the values of the foreground attenuation scalars from values that result in no attenuation of the foreground signal to values that result in complete attenuation of the foreground signal . The values of the foreground attenuation scalars may be changed in accordance with these commands .

Conversely suppose that the perceptual location of an audio source is being changed from the background region to the foreground region . The control signals may include commands to immediately set the foreground mixing scalars and the foreground angle control scalars within the foreground angle control component to values that correspond to the new perceptual location of the audio source . The values of the foreground mixing scalars and the foreground angle control scalars may be changed in accordance with these commands .

The control signals may also include commands to gradually transition the values of the foreground attenuation scalars from values that result in complete attenuation of the foreground signal to values that result in no attenuation of the foreground signal . The values of the foreground attenuation scalars may be changed in accordance with these commands .

The control signals may also include commands to gradually transition the values of the background attenuation scalars from values that result in no attenuation of the background signal to values that result in complete attenuation of the background signal . The values of the background attenuation scalars may be changed in accordance with these commands .

If the perceptual location of an audio source is being changed within the background region the control signals may also include commands to gradually transition the values of the mixing angle control scalars within the background angle control component from values that correspond to the current perceptual location to values that correspond to the new perceptual location. The values of the mixing angle control scalars may be changed in accordance with these commands .

If the perceptual location of an audio source is being changed within the foreground region the control signals may also include commands to gradually transition the values of the foreground mixing scalars and the foreground angle control scalars within the foreground angle control component from values that correspond to the current perceptual location to values that correspond to the new perceptual location. The values of the foreground mixing scalars and the foreground angle control scalars may be changed in accordance with these commands .

The method of may be implemented such that for any transition the arc that is less than 180 to execute may be automatically selected. For example consider a transition from 120 to 270 . With reference to the definition of a perceptual angle that is shown in where 0 is straight in front of the listener this transition could be made in a counter clockwise direction or a clockwise direction. However in this example the clockwise direction would be less than 180 and the counter clockwise direction would be greater than 180 . As a result the arc that corresponds to the clockwise direction may be automatically selected.

The method of described above may be performed by corresponding means plus function blocks illustrated in . In other words blocks through illustrated in correspond to means plus function blocks through illustrated in .

The audio source processor shown in may be similar in some respects to the audio source processor shown in . Components of the audio source processor shown in that are similar to components of the audio source processor shown in are labeled with corresponding reference numbers.

There are some differences between the audio source processor shown in and the audio source processor shown in . For example the audio source processor is shown receiving an input audio source that has just one channel. In contrast the audio source processor shown in is shown receiving an input audio source having two channels 

The input audio source is shown being split into a foreground signal and a background signal . Because the input audio source includes one channel the foreground signal and the background signal both initially include one channel.

Because the foreground signal initially includes just one channel the foreground angle control component may be configured to receive just one input . In contrast as discussed above the foreground angle control component in the audio source processor of may be configured to receive two inputs . The foreground angle control component shown in may be configured to split the single channel of the foreground signal into two signals.

The foreground angle control component in the audio source processor of may be configured to provide a foreground perceptual angle for the foreground signal . However because the foreground signal initially includes one channel the foreground angle control component may not be configured to balance the contents of multiple channels as was the case with the foreground angle control component in the audio source processor of .

As mentioned the background signal also initially includes just one channel. Thus the audio source processor of is shown with just one low pass filter instead of the two low pass filters that are shown in the audio source processor of . The output of the single low pass filter may be split into two signals one signal that is provided to the delay line and another signal that is provided to the IID attenuation component .

The audio source processor shown in illustrates another example of how separate foreground processing and background processing may be implemented in order to change the perceptual location of an audio source . An input audio source is shown being split into two signals a foreground signal and a background signal . The foreground signal and the background signal are then processed separately. In other words there are differences between the way that the foreground signal is processed as compared to the way that the background signal is processed. These differences were described above.

The foreground angle control component is shown receiving the single channel of a foreground signal as input. The foreground angle control component may be configured to provide a foreground perceptual angle for the foreground signal . This may be accomplished through the use of two foreground angle control scalars which in are labeled as the g L scalar and the g R scalar . The foreground signal may be split into two signals . One signal may be multiplied by the g L scalar and the other signal may be multiplied by the g R scalar

The apparatus is shown with a processor and memory . The processor may control the operation of the apparatus and may be embodied as a microprocessor a microcontroller a digital signal processor DSP or other device known in the art. The processor typically performs logical and arithmetic operations based on program instructions stored within the memory . The instructions in the memory may be executable to implement the methods described herein.

The apparatus may also include one or more communication interfaces and or network interfaces for communicating with other electronic devices. The communication interface s and the network interface s may be based on wired communication technology wireless communication technology or both.

The apparatus may also include one or more input devices and one or more output devices . The input devices and output devices may facilitate user input. Other components may also be provided as part of the apparatus .

As used herein the term determining and grammatical variants thereof is used in an extremely broad sense. The term determining encompasses a wide variety of actions and therefore determining can include calculating computing processing deriving investigating looking up e.g. looking up in a table a database or another data structure ascertaining and the like. Also determining can include receiving e.g. receiving information accessing e.g. accessing data in a memory and the like. Also determining can include resolving selecting choosing establishing and the like.

Information and signals may be represented using any of a variety of different technologies and techniques. For example data instructions commands information signals and the like that may be referenced throughout the above description may be represented by voltages currents electromagnetic waves magnetic fields or particles optical fields or particles or any combination thereof.

The various illustrative logical blocks modules and circuits described in connection with the present disclosure may be implemented or performed with a general purpose processor a digital signal processor DSP an application specific integrated circuit ASIC a field programmable gate array signal FPGA or other programmable logic device discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor but in the alternative the processor may be any commercially available processor controller microcontroller or state machine. A processor may also be implemented as a combination of computing devices e.g. a combination of a DSP and a microprocessor a plurality of microprocessors one or more microprocessors in conjunction with a DSP core or any other such configuration.

The steps of a method or algorithm described in connection with the present disclosure may be embodied directly in hardware in a software module executed by a processor or in a combination of the two. A software module may reside in any form of storage medium that is known in the art. Some examples of storage media that may be used include RAM memory flash memory ROM memory EPROM memory EEPROM memory registers a hard disk a removable disk a CD ROM and so forth. A software module may comprise a single instruction or many instructions and may be distributed over several different code segments among different programs and across multiple storage media. A storage medium may be coupled to a processor such that the processor can read information from and write information to the storage medium. In the alternative the storage medium may be integral to the processor.

The methods disclosed herein comprise one or more steps or actions for achieving the described method. The method steps and or actions may be interchanged with one another without departing from the scope of the claims. In other words unless a specific order of steps or actions is specified the order and or use of specific steps and or actions may be modified without departing from the scope of the claims.

The functions described may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored on or transmitted over as one or more instructions or code on a computer readable medium. Computer readable media includes both computer storage media and communication media including any medium that facilitates transfer of a computer program from one place to another. A storage media may be any available media that can be accessed by a computer. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Also any connection is properly termed a computer readable medium. For example if the software is transmitted from a website server or other remote source using a coaxial cable fiber optic cable twisted pair digital subscriber line DSL or wireless technologies such as infrared radio and microwave then the coaxial cable fiber optic cable twisted pair DSL or wireless technologies such as infrared radio and microwave are included in the definition of medium. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

It is to be understood that the claims are not limited to the precise configuration and components illustrated above. Various modifications changes and variations may be made in the arrangement operation and details of the methods and apparatus described above without departing from the scope of the claims.

