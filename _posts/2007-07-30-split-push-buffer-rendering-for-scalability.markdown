---

title: Split push buffer rendering for scalability
abstract: Frames are rendered by multiple graphics processors (GPUs), which may be heterogeneous. Graphics processors split the execution of the command in a push buffer of a frame. One GPU begins rendering a frame, and a second GPU takes over rendering that frame after the second GPU is done rendering a previous frame. The second GPU may then begin rendering a subsequent frame.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08941669&OS=08941669&RS=08941669
owner: NVIDIA Corporation
number: 08941669
owner_city: Santa Clara
owner_country: US
publication_date: 20070730
---
The present disclosure is related to the following commonly assigned co pending U.S. patent applications 

The present invention relates generally to computer systems with multiple graphics processors and in particular to the efficient rendering of frames using the multiple graphics processors.

The present invention relates to the field of computer graphics. Many computer graphic images are created by mathematically modeling the interaction of light with a three dimensional scene from a given viewpoint. This process called rendering generates a two dimensional image of the scene from the given viewpoint and is analogous to taking a photograph of a real world scene.

As the demand for computer graphics and in particular for real time computer graphics has increased computer systems with graphics processors adapted to accelerate the rendering process have become widespread. In these computer systems the rendering process is divided between a computer s general purpose central processing unit CPU and a graphics processing units GPU . Typically the CPU performs high level operations such as determining the position motion and collision of objects in a given scene. From these high level operations the CPU generates a set of rendering commands and data defining the desired rendered image or images. For example rendering commands and data can define scene geometry lighting shading texturing motion and or camera parameters for a scene. The graphics processor creates one or more rendered images from the set of rendering commands and data.

To maximize rendering performance the computer system may include two or more graphics processing units GPUs operating in parallel. The graphics processing units can distribute the rendering workload in a number of different ways. For example different portions of an image can be rendered in parallel by different GPUs. The portions are then combined to produce a complete rendered image. In another example parallel rendering scheme each GPU renders one image in a sequence of images.

Typically if a computer system includes two or more GPUs the GPUs running on a computer system are required have equivalent performance. One reason is that the usual methods for distributing the rendering workload work best when the GPUs are equivalent. However for cost and availability reasons a user may desire to implement two GPUs that are non equivalent or heterogeneous in terms of performance. For instance a user may want to use both an integrated GPU already present on a motherboard and a discrete GPU present on a separate board.

Therefore it is desirable to provide systems methods and apparatus for efficient distribution of the rendering workload when using heterogeneous GPUs.

Embodiments of the present invention are directed to rendering of multiple frames by multiple GPUs which may differ from one another. In one aspect two GPUs split the execution of the commands to render a frame. A slower GPU begins rendering a frame and a faster GPU takes over rendering that frame when the faster one is done rendering a previous frame. The slower GPU may then begin rendering a subsequent frame. A command buffer may hold the commands for a single frame or hold the commands for multiple frames.

One exemplary embodiment of the present invention provides a method of rendering a plurality of frames with a plurality of graphics processors configured to operate in parallel. A command buffer including commands for rendering a plurality of current frames is provided. For each current frame there exist commands for a previous frame and a subsequent frame. Different sections or portions of the commands for rendering a specific current frame may be written by different central processors.

For each current frame a first graphics processor executes a first portion of the commands for rendering the current frame. Also an execution of the commands for the current frame is switched from the first graphics processor to a second graphics processor based on the second graphics processor completing a rendering of a frame previous the current frame. While the second graphics processor completes the rendering of the current frame the first graphics processor executes a first portion of the commands for rendering a frame subsequent to the current frame.

In one embodiment the first graphics processor is an integrated graphics processor and the second graphics processor is a discrete graphics processor. In one aspect these two graphics processors are heterogeneous to each other and operate to produce identical results upon executing identical commands. In yet another embodiment the second graphics processor executes all of the commands for the previous buffer of a first current frame.

In another embodiment the rendered current frames are stored in a memory. The memory may be a system memory of a computer system that includes the first and second graphics processors a memory that is connected to the first or second graphics processor or any other memory of the computer system. In yet another embodiment prior to the second graphics processor completing the rendering of the previous frame the first graphics processor changes from executing the first portion of the commands for the current frame to executing the first portion of the commands for a subsequent frame.

In one embodiment the command buffer is created in part by storing different instances of complete state data at a plurality of locations within the commands of each current frame. The second graphics processor may then read the instance of complete state data that is stored before where the first graphics processor stopped executing the commands of the current frame. In one aspect the different instances of complete state data are stored at periodic locations within the command buffer.

In another embodiment the current frames are alternate frames of a video stream. Other current frames may be rendered by other graphics processors. These other current frames can be different alternate frames of a video stream. In one aspect the method provides another command buffer for these other current frames. For each of these other current frames a third graphics processor executes a first portion of the commands for rendering the other current frame. The execution of the commands for the other current frame switches from the first graphics processor to a fourth graphics processor based on the fourth graphics processor completing the rendering of a previous other frame. The third graphics processor may then execute a first portion of the commands for rendering a subsequent other frame while the fourth graphics processor completes rendering the current other frame.

Another exemplary embodiment of the present invention provides a method of rendering a plurality of frames with a plurality of graphics processors configured to operate in parallel. A first command buffer including commands for rendering a first frame and a second command buffer including commands for rendering a second frame are provided. The first graphics processor executes a first portion of the first command buffer. Upon determining an availability of a second graphics processor the first graphics processor stops execution of the first command buffer. The first graphics processor then executes a first portion of the second command buffer. While the first graphics processor executes the first portion of the second command buffer the second graphics processor executes a remaining portion of the first command buffer.

In one embodiment determining the availability of the second graphics processor is based on when the second graphics processor completes executing commands for a command buffer for a frame previous to the first frame. In another embodiment determining the availability of the second graphics processor is based on a pre indication signal that determines that the second graphics processor will be available soon. Determining an availability of the second graphics processor may include communicating the availability from the second graphics processor to the first graphics processor.

In another embodiment a third command buffer including commands for rendering a third frame is provided. Upon determining another availability of the second graphics processor the first graphics processor stops execution of the second command buffer. The first graphics processor may then execute a first portion of the third command buffer. While the first graphics processor executes the first portion of the third command buffer the second graphics processor executes a remaining portion of the second command buffer.

Another exemplary embodiment of the present invention provides a computer program product having a computer readable medium encoded with program code for controlling operation of a computer system to render a plurality of frames with a plurality of graphics processors configured to operate in parallel.

The following detailed description together with the accompanying drawings will provide a better understanding of the nature and advantages of the present invention.

Embodiments of the present invention provide for the rendering of multiple frames by multiple GPUs which GPUs may be heterogeneous. In one aspect two GPUs split the execution of the commands for rendering a frame. A slower GPU begins rendering a frame and a faster GPU takes over rendering that frame when the faster one is done rendering a previous frame. The slower GPU may then begin rendering a subsequent frame. In another aspect more GPUs may be employed as described herein.

I O bridge which may be e.g. a conventional Southbridge chip receives user input from one or more user input devices e.g. keyboard mouse and forwards the input to CPU via bus and memory bridge . Visual output is provided on a pixel based display device e.g. a conventional CRT or LCD based monitor operating under control of a graphics subsystem coupled to memory bridge via a bus or other communication path e.g. a PCI Express PCI E or Accelerated Graphics Port AGP link. A system disk is also connected to I O bridge . A switch may provide connections between I O bridge and other components such as a network adapter and various add in cards .

Other components not explicitly shown including USB or other port connections CD drives DVD drives and the like may also be connected to I O bridge . Bus connections among the various components may be implemented using bus protocols such as PCI Peripheral Component Interconnect PCI E AGP HyperTransport or any other bus or point to point communication protocol s and connections between different devices may use different protocols as is known in the art.

It will be appreciated that the system shown herein is illustrative and that variations and modifications are possible. The bus topology including the number and arrangement of bridges may be modified as desired. For instance in some embodiments system memory is connected to CPU directly rather than through a bridge and other devices communicate with system memory via memory bridge and CPU . In other alternative topologies graphics subsystem is connected to I O bridge rather than to memory bridge . In still other embodiments I O bridge and memory bridge might be integrated into a single chip. The particular components shown herein are optional for instance any number of add in cards or peripheral devices might be supported.

Graphics processing subsystem includes at least two graphics processing units GPUs . GPU has an associated graphics memory and GPU has an associated graphics memory . GPUs and graphics memories may be implemented e.g. using one or more integrated circuit devices such as programmable processors application specific integrated circuits ASICs and memory devices. In some embodiments GPUs and graphics memories are implemented in one or more expansion cards or other adapters that can be inserted into and removed from expansion slots e.g. PCI E slots in system . Additional GPUs not shown in may also be included.

Each of GPUs may be configured to perform various tasks related to generating pixel data also referred to herein as pixels from graphics data supplied by CPU and or system memory via memory bridge and bus interacting with a respective graphics memories to store and update pixel data and the like. For example GPUs may generate pixel data from 2 D or 3 D scene data provided by various programs executing on CPU . GPUs may also store pixel data received via memory bridge to respective graphics memories with or without further processing. Each of GPUs may also include a scanout module also referred to herein as a display pipeline that can be configured to deliver pixel data from respective graphics memories to an output port of the GPUs . The output port might be connected to a monitor or to another GPU.

Each GPU may be provided with any amount of local graphics memory including no local memory and may use local memory and system memory in any combination. For instance in a unified memory architecture UMA embodiment no dedicated graphics memory device is provided and some or all of the GPUs may use system memory exclusively or almost exclusively. In UMA embodiments a GPU may be integrated into a bus bridge chip or provided as a discrete chip with a high speed bus e.g. PCI E connecting the GPU to the bridge chip and system memory.

Interconnection between the GPUs may also be modified. For instance a bridge unit might be provided to interconnect GPUs. A bridge unit which can be in a separate chip or integrated with one of the GPUs receives incoming data from system bus and distributes it appropriately e.g. to all GPUs or to those GPUs identified by a sub device mask . Another bridge unit might be provided to manage selection among candidate pixels during scanout.

In addition GPUs embodying aspects of the present invention may be incorporated into a variety of devices including general purpose computer systems video game consoles and other special purpose computer systems DVD players handheld devices such as mobile phones or personal digital assistants and so on.

GPUs may be controlled in the following manner. CPU operates as the master processor of system controlling and coordinating operations of other system components. In particular CPU issues commands that control the operation of GPUs and . In some embodiments CPU writes a stream of commands for GPUs to a command buffer which may be in system memory graphics memories and or another storage location accessible to both CPU and GPUs . The commands may include conventional rendering commands for generating images as well as general purpose computation commands that enable applications executing on CPU to leverage the computational power of GPUs for data processing that may be unrelated to image generation.

Command buffer stores sets of rendering commands such as rendering command and sets of rendering data such as rendering data . In one embodiment a rendering command is associated with rendering data. The rendering command defines the set of rendering processes to be performed by a GPU on an associated rendering data. In a further embodiment the rendering data is stored in the command buffer adjacent to the corresponding rendering command.

The CPU writes rendering commands and data sets to the command buffer . The command buffer can include a number of rendering commands and data sets. The CPU writes commands and data sets into the command buffer at the location determined by put pointer . Following each CPU write into the command buffer the CPU increments the put pointer to the next unused location in the command buffer . In an embodiment a driver software program executed by the CPU translates high level rendering commands from a rendering application into commands and data sets which are then written into the command buffer . In a further embodiment the driver software program receives high level rendering commands via an application programming interface for example DirectX or OpenGL .

The GPUs and read commands and data sets from the command buffer at a location determined by get pointers and . Following each GPU read from the command buffer the GPUs and increment the get pointers and to the location of the next command or data set in the command buffer . In one embodiment each GPU has a separate get pointer which is incremented. In other embodiments this pointer is shared and only one GPU increments the get counter following a GPU read.

The CPU and GPUs and can access the command buffer independently. In an embodiment the CPU periodically adds new commands and data sets to the command buffer . In embodiments with more than one CPU each CPU may add new commands and data sets to the command buffer . Simultaneously the GPUs and read processes commands and data sets previously stored by the CPU . Provided the CPU stays ahead of the GPUs and the GPUs and are able to render images without waiting for the CPU . In an embodiment the CPU writes commands and data sets for frames that are several frames ahead of the frame being rendered by the GPUs and e.g. 2 or 3 frames ahead.

In an embodiment of the present invention the command buffer is limited in size. As an example a typical command buffer may be five megabytes in size. When either the get pointers and or put pointer reaches the end of the command buffer the pointer is reset to the location of the beginning of the command buffer . In this manner the command buffer wraps around enabling the CPU and GPUs and to access the command buffer in a continuous loop.

In order to make full use of both GPUs and it may be desirable that each GPU render a unique set of geometries. The less overlap there is in their rendering workload the higher the efficiency of each GPU. Accordingly each GPU and may receive a unique set of geometries and corresponding rendering commands.

But this division of rendering commands has limited practicality and requires a great deal of overhead complexity to achieve. Some rendering commands contain information that is needed by all the GPUs in a system. For example a rendering command may contain state information regarding a change in the point of view referred to as camera position current color or texture current shader program or the like. If these updates are not received by each GPU the image will be incorrect. For example if a change in camera position is not received by each GPU the point of view for images or image portions rendered by different GPUs will vary leading to unfortunate results. Accordingly an embodiment of the present invention provides for a shared command buffer. Some embodiments provide for rendering commands to be received by each GPU in a system while eliminating or reducing unneeded or redundant rendering and 3 D pipeline tasks.

Where GPUs are communicably coupled to each other distributed rendering in various forms can be supported. For example in split frame rendering SFR GPU can render a top portion of an image while GPU renders a bottom portion of the same image. In alternate frame rendering AFR GPU can render a first frame in an image sequence while GPU renders a second frame and so on. In Z first distributed rendering GPU can populate a Z buffer and deliver the Z buffer data to GPU which uses the Z buffer data provided by GPU to determine which primitives to process in a fragment shader. Combinations of the above distributed rendering may also be used. The distribution of the commands to the GPUs differs depending on the form of distributed rendering used.

In the split frame rendering mode multiple GPUs operate in parallel to render different portions of an image for a display device. Each GPU renders pixel data for a different portion of the displayable image such as a number of lines of a raster based display. The image portions may correspond to horizontal bands vertical bands or other divisions as desired. Horizontal bands are usually chosen. The image is displayed by reading out the pixel data from each GPU s display buffer in an appropriate sequence.

To generate a displayable image consisting of M rows of pixel data the first GPU can be instructed to render rows 1 through P while the second GPU is instructed to render rows P 1 through M. Often to preserve internal consistency of the displayed image frame coherence each GPU is prevented from rendering a subsequent frame until the other GPU has also finished the current frame so that both portions of the displayed image are updated in the same scanout pass.

In general split frame parallel rendering schemes such as that illustrated by require GPUs to be programmed with a combination of common rendering commands which are executed by all of the GPUs of the system and specific rendering commands which are executed by a subset of the GPUs of the system. In the example of both GPUs are programmed with common rendering commands necessary to render all of the geometry and shading of the scene. The GPUs are then programmed with separate rendering commands to define clipping windows corresponding to image portions and .

Following the programming of GPU specific commands using commands sets and an SDM command with a device mask of 11 is used to enable simultaneous programming of all of the GPUs. Common rendering commands for rendering the scene are executed by all of the GPUs. Following the rendering of the separate portions of the output image an embodiment of the invention assembles these portions into a complete output image. Blit commands may be used to copy the portions rendered by GPU to the display memory of GPU . When more GPUs are involved blit commands may include a set of SDM commands to selectively program the other GPUs with different copy commands as each image portion is copied to a different location in the display memory of GPU . GPU may then output the assembled image to a display device. In blitless versions partial buffers are scanned out be each individual GPU and are combined by the GPU actually attached to the display.

Ideally the display area or screen is partitioned in such a way that each GPU requires an equal amount of time to render its portion clipping window of the image. If the rendering times are unequal a GPU that finishes its portion of the frame first will be idle wasting valuable computational resources. For example in a typical scene from a video game the foreground characters and or vehicles which are often complex objects rendered from a large number of primitives tend to appear near the bottom of the image while the top portion of the image is often occupied by a relatively static background that can be rendered from relatively few primitives and texture maps. When such an image is split into top and bottom halves the GPU that renders the top half will generally complete its portion of the image then wait for the other GPU to finish. To avoid this idle time the display area may be divided unequally with the top portion being larger than the bottom portion. In general the optimal division depends on the particular scene being rendered and may vary over time even within a single video game or other graphics application.

Load balancing may be performed by determining whether one of two graphics processors finishes rendering a frame last more often than the other. If one of the processors finishes last more often a portion of the processing burden e.g. a number of lines of pixels to render is shifted from that processor to the other processor. The comparison can be repeated and the load adjusted as often as desired.

The load balancing typically assumes that the GPUs are homogeneous i.e. the same type of processor by partitioning the image equally. Additionally the load balancing method works best when the GPUs are homogeneous as both GPUS will then react the same to rendering complicated objects. Load balancing may also be done by distributing whole frames to different GPUs via alternate frame rendering AFR . There are techniques where one GPU might render two frames in a row while the other works on a third however this creates issues of buffering up too many frames and latency of response issues.

Following rendering command set rendering command set programs the GPU 0 to render frame 2. This pattern of programming is repeated for all subsequent frames. In an alternate embodiment rendering command set programs a third GPU to render frame 2. In this embodiment frame 2 is rendered simultaneously with frames 0 and 1. This embodiment can be extended to accommodate any number of GPUs. The frames are usually divided equally among the GPUs which are typically homogeneous. However problems may arise when heterogeneous GPUs are used.

In accordance with embodiments of the present invention GPUs and may be heterogeneous meaning that their designs may be different in at least some respects. In one embodiment GPUs and are advantageously operable in a compatible mode in which they process the same commands and produce identical results regardless of any design differences that may exist as described in U.S. patent application Ser. No. 11 303 565 which is incorporated herein by reference. The compatible mode may be used to support distributed rendering. Heterogeneous GPUs may particularly occur when one GPU is integrated IGPU onto a motherboard and the other GPU resides in on an add on card as a discrete graphics processor DGPU . However heterogeneous GPUs may also occur when different GPUs reside on different add on cards each as discrete graphics processors DGPUs . Heterogeneous often will have different processing capabilities which may be measured in triangles per second.

In one embodiment SPP includes an IGPU which may instead be included in MCP . An IGPU may also be a separate chip on the same motherboard as SPP and MCP . IGPU and MCP are commonly referred to as a chipset. The memory is often a number of dynamic random access memory devices arranged in a number of the dual in line memory modules DIMMs .

CPU connects to IGPU over the host bus . IGPU is in communication with the DGPU over a PCIE PCI express bus . IGPU reads and writes data to and from the system memory over the memory bus . The MCP communicates with the IGPU via a high speed connection such as a HyperTransport bus and connects network and internal and peripheral devices to the remainder of the computer system. DGPU receives data over the PCIE bus and generates graphic and video images for display over a monitor or other display device not shown . IGPU can also generate graphic and video images for display over a monitor.

A frame buffer local or graphics memory is also included but shown by dashed lines. The dashed lines indicate that frame buffer may be located as a separate off chip memory from DGPU an on chip memory and or part of a system memory as frame buffer . On chip memory may be referred to as a buffered fast response RAM or BFR. In one embodiment following system power up or reset the DGPU initially renders comparatively low resolution images to the BFR for display. Afterward the GPU renders images which are typically higher resolution and stores them in a system memory e.g. in frame buffer . BFR which is no longer needed for image storage instead stores address information referred to as page tables identifying the location of data stored by the DGPU in the system memory as described in embodiments of U.S. patent application Ser. No. 11 253 438.

Typically a DGPU will render image frames faster than an IGPU. In one embodiment a DGPU may render an image 4 times faster than an IGPU. Thus when parallel rendering with the DGPU and the IGPU is attempted problems with efficiency may ensue e.g. the DGPU may be idle for significant amounts of time. In fact the performance may even be slower than the DGPU executing by itself.

For example to perform alternate frame rendering in a given cycle a DGPU would need to render a four images while the IGPU would need to render the fifth image with a similar sequence following for other cycles. This high number of images to be rendered in parallel can be costly as many images need to be buffered and can cause latency problems for user response. Also the IGPU may need information from previous frames and thus it may take significant time before rendering the fifth image can even begin causing the DGPU to sit idle while waiting for the IGPU to finish.

For performing split frame rendering the partition of an image into equivalent workloads may be difficult. Based on the example above the DGPU would get roughly 80 of an image and the IGPU would get roughly 20 . However that 20 of the image may include a lot of complexity and thus the relative workload may vary drastically from one image to another. Thus heterogeneous GPUs prove difficult to efficiently perform distributed rendering. Another issue is that the iGPU must perform all the geometry calculations in order to figure out if it is responsible for the corresponding raster work. Since SFR only scales pixel work a weak iGPU could completely limit the performance of the system if it is too slow at processing geometry. To this end embodiments of the present invention provide efficient distribution of a rendering workload to two or more heterogeneous GPUs. Embodiments may be useful for homogeneous GPUs as well e.g. when for SFR it is hard to find partitions of a frame that take equal times to render.

To overcome the limitations of AFR and SFR embodiments of the present invention switch execution of the commands for a frame from one GPU to another GPU at changing points within the command buffer. Splitting the workload of rendering an image based on the commands in a command buffer provides greater efficiency than a distribution that is based solely on the images themselves. Particularly when it is known that one GPU is slower than another one the switching may take place an optimal position within the command buffer.

In step the DGPU begins rendering frame 0. In one embodiment this rendering of frame 0 starts from the beginning of the commands for frame 0 e.g. at the beginning of a first command buffer. In step IGPU begins rendering frame 1. At least part of this rendering of frame 1 occurs while the DGPU is rendering frame 0.

In step the DGPU finishes rendering frame 0. In step the IGPU receives notification that the DGPU is available. The determination of availability may be made by the DGPU a CPU or another processor in the system. In one aspect DGPU communicates directly to the IGPU that it has finished rendering the previous frame i.e. frame 0. In step the IGPU passes control for rendering its current frame frame 1 to the DGPU. In one embodiment this is done by passing a get pointer from the IGPU to the DGPU. In another embodiment it could also be done by estimating how the work load would be split and letting each GPU finish its estimated portion. The portions sizes could be adjusted to achieve a good balance.

In step the DGPU takes over rendering frame 1. In one embodiment DGPU begins rendering frame 1 at a command that occurs immediately after the last command that the IGPU had executed. In another embodiment the DGPU takes over rendering frame 1 at a convenient location in the command buffer that occurs before the last command that IGPU had executed. For example the convenient location may be any one of a number of predetermined locations containing all of the state data required for rendering from that location forward as is described later. In yet another embodiment the IGPU and the DGPU both process all state commands but only process graphics operations for their respective parts of the command buffer.

In step the IGPU begins rendering a subsequent frame frame 2 after it has passed control of rendering its current frame frame 1 to the DGPU. Thus the DGPU is rendering frame 1 in parallel with the IGPU rendering frame 2. In step the DGPU finishes rendering frame 1. In step the IGPU receives notification that the DGPU is available to render frame 2. In step the IGPU passes control for rendering frame 2 to the DGPU. In step the DGPU takes over rendering frame 2. This process may continue for additional frames. In the very unlikely event that the IGPU would finish rendering a frame before the DGPU is available the IGPU can move on to start rendering the subsequent frame or wait for the DGPU to finish the previous frame.

At a time T1 the DGPU finishes rendering frame 0. Based on the DGPU finishing rendering frame 0 the IGPU changes from executing commands for its current frame frame 1 to executing commands for the subsequent frame frame 2 during time period . After finishing rendering frame 0 the DGPU then finishes rendering frame 1 during time period . Thus there is a switching of an execution of commands for frame 1 from the IGPU to the DGPU based on the DGPU completing the rendering frame 0. In another embodiment DGPU may remain idle until the IGPU reaches time T2. Thus rendering would start with frame 1. In this embodiment T2 may be determined by a specific percentage e.g. 20 of commands for frame 1 being executed by the IGPU. Thus in one embodiment the finishing of one frame and beginning rendering another frame happen sequentially.

In another embodiment at a time T3 the DGPU finishes rendering frame 1. Then DGPU begins reading processing state data for frame 2 during time period . After the DGPU reads sufficient state data T5 it then finishes rendering frame 2 during the time period . Based on the DGPU reading state data to match the position of the IGPU the IGPU changes from executing commands for its current frame frame 2 to only reading state data from frame 2 during time period . After finishing processing only the rest of the state data T6 the IGPU begins executing all commands for the subsequent frame frame 3 during time period . In this manner even though the time periods for rendering different frames may vary neither the DGPU nor the IGPU are waiting for significant time periods for the other processor to complete the rendering of a frame.

In one embodiment the time that the IGPU changes rendering a current frame to a subsequent frame may occur immediately after the DGPU finishes rendering a previous frame. In another embodiment there may be some lag time for the IGPU to change frames it is rendering and thus the DGPU may also be slightly delayed in starting to render the current frame. In yet another embodiment a pre indication of the DGPU being available soon may be sent to the IGPU and thus the IGPU may change rendering frames prior to the DGPU finishing rendering a previous frame. Regardless of when the switch happens the switching is based on the DGPU finishing rendering a previous frame whether the switch is just before simultaneous or just after the DGPU finishing rendering a previous frame.

A command arrow shows that once the DGPU finishes rendering frame 0 that it takes over the rendering of frame 1 from the IGPU. Command arrow signifies that the IGPU then begins rendering frame 2. Command arrow signifies that once the DGPU finishes rendering frame 1 that it again takes over rendering of the frame that the IGPU is currently rendering in this case frame 2. Note that the size of the respective areas for the IGPU and the DGPU varies between frame 1 and frame 2.

A command arrow shows that once the DGPU 0 reaches a designated point of the command buffer of frame 0 that it switches to rendering frame 1. A command arrow shows that once DGPU 1 finishes rendering frame 0 that it takes over the rendering of frame 1 from DGPU 0 and similarly for command arrows and .

In one embodiment where there are more than two DGPUs a combination of AFR and split command buffer rendering may be implemented. illustrates the distribution of the rendering workload among command buffers for multiple frames using four GPUs according to an embodiment of the present invention. In a similar fashion to DGPU 0 and DGPU 1 split the execution of command buffers however they now split command buffers for frames 0 2 and 4 and other even numbered additional frames. Command arrows signify the switches in the execution of the command buffers.

As to the odd numbered frames a command buffer for frame 1 is split between a DGPU 2 and DGPU 3. Once DGPU 2 reaches a designated point while rendering frame 1 then DGPU 2 begins rendering frame 3 as signified by command arrow . Once DGPU 3 finishes rendering frame 1 it takes over rendering frame 3 from DGPU 2 as signified by command arrow . In one embodiment DGPU 0 and DGPU 2 are the same type of processor which is slower than DGPU 1 and DGPU 3 which are both a type of a second processor.

As the control of executing commands of a frame switches the new GPU may need to be aware of the current state of a switch and or any state changes that occur before the switch. Thus in one embodiment the DGPU reads all of the information in the command buffer including commands and data that occur before the location that the IGPU stopped rendering the current frame but the DGPU does draws nothing until it reaches the hand off point. Similarly the IGPU may scan the entire command buffer following the hand off point in order to correctly track state information up to the beginning of the next frame which it is moving to start rendering.

In another embodiment the DGPU only reads the data information. However this time for reading the commands and or the data appearing before the switch may consume a lot of time. Accordingly embodiments of the present invention save complete state data i.e. all of the state data required for rendering from that point forward at periodic handoff locations.

In embodiments where more than one CPU writes commands to command buffer different CPUs may write to different sections of command buffer . For example the commands of a section may be written by CPU 0. At a section break area CPU 0 writes data that encapsulates the present state. The commands of the next section may be written by CPU 1 which writes the current state data in a defined section break area. At least parts of section and may be written in parallel with each other. In this manner command buffer may be written more quickly.

In another embodiment the DGPU also finishes rendering a command buffer for a previous frame when the IGPU has executed only part of the commands for a section e.g. section of the current command buffer . The IGPU is allowed to finish rendering the current section . The DGPU then starts to render command buffer at the beginning of the next section e.g. by reading the state data stored at the beginning of section or a section break area between section and the previous section.

Embodiments of the present invention can be implemented in the form of control logic in software or hardware or a combination of both. For example the control logic may be stored in an information storage medium as a plurality of instructions adapted to direct an information processing device to perform a set of steps disclosed in embodiment of the present invention or may be stored in a computer program product including a computer readable medium encoded with program code for controlling operation of a computer system.

The above description of exemplary embodiments of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form described and many modifications and variations are possible in light of the teaching above. The embodiments were chosen and described in order to best explain the principles of the invention and its practical applications to thereby enable others skilled in the art to best utilize the invention in various embodiments and with various modifications as are suited to the particular use contemplated.

