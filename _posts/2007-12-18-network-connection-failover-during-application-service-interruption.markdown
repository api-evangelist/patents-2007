---

title: Network connection failover during application service interruption
abstract: A system, method and computer program product for implementing network connection failover during application service interruption. While the application is quiesced, a network socket that terminates a network connection to a network peer is maintained on behalf of the application. The socket's network connection state information is sustained by providing acknowledgements of incoming network traffic to the network peer that prevent the peer from terminating the connection. Upon restart, the application is brought up with a blocked socket. The state of the blocked socket is conformed to a current network connection state of the original socket and the blocked socket is unblocked.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09473598&OS=09473598&RS=09473598
owner: International Business Machines Corporation
number: 09473598
owner_city: Armonk
owner_country: US
publication_date: 20071218
---
The present invention relates to the management of connections between end points in a network. More particularly the invention is directed to maintaining a network connection when one network end point experiences a planned service interruption such as during transfer of an application that implements the end point from one network system to another as part of a software migration operation.

By way of background it is sometimes necessary to temporarily disable a software application while the application is engaged in network communication at one endpoint of a network connection. By way of example such an interruption could occur when the application is migrated from one network system to another for load balancing or other reasons. During the period of interruption it may be desirable to maintain the application s network connection even though the application is unable to process network data. This would be the case for example if the application was involved in a complex transaction with a network peer and the transaction state would be lost if the network connection was terminated.

Techniques have been proposed whereby a live TCP Transmission Control Protocol or UDP User Datagram Protocol connection can be passed from one machine to another without connection loss. Such techniques have included solutions such as 1 offloading the application s network protocol processing to a front end communication entity 2 having a takeover node continuously snoop the connection and thereby mirror the application s network protocol processing 3 isolating the network connection so that no packets are received or sent 4 placing the network peer in a persist mode and having a remote home agent assume responsibility for the connection or 5 modifying the TCP protocol at both network connection endpoints to support temporary connection inactivity. The first two solutions have the disadvantage of requiring duplicative processing resources to monitor the network connection. The third solution runs the risk that the network peer will drop the connection if the interruption takes longer than the peer s view of retransmission time and the number of transmissions that are allowed before the connection is terminated. The fourth solution requires a separate machine to assume connection responsibility. The fifth solution requires modification to the network stacks of both endpoints.

It would be desirable to provide an alternative technique whereby an application s network connection can be maintained during a temporary cessation of application processing activity. What is particularly needed is a solution that accomplishes the foregoing without the attendant disadvantages noted above.

The foregoing problems are solved and an advance in the art is obtained by a system method and computer program product for implementing network connection failover during application service interruption. While the application is quiesced a network socket that terminates a network connection to a network peer is maintained on behalf of the application. The network connection is sustained by providing acknowledgements of incoming network traffic to the network peer that prevent the peer from terminating the connection. Upon restart the application is brought up with a blocked socket. The state of the blocked socket is conformed to a current network connection state of the original socket and the socket is unblocked.

According to exemplary disclosed embodiments the application may be disposed in a virtual application environment and the service interruption may be due to the application being quiesced as part of an application migration operation wherein the virtual application environment is migrated from a source machine to a target machine. In this environment the source socket may be maintained by a connection manager that resides on the target machine. Alternatively there could be two connection managers. One connection manager could be a source connection manager residing on the source machine or an intermediary machine. The other connection manager could be a target network connection manager on the target machine. The target connection manager may be used to conform the state of the blocked socket to the current network connection state of the original socket that is maintained by the source connection manager and unblock the blocked socket. The virtual application may or may not include an operating system that contains the network socket. If it does the source connection manager may be distributed between a first source connection manager part residing in the virtual application environment on the source machine and a second source connection manager part residing outside the virtual application environment and further wherein the target connection manager resides in the virtual application environment on the target machine. During the period that the application is out of service the network connection may be sustained by the transport layer of the network protocol stack associated with the original socket maintained by the source connection manager. The network connection may be sustained in part by reducing a window size associated with the connection manager socket in accordance with data received from the network peer. Eventually the network peer may enter a persist state. This state along with other transport layer states can be easily sustained by acknowledging future packets sent by the peer. The network connection state information used to conform the blocked socket may include one or more of 4 tuple source and destination addresses port numbers TCP flags Selective ACKnowledgement SACK options data an Initial Send Sequence number ISS current sequence and acknowledgement numbers a current state of a receive buffer and transmitted but unacknowledged data.

The invention will now be described by way of exemplary embodiments shown by the drawing figures in which like reference numerals indicate like elements in all of the several views.

Turning to a data processing system that may be used to implement network connection failover in accordance with the present disclosure includes a hardware platform and an operating system that manage resources provided by the hardware platform on behalf of one or more application programs applications . The operating system is assumed for purposes of illustration only and not by way of limitation to provide virtual application environments and that in turn support respective applications and . Each application and may comprise one or more application processes threads or other execution contexts. As will be seen below in connection with operating systems that do not support virtual application environments may also be used to implement network connection failover in accordance with the present disclosure.

The hardware platform may be implemented using any known data processing equipment that is capable of supporting execution of the operating system including the exemplary data processing hardware described below in connection with . The operating system may be implemented using any conventional operating system software capable of optionally supporting the virtual application environments and with appropriate modifications being made thereto to provide network connection failover as disclosed herein. This type of virtualization is known as operating system level virtualization. In operating system level virtualization virtual application environments are sometimes referred to as containers. As will be seen in the discussion of below an alternative form of virtualization may also be used in which multiple operating systems which do not require support for application containers run on a virtual machine monitor or hypervisor. 

Examples of operating systems that have application container support capability include the IBM AIX 6 operating system with WPAR Workload PARtition support IBM Meiosys virtualization products and Linux operating system kernels built in accordance with the OpenVZ project the VServer project or the Free VPS project. These operating systems have the ability to selectively allocate physical and logical resources to their containers virtual application environments . Such resource allocations may include CPU time memory I O Input Output ports network devices disk partitions etc. Depending on the particular virtualization implementation being used each virtual application environment may have its own process tree file system directory tree users and groups system libraries network addresses disk space etc. Thus residing within the container are all of the application s core executable and binary code files representing everything needed by the application to operate. Only nonessentials such as configuration settings and user data are maintained outside the container. The system resources file system and networking are virtualized. To the applications within the containers and to users of the applications each container appears like an independent operating system instance i.e. as a virtual machine. The applications and users within a container cannot see outside the container. Typically there is also a container used by a privileged root user that can view the contents of all the other containers. This is sometimes referred to as the global container or context. Note that the reference to the above named technologies is not intended to suggest that the network connection failover techniques disclosed herein are limited to particular product offerings.

With respect to the applications and it should be understood that the term application as used herein refers to the performance of a particular function and rather than to signify separate software that is distinct from an operating system. Although an application will in many cases be a distinct software program in other cases an application may consist of little or no code that could be considered separate from the operating system itself. For example if one of the virtual application environments and is configured as a firewall appliance almost all of the processing will take place in kernel mode.

The system provides an environment in which each of the applications and and their workloads can be readily transferred from one point of use to another. This is particularly advantageous for server systems wherein workloads need to be balanced between multiple servers. The virtual application environments and make this possible by acting as mediators between the applications and and the underlying operating system . Whereas it is not normally possible to transfer a live application without losing its state this can be done in an operating system level virtualization environment by migrating the virtual application environments and that contain the applications and . This type of migration involves a conventional technique known as checkpointing and is handled by conventional migration management logic. As is well known to persons skilled in the art checkpointing entails capturing an application s running state and memory footprint and saving it to disk so that it can be recovered later using an operation known as a restart. Application migration entails checkpointing an application on a source system and restarting the application on a target system. Virtual application environments facilitate the migration process by eliminating application dependencies in such areas as mail settings network addresses libraries and the like such that the containerized applications are not aware that they are being hosted by a different system.

Unfortunately using conventional virtual application environment migration techniques to perform the foregoing migration raises the problem of network connection failover discussed by way of background above. As such a mechanism is needed to prevent network connections from being dropped during the period in which an application within a migrating virtual application environment is not able to process network communications because the application is temporarily out of service. The problem is that the remote network peer may reset the connection if the failover takes too much time. This could be the case if the remote system has short keepalive or retransmission timeouts. This issue may be exacerbated if the application restart on target machine takes time. Such delay could be due to a need to suspend the workload on the target the handling of operating system upgrades or more important jobs or a large number of connections having to be resurrected as part of the transfer.

This problem can be solved by a connection manager described in more detail below that acts as a temporary intermediary between the migrating application and a network peer that is communicating with the application via a network connection. During application migration the connection manager keeps the network connection alive by assuming control of the network socket owned by the application and representing the application s network connection endpoint thereby keeping the socket alive and allowing the transport protocol e.g. TCP layer of the underlying network stack to continue to manage the network connection. In a connection oriented windowing protocol such as TCP incoming data is accepted and buffered while the transport layer simultaneously closes the window as per the data. Eventually in the case of TCP the remote client may enter a persist state. This state along with other TCP states is easily sustained by virtue of the transport layer logic acknowledging future packets sent by the network peer.

On the source machine the application communicates with the peer via a source socket a source network stack A and a source network interface B. Before migration the source socket is owned by the application due to the application having established the source socket and by maintaining a file descriptor thereto that the application uses to pass data to and from the peer using conventional socket read write operations. After the application has been migrated to the target machine and network connection failover has completed the application communicates with the peer via a target socket a target network stack A and a target network interface B. Following migration the application owns the target socket by maintaining a file descriptor thereto that the application use to pass data to and from the peer using conventional socket read write operations.

As described in more detail in connection with the connection managers and function to cache the state of the migrating application s network connection during the period that the application remains quiescent due to the migration. The source connection manager also takes over operation of the source network socket allowing the transport protocol layer of the source network stack A to continue managing the network connection. The target connection manager is responsible for setting up the application s network connection on the target machine . Its functions include receiving the network connection state information from the source connection manager updating the network stack A on the target machine and activating the target socket following successful migration.

In block of application checkpointing and migration is initiated by the migration management logic . As is known in the art this conventional operation may be initiated by having the migration management logic start trapping calls from the application then saving the application s in memory state e.g. to permanent storage so that the saved application state information can be later redeployed on the target machine . In block the migration management logic requests the source connection manager to assume control of the source socket and maintain it. The source connection manager may implement a suitable API Application Programming Interface that the migration management logic may use to initiate the socket control transfer.

The socket control transfer will allow the source connection manager to access all or a portion of the TCP state information C as will be required to later pass the network connection state information to the target connection manager following the application migration. The TCP state information may include but is not limited to the 4 tuple source and destination addresses and port numbers various TCP flags such as the TCP window size the window scaling option if any Selective ACKnowledgement SACK options data if any the Initial Send Sequence number ISS the current sequence and acknowledgement numbers the current state of the receive buffer C and transmitted but unacknowledged data C . Note that the actual buffer contents are not required insofar as the source connection manager is only required to keep the connection alive and maintained not to process the application s network data.

During application checkpointing and migration the source socket is no longer be readable by the application and the socket s buffering may be reduced by the source connection manager to the actual window size. The local IP address will be visible to the root context of the application environment but no other application can use or access it. One exemplary mechanism for transferring control of the source socket to the source connection manager will now be described. When the application is checkpointed the virtual application environment will be stopped frozen by the migration management logic using a conventional technique such as the checkpointing operation performed by operating system level virtualization systems described above including IBM Meiosys virtualization products. Instead of deleting the socket descriptor used by the application to access the source socket which would ordinarily result in destruction of the socket s kernel data structures the source connection manager is informed by the migration management logic of the source socket . In particular as part of block of the migration management logic provides the source connection manager with the source socket s 5 tuple information consisting of the source and destination address and port numbers and the protocol. This information is used by socket descriptor TCP state receive logic A of the source connection manager to access the source socket and open a duplicate file descriptor to the socket. This socket access operation which is part of block of may be handled in a variety of ways. For example the logic A may include a user space component that makes a system call to a kernel module component of the logic A or other operating system code that provides a special system call handler. The system call parameters pass some or all of the 5 tuple information for the source socket . The system call handler uses this parameter information to determine the identity of the source socket and set a flag that enables the creation of a duplicate file descriptor so that a new application the source connection manager may access the socket. This will allow the source socket to be kept open and maintained by the source connection manager while its logic A keeps track of the source socket state e.g. whether it is active or quiesced using conventionally available query mechanisms.

The flag that allows the source connection manager to access the source socket could be a special purpose flag that allows one socket to be opened by several applications. This flag could thus be modeled on the conventional SO REUSEPORT flag that allows multiple applications to bind to the same port. In such a case the source connection manager may open the source socket with the special flag specified and will obtain a duplicate socket file descriptor. One issue relative to using such a flag is that it might allow other applications or another instance of the same application to also open the source socket . Therefore a socket flag with similar features but higher security could be created as an alternative. By way of example the flag may signify that only a root user in the global context of the virtual application environment or a user with special security privileges can open a socket marked with this flag. Another option would be to create a special system call that takes the socket s 5 tuple information and returns a duplicate socket linked to the existing socket infrastructure.

If desired the source connection manager may also be provided in block of with an identifier container ID that identifies the virtual application environment . At the time the source connection manager is requested to accept the source socket the migration management logic may calculate a hash based on a timestamp the source socket 5 tuple and the container ID or other suitable elements . This hash may be saved by the migration management logic in the checkpoint image and also provided to the source connection manager . As described in more detail below the hash may be used to authenticate a subsequent request for connection state migration from the source connection manager to the target connection manager .

Returning now to as a further part of block the source connection manager assumes responsibility for the connection associated with the source socket i.e. the connection between the source socket and the peer but is not itself required to perform any network processing. Instead the source connection manager allows the transport layer C of the source network stack A to sustain the network connection by performing its normal TCP functions. These functions include accepting all data that is received from the remote network peer and using the TCP state responding with an acknowledgement ACK while reducing the TCP window size in accordance with the data accepted into the TCP receive buffer . Thus the peer is not forced to retransmit and retry or in a worse case drop the connection. If the TCP window fills up the peer can be given a zero sized window thereby sending it into a persist state. This state does not timeout and the peer will periodically send persist probes that can be responded to by ACK responses generated by the transport layer C. If the peer sends a keepalive probe an ACK response can be sent to keep the connection alive. If the connection is closed by the peer the connection can be maintained in the TCP CLOSE WAIT state until the application is restarted and an ACK response is sent to close the connection. As indicated above the foregoing processing is performed automatically by the transport layer C of the source network stack A. The source connection manager does not need to be involved in this processing or any other aspect of sustaining the application s network connection to the peer other than ensuring that the source socket is maintained.

The virtual application environment will normally be kept in a suspended state until there is successful migration of the application and its network connection state information to target machine . However the source network stack A is not quiesced and continues to accept packets at the local IP address of the source socket . If for some reason the virtual application environment is terminated before the successful migration is complete then the source network stack A must be kept alive. This may be accomplished by ensuring that the network interface B to which the source socket s local IP address is associated is not deactivated e.g. by disabling its driver . The interface B may be a virtual interface used by the virtual application environment or a real interface to which the socket s local IP address is associated in the virtual application environment s global context.

The migration of the application from the source machine to the target machine is handled by the migration management logic in conventional fashion. Once the migration of the virtual application environment to the target machine has been completed the application is ready to be restarted and the TCP connection is ready to be migrated from the source connection manager to the target connection manager . illustrates exemplary logic within the target connection manager that is involved in this second portion of the network connection failover operations of . also illustrates the target socket and the transport layer C of the target network stack A. The transport layer C maintains TCP state information C as well as a receive buffer C for incoming packets and transmitted but unacknowledged data C for outgoing packets all of which is conventional. The lower layers of the source network protocol stack are shown by reference numeral D and are also conventional.

In block of the migration management logic restarts the application on the target machine with the target socket in a blocked state. Note that bringing up an application s socket s in a blocked state is normally part of conventional application migration and means that the socket data structures and socket descriptor s are recreated from the application s checkpoint information and each socket is recreated with the 5 tuple consisting of the local and peer IP addresses the local and peer port numbers and the protocol. Transfer of the network address and port information from the source machine to the target machine can be handled in conventional fashion by the migration management logic . At this point however the local IP address of the blocked target socket is not yet associated with the network interface B on the target machine . Therefore no packets are received at the blocked target socket . Note that the local IP address port number of the blocked target socket will be the original local IP address port number associated with the source socket on the source machine . The local IP address port number information is assigned to the blocked target socket as part of the application migration process.

In block of the migration management logic requests the target connection manager via an appropriate API built in to the connection manager to migrate the connection state information from the source connection manager . The migration management logic may provide the target connection manager with the hash value that was recorded at the time of checkpointing the application . Alternatively the migration management logic could request the source connection manager to push the connection state information to the target connection manager . In block of connection state migration logic A in the target connection manager issues a network request to the source connection manager to initiate the migration of connection state information for the source socket . The destination IP address used for the migration request is an address in the global context of the virtual application environment on the source machine . Connection state migration logic B in source connection manager maintains a network service listening port for receiving the migration request. The target connection manager may identify this service port using any of various known mechanisms. Alternatively the listening port could be assigned to a well known port number. In block of the source connection manager after authenticating the hash sends its current connection state information this includes but is not limited to the TCP state window size etc. to the target connection manager . Once the target connection manager has acquired the connection state information its target socket setup logic B updates the network connection state of the blocked target socket as shown in block of . This entails the target connection manager updating the relevant socket data structures of the target network protocol stack A with the connection state information to conform the network connection state of the blocked target socket to the current state of the source socket .

The target connection manager may also use a system call e.g. the same as that used by the source connection manager for setting a flag on the target socket that allows the target socket to be accessed via a duplicate file descriptor. The target connection manager may then use the duplicate file descriptor to access the target socket using an input output control command e.g. a Linux ioctl command to update the socket state. If desired special capability or credential checking may be put in place to ensure that no other application is able to update the target socket state. Another condition that may be enforced is that the target socket state can be updated only as long as is not associated with an active IP address the IP address is not yet bound to a local interface .

In block of the migration logic removes the local IP address from the source machine e.g. upon request from the target connection manager . In block of the source and target connection managers and reiterate on the connection state migration of block to ensure nothing was missed or changed during the short time between the initial connection state migration and the source IP address being removed. This operation may not be needed if the source socket was in a persist state or one of the protocol close states in which no additional data can transfer or no state changes can occur with respect to the source socket. Under these conditions there will be no new state information that needs to be transferred to the target migration manager .

The migration management logic then adds the local IP address of the target socket to the target network interface B in block of . It may also optionally send out a gratuitous ARP Address Resolution Protocol request to update the ARP cache of the remote peer and other network peers with the MAC Media Access Control address of the target network interface B. In some networks gratuitous ARP requests are ignored. In such a network the virtual application environment may be created on the target machine with a locally administered MAC address being associated therewith. This MAC address may be created using an agreed upon rule and in this way may be associated with the new network endpoint. At this point the target connection manager may close its handle to the target socket . However the target socket is kept open by the migrated application which has its own socket file descriptor.

At this stage the blocked target socket has the correct network connection state and is associated with the proper IP address in order to receive and send data. The migration management logic is informed of this status and it enables the application . The target connection manager then removes the block on the target socket in block of . Unblocking the socket on the target machine entails the target connection manager inserting the local IP address and port number for the target socket into kernel routing and TCP lookup tables. Once this happens new packets received or sent will be correctly processed. Note that if the migration operation fails the application may be restarted on the source machine . Its IP address will then be reenabled and source socket can be reattached. The source connection manager may be quiesced once it is no longer required by the migration operation.

It should be noted that the ordering of the foregoing processing could be changed so that the connection to the peer is migrated immediately after the application is checkpointed and before it is restarted on the target machine . Instead of waiting for the checkpointed application to be restarted at on the target machine as per block of the IP address and connection transfer of blocks could be initiated as soon as the application is blocked during the checkpoint operation. In lieu of block of being implemented prior to the connection migration the target connection manager would create the target socket migrate the connection per blocks of and then update the socket s kernel structures per block of . The IP address and port number of the source socket would then be removed from the source machine and associated with the target machine per blocks and of . As per block of the target connection manager would also update the TCP lookup and routing tables so that the target socket becomes operational. The TCP state of the target socket would thus be valid when the application is restarted on the target machine . The application restart logic implemented by the migration management logic would find that the target socket already exists. Optionally it may verify that the connection is the same connection that existed on the source machine using the hash stored by the migration management logic in the checkpoint image. The target connection manager may then close its handle to the target socket .

Turning now to an alternative data processing system is shown to illustrate that the network connection failover technique disclosed herein is not limited to operating system level virtualization of the type shown in . Rather the concepts disclosed herein are applicable to any virtual environment. The data processing system represents one such alternative environment wherein a hardware platform runs a virtual machine monitor VMM also known as a hypervisor. The VMM supports multiple operating system instances such as operating systems and each of which operates in a virtual machine environment and created by the VMM. These virtual machines represent an alternative form of virtual application environment that respectively supports applications and but also includes the operating systems and . Application migration in the environment of involves moving an entire virtual machine including its operating system.

As is well known a VMM is a conventional low level software service that virtualizes the underlying hardware to provide a subset of the CPU memory and I O resources i.e. a virtual machine on behalf of higher level operating system guests. The VMM may be implemented according to any of the VMM design concepts that have been in use since hypervisors were first developed in the late 1960s taking into account the VM support capabilities of the underlying hardware . Existing examples of commercial hypervisors include the CP Control Program used in the IBM VM 370 mainframe product introduced by International Business Machines Corporation in 1972 the current zVM hypervisor used in the IBM zSeries mainframe product and the hypervisor used in the IBM pSeries and iSeries PowerPC products. A Linux kernel compiled to support the Xen Domain 0 virtual machine monitor and one or more Xen Domain 1 Domain 2 . . . Domain n virtual machines is another example. Other open source virtualization solutions supported by recent Linux kernels such as Qemu and KVM Kernel based Virtual Machine could potentially also be used. Note that the reference to the foregoing technologies is not intended to suggest that the invention is limited to particular product offerings.

The processing used to implement network connection failover in the data processing system is analogous to the failover technique used for the data processing system of . However the global context of the virtual application environments and is the VMM . As such the connection managers could be implemented in whole or in part within the VMMs of source and target machines or within virtual machines supported by such VMMs see below . Conventional techniques are available to migrate VMMs from one machine to another including those implemented by the VMM products described above. Virtual Machines can be quiesced and saved as files that are easily transferred from one machine to another. The migration management logic that implements this operation in the VMM environment of would be analogous to the migration management logic described above.

For example when migrating a virtual application environment that includes an operating system the migration management logic may suspend the source virtual application environment then copy its memory image e.g. as a file and restart it on the target machine. An alternative technique is to first copy the virtual application environment image to the target machine and then copy over the memory pages that have been dirtied since the initial transfer. This process may continue with the source virtual application environment continuing to execute until there is a small set of dirty pages or none . At that point the target virtual application environment is synchronized with the source virtual application environment. The source virtual application environment is then be suspended and the target virtual application environment is be started. At the end of this process the IP address of the source virtual application environment is transferred to the target machine linked to the target virtual application environment and the migration is complete.

In the first scheme which may be referred to as suspend and migrate the source virtual application environment s network connection might be lost when that environment is suspended and before the target virtual application environment is started. In the second scheme which may be referred to as live migration the network connection could be lost during the migration process and prior to startup of the target virtual application environment. Even if the connection is not lost the synchronization of the source and target machines and or the target virtual application start could take a long time. This situation could arise if there is a significant amount of network traffic and related activity such that the source virtual application environment does not converge to a small set of dirty pages as a result.

In both the foregoing cases the connection transfer technique described herein may be used to transfer the network connection. For the suspend and migrate case the technique disclosed herein will prevent the peer from dropping the connection following suspension on the source machine and prior to restart on the target machine. For the live migration case the disclosed technique will allow the source machine version of the virtual application environment to rapidly quiesce its network state because responsibility for its network connection s will be taken over by a connection manager. The source and target versions of the virtual application environment may thus be quickly synchronized thereby speeding up the migration operation.

In the context of the data processing system of the source and target connection managers could be essentially the same as any of the source and target connection managers described above except that the operations of the source connection manager would be distributed between the source virtual application environment being migrated e.g. and either the VMM or a separate virtual application environment e.g. that could perhaps be dedicated to network connection migration support for other virtual application environments.

After the system call returns the socket state information the source connection manager part A transfers this information to the source connection manager part B as per block B of . The information transfer may utilize a conventional communication mechanism such as a virtual network communication pathway or other communication mechanism supported by the underlying VMM e.g. hypersockets on IBM System zSeries systems . If no special mechanism exists a local network IP address may be assigned to a network interface associated with the virtual application environment over which this domain can communicate with VMM or virtual machine domain containing the source connection manager part B. In block C the source connection manager part B assumes control of the original source socket A by making a copy thereof B using the TCP state information provided by the source connection manager part A. This operation may be implemented by way of an input output control command e.g. a Linux ioctl command to update the socket state. The source manager part B would create the source socket copy B and invoke the input output command to populate the socket data structures with the socket data for the original source socket A. The source connection manager part B may be implemented as a user space application that uses a conventional operating system call to create the socket.

In block D the source connection manger part A requests the operating system of the virtual application environment to send an acknowledgement of received but unacknowledged packets and suspend the original source socket A. The suspension request to the operating system of the virtual application environment may be implemented in block D as a system call that is invoked by the source connection manager part A. This could be part of the socket data gathering system call described above or a separate system call. In block E the source connection manager part B transfers the network connection to the source socket copy B it has created and activates the socket. Block E may be implemented by the operating system of the source connection manager part B acquiring the IP address of the network connection and then unblocking the source socket copy B. The source connection manager part B thereby assumes control of the original source socket A by way of its copy B and relies on operating system transport layer services to maintain the network connection to the peer as described above.

The virtual application environment may now be suspended. Upon restart on the target machine per block of the networking of the virtual application environment will be initially suspended. The target connection manager is invoked by the migration management logic per block and it contacts the source connection manager part B to initiate connection migration per block . Blocks are then performed as per blocks of and the target connection manager may terminate.

Accordingly a mechanism for handling network connection failover during application service interruption has been disclosed. It will be appreciated that the foregoing concepts may be variously embodied in any of a data processing system a machine implemented method and a computer program product in which programming logic is provided by one or more machine readable media for use in controlling a data processing system to perform the required functions. Relative to a data processing system and machine implemented method illustrates an exemplary hardware environment in which the various data processing systems and machines heretofore described may be implemented. The hardware environment includes one or more of a CPU or other data processing resource a physical memory an optional graphics card for generating visual output to an optional monitor not shown a peripheral storage device other peripheral devices and a bus infrastructure interconnecting the foregoing elements. The various virtual application environments described above as well as the supporting global contexts migration managers connection managers and networking logic may be implemented as software loaded in the memory for execution on the data processing resource . They could also be implemented using hardware logic or firmware in the environment . If a user interface is provided it may be accessed through user interaction with the peripheral devices e.g. keyboard mouse etc. .

Relative to a computer program product having a machine readable media and programming logic for controlling a data processing system exemplary machine readable media for providing such programming logic are shown by reference numeral in . The media are shown as being portable optical storage disks of the type that are conventionally used for commercial software sales such as compact disk read only memory CD ROM disks compact disk read write CD R W disks and digital versatile disks DVDs . Such media can store the programming logic of the invention either alone or in conjunction with another software product that incorporates the required functionality. Moreover the network connection failover functionality described herein could be distributed across several media each of which is intended to be used by a different data processing system. The programming logic could also be provided by portable magnetic media such as floppy disks flash memory sticks etc. or magnetic media combined with drive systems e.g. disk drives or media incorporated in data processing platforms such as random access memory RAM read only memory ROM or other semiconductor or solid state memory. More broadly the media could comprise any electronic magnetic optical electromagnetic infrared semiconductor system or apparatus or device transmission or propagation signal or signal carrying medium such as a network or other entity that can contain store communicate propagate or transport the programming logic for use by or in connection with a data processing system computer or other instruction execution system apparatus or device.

Although various embodiments of the invention have been described it should be apparent that many variations and alternative embodiments could be implemented in accordance with the invention. For example the disclosed network connection failover technique could potentially be used during other types of applications service interruptions that are not due to application migration. Suspending an application for a system software or hardware upgrade e.g. replacing a network interface card would be such a case. The application would be checkpointed but thereafter recreated on the same system. Another case would be where the application is checkpointed due to a need to hotplug new hardware insert a kernel module or modify an application library provided this does not affect the application s state . In each case the target socket could also be the source socket and thus simply transferred back to the application upon restart. It will also be appreciated that the connection managers described herein may handle multiple network connections simultaneously which is advantageous for server virtual application environments.

It is understood therefore that the invention is not to be in any way limited except in accordance with the spirit of the appended claims and their equivalents.

