---

title: Spatial audio conferencing
abstract: Audio in an audio conference is spatialized using either virtual sound-source positioning or sound-field capture. A spatial audio conference is provided between a local and remote parties using audio conferencing devices (ACDs) interconnected by a network. Each ACD captures spatial audio information from the local party, generates either one, or three or more, audio data streams which include the captured information, and transmits the generated stream(s) to each remote party. Each ACD also receives the generated audio data stream(s) transmitted from each of the remote parties, processes the received streams to generate a plurality of audio signals, and renders the signals to produce a sound-field that is perceived by the local party, where the sound-field includes the spatial audio information captured from the remote parties. A sound-field capture device is also provided which includes at least three directional microphones symmetrically configured about a center axis in a semicircular array.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08073125&OS=08073125&RS=08073125
owner: Microsoft Corporation
number: 08073125
owner_city: Redmond
owner_country: US
publication_date: 20070925
---
Various techniques exist to provide for collaboration between parties situated remotely from one another. Two popular examples of such techniques that support live collaboration are audio conferencing and video conferencing. Audio conferencing systems provide for the live exchange and mass articulation of audio information between two or more parties situated remotely from one another and linked by a communications network. Video conferencing systems on the other hand generally provide for the live exchange of both video and audio information between the parties. Despite the audio only nature of audio conferencing systems they are still quite popular and are frequently employed because of their ease of use high reliability support for live collaboration between a reasonably large number of parties compatibility with ubiquitous global communications networks overall cost effectiveness and the fact that they don t generally require any specialized equipment.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described hereafter in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

The present spatial audio conferencing technique generally involves spatializing the audio in an audio conference by using one of two different methods a virtual sound source positioning method and a sound field capture method. The resulting spatial audio is perceived by conferencees participating in the audio conference to have a three dimensional 3D effect in which a plurality of different sounds are perceived to emanate from a plurality of different reproduced sound sources distributed in 3D space. The provision of spatial audio in an audio conference significantly improves the quality and effectiveness of the audio conference.

In one embodiment the present spatial audio conferencing technique provides a spatial audio conference between a local party and one or more remote parties each of which is situated at a different venue. This is accomplished using a plurality of audio conferencing devices ACDs which are interconnected by a network and a computer program that is executed by each ACD. Each venue includes an ACD. The computer program includes the following program modules. One program module captures spatial audio information emanating from the local party and processes the captured audio information to generate a single audio data stream which includes the captured information. Another program module transmits the single audio data stream over the network to each remote party and receives the single audio data stream which is transmitted over the network from each remote party. Yet another program module processes the received audio data streams to generate a plurality of audio signals and renders the audio signals to produce a sound field which is perceived by the local party where the sound field includes the spatial audio information captured from the remote parties.

In another embodiment of the present technique the computer program includes the following program modules. One program module captures spatial audio information emanating from the local party and processes the captured audio information to generate one audio data stream whenever there is only one conferencee in the local party and three or more audio data streams whenever there are a plurality of conferencees in the local party where the generated audio data stream s includes the captured information. Another program module transmits the generated audio data stream s over the network to each remote party. Yet another program module receives the one audio data stream which is transmitted over the network from each remote party containing only one conferences and the three or more audio data streams which are transmitted over the network from each remote party containing a plurality of conferencees. Yet another program module processes the received audio data streams to generate a plurality of audio signals and renders the audio signals to produce a sound field which is perceived by the local party where the sound field includes the spatial audio information captured from the remote parties.

In yet another embodiment the present technique includes a sound field capture device for capturing spatial audio information from a sound field. The device includes at least three microphones configured in a semicircular array. The microphones are disposed symmetrically about a center axis. Each microphone includes a directional sound capture element.

In addition to the just described benefits other advantages of the present technique will become apparent from the detailed description which follows hereafter when taken in conjunction with the drawing figures which accompany the detailed description.

In the following description of embodiments of the present spatial audio conferencing technique reference is made to the accompanying drawings which form a part hereof and in which are shown by way of illustration specific embodiments in which the present technique may be practiced. It is understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the present technique.

The term conferencee is used herein to refer to a person that is participating in an audio conference. The term party is used herein to refer to either a single conferencee that is situated at a particular venue by themselves or a plurality of conferencees that are co situated at a particular venue. The term reproduced sound source is used herein to refer to a particular spatial location that is audibly perceived as sourcing sound. The term spatial audio is used herein to refer to a particular type of audio that when audibly rendered is perceived to have a three dimensional 3D effect in which a plurality of different sounds are perceived to emanate from a plurality of different reproduced sound sources distributed in 3D space. The term spatial audio conference is used herein to refer to an audio conference that contains spatial audio information. In other words generally speaking the audio conferencing system used to provide for an audio conference between parties has spatial audio capabilities in which spatial audio information is captured from each party and transmitted to the other parties and spatial audio information is received from the other parties is audibly rendered in a spatial format for each party to hear.

Before providing a description of embodiments of the present spatial audio conferencing technique a brief general description of a suitable computing system environment in which portions thereof may be implemented will be described. This environment provides the foundation for the operation of embodiments of the present technique which are described hereafter. The present technique is operational with numerous general purpose or special purpose computing system environments or configurations. Exemplary well known computing systems environments and or configurations that may be suitable include but are not limited to personal computers PCs server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the aforementioned systems or devices and the like. The present technique is also operational with a variety of phone devices which will be described in more detail hereafter.

As illustrated in an exemplary system for implementing the present technique includes one or more computing devices such as computing device . In its simplest configuration computing device typically includes at least one processing unit and memory . Depending on the specific configuration and type of computing device the memory may be volatile such as RAM non volatile such as ROM and flash memory among others or some combination of the two. This simplest configuration is illustrated by dashed line .

As exemplified in computing device can also have additional features and functionality. By way of example computing device can include additional storage such as removable storage and or non removable storage . This additional storage includes but is not limited to magnetic disks optical disks and tape. Computer storage media includes volatile and non volatile media as well as removable and non removable media implemented in any method or technology. The computer storage media provides for storage of various information required to operate the device such as computer readable instructions associated with an operating system application programs and other program modules and data structures among other things. Memory removable storage and non removable storage are all examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media can be part of computing device .

As exemplified in computing device also includes a communications connection s that allows the device to operate in a networked environment and communicate with a remote computing device s such as remote computing device s . Remote computing device s can be a PC a server a router a peer device or other common network node and typically includes many or all of the elements described herein relative to computing device . Communication between computing devices takes place over a network s which provides a logical connection s between the computing devices. The logical connection s can include one or more different types of networks including but not limited to a local area network s and wide area network s . Such networking environments are commonplace in conventional offices enterprise wide computer networks intranets and the Internet. It will be appreciated that the communications connection s and related network s described herein are exemplary and other means of establishing communication between the computing devices can be used.

As exemplified in communications connection s and related network s are an example of communication media. Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example but not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. The term computer readable media as used herein includes both storage media and communication media.

As exemplified in computing device also includes an input device s and output device s . Exemplary input devices include but are not limited to a keyboard mouse pen touch input device audio input devices and cameras among others. A user can enter commands and various types of information into the computing device through the input device s . Exemplary audio input devices not illustrated include but are not limited to a single microphone a plurality of microphones in an array a single audio video A V camera and a plurality of A V cameras in an array. These audio input devices are used to capture a user s or co situated group of users voice s and other audio information. Exemplary output devices include but are not limited to a display device s a printer and audio output devices among others. Exemplary audio output devices not illustrated include but are not limited to a single loudspeaker a plurality of loudspeakers and headphones. These audio output devices are used to audibly play audio information to a user or co situated group of users. With the exception of microphones loudspeakers and headphones which are discussed in more detail hereafter the rest of these input and output devices are well known and need not be discussed at length here.

The present technique can be described in the general context of computer executable instructions such as program modules which are executed by computing device . Generally program modules include routines programs objects components and data structures among other things that perform particular tasks or implement particular abstract data types. The present technique can also be practiced in a distributed computing environment where tasks are performed by one or more remote computing devices that are linked through a communications network . In a distributed computing environment program modules may be located in both local and remote computer storage media including but not limited to memory and storage devices .

An exemplary environment for the operation of embodiments of the present technique having now been described the remainder of this Detailed Description section is devoted to a description of the systems processes and devices that embody the present technique.

The present technique generally spatializes the audio in an audio conference between a plurality of parties situated remotely from one another. This is in contrast to conventional audio conferencing systems which generally provide for an audio conference that is monaural in nature due to the fact that they generally support only one audio stream herein also referred to as an audio channel from an end to end system perspective i.e. between the parties . More particularly the present technique generally involves two different methods for spatializing the audio in an audio conference a virtual sound source positioning VSP method and a sound field capture SFC method. Both of these methods are described in detail hereafter.

The present technique generally results in each conferences being more completely immersed in the audio conference and each conferences experiencing the collaboration that transpires as if all the conferencees were situated together in the same venue. As will become apparent from the description that follows the present technique can be used to add spatial audio capabilities into conventional audio conferencing systems for minimal added cost and a minimal increase in system complexity.

Using their two ears a human being can generally audibly perceive the direction and distance of a sound source. Two cues are primarily used in the human auditory system to achieve this perception. These cues are the inter aural time difference ITD and the inter aural level difference ILD which result from the distance between the human s two ears and shadowing by the human s head. In addition to the ITD and ILD cues a head related transfer function HRTF is used to localize the sound source in 3D space. The HRTF is the frequency response from a sound source to each ear which can be affected by diffractions and reflections of the sound waves as they propagate in space and pass around the human s torso shoulders head and pinna. Therefore the HRTF for a sound source generally differs from person to person.

In an environment where a plurality of people are talking at the same time the human auditory system generally exploits information in the ITD cue ILD cue and HRTF and provides the ability to selectively focus one s listening attention on the voice of a particular talker. This selective attention is known as the cocktail party effect. In addition the human auditory system generally rejects sounds that are uncorrelated at the two ears thus allowing the listener to focus on a particular talker and disregard sounds due to venue reverberation.

The ability to discern or separate apparent sound sources in 3D space is known as sound spatialization. The human auditory system has sound spatialization abilities which generally allow a human being to separate a plurality of simultaneously occurring sounds into different auditory objects and selectively focus on i.e. primarily listen to one particular sound.

Referring again to by way of example but not limitation venue A is a large meeting venue and party A has 12 different conferencees A A . Venue B is a home office and party B has of a single conferences B. Venue C is also a large meeting venue and party C has 6 different conferencees C C . Venue D is a small meeting venue and party D has two different conferencees D D. The number of conferencees in each party is variable and the maximum number of conferencees in any particular party is generally limited only by the physical size of the particular venue being used to house the party during the audio conference. As will be described hereafter the conferencees in each party do not have to be located in any particular spot within the venue and do not have to remain stationary during the audio conference. In other words the present technique allows the conferencees in each party to freely roam about the venue during the audio conference.

Referring again to each particular venue has an audio conferencing device ACD which is responsible for concurrently performing a number of different operations. Using venue A as an example these operations generally include but are not limited to the following a an audio capture module uses an audio input device not illustrated to capture spatial audio information from a captured sound field emanating from the party at the venue b a capture processor module processes the captured spatial audio information as necessary based on the particular audio spatialization method being employed to generate one or more audio data streams not illustrated c a network communications module transmits the one or more audio data streams over the network to each remote party d the network communications module also receives one or more audio data streams not illustrated over the network from each remote party where each received stream s includes spatial audio information that was captured from the sound field emanating from the remote party e a playback processor module processes these various received audio data streams as necessary based on the particular audio spatialization method being employed to generate a plurality of different audio signals not illustrated and f an audio playback module uses an audio output device not illustrated to render the audio signals into a spatial audio playback sound field that is audibly perceived by the party where this playback sound field includes all the various spatial audio information that was captured from the remote parties .

In an alternate embodiment of the present technique a multipoint conferencing unit or multipoint control unit not shown MCU is used to connect the ACD to the network . In this alternate embodiment the network communications module transmits one or more audio data streams to the MCU which in turn transmits the streams over the network to each remote party. The MCU also receives one or more audio data streams over the network from each remote party and in turn transmits the received streams to the network communications module .

Referring again to the audio capture module can generally employ different types of audio input devices in order to capture the aforementioned spatial audio information from the captured sound field . Additionally different types of audio input devices can be employed at the different venues . Exemplary audio input devices have been described heretofore and will be further described hereafter in particular relation to the aforementioned VSP and SFC methods for spatializing the audio in an audio conference. Furthermore different types of networks and related communication media can be employed in the network and related network communications module . Exemplary types of networks and related communication media have been described heretofore. Additionally the network and related network communications module can include a plurality of different types of networks and related communication media in the system where the different types of networks and media are interconnected such that information flows between them as necessary to complete transmissions over the network .

Referring again to in one embodiment of the present technique the aforementioned playback processor module s processing of the various received audio data streams is performed using a conventional computer based audio processing application programming interface API of which several are available. In tested embodiments of the present technique Microsoft s DirectSound a registered trademark of Microsoft Corporation API was employed. However any other suitable API could also be employed. As will be described in more detail hereafter the audio playback module can generally employ different types and configurations of audio output devices in order to generate the spatial audio playback sound field . Additionally the particular type and configuration of the audio output device employed at each venue can vary.

Referring again to the functionality of the various aforementioned modules in the ACD is hereafter described in more detail as necessary for both the aforementioned VSP and SFC methods for spatializing the audio in an audio conference. Except as otherwise described herein the ACDs at each of the venues operate in a generally similar fashion.

Referring again to it is noted that the embodiments of the present technique described herein include ACDs which generally capture audio information and transmit the captured audio information as well as receive audio information and playback the received audio information. However it should also be noted that other embodiments not illustrated of the present technique are also possible that include ACDs which generally receive audio information and playback the received audio information but do not capture or transmit any audio information. Such ACDs could be used by a party that is simply monitoring an audio conference.

This section describes exemplary embodiments of the VSP method for spatializing the audio in an audio conference hereafter simply referred to as the VSP method according to the present technique. illustrates an exemplary embodiment of a general architecture of an audio conferencing system according to the present technique. This system architecture along with the general operations that are concurrently performed by the ACD at each venue are described in the General Architecture section heretofore. The ACD s operations will now be described in further detail as necessary according to the VSP method of the present technique.

Referring again to this section further describes aforementioned ACD operations a b and c according to the VSP method of the present technique. Using venue A as an example the ACD s capture processor module generates a single i.e. monaural audio data stream that includes all the spatial audio information captured from the sound field emanating from the various conferencees A A in party A . More particularly as exemplified in this audio data stream includes monaural audio data and a related captured sound source identification ID metadata header that is appended to the monaural audio data by the capture processor module . The captured sound source ID metadata describes various attributes of the monaural audio data as will be described hereafter. The network communications module transmits this single audio data stream over the network to each remote party .

As exemplified in and referring again to in one embodiment of the present technique the metadata includes a prescribed bit length venue ID field which specifies the particular venue the monaural audio data is emanating from. As exemplified in in another embodiment the metadata includes a prescribed bit length direction ID field which among other things specifies a particular direction within the captured sound field emanating from the venue s party that the monaural audio data is principally emanating from at each point in time. As will be described in detail hereafter the direction ID field serves the function of allowing remote venues which receive the monaural audio data to render a playback sound field containing spatial audio information that simulates the captured sound field emanating from a remote venue. As exemplified in in yet another embodiment the metadata includes both the aforementioned venue ID field and direction ID field . The particular bit length chosen for the venue ID field is variable and is generally based on an expected maximum number of different venues to be supported during an audio conference. The particular bit length chosen for the direction ID field is also variable and is principally based on an expected maximum number of conferencees in a party to be supported during an audio conference. In determining the bit length of the direction ID field consideration should also be given to factors such as the processing power of the particular ACDs employed in the system and the bandwidth available in the network among others. In tested embodiments of the present technique a bit length of four bits was employed for both the venue ID field and direction ID field which thus provided for a system in which up to 16 different venues and up to 16 different directions per venue can be specified.

Referring again to for particular venues that have only a single conferencee in the party such as venue B there is generally no useful direction information to be generated from the captured sound field emanating from the party since there is only one possible talker at the venue. Therefore at such particular venues it generally suffices to employ a single conventional microphone not illustrated as the audio input device in the ACD s audio capture module in order to capture audio from the sound field emanating from the party in the form of a single audio signal not illustrated .

Referring again to B and C for particular venues that have a plurality of conferencees in the party such as venues A C and D useful direction information generally does exist in the captured sound field emanating from the party . At such particular venues different methods can be employed to generate the information in the direction ID field . In one embodiment of the present technique an array of two or more directional microphones not illustrated is employed as the audio input device in the ACD s audio capture module in order to capture audio from the sound field in the form of two or more different audio signals not illustrated . Appropriate captured sound source location methods are then used to process the two or more different audio signals in order to calculate the particular location within the captured sound field that the audio such as the conferences in the party that is currently talking is principally emanating from at each point in time and generate the corresponding direction ID . Appropriate methods are also used to process the different audio signals in order to translate them into the monaural audio data .

Referring again to B and C in another embodiment of the present technique a computer vision sub system not illustrated is employed as the audio input device in the ACD s audio capture module . The vision sub system includes a video camera with an integrated microphone. The video camera tracks where the audio within the captured sound field such as the conferences in the party that is currently talking is principally emanating from at each point in time. The integrated microphone correspondingly captures this audio in the form of an audio signal not illustrated . The processor module then uses the video camera s current position information to calculate the direction ID which specifies the direction within the captured sound field that the primary source of audio is emanating from at each point in time. The audio signal is also processed using appropriate methods in order to translate it into the monaural audio data .

Referring again to B and C whenever the aforementioned array of directional microphones or video camera is located close to the party such that the audio signal s are captured from a near field region of the captured sound field this information is additionally included in the direction ID field .

Referring again to FIGS. and A C this section further describes aforementioned ACD operations d e and f according to the VSP method of the present technique. Using venue A as an example the network communications module receives the single audio data stream transmitted from each remote party over the network. The playback processor module subsequently processes the monaural audio data and appended captured sound source ID metadata included within each received stream in order to render a spatial audio playback sound field through the audio playback module and its audio output device not illustrated where the spatial audio playback sound field includes all the spatial audio information received from each remote party in a spatial audio format. As will become apparent from the description that follows these audio rendering operations are not intended to faithfully reproduce the captured sound fields emanating from the party at each remote venue. Rather these audio rendering operations generate a playback sound field that provides the venue s party with the perception that different sounds emanate from a plurality of different reproduced sound sources in the playback sound field thus providing the party with a spatial cue for each different sound.

Referring again to FIGS. and A C in one embodiment of the present technique stereo headphones not illustrated can be employed as the audio output device in the audio playback module at a particular venue where the headphones include a pair of integrated loudspeakers which are disposed onto the ears of each conferences in the particular party . In this case the playback processor module generates a left channel audio signal not illustrated and a right channel audio signal not illustrated which are connected to the headphones. The headphones audibly render the left channel signal into the left ear and the right channel signal into the right ear of each conferencee. The processor employs an appropriate headphone sound field virtualization method such as the headphone virtualization function provided in the Microsoft Windows Vista a registered trademark of Microsoft Corporation operating system to generate the two playback audio signals such that each conferencee perceives a spatial audio playback sound field not illustrated emanating from the headphones where the different captured sound sources identified for the monaural audio data in each received audio data stream are perceived to emanate from different locations within the playback sound field.

Referring again to in another embodiment of the present technique a stereo pair of stand alone loudspeakers not illustrated can be employed as the audio output device in the audio playback module at a particular venue . The pair of stand alone loudspeakers are disposed in front of the party where one loudspeaker is disposed on the left side of the venue and the other loudspeaker is symmetrically disposed on the right side of the venue.

Referring again to in yet another embodiment of the present technique a surround sound speaker system not illustrated including three or more stand alone loudspeakers can be employed as the audio output device in the audio playback module at a particular venue . The three or more stand alone loudspeakers can be disposed in front of the party such that one loudspeaker is disposed on the left side of the venue another loudspeaker is symmetrically disposed on the right side of the venue and the remaining loudspeaker s are symmetrically disposed between the left side and right side loudspeakers. The three or more stand alone loudspeakers can also be disposed around the party such that two or more loudspeakers are disposed in front of the party in the manner just described one or more loudspeakers are disposed to the left of the party and one or more loudspeakers are symmetrically disposed to the right of the party. In addition one or more loudspeakers could also be disposed behind the party.

As also illustrated in and referring again to in one embodiment of the present technique the ACD playback processor includes a time delay stage a filter stage and a gain adjustment stage which process the single audio data stream received from each remote venue to generate the plurality of playback audio signals . As will be described in more detail hereafter the different captured sound sources identified for the monaural audio data in each received audio data stream can be processed in a manner that spatially places the different captured sound sources within the playback sound field such that the party audibly perceives the different captured sound sources to emanate from different reproduced sound sources which are spatially disposed within the playback sound field. As will also be described in more detail hereafter these reproduced sound sources can be disposed at various locations within the playback sound field . By way of example but not limitation in one embodiment of the present technique in which a stereo pair of stand alone loudspeakers left and right is employed in the audio output device a reproduced sound source can be disposed directly in front of each loudspeaker and a reproduced sound source can be disposed midway between the loudspeakers. Additionally a reproduced sound source can be disposed to the left of the left loudspeaker and to the right of the right loudspeaker by employing an appropriate stereo spatial enhancement processing method such as reduction to a mid channel side channel M S stereo signal format followed by enhancement of the S channel and then reconstruction of a left channel right channel L R stereo signal. In another embodiment of the present technique in which three stand alone loudspeakers left center and right are employed in the audio output device a reproduced sound source can be disposed directly in front of each loudspeaker a reproduced sound source can be disposed midway between the left and center loudspeakers a reproduced sound source can be disposed midway between the center and right loudspeakers and a reproduced sound source can be disposed to the left of the left most loudspeaker and to the right of the right most loudspeaker by employing the aforementioned stereo spatial enhancement processing method. In other embodiments of the present technique not illustrated in which more than three stand alone loudspeakers are employed the aforementioned methods of disposing reproduced sound sources can be extended to generate an even larger number of different reproduced sound sources.

Referring again to seven different reproduced sound sources and three different stand alone loudspeakers and related playback audio signals are depicted by way of example but not limitation. As noted heretofore and further described hereafter the particular type number and spatial location of stand alone loudspeakers and the related particular number of playback audio signals employed at each venue is variable. As will be described in more detail hereafter the particular number and spatial location of reproduced sound sources employed at each venue is also variable.

Referring again to and the particular number and spatial location of different reproduced sound sources employed in the playback sound field rendered at each venue and the related particular characteristics of the ACD playback processing performed at each venue in the time delay stage filter stage and gain adjustment stage are prescribed based on various system attributes including but not limited to the following a whether or not the captured sound source ID metadata employs a venue ID field and if so the number of bits employed in this field b whether or not the captured sound source ID metadata employs a direction ID field and if so the number of bits employed in this field c whether or not the captured sound source ID metadata employs both a venue ID field and direction ID field d the total number of remote parties participating in a particular audio conference e the type of audio output device employed at the venue and f the particular number and configuration of stand alone loudspeakers employed in the audio output device .

Referring again to and regardless of the particular configuration of reproduced sound sources employed in the playback sound field rendered at a particular venue and regardless of the total number of different captured sound sources identified in the information received from the remote venues the following guidelines should be followed. The mapping of which particular identified captured sound sources are assigned to which particular reproduced sound sources should not change during an audio conference in order to maintain spatial continuity i.e. sound source stationarity and not confuse the listening party . If the direction ID field is employed in the system regardless of which of the aforementioned methods is employed at each venue to generate the information in this field whenever the direction ID field specifies more than two captured sound sources for particular monaural audio data the mapping of these captured sound sources to particular reproduced sound sources should be implemented in a manner that results in equal separation between each of the captured sound sources. This is desirable for the following reason. If the party has a plurality of conferencees sitting around a table as is typical for any reasonable size party and if the aforementioned array of directional microphones or video camera is located at one end of the table the angle between the microphones camera and two adjacent conferencees sitting farthest from the microphones camera is much smaller than the angle between the microphones camera and two adjacent conferencees sitting closest to the microphones camera.

Referring again to C and as described heretofore the direction ID field can include information as to if the monaural audio data received from a particular remote venue was captured from a near field region of the captured sound field or not. Whenever the direction ID field is employed in the system and whenever this field indicates that the monaural audio data was captured from a near field region of the captured sound field at a particular remote venue in one embodiment of the present technique the ACD playback processor can use an appropriate method such as standard panpots to calculate prescribed time delay optional and gain required adjustments for the monaural audio data received from the particular remote venue in order to simulate the captured sound field at the particular remote venue. These adjustments are applied as follows to each captured sound source identified for the monaural audio data received from the remote venue as the captured sound source is reproduced and played back through the audio output device in the manner described herein. A non adjusted version of the captured sound source is mapped to one particular reproduced sound source in the playback sound field . The time delay and gain adjusted version of the captured sound source is commonly mapped to at least three other reproduced sound sources in the playback sound field. This results in the listening party being able to accurately audibly perceive the intended location of the captured sound source within the playback sound field for the following reason. As is understood by those skilled in the art the human auditory system exhibits a phenomena known as the Hass effect or more generally known as the precedence effect in which early arrival of a sound at a listener s two ears substantially suppresses the listener s ability to audibly perceive later arrivals of the same sound. As such the non adjusted version of the captured sound source serves the function of an early audio signal which masks the listening party s perception of later arrivals of the same audio signal due to venue reflections of the captured sound source.

Referring again to and in one embodiment of the present technique the filter stage can analyze certain voice properties such as pitch of the received monaural audio data and this analysis can be used to map different identified captured sound sources with similar voice properties to reproduced sound sources that are far apart in the playback sound field in order to optimize the listening party s ability to identify who is talking at the remote venues. In another embodiment of the present technique the filter stage is implemented using an actual head related transfer function HRTF measurement for a prototypical conferences thus enhancing the accuracy of the party s perception of the reproduced sound sources employed in the playback sound field and in general enhancing the overall spatial effect audibly perceived by the party. Having a plurality of audio channels in the audio output device allows some reproduction of the de correlation of the sound due to venue reverberation that is captured at each venue. This results in each remote conferencee perceiving the sound as if they were physically present in the venue that the sound was originally captured in.

Referring again to and the following is a description of exemplary embodiments of different reproduced sound source configurations and related mappings of identified captured sound sources to reproduced sound sources that can be employed in the playback sound field according to the present technique. This description covers only a very small portion of the many embodiments that could be employed. In a simple situation A in which three different venues are participating in an audio conference and the audio conferencing system employs only the venue ID field in the captured sound source ID metadata and at a particular venue a stereo pair of stand alone loudspeakers is employed as the audio output device the monaural audio data received from one remote venue could be routed directly to the left loudspeaker i.e. mapped to reproduced sound source and the monaural audio data received from the second remote venue could be routed directly to the right loudspeaker i.e. mapped to reproduced sound source . If this situation A is modified such that four different venues are participating in the audio conference resulting in situation B the monaural audio data received from the third remote venue could be mapped to reproduced sound source located midway between the left and right loudspeakers by processing this audio data as follows. A pair of differentially delayed partial amplitude playback audio signals can be generated such that one partial amplitude delayed signal is audibly rendered by the left loudspeaker and the other partial amplitude differentially delayed signal is audibly rendered by the right loudspeaker thus resulting in the party s perception that this audio data emanates from reproduced sound source .

Referring again to and if aforementioned situation B is modified such that a third center stand alone loudspeaker is added resulting in situation C then the monaural audio data received from the third remote venue could be routed directly to the center loudspeaker i.e. mapped to reproduced sound source . If this situation C is modified such that six different venues are participating in the audio conference resulting in situation D the monaural audio data received from the fourth remote venue could be mapped to reproduced sound source located midway between the left and center loudspeakers by processing this audio data as follows. A pair of differentially delayed partial amplitude playback audio signals can be generated such that one partial amplitude delayed signal is audibly rendered by the left loudspeaker and the other partial amplitude differentially delayed signal is audibly rendered by the center loudspeaker thus resulting in the party s perception that this audio data emanates from reproduced sound source . Additionally the monaural audio data received from the fifth remote venue could be mapped to reproduced sound source located midway between the center and right loudspeakers by processing this audio data as follows. A pair of differentially delayed partial amplitude playback audio signals can be generated such that one partial amplitude delayed signal is audibly rendered by the center loudspeaker and the other partial amplitude differently delayed signal is audibly rendered by the right loudspeaker thus resulting in the party s perception that this audio data emanates from reproduced sound source .

Referring again to C and the aforementioned exemplary mappings of received identified captured sound sources to reproduced sound sources in the playback sound field at each venue are similarly applicable to situations in which the audio conferencing system employs only the direction ID field in the captured sound source ID metadata or situations in which the system employs both the venue ID field and direction ID field in the metadata . In particular audio conference situations where the number of different identified captured sound sources received at a particular venue is larger than the number of different reproduced sound sources available in the playback sound field at the venue a plurality of captured sound sources could be mapped to a common reproduced sound source.

This section describes exemplary embodiments of the SFC method for spatializing the audio in an audio conference hereafter simply referred to as the SFC method according to the present technique. illustrates an exemplary embodiment of a general architecture of an audio conferencing system according to the present technique. This system architecture along with the general operations that are concurrently performed by the ACD at each venue are described in the General Architecture section heretofore. The ACD s operations will now be described in further detail as necessary according to the SFC method of the present technique.

Referring again to this section further describes aforementioned ACD operations a b and c according to the SFC method of the present technique. In general contrast to the VSP method for spatializing the audio in an audio conference which employs the transmission of a single i.e. monaural audio data stream between venues over the network the SFC method employs the transmission of one or more different audio data streams between venues. Using venue A as an example the ACD s capture processor module generates a prescribed number N of different audio data streams that represent the captured sound field emanating from the various conferencees A A in the party . More particularly as exemplified in each of these N different audio data streams includes an audio data channel and a related captured sound source identification ID metadata header that is appended to the audio data channel by the processor module where the captured sound source ID metadata describes various attributes of the audio data contained within the audio data channel. As will be described in more detail hereafter the particular number N of different audio data streams employed at and transmitted from each venue is prescribed independently for each venue where N is equal to or greater than one. The network communications module transmits the N different audio data streams to each remote venue .

As exemplified in and referring again to in one embodiment of the present technique the metadata includes the following two fields. A prescribed bit length venue ID field specifies the particular venue the audio data channel N is emanating from. As will be described in more detail hereafter a prescribed bit length channel ID field specifies attributes of the particular microphone in the audio capture module that was used to capture the audio signal related to audio data channel N . The particular bit lengths chosen for the venue ID field and channel ID field are variable and are generally based on a variety of different attributes of the audio conferencing system such as an expected maximum number of different venues to be supported during an audio conference an expected maximum number of microphones to be used in the audio capture module and a related expected maximum number of different audio data streams to be transmitted from a venue the processing power of the particular ACDs employed in the system and the bandwidth available in the network among others. In tested embodiments of the present technique a bit length of four bits was employed for the venue ID field and a bit length of two bits was employed for the channel ID field which thus supported the ID of up to 16 different venues and up to four different audio data channels per venue.

Referring again to for particular venues that have only a single conferencee in the party such as venue B since there is only one possible talker at the venue in one embodiment of the present technique it can suffice to employ a single conventional microphone not illustrated as the audio input device in the ACD s audio capture module in order to capture a single audio signal from the captured sound field emanating from the party . In this case the ACD s capture processor module generates only a single audio data channel and puts information into the channel ID field for the channel that specifies this is the only channel that was captured from the sound field emanating from party B . Accordingly the network communications module transmits only one audio data stream to each remote venue . In an alternate embodiment of the present technique assuming the ACD has sufficient processing power and the network has sufficient bandwidth a sound field capture microphone array not illustrated can be employed as the audio input device. This microphone array which will be described in detail hereafter generally includes three or more microphones which capture three or more different audio signals from the captured sound field emanating from the party . In this case the ACD s capture processor module generates a different audio data channel for each signal. The capture processor module also puts information into the channel ID field for each audio data channel that specifies a directional orientation within the captured sound field for the particular microphone that captured the particular signal that resulted in the audio data channel. Accordingly the network communications module transmits three or more different audio data streams to each remote venue.

Referring again to for particular venues that have a plurality of conferencees in the party such as venues A C and D useful spatial audio information can exist in the captured sound fields emanating from the parties since there are a plurality of possible talkers at these venues. Therefore at such particular venues the aforementioned sound field capture microphone array can be employed as the audio input device in the audio capture module . As discussed heretofore this microphone array captures three or more different audio signals from the captured sound fields emanating from the parties . In this case the ACD s capture processor module generates a different audio data channel for each signal. The capture processor module also puts information into the channel ID field for each audio data channel that specifies a directional orientation within the captured sound field for the particular microphone that captured the particular signal that resulted in the audio data channel. Accordingly the network communications module transmits three or more different audio data streams to each remote venue.

Referring again to the value of angle A is prescribed such that the distance E between the left most capture element and right most capture element approximates the time delay between the ears on a typical adult human head. This fact combined with the aforementioned fact that the sound capture elements are highly directional results in the microphone array s ability to direct capture sound waves in a manner that imitates a human s inter aural head delay while generating a set of audio signals which has substantial energy in each signal at all times. Therefore the captured audio signals contain the aforementioned necessary ITD and ILD cues such that when the audio data channels containing these signals are received and rendered at the remote venues as will be described in more detail hereafter the party at each remote venue properly audibly perceives where each direct sound in the captured sound field is coming from.

Referring again to in tested embodiments of the present technique hypercardioid type microphones were employed in the microphone array . The high degree of directionality associated with the hypercardioid type microphones ensures the audio signal generated for each different portion of the captured sound field has a different gain profile. Thus the captured audio signals contain both time and amplitude panning information which as will also be described in more detail hereafter further improves a remote party s perception of the playback sound field that is rendered from these signals. The high degree of directionality associated with the hypercardioid type microphones also ensures that each microphone captures a different reverberant field. Thus when the corresponding captured audio signals are rendered to produce a playback sound field in the manner described hereafter the different reverberant fields are de correlated. As will also be described in more detail hereafter this yet further improves a remote party s perception of the playback sound field that is rendered from these signals .

Referring again to for each particular venue the microphone array is placed in what is commonly termed the sweet spot of the captured sound field at that venue. This sweet spot is defined in terms of both a vertical height of the sound capture elements and a horizontal positioning of the sound capture elements in relation to the conferencees in the party. The vertical height of the sweet spot is along the horizontal plane formed by the average height of the mouths of the conferencees in the party. The horizontal positioning of the sweet spot is defined as follows. By way of example but not limitation if the conferencees at a particular venue are sitting around a table the horizontal positioning of the sweet spot is located at the center of one end of the table as generally illustrated in . By way of further example as generally illustrated in if the conferencees at a particular venue are not sitting around a table but rather are disposed at various locations throughout a venue the horizontal positioning of the sweet spot is located at the center of the front of the venue.

It is noted that other embodiments not illustrated of the sound field capture microphone array are also possible which include more than three highly directional microphones. In these other embodiments the more than three microphones are also disposed symmetrically about a horizontal axis. Each of the more than three microphones also includes a sound capture element which is highly directional and independently captures sound waves emanating directly from and generates a corresponding audio signal for a different particular direction in the captured sound field. As such referring again to the more than three different captured audio signals would be processed as described heretofore to generate more than three different audio data streams each of which includes an audio data channel corresponding to a particular captured audio signal along with a channel ID that specifies which channel the data is for. In the event that the microphone array includes more than four microphones the bit length chosen for the channel ID field would accordingly need to be more than two bits.

Referring again to this section further describes aforementioned ACD operations d e and f according to the SFC method of the present technique. Using venue A as an example the network communication module receives the N different audio data streams transmitted from each remote venue . The playback processor module subsequently processes the audio data channel and appended captured sound source ID metadata included within each received stream in order to render a spatial audio playback sound field through the audio playback module and its audio output device not illustrated where the spatial audio playback sound field includes all the audio information received from the remote venues in a spatial audio format.

Referring again to in one embodiment of the present technique stereo headphones not illustrated can be employed as the audio output device in the audio playback module at a particular venue where the headphones include a pair of integrated loudspeakers which are disposed onto the ears of each conferences in the particular party . In this case the playback processor module generates a left channel audio signal not illustrated and a right channel audio signal not illustrated which are connected to the headphones. The headphones audibly render the left channel signal into the left ear and the right channel signal into the right ear of each conferencee. The processor employs an appropriate headphone sound field virtualization method such as the headphone virtualization function provided in the Microsoft Windows Vista a registered trademark of Microsoft Corporation operating system to generate the two playback audio signals such that each conferencee perceives a spatial audio playback sound field not illustrated emanating from the headphones where the different audio data channels in the different received audio data streams are perceived to emanate from different locations within the playback sound field.

Referring again to in another embodiment of the present technique a surround sound speaker system not illustrated including three or more stand alone loudspeakers can be employed as the audio output device in the audio playback module at a particular venue . The three or more stand alone loudspeakers can be disposed in front of the party such that one loudspeaker is disposed on the left side of the venue another loudspeaker is symmetrically disposed on the right side of the venue and the remaining loudspeaker s are symmetrically disposed between the left side and right side loudspeakers. The three or more stand alone loudspeakers can also be disposed around the party such that two or more loudspeakers are disposed in front of the party in the manner just described one or more loudspeakers are disposed to the left of the party and one or more loudspeakers are symmetrically disposed to the right of the party. In addition one or more loudspeakers could also be disposed behind the party.

As also illustrated in and referring again to as described heretofore the ACD playback processor processes the one or more audio data streams received from each remote venue to generate the different playback audio signals . As will be described in more detail hereafter each received audio data stream can be processed in a manner that spatially places its audio within the playback sound field such that the party audibly perceives this audio to emanate from a particular reproduced sound source which is spatially disposed within the playback sound field. As will also be described in more detail hereafter these reproduced sound sources can be disposed at various locations within the playback sound field . By way of example but not limitation in one embodiment of the present technique in which three stand alone loudspeakers left center and right are employed in the audio output device a reproduced sound source can be disposed directly in front of each loudspeaker a reproduced sound source can be disposed midway between the left and center loudspeakers a reproduced sound source can be disposed midway between the center and right loudspeakers and a reproduced sound source can be disposed to the left of the left most loudspeaker and to the right of the right most loudspeaker by employing an appropriate stereo spatial enhancement processing method such as reduction to a mid channel side channel M S stereo signal format followed by enhancement of the S channel and then reconstruction of a left channel right channel L R stereo signal.

In another embodiment of the present technique in which five stand alone loudspeakers left left center center right center and right are employed in the audio output device a reproduced sound source can be disposed directly in front of each loudspeaker a reproduced sound source not illustrated can be disposed midway between the left and left center loudspeakers a reproduced sound source not illustrated can be disposed midway between the left center and center loudspeakers a reproduced sound source not illustrated can be disposed midway between the center and right center loudspeakers a reproduced sound source not illustrated can be disposed midway between the right center and right loudspeakers and a reproduced sound source can be disposed to the left of the left most loudspeaker and to the right of the right most loudspeaker by employing the aforementioned stereo spatial enhancement processing method. In other embodiments of the present technique not illustrated in which more than five stand alone loudspeakers are employed the aforementioned methods of disposing reproduced sound sources can be extended to generate an even larger number of different reproduced sound sources.

Referring again to seven different reproduced sound sources and three or optionally five different stand alone loudspeakers and related playback audio signals are depicted by way of example but not limitation. As noted heretofore and further described hereafter the particular type number and spatial location of stand alone loudspeakers and the related particular number of playback audio signals employed at each venue is variable. As will be described in more detail hereafter the particular number and spatial location of reproduced sound sources employed at each venue is also variable.

Referring again to and the particular number and spatial location of different reproduced sound sources employed in the playback sound field rendered at each venue and the related particular characteristics of the ACD playback processing performed at each venue are prescribed based on various system attributes including but not limited to the following a the number of bits employed in the venue ID field and channel ID field b the number of venues participating in a particular audio conference and c the characteristics of the particular audio output device employed at the venue such as the particular number of stand alone loudspeakers employed and their spatial location.

Referring again to and regardless of the particular number and spatial location of reproduced sound sources employed in the playback sound field rendered at a particular venue and regardless of the total number of different audio data streams received at the venue from each remote venue the following guidelines should be followed. Each received audio data stream whose audio data channel includes a left channel audio signal should be mapped to a particular reproduced sound source generally disposed on the left side of the playback sound field . Each received audio data stream whose audio data channel includes a center channel audio signal should be mapped to a particular reproduced sound source generally disposed in the center of the playback sound field . Each received audio data stream whose audio data channel includes a right channel audio signal should be mapped to a particular reproduced sound source generally disposed on the right side of the playback sound field . Whenever a remote venue transmits only a single audio data stream such as the aforementioned venue that has only one conferences in the party when this single audio data stream is received the audio data channel contained therein can be mapped to any available reproduced sound source. The mapping of which audio data channels are assigned to which reproduced sound sources should not change during an audio conference in order to maintain spatial continuity i.e. audio channel stationarity and not confuse the listening party .

Referring again to the following is a description of exemplary embodiments of different reproduced sound source configurations and related mappings of received audio data channels to reproduced sound sources that can be employed in the playback sound field according to the present technique. This description covers only a very small portion of the many embodiments that could be employed. A simple situation R will first be described in which three different venues are participating in an audio conference. At a particular venue three spatially disposed stand alone loudspeakers and are employed as the audio output device . The first remote venue has only a single conferences in its party and therefore employs a single microphone as the audio input device and transmits only a single audio data stream . The second remote venue has a plurality of conferencees in its party and therefore employs the aforementioned sound field capture microphone array which includes three highly directional hypercardioid type microphones and transmits three different audio data streams as described heretofore one for a left channel one for a center channel and one for a right channel. The audio data channel included in the audio data stream received from the first remote venue could be routed to the center loudspeaker i.e. mapped to reproduced sound source . The audio data channel included in the left channel audio data stream received from the second remote venue could be routed to the left loudspeaker i.e. mapped to reproduced sound source . The audio data channel included in the right channel audio data stream received from the second remote venue could be routed to the right loudspeaker i.e. mapped to reproduced sound source . The audio data channel included in the center channel audio data stream received from the second remote venue could be mapped to reproduced sound source located midway between the left and center loudspeakers by processing this audio data as follows. A pair of differentially delayed partial amplitude playback audio signals can be generated such that one partial amplitude delayed signal is audibly rendered by the left loudspeaker and the other partial amplitude differentially delayed signal is audibly rendered by the center loudspeaker thus resulting in the party s perception that this audio data emanates from reproduced sound source .

Referring again to a situation S will now be described in which aforementioned situation R is modified such that a third remote venue is also participating in the audio conference. The third remote venue has a plurality of conferencees in its party and therefore employs the aforementioned sound field capture microphone array which includes three highly directional hypercardioid type microphones and transmits three different audio data streams as described heretofore. The audio data channels included in the left channel and right channel audio data streams received from the third remote venue could be respectively mapped to reproduced sound sources and by employing the aforementioned stereo spatial enhancement processing method in the ACD playback processor . The audio data channel included in the center channel audio data stream received from the third remote venue could be mapped to reproduced sound source located midway between the center and right loudspeakers by processing this audio data as follows. A pair of differentially delayed partial amplitude playback audio signals can be generated such that one partial amplitude delayed signal is audibly rendered by the center loudspeaker and the other partial amplitude differentially delayed signal is audibly rendered by the right loudspeaker thus resulting in the party s perception that this audio data emanates from reproduced sound source .

Referring again to for situations in which an even larger number of remote venues is participating in the audio conference such that the number of different audio data streams received at a particular venue is larger than the number of different reproduced sound sources available in the playback sound field at the venue a plurality of audio data channels could be mapped to a common reproduced sound source. In an optional embodiment of the present technique the number of different reproduced sound sources available in the playback sound field at the venue could be increased by employing two additional stand alone loudspeakers and in the audio output device . One loudspeaker would be spatially disposed between the left and center loudspeakers and the other loudspeaker would be spatially disposed between the center and right loudspeakers. By employing the playback processing methods described heretofore such a five loudspeaker array could provide for a playback sound field which includes 11 different reproduced sound sources not illustrated . It is noted that such an 11 reproduced sound source embodiment would generally only be employed in a large venue so that there would be a reasonable distance between adjacent reproduced sound sources .

Referring again to and the following are exemplary reasons why the present technique optimizes each party s audible perception of the playback sound field and more particularly optimizes each party s comprehension of what is discussed during live collaboration with and between remote parties and the general effectiveness of the live collaboration between all parties. As described heretofore the audio signals captured from remote venues and hence the respective audio data channels received from these venues contain the aforementioned necessary ITD and ILD cues so that when the audio data channels are rendered through different reproduced sound sources the listening party can properly audibly perceive where each direct sound in the remote venue s captured sound field is coming from. As also described heretofore the audio signals captured from remote venues and hence the respective audio data channels received from these venues can contain both time and amplitude panning information. As a result each party s audible perception of the playback sound field rendered from these respective audio data channels is substantially the same largely regardless of the particular spatial position of a particular listener in the playback sound field. In other words the present technique provides for a wide range of good listening locations within each playback sound field . Furthermore as a listener moves throughout the playback sound field the sounds emanating from the different reproduced sound sources which first arrive at the listener s ears are combined such that the listener audibly perceives a perspective movement rather than the snap the listener typically perceives when they move off axis in a playback sound field generated by a conventional two channel stereo rendering. As also described heretofore the high degree of directionality associated with the hypercardioid type microphones used at the remote venues ensures that each microphone captures a different reverberant field. Thus when the audio data channels corresponding to the captured audio signals are received and rendered through different reproduced sound sources in the manner described heretofore the sound emanating from each reproduced sound source in the playback sound field will contain a de correlated reverberant component. Therefore at least some de correlation of the remote capture venue s reverberation i.e. indirect sound will occur at each listener s ears thus allowing each listener to hear through the playback sound field in a natural manner as if the listener were situated in the remote capture venue.

Referring again to in another embodiment of the present technique a stereo pair of stand alone loudspeakers not illustrated can be employed as the audio output device in the audio playback module at a particular venue . The pair of stand alone loudspeakers is disposed in front of the party where one loudspeaker is disposed on the left side of the venue and the other loudspeaker is symmetrically disposed on the right side of the venue. However it is noted that in this embodiment the range of good listening locations within the playback sound field is narrower than that for the aforementioned embodiment that employs a surround sound speaker system including three or more stand alone loudspeakers as the audio output device.

While the present technique has been described in detail by specific reference to embodiments thereof it is understood that variations and modifications thereof may be made without departing from the true spirit and scope of the present technique. It is noted that any or all of the aforementioned embodiments may be used in any combination desired to form additional hybrid embodiments. Although the present technique has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described heretofore. Rather the specific features and acts described heretofore are disclosed as example forms of implementing the claims.

