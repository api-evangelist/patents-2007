---

title: Method and system for automatic correlation of asynchronous errors and stimuli
abstract: A test and system state recorder (TSSR) controller of a test and system state recorder automatically correlates and captures information about possible stimuli from telemetry information events generated by a test or tests of a test system. The TSSR controller simultaneously and automatically correlates and captures information about other possible stimuli, such as environmental stimuli from telemetry information events generated by optional telemetry event generators. TSSR controller keeps a snap-shot list of the most current stimuli from each sender of telemetry information events. On receipt of an asynchronous trigger event generated by a fault management controller the snap-shot list is logged in a test and system state recorder log. The entry in the log provides automatic correlation of asynchronous errors and stimuli.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07757124&OS=07757124&RS=07757124
owner: Oracle America, Inc.
number: 07757124
owner_city: Menlo Park
owner_country: US
publication_date: 20070716
---
A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever.

The present invention relates generally to root cause and corrective action and more particularly to automated systems to facilitate root cause and corrective action.

With advances in technology computer system product life cycles are getting shorter whereas the systems themselves are becoming more and more complex. At the same time there is ever increasing pressure to reduce the time and cost involved in isolating and fixing any faults that are detected during the productive life of the system.

A defect fault refers to deviation of the functioning of a component from desired behavior. Stimulation of a fault results in a failure and manifestation of a failure is called an error. In other words an error is a symptom of a fault and is seen on the occurrence of a failure. As such a fault can exist in a system and stay undetected absence of errors until a particular kind of stimuli is applied that causes the failure.

Correlating errors to a fault is called diagnosis. Analyzing the cause of a defect fault is called root cause analysis RCA an important first step in taking corrective action for improving product quality. Often times identifying the factors stimuli that impact the time to failure can lead to the timely root cause and corrective action RCCA .

The need for timely root cause and corrective action is well understood. Those who are tasked with conducting root cause and corrective action also know how important it can be to reproduce a failure to identify the stimuli of interest. At the same time it can be difficult to reproduce certain transient faults that may have been stimulated by a specific yet unknown set of stimuli. Such stimuli can consist of specific test algorithms data patterns addressing sequences environmental conditions etc. or a combination thereof.

To make matters complicated most of the hardware errors in today s systems are reported asynchronously. This is true for correctable and non fatal errors both of which may be indications of an incipient fault. For example in case of ECC Error Correction Code protected memory every time the processor reads a memory location the processor checks for the correctness of the data against the ECC code previously stored during the write operation. On detecting a single bit upset the processor may transparently provide the corrected data to the application possible stimulus that requested the data. While the processor may also generate a trap to report the error event by default this is totally transparent to the application. As such the application that stimulated the failure is not even aware of the error.

One can see how such mechanisms are required and useful from normal user customer application s point of view. At the same time this means that special test applications designed to stimulate errors have to deal with an extra hurdle to detect the occurrence of an error and log information about the activity that might have stimulated the fault. For failures which are stimulated by a combination of different stimuli like temperature voltage signal noise etc. the process of error duplication and root cause analysis can be even more complicated.

Various tools have been developed for use in root cause and corrective action. Efforts to facilitate root cause and corrective action are not new. With the introduction of a Fault Management Architecture that provides Protective Self Healing in the Solaris 10 operating system available from Sun Microsystems Inc of Santa Clara Calif. the operating system has taken on the onus of doing fault diagnosis and management.

With the Fault Management Architecture a fault or defect in software or hardware can be associated with a set of possible observed symptoms called errors. When an error is observed an error report is generated. Error reports are encoded as a set of name value pairs described by an extensible protocol forming an error event.

Error events and other data that can be gathered to facilitate automated repair of the fault are dispatched to diagnosis engines designed to diagnose the underlying problems corresponding to these symptoms. Diagnosis engines run in the background silently consuming telemetry until a diagnosis can be completed or a fault can be predicted. After processing sufficient telemetry to reach a conclusion a diagnosis engine produces another event called a fault event which is broadcast to any agents deployed on the system that know how to respond.

A software component known as a Fault Manager in the Fault Management Architecture which is implemented as daemon manages the diagnosis engines and agents provides a simplified programming model for these clients as well as common facilities such as event logging and manages the multiplexing of events between producers and consumers.

Thus the Fault Management Architecture does the fault diagnosis based on the error reports e reports . The Fault Manager collects the e report s and utilizes the diagnosis engines to identify the action needed to isolate the impact of the fault from the rest of the working system. This action is based on a set of pre defined rules that may involve diagnosing the error to find the exact fault. The primary goal is to deduce an actionable conclusion.

Whether the exact fault is identified the action in general consists of identifying an Automated System Recovery Unit ASRU that can be disabled to isolate the impacts of the fault. The Fault Management Architecture does not attempt to collect telemetry about the stimuli that may have instigated the fault.

The action that Fault Management Architecture takes is the right first response by correcting the problem and keeping the system running. However the more time consuming root cause and corrective action phase comes later and is not dealt with by the Fault Management Architecture.

A Continuous System Telemetry Harness CSTH from Sun Microsystems Inc. records system environmental data typically available via showevn command component temperature voltage levels etc. as continuous time series signals. In addition under certain circumstances CSTH aims to analyze the data so archived and predict failures that may occur in the future.

For example predictions maybe based on voltage or temperature fluctuations historically known to be indicative of an incipient fault. Such prediction is typically possible and useful in cases where the degradation may appear hours or sometimes days in advance of failure.

For crashes that occur with no predictive warning the CSTH is still often valuable because the archived telemetry data may be mined to identify signatures from variables that showed anomalies just prior to crash thereby helping to mitigate No Trouble Found NTF events. As CSTH keeps a circular file of the captured telemetry the information in the file can also be used to validate the functionality of various sensors that monitor voltage and temperature of the system.

Although CSTH implements an excellent Black Box Flight Recorder for computer systems CSTH does not automatically correlate asynchronous error events with the stimuli. Root cause analysis requires post processing of significant amounts of data and a manual correlation of the stimulus with the telemetry readings say based on time stamps . While the circular log of all telemetry information is useful in some situations as explained above such a file is not well suited for correlating error occurrences with test stimuli because some the needed stimuli may have been overwritten.

Test suites like SunVTS diagnostic tool can have multiple test processes running concurrently on the system and different tests may start and complete asynchronously. Furthermore such tests can generate massive amounts of messages telemetry about test progress patterns and algorithm logic being executed. This can lead to huge logs in a short amount of time and obviously makes it difficult to manually correlate exactly which test processes were running at the time of error. Thus while these various systems represent significant advances root cause and corrective action still requires manually combing through extensive logs that may or may not contain the information about the stimuli that resulted in the error.

In one embodiment of this invention a computer based method includes receiving telemetry events from at least one telemetry event provider. Each telemetry event provider provides telemetry information about a stimulus applied to a system on which the computer based method is executing.

The method maintains a snap shot list of information from the telemetry events. The snap shot list includes at most one entry from each telemetry provider that has sent a telemetry event.

The method also logs upon receiving a trigger event associated with an error in the system the snap shot list as a log entry in a log file stored in a non volatile memory. The trigger event indicates an error in the system. The log file stores a snap shot of stimuli applied to the system at the time of the receipt of the trigger event.

In one embodiment the telemetry event is a telemetry information event. The method further includes queuing the telemetry information event when a trigger event is being processed. The method also includes extracting information from the telemetry information event and using the information to form a unique identifier. In one embodiment only when a read lock is not active can a write lock be obtained for writing telemetry information in the telemetry information event to the snap shot list.

In another embodiment the telemetry event comprises a telemetry terminate event. In response to the telemetry terminate event information is extracted from the telemetry terminate event. The information is used to form a unique identifier. Any entry in the snap shot list including that unique identifier is deleted from the snap shot list.

In yet another embodiment a test and system recorder includes a log file stored in a non volatile memory and a unit under test. The unit under test includes a test system including at least one test process executing on the unit. The test process generates telemetry events and at least one of the telemetry events includes telemetry information about a stimulus applied to the unit under test.

The unit under test also includes a fault management controller executing on the unit. The fault management controller receives an error report describing an error in the unit and generates a trigger event in response to the error report.

The unit under test further includes a test and system state recorder TSSR controller executing on the unit. The TSSR controller receives the telemetry events and the trigger events. The TSSR controller also maintains a snap shot list of information from the telemetry events. The snap shot list includes at most one entry from the at least one test process. The TSSR controller logs upon receiving a trigger event the snap shot list as a log entry in the log file. Thus the log file stores a snap shot of stimuli applied to the unit under test at the time of receipt of the trigger event.

In the drawings and following Detailed Description elements with the same reference numeral are the same or equivalent elements. The first digit of a reference numeral is the figure number of the figure in which the element with that reference numeral first appeared.

In one embodiment of this invention a test and system state recorder TSSR controller of a test and system state recorder automatically correlates and captures information about possible stimuli from telemetry information events generated by a test or tests of test system . TSSR controller simultaneously and automatically correlates and captures information about other possible stimuli such as environmental stimuli from telemetry information events generated by optional telemetry event generators .

TSSR controller keeps a snap shot list of the most current stimuli from each sender of telemetry information events. Typically the snap shot list is maintained in a volatile memory of TSSR controller such as random access memory.

There is no limit on the number of senders providing telemetry information events to TSSR controller . To maintain only the latest snap shot of the telemetry information only one entry is allowed per sender in the snap shot list. If a new telemetry event is received from the same sender information obtained via the previous event from the same sender is over written automatically in the snap shot list. Multiple telemetry information events from the same or multiple senders can be sent received at the same time. TSSR controller is responsible to maintain the coherency of the snap shot list.

On receipt of an asynchronous trigger event generated by fault management controller the snap shot list is logged in test and system state recorder log in a non volatile memory for example a disk of a hard disk drive. Thus test and system state recorder provides a snap shot of the executing applications i.e. tests and other captured information such as environmental conditions system load time etc. at the time of the occurrence of trigger event . In one embodiment the snap shot list provides information like a name of the test executing at the time of receipt of the trigger event specific algorithm in use by the test test logic or sub test data pattern addressing pattern other test specific instrumentation component temperature overall system stress name of different processes running on the system state of system memory etc.

Trigger event which causes the snap shot list to be logged in TSSR log can include any desired events e.g. occurrence of a test failure expiry of a timer a signal event generated by a software module that is exiting due to an exception etc. which are referred to herein as error events. Trigger event is not limited to hardware errors alone in components under test . The telemetry from test system and telemetry event generators does not persist by default logging action occurs only when a trigger event i.e. an error event is received.

Thus in each instance the stimuli at the time of receipt of a trigger event are recorded. Accordingly doing root cause and corrective action no longer requires pouring over massive volumes of log data and attempting to deduce the stimuli. Rather the snap shot list provides the stimuli and thereby correlates the trigger event with specific stimuli automatically.

The log is not only useful for root cause and corrective action analysis but also useful in other applications. For example on a manufacturing floor where assembled computers are subjected to twenty four hours of testing it may be desirable to reduce the testing period to twenty hours. By examination of the logs from the twenty four hour tests and evaluating which tests are stimulating what kind of errors the test process may be optimized by adjusting test sequences as well as by removing tests that are not effective.

As explained more completely below test and system state recorder provides a protocol and interfaces for different modules to generate telemetry events and trigger events that test and system state recorder controller can listen to and take appropriate action on. Test and system state recorder controller does not need any prior knowledge of the specific modules that generate the trigger and telemetry events. Such modules can therefore be added and removed at any time from unit under test i.e. before or after deployment of test and system state recorder controller . This gives flexibility to add new telemetry modules on an as needed basis without disturbing test and system state recorder controller even if additional stimuli of interest are identified late in a debug process.

In one embodiment test system is the SunVTS diagnostic tool. The Sun Microsystems Inc. validation test suite software i.e. SunVTS diagnostic tool is a comprehensive software diagnostic package that tests and validates hardware by verifying the connectivity and functionality of most hardware components. SunVTS diagnostic tool is a system exerciser that checks for intermittent or long term failures. SunVTS software executes multiple diagnostic tests from a GUI that provides test configuration and status monitoring. The SunVTS interface can run on one workstation to display a SunVTS test session of another workstation on the network. See SunVTS 6.2 User s Guide Sun Microsystems Inc. 4150 Network Circle Santa Clara Calif. 95054 U.S.A. 2006 which is incorporated herein by reference to demonstrate the level of skill in the art.

Herein when it is stated that software a computer program a test process an instruction etc. performs an action or actions those of skill in the art will understand that the action or actions are the result of executing one or more instructions on a processor or for example the result of executing one or more instructions in combination with automated hardware.

Also in one embodiment fault management controller is the Fault Manager daemon in the Fault Management Architecture FMA of the Solaris 10 operating system Solaris OS . The Solaris OS uses the Fault Manager daemon fmd 1M which starts at boot time and runs in the background to monitor the system. If a component generates an error the daemon handles the error by correlating the error with data from previous errors and other related information to diagnose the problem. Each problem diagnosed by the Fault Manager daemon is assigned a Universal Unique Identifier UUID . The UUID uniquely identifies this particular problem across any set of systems. When possible the Fault Manager daemon initiates steps to self heal the failed component and take the component offline. The Fault Manager daemon also logs the fault to the syslog daemon and provides a fault notification with a message ID MSGID .

In the embodiment of telemetry event generators are represented by environment monitor application and system load chron application . In one embodiment environment monitor application is the Continuous System Telemetry Harness discussed above and that description is incorporated herein by reference. Environment monitor application sends telemetry events including environmental information while system load chron application sends information on system stress etc.

In the following description of only the telemetry events from test system are considered. However in view of this description the processing of other telemetry events by TSSR controller is apparent and equivalent to that described more completely below.

In one embodiment TSSR controller runs as a system daemon process and is purely event driven. During initialization of TSSR controller controller registers with fault management controller for the trigger events of which controller wants to be notified. For the Fault Manager daemon embodiment the registration utilizes a module implemented as a dynamically load able object that is loaded into the Fault Management daemon s address space. This object subscribes to error events and fault events. On receiving a fault management error report the associated error event is a trigger event for TSSR controller . Fault manager controller includes a fault management error report in the trigger event sent to TSSR controller . Similarly a fault event is a trigger event and results in sending TSSR controller the corresponding report which can be used to provide feedback to the tests.

After registering with fault management controller TSSR controller processes i telemetry events from test system and ii trigger events from fault management controller . In this embodiment each telemetry information event includes at least a information to uniquely identify the sender of the event and b telemetry information about the stimulus or stimuli applied by the event provide to unit under test like test and sub test name currently being executed or current temperature etc. . The telemetry information event optionally can include additional information e.g. a header like the time when the event was generated operating system process ID PID of the process that generated the event etc. For example test process Test sends a telemetry information event T  where the unique identifier is T  and is the telemetry information that identifies a stimulus.

Upon receipt of telemetry information event T  TSSR controller extracts unique identifier T  for the sender and telemetry information from the event. Next TSSR controller determines whether the sender associated with unique identifier T  has previously sent an event e.g. the second column of index table is searched for unique identifier T . Since this is the first event from the sender unique identifier T  is not found. Thus TSSR controller assigns an index in this example to the sender See . Next TSSR controller accesses the location in current telemetry event list sometimes called snap shot list associated with the index and writes a name value pair the unique identifier and the telemetry information in list . This concludes the processing of event T  .

The use of table and list are illustrative only of structures in a memory of TSSR controller that are used to store information and are not intended to limit the invention to this specific embodiment. In view of this disclosure the information in these structures can be stored in a manner appropriate for a particular implementation of TSSR controller .

Next test process Test sends another telemetry information event T  . to indicate that a subprocess has been started. Upon receipt of telemetry information event T  . TSSR controller extracts unique identifier T  for the sender test process Test and telemetry information . from the event. Since the sender associated with unique identifier T  has previously sent an event TSSR controller retrieves the index from table . Next TSSR controller accesses the location in current telemetry event list associated with the index and writes a new name value pair the unique identifier and the telemetry information in list . Since only one entry per event sender is permitted in list the old data is overwritten in this embodiment. This concludes the processing of event T  . .

Telemetry information event T N A from test process Test N is received next by TSSR controller . Upon receipt of the event T N A TSSR controller extracts unique identifier T N for the sender and telemetry information A from the event. TSSR controller determines whether the sender associated with unique identifier T N has previously sent an event e.g. the second column of index table is searched for unique identifier T N. Since this is the first event from the sender unique identifier T N is not found. Thus TSSR controller assigns an index in this example to the sender See . Next TSSR controller accesses the location in current telemetry event list associated with the index and writes a name value pair the unique identifier and the telemetry in list . This concludes the processing of event T N A .

Test process Test N sends another telemetry information event T N B . Upon receipt of telemetry information event T N B TSSR controller extracts unique identifier T N for the sender test process Test N and telemetry information B from the event. Since the sender associated with unique identifier T N has previously sent an event TSSR controller retrieves the index from table . TSSR controller accesses the location in current telemetry event list associated with the index and writes a new name value pair the unique identifier and the telemetry information in list . This concludes the processing of event T N B .

Next test process Test N sends yet another telemetry information event T N C . Upon receipt of telemetry information event T N C TSSR controller extracts unique identifier T N for the sender test process Test N and telemetry information C from the event. Since the sender associated with unique identifier T N has previously sent an event TSSR controller retrieves the index from table . Next TSSR controller accesses the location in current telemetry event list associated with the index and writes a new name value pair the unique identifier and the telemetry information in list . This concludes the processing of event T N C . In this example list is an example of an internal data structure in memory of TSSR controller that holds a snap shot of the possible stimuli for an error or fault.

Fault Management controller sends a trigger event CE . Trigger event CE includes information to allow identification of the event type e.g. hardware error software error expiration of a timer etc. and optionally details about the triggering event e.g. location hardware component etc. Upon receipt of trigger event CE in one embodiment TSSR controller momentarily stop updating list . Any new telemetry events that are received while trigger event CE is being processed are queued for updating list i.e. the snap shot list after processing of trigger event CE is completed.

In response to trigger event CE TSSR controller creates a log entry in TSSR log i.e. logs the current state snap shot of the possible stimuli. Information logged includes details CEdata about trigger event CE along with an annotation of the snap shot capture of possible stimuli at the time of the error. Thus processing of reams of data in multiple logs in an attempt to identify processes and state information is no longer necessary. Log entry includes sufficient information for root cause and corrective action.

In one embodiment log entry is written in the XDR format. See for example Network Working Group RFC 1832 XDR External Data Representation Standard R. Srinivasan Sun Microsystems August 1995 which is incorporated herein by reference as evidence of the knowledge of those of skill in the art. To view the log the XDR data is rendered for example in either text of XML and printed or displayed for viewing.

The snap shot capability of TSSR controller allows better test instrumentation and error correlation e.g. ability to monitor what tests were running on test system and what the tests were doing when a particular error was observed. In addition to being useful during root cause and corrective action of a hardware issue such snap shot capabilities also lead to better test characterization both during experimental stages as well via data mining from the computer system manufacturing floor.

In one embodiment in response to trigger event CE TSSR controller provides dynamic feedback to test system e.g. to repeat a particular test or to launch a new test. This feedback loop on test performance allows improvement of test effectiveness and repeatability. The dynamic feedback also facilitates informed decisions when deploying the tests on a computer system manufacturing floor.

The dynamic feedback infrastructure can be used to implement smart testing capabilities based on feedback from TSSR controller . For example tests could be implemented to automatically repeat a test sequence on error detection. This can be useful in reducing the time to failure on the computer system manufacturing floor as many times the component rejection criteria requires multiple failure occurrences.

When test process Test has completed test process Test issues a telemetry terminate event T  . A telemetry terminate event does not carry any telemetry information in this embodiment. In response to telemetry terminate event T  TSSR controller extracts unique identifier T  and determines the index associated with unique identifier T . TSSR controller clears the entry in the index table and the entry in current telemetry event list associated with that index. Telemetry event providers the senders in the above description are expected to issue a telemetry terminate event before exiting.

A telemetry event provider may also issue a telemetry terminate event when there is no new telemetry to provide and the telemetry event provider knows that the previously reported information is out of date. As noted a telemetry terminate event instructs TSSR controller to throw away any previously reported information from that telemetry event provider.

There is a possibility that a telemetry event provider may be killed without sending a telemetry terminate event. Such a scenario can occur due to an exception encountered by the telemetry event provider or a hardware fault e.g. a process may be killed if that process steps on a memory location that has an uncorrectable error. In such cases the snap shot of the state of the stimuli being maintained in TSSR controller can get out of sync with the telemetry event providers actually executing. The telemetry information event last sent by the telemetry event provider that was killed would be left in snap shot structure indefinitely without any updates.

In one embodiment TSSR controller and all telemetry event providers Test . . . Test N are managed under a Service Management Framework such as smf 5 which is provided as a core part of the Fault Management Architecture available in the Solaris 10 operating system. As such any failure of a particular telemetry event provider results in automatic restart of the same. Hence no special handling is required in TSSR controller . Also the expectation of a high frequency of telemetry information events suggests that any check point mechanisms in TSSR controller may be unwarranted.

Where it is not possible to have a Service Management Framework TSSR controller handles any exceptions that might occur in the telemetry event providers. In one embodiment TSSR controller implements a life time for every telemetry event and flushes a telemetry event upon expiration of its lifetime.

In another embodiment TSSR controller extracts a process ID PID of the telemetry event sender from any telemetry information event or more accurately the process that will be ultimately responsible to send the telemetry terminate event for that particular stimulus. The PID is maintained in a separate list that has the unique name of the telemetry event provider and the PID. This list is periodically checked by TSSR controller for the presence of the PID and if a particular telemetry event provider does not exist corresponding telemetry information is automatically removed from snap shot .

In yet another embodiment one harness process spawns all telemetry event providers and the harness has the responsibility to generate the telemetry terminate events as the child processes exit. Thus the harness process is responsible to spawn all tests and then send the telemetry terminate event for each test. TSSR controller knows the PID of this harness process and monitors its existence. If the harness process were to get killed TSSR controller knows that the telemetry snap shot may be out of date from there on and self exits.

These embodiments for maintaining synchronization between stimuli information in the snap shot list and the executing telemetry event providers are illustrative only and are not intended to limit the invention. In view of this disclosure one of skill in the art can maintain synchronization in a particular application using any one or any combination of these or other techniques.

Since there can be multiple threads events accessing the name value list at the same time synchronization was implemented in the embodiment of . In general many threads can have simultaneous read only access to data while only one thread can have write access at any given time. However TSSR controller gives higher priority to reader threads e.g. trigger events that result in reading the snap shot name value list and write the list to the log file. TSSR controller allows one telemetry event at a time to update the snap shot name value list. In general TSSR controller enforces the rule that no writing to the snap shot name value is permitted if a reader thread is waiting to read or is reading the snap shot name value list. This allows TSSR controller to log the current snap shot name value list in response to a trigger event without any further changes to the name value list due to subsequent telemetry events.

TSSR controller processes at least three types of events i trigger events ii telemetry information events and iii telemetry terminate events using process . Telemetry events include telemetry information events and telemetry terminate events.

Upon receipt of a telemetry information event trigger event check operation determines whether a trigger event is reading the snap shot name value list i.e. whether a trigger event is active or whether a trigger event is waiting for completion of processing of a current telemetry event. If a trigger event is active or waiting processing transfers to queue operation and otherwise to telemetry event active check operation information operation .

Queue operation queues the telemetry information event for subsequent processing when no trigger event is active or waiting. This is represented in by queue operation transferring to trigger event check operation . Processing remains in check operation until there is no trigger event either active or waiting note multiple trigger events can be executed simultaneously as separate threads and then processing transfers to telemetry event active check operation . Check operation is used to indicate that processing of the telemetry information event is delayed until the processing of all trigger events is completed. should not be interpreted as requiring repetitive polling to determine whether any trigger event is active or waiting.

In this embodiment if TSSR controller receives a new telemetry event while a current telemetry event is being processed the new telemetry event is held until processing of the current telemetry event is completed. Also recall that priority is given to a trigger event that results in reading the snap shot name value list over a telemetry event that results in writing to the snap shot name value list. Thus if a trigger event also is received while the current telemetry event is being processed in this embodiment the new telemetry event is queued and the trigger event processing commences upon completion of the processing of the current telemetry event. In another embodiment when a current telemetry event is being processed and a new telemetry event is followed by a trigger event the new telemetry event is processed and then the trigger event is processed.

In the embodiment of a trigger event is always given priority. Thus when processing reaches telemetry event active check operation a trigger event is not active but a current telemetry event may be active. If a current telemetry event is active check operation transfers to trigger event active check operation to determine whether a trigger event arrived after the new telemetry event but before the current telemetry event completed processing. If a trigger event was received the new telemetry event is queued in queue operation and otherwise processing returns to check operation . Conversely if another telemetry event is not being processed upon entry to check operation check operation transfers to extract information operation .

Extract information operation extracts the telemetry information and the unique identification of the sender from the telemetry information event. In one embodiment application programming interface API int sendTestInfoEvent char testName int instance no nvlist t nvl is used by any telemetry event provider to send a telemetry information event. In this embodiment telemetry events are synchronous. This means that when a test process i.e. a telemetry event provider calls the API to send a telemetry event the API function does not return until the event has been processed thereby preventing the stimuli from changing state once a trigger event has been received

In API sendTestInfoEvent a test name parameter testName and an instance name parameter instance no are used to uniquely identify the sender of the event. In one implementation a concatenation of the test name and instance number is used as the unique name when adding the information to snap shot name value list nvlist. A third parameter nvl a name value list forms the value of the name value pair to be added into snap shot name value list nvlist. Thus in this embodiment extraction operation i creates a unique identifier using the first two parameters and uses the unique identifier as the name in the name value pair stored in the snap shot and ii uses third parameter nvl as the corresponding value . Snap shot name value list nvlist is therefore a name value list of name value lists with each name value pair representing a unique telemetry provider name and corresponding telemetry information parameter nvl saved as value . Extract information transfers to new sender operation .

If this is a first telemetry information event from a sender a new sender check operation transfers to generate index operation and otherwise to determine index . Both operations obtain an index to the snap shot name value list as described above and transfer to write operation .

In write operation the telemetry information from the telemetry event is written in the snap shot name value list at the location addressed used the index. If there is already information in that location the old telemetry information in the snap shot name value list is overwritten. This completes the processing of the telemetry information event.

Upon receipt of a telemetry terminate event by TSSR controller operations A to A are performed for the telemetry terminate event. Operations A to A are equivalent to operations of to and so the descriptions of those operations are incorporated herein by reference with the telemetry information event replaced with the telemetry terminate event.

Extract information operation extracts the unique identification of the sender from the telemetry terminate event. In one embodiment application programming interface API int sendTestDoneEvent char testName int instance no is used by any telemetry event provider to indicate the end of a test. This API is registered by the test to be executed during the cleanup routine or test end in general.

In this embodiment extract information operation extracts the test name and the instance name and concatenates the two to form the unique identifier and then transfers to determine index operation that in turn determines the index for the name value list for the unique identifier. Operation transfers to clear operation .

In clear operation TSSR controller simply removes any name value pair in snap shot name value list nvlist that matches the name formed by concatenation of test name and instance number. This completes the processing of the telemetry terminate event.

Upon receipt of a trigger event by TSSR controller TSSR controller determines whether a telemetry event is currently being processed in telemetry event active check operation . If a telemetry event is not being processed check operation transfers to update log operation . Otherwise processing remains in telemetry event active check operation until the processing of the telemetry event completes and then transfers to update log operation .

In update log operation controller adds snap shot name value list nvlist and a report for the trigger event in tandem to the log file.

In one embodiment the synchronization described with respect to is implemented using a special read write lock. In general a read write lock allows many threads to have simultaneous read only access to data while only one thread can have write access at any given time. However with this special read write lock TSSR controller gives higher priority to the reader threads i.e. trigger events. TSSR controller grabs the write lock whenever the snap shot name value list is updated in response to a telemetry vent. Similarly TSSR controller grabs the read lock before logging the snap shot list as a log entry. Use of this special read write lock allows TSSR controller to enforce the rule that no write locks are given if a reader thread is waiting on acquiring a lock. This allows TSSR controller to log the current snap shot name value list in response to a trigger event without any further changes to the name value list due to subsequent telemetry events.

The APIs in the above description are illustrative only and are not intended to limit the invention to this specific embodiment. are a computer program listing written in the C programming language for another embodiment of the APIs. In this embodiment TSSR controller is referred to as a TSSR agent. Test system is the VTS system available from Sun Microsystems as described above. Fault management controller is the Fault. Management daemon in the Fault Management Architecture in the Solaris 10 operation system.

Some sample log entries are presented below in Tables 1 to 3. In a first case the trigger event was a correctable memory error which occurred while running tests vmemtest and pmemtest in SunVTS functional mode. Both tests were executed with 6 instances each meaning that there could be at most 6 processes spawned for each of the tests . Internally SunVTS diagnostic tool manages each instance and the test instances behave differently based on instance number and total number of instances. For example the memory locations accessed by test pmemtest would be different depending on the instance number and total number of instances.

At the time of the error the SunVTS user interface showed that test vmemtest instance 0 and instance 5 were executing concurrent to test pmemtest instances 2 4 and 5. This information is not logged by default by SunVTS diagnostic tool but can be of interest for root cause and corrective action on occurrence of an error. The log entry in Table 1 below shows the snap shot of this information automatically captured by TSSR controller along with the header and the error information The date is fictitious .

Another test ramtest was modified to provide information about subtests as well. An example of the log entry is provided in TABLE 2.

Once the tests had completed execution an error event was injected to show that TSSR agent correctly identified that no tests were running. This log entry is shown in TABLE 3.

In many new systems logical domains where multiple images of an operating system can be running on the same piece of shared hardware are used. In such cases a hardware error may be stimulated by an activity in any of the logical domains. An application running in a single domain does not have the system wide view its visibility is limited to the logical domain in which it resides. TSSR controller can support logical domains by changing the event transport.

Herein a computer program product comprises a computer readable medium configured to store or transport computer readable code for one all or any combination of test system TSSR controller and fault management controller or in which computer readable code for one all or any combination of test system TSSR controller and fault management controller is stored. Some examples of computer program products are CD ROM discs DVD discs flash memory ROM cards floppy discs magnetic tapes computer hard drives servers on a network and signals transmitted over a network representing computer readable program code. A tangible computer program product comprises a computer readable medium configured to store computer readable code for one all or any combination of test system TSSR controller and fault management controller or in which computer readable code for one all or any combination of test system TSSR controller and fault management controller is stored. Some examples of tangible computer program products are CD ROM discs DVD discs flash memory ROM cards floppy discs magnetic tapes computer hard drives and servers on a network.

In view of this disclosure one all or any combination of test system TSSR controller and fault management controller can be implemented in a wide variety of computer system configurations using an operating system and computer programming language of interest to the user. In addition instructions for one all or any combination of test system TSSR controller and fault management controller could be stored as different modules in memories of different devices. For example instructions for one all or any combination of test system TSSR controller and fault management controller could initially be stored in a server computer and then as necessary a module of the method could be transferred to a client device and executed on the client device.

In yet another embodiment instructions for the method are stored in a memory of another computer system. Stored instructions for the method are transferred over a network to the unit under test.

Test system TSSR controller and fault management controller are implemented in one embodiment using a computer source program. The computer program may be stored on any common data carrier like for example a floppy disk or a compact disc CD as well as on any common computer system s storage facilities like hard disks. Therefore one embodiment of the present invention also relates to a data carrier for storing a computer source program for carrying out the inventive method. Another embodiment of the present invention also relates to a method for using a computer system for carrying out the method. Still another embodiment of the present invention relates to a computer system with a storage medium on which a computer program for carrying out the method is stored.

While test system TSSR controller and fault management controller hereinbefore have been explained in connection with one embodiment thereof those skilled in the art will readily recognize that modifications can be made to this embodiment without departing from the spirit and scope of the present invention.

