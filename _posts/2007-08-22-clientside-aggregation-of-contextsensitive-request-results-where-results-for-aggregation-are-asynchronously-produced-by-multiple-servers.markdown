---

title: Client-side aggregation of context-sensitive request results where results for aggregation are asynchronously produced by multiple servers
abstract: The present invention discloses a solution for handling HTTP requests for content produced asynchronously by multiple servers, where a requesting client aggregates content. In the solution, a client can issue a content request to a request receiving server. The content request can define a request context. The request receiving server can deliver initial content including placeholders to the client, can issue asynchronous requests to multiple placeholder content servers, and can thereafter terminate threads/processes and can free resources involved in handling the request context. Each of the placeholder content servers can process one of the asynchronous requests and can convey placeholder content results to a result distribution service. The result distribution service can provide the client with the placeholder content. The client can aggregate the content from all sources.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09069870&OS=09069870&RS=09069870
owner: INTERNATIONAL BUSINESS MACHINES CORPORATION
number: 09069870
owner_city: Armonk
owner_country: US
publication_date: 20070822
---
This continuation in part application claims the benefit of U.S. patent application Ser. No. 11 553 103 filed Sep. 19 2006 and the benefit of U.S. patent application Ser. No. 11 846 423 filed Aug. 28 2007 which are incorporated by reference herein.

The present invention relates to HTTP request handling and more particularly to client side aggregation of context sensitive request results where results for aggregation are asynchronously produced by multiple servers.

In an application server architecture requests are made for resources URLs that often include a set of operations to be performed such as includes or forwards to other resources. Generally a small percentage of the operations are expensive in terms of incurred delay. The synchronous nature of a conventional request lifecycle causes a delay incurred by one operation to affect throughput as a whole. Additionally resources of the server that are primarily responsible for handling a request are tied up until the request context has been entirely processed and a response conveyed to a requesting client. Further the requesting client does not receive a response to their request until the primary server has aggregated responses from all operations which execute sequentially.

Current solutions to the above problem include utilizing frames or server side includes SSI where each portion of a requested Web page is associated with a separate distinct request from a client. Use of frames and SSIs however results in an inability to share context related to the original request among the separate distinct requests. Sharing context among these requests is highly desired because the operations called by the requests need access to the original request information sent by the client or set in the processing before dispatch.

U.S. patent application Ser. No. 11 456 905 disclosed a solution for aggregating content from different container types and languages with shared request context synchronously. That is the referenced solution provided an extensible framework that allows a Remote Request Dispatcher RRD to handle portlets and other containers. This technology permits a server to distribute request handling operations across a set of servers. Thus a single request context is handled by multiple servers. The disclosed solution however still requests that a primary server waits for remote content to return de serializes it and return serialized responses which occur synchronously.

US patent application Ser. No. 11 846 423 disclosed a solution for client side aggregation of asynchronous context sensitive request operations in a single application server environment. This solution solved a problem of a server or proxy being responsible for aggregating operation results which can be costly in terms of memory and request processing resources. Instead US patent application Ser. No. 11 846 423 offloads aggregation responsibility to a client. This client side aggregation however was limited to a single server and was not able to pass request context to multiple servers.

The problem solved by the present invention is that of asynchronously aggregating remote content from multiple servers within the same request context. There does not appear to be any known solutions to this problem as even the concept of aggregating content from different container types and languages with shared request context e.g. U.S. patent application Ser. No. 11 456 905 is considered unique as is the concept of client side aggregation of asynchronous context sensitive request operations e.g. U.S. patent application Ser. No. 11 846 423 .

The present invention discloses a solution for client side aggregation of context sensitive request results where results are asynchronously handled by multiple servers. In the solution a client can request a piece of content from a public server where the requested content is an aggregation of several pieces of remote content. The remote content can optionally be provided by non public servers. The public server can return content to the client which contains one or more placeholders. The public server can then initiate one or more asynchronous processes threads to remote servers each of which is responsible for providing content for a placeholder. Once each of the remote servers is finished processing content which is still part of the same request context the content can be conveyed to a result distribution service. The client can send queries to the result distribution service one query for each placeholder. As placeholder content becomes available it can be conveyed to the client by the service. The client can complete a portion of a presented Web page associated with the service provided content as it is received. Other portions of the presented Web page do not need to be updated.

The disclosed solution has clear advantages over conventional technologies and over U.S. patent application Ser. No. 11 533 103 and U.S. patent application Ser. No. 11 846 423. Specifically all RequestDispatcher includes initiated by the originating server are handled asynchronously by multiple servers and a load is distributed evenly among the requesting client and the content processing or providing servers which allows for greater throughput than any known solution. The client receives content in stages as soon as it is available which enhances a user s experience. A request receiving server is not burdened with aggregating content from multiple remote servers and is not forced to expend memory or other limited resources for the duration of a request context. Rather once the request receiving server has conveyed content with placeholders to a client and spawned threads for placeholder content to other servers the request receiving server is through with its portion of the request context. The result distribution service can be any component able to service RESTful e.g. HTTP requests such as a servlet a Java Service Page JSP an ASP and ESB component.

The present invention can be implemented in accordance with numerous aspects consistent with the material presented herein. For example one aspect of the present invention can include a method for handling client request within a request context. The method can include a step of a client issuing a content request to a request receiving server. The content request can define a request context. The request receiving server can deliver initial content including placeholders to the client can issue asynchronous requests to multiple placeholder content servers and can thereafter terminate threads processes and can free resources involved in handling the request context. Each of the placeholder content servers can process one or more of the asynchronous requests and can convey placeholder content results to a result distribution service. The result distribution service can provide the client with the placeholder content. The client can aggregate the content from all sources.

Another aspect of the present invention can include a system for handling client requests for a request context that includes a client configured to convey a content request to a remotely located content server. The content request can define a request context. Request results can be presented within the interface of the client. The request results can include content produced by two or more servers that each asynchronously perform operations to produce that server s content. The client can aggregate the content from the content producing servers.

Still another aspect of the present invention can include a result distribution service used in a system that handles content requests processed by multiple services where the content requests are aggregated by a client. The result distribution service can receive and store results related to a request context from one or more different content providing servers. The result distribution service can also receive asynchronous requests from a client which initiated a content request that defines the request context. In response to each received client request the result distribution service can provide the stored results obtained from the content providing servers to the client as these results become available to the service.

It should be noted that various aspects of the invention can be implemented as a program for controlling computing equipment to implement the functions described herein or as a program for enabling computing equipment to perform processes corresponding to the steps disclosed herein. This program may be provided by storing the program in a magnetic disk an optical disk a semiconductor memory or any other recording medium. The program can also be provided as a digitally encoded signal conveyed via a carrier wave. The described program can be a single program or can be implemented as multiple subprograms each of which interact within a single computing device or interact in a distributed fashion across a network space.

The server at this point has completed it s handling of the request and can release any and all resources and stored content dedicated to handling the request . That is an original request handling thread process is freed up since additional results generated by servers e.g. placeholder filler content are later retrieved by other requests from the result distributing service .

The server can process the asynchronous request and provide a result to the result distributing service . Similarly the server can process asynchronous request and provide result to the result distributing server . Once each of the servers and has provided request results or that server or has completed tasks required of it for the request context. All threads processes spawned to handle a request can be terminated and associated resources released.

The client can asynchronously request placeholder content i.e. content for placeholder provided by server and can asynchronously request placeholder content i.e. content for placeholder provided by server from the result distribution service . When the requested content becomes available the result distribution service can deliver it to the client as results and . Upon receiving the results an associated placeholder or can be populated with the content by updating an interface region associated with the results . Other portions of the interface need not be updated.

In system the servers and can be computing systems capable of handling Hypertext Transfer Protocol HTTP requests from a network and of providing HTTP responses to these requests. Each of the servers can be associated with a Uniform Resource Identifier URI used for server identification when conveying HTTP requests. The HTTP responses can include static and dynamic content. Typically the initial content and placeholder produced by server will include static content and the placeholder content produced by the servers and will include dynamic content. Each of the servers and can include numerous optional features such as authentication support encrypted channel support e.g. HTTPS support through Transport Layer Security TLS technologies Secure Sockets Layer SSL technology and the like content compression and decompression support and the like. Each of the servers can allocate resources to process a received request and can release these resources once that server s processing tasks are completed. That is a time period in which any of the servers is used to handle the request context is less than a total time needed to handle the request context. The servers can be implemented within physical machines as well as virtual computing devices such as those provided through virtualization solutions e.g. VMWARE MS VIRTUAL SERVER and the like .

One or more of the servers can be private servers that are not directly accessible over a public network. The private servers can be firewall protected can be part of a virtual private network VPN linked to the server and can be part of a private network that server is permitted to access. Each of the servers can also be public servers. Although two servers are shown in system that provide placeholder content the invention is not to be limited in this regard and any number of placeholder content providing servers can be utilized. Additionally although system shows that each request issued by server is handled by a single server which provides results to service other arrangements are contemplated. For example server can initially process request convey results to an intermediate server not shown for further processing and the intermediate server can send results to the service .

The result distribution service can be a server side software program able to handle HTTP and other RESTful messages. For example the result distribution server can be implemented as a servlet a JAVA Server Page JSP an Active Server Page ASP an Enterprise Java Bean EJB an Enterprise Service Bus ESB service and the like. The service can be associated with a URI to which the servers can convey responses and and to which the client can convey the requests . The result distribution service can reside within server server or any other server. When the service is associated with a component other than the one addressed in the original HTTP request then system must implement measures to ensure that the URLs of the service are available to the servers and the client .

The client can be any computing device capable of sending HTTP request and capable of rendering responses to these requests. For example the client can include a personal computer a notebook computer a mobile computing device a smart phone a personal data assistant PDA an embedded computing device an electronic gaming system and the like. Client can include a browser which handles HTTP communications. The browser can be linked to an interface with which a user interacts with client . The interface can be a graphical user interface GUI a multi modal interface a voice user interface VUI and the like. Interface can include content and placeholders .

Each placeholder can be a container for Web content. Each placeholder can be filled with dynamically generated content. The placeholders can include widgets portlets and other types of content. In one embodiment the placeholder stands in place of content from a remote request dispatcher RRD request. Initially the placeholders can lack content. Each time a placeholder response is received a related placeholder can be completed. The content can be rendered even when the placeholder content is unavailable. In one embodiment the placeholders can be objects conforming to a browser object model BOM or any document object model DOM .

In one implementation the client side aggregation of content can occur in a user transparent fashion. For example the browser can be enhanced with a plug in or extension that automatically submits the requests until responses are received. In one embodiment the server can convey an address of the service to the client and to the servers . so that each computing device is able to determine a target for requesting e.g. client and or delivering e.g. servers content. In another embodiment the public server can convey a user identifying address to the servers which are in turn conveyed to the service . The service can then deliver results to the client referenced by the address and or the service can then convey a message to the client so that the client knows where to send requests .

The various components of system can be communicatively linked via a network not shown . The network can include components capable of conveying digital content encoded within carrier waves. The content can be contained within analog or digital signals and conveyed through data or voice channels and can be conveyed over a personal area network PAN or a wide area network WAN . The network can include local components and data pathways necessary for communications to be exchanged among computing device components and between integrated device components and peripheral devices. The network can also include network equipment such as routers data lines hubs and intermediary servers which together form a packet based network such as the Internet or an intranet. The network can further include circuit based communication components and mobile communication components such as telephony switches modems cellular communication towers and the like. The network can include line based and or wireless communication pathways.

In diagram a client can convey a request to a server . The request can require content from the server and from servers . For example the server can provide static content for the request and the servers can provide dynamic content. The server can establish a container or placeholder for each dynamic content segment. Then the server can generate and convey an asynchronous request to server for content relating to one of the containers. The server can generate and convey a separate asynchronous request for content relating to a different container to server . Additionally the server can send the static content containing placeholders to the client which can immediately present the content including blank placeholders within an interface. At this point processes threads relating to request can be terminated by server which can free all resources related to handling request .

Server can asynchronously process request and generate response which is sent to service . Server can process request and generate response which is conveyed to service . Each server can terminate all processes threads relating to request and release related resources once that server has conveyed response or to service .

The client can asynchronously and repetitively request content from the service where the requested content is used to fill placeholders or containers. When request satisfying content is registered with the service it can be provided to the client in response to the related request . Upon receiving the placeholder content or the client can immediately render the content or and present or in an interface.

It should be appreciated that the details of flow diagram are used herein to illustrate a technology for client side aggregation of a set of asynchronous operations performed by multiple servers in response to a single request context. Specific process flows of diagram are to be construed liberally within the scope of the invention disclosed as a whole. That is the invention is not to be limited to the precise flow order shown and derivatives of the diagram that serve an equivalent purpose are to be considered as included within the scope of the invention. For example diagram shows a request response polling approach for obtaining content from the service . In an alternative implementation still within scope of the invention a subscription methodology can be used where the client subscribes with the service and the service automatically provides updated content as per the subscription as the content becomes available.

The present invention may be realized in hardware or a combination of hardware and software. The present invention may be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software may be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention also may be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program in the present context means any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation b reproduction in a different material form.

This invention may be embodied in other forms without departing from the spirit or essential attributes thereof. Accordingly reference should be made to the following claims rather than to the foregoing specification as indicating the scope of the invention.

