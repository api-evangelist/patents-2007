---

title: Handling potential deadlocks and correctness problems of reduce operations in parallel systems
abstract: In one embodiment, the present invention includes a method for executing a first reduction operation on data in an input buffer, executing a second reduction operation on the data, where the second reduction operation has a higher reliability than the first reduction operation, and comparing the first and second results. Other embodiments are described and claimed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08621484&OS=08621484&RS=08621484
owner: Intel Corporation
number: 08621484
owner_city: Santa Clara
owner_country: US
publication_date: 20070830
---
Message passing serves as an effective programming technique for exploiting coarse grained concurrency on distributed computers as seen in the popularity of the Message Passing Interface MPI . Unfortunately debugging message passing applications can be difficult. Analysis tools for MPI applications produce tracefiles that can be analyzed with a trace analyzer performance analysis tool. In MPI processes such tools record calls to the MPI library and transmitted messages and allow arbitrary user defined events to be recorded. Instrumentation can be switched on or off at runtime. While such tools can aid in detecting errors current correction checking tools cannot adequately detect transmission and implementation problems for various operations such as reduce operations.

Hardware driver and system software problems can introduce bit errors into data transmitted between processes in a parallel application or lead to truncated transmissions. Traditionally checksums are used to detect errors. Error correction codes help to reconstruct the original data. This can be done at all levels in a communication stack as well as added to it at the application level. Parallel reduce operations differ from verbatim transmission of data in that they modify the data in some configurable and perhaps programmable way while the data is in transmission.

In addition deadlocks caused by communication between processes in parallel applications can occur. Such deadlocks may include actual or real deadlocks as well as potential deadlocks which are deadlocks that only occur on specific platforms or configurations and thus cannot be detected using traditional monitoring of application progress and or timeouts as with actual deadlocks. Accordingly current correction checking tools cannot adequately detect potential conflicts.

Embodiments may detect incorrect execution of a reduce operation without requiring changes inside a communication stack or in an application using the communication stack. Embodiments may be based on the fact that a reduce operation can be executed twice without violating the semantic of the call once using a first implementation which is to be checked and which might produce incorrect results or fail then once more with a second implementation e.g. a more reliable implementation that protects itself better against network problems and or uses different algorithms to avoid implementation mistakes. In some embodiments both executions of the operation may use original buffers provided by the application as the original memory layout might be hard to reproduce and an application callback might expect that memory layout. Note that while the order of reliable and original implementation may enable the output buffer to contain the correct results afterwards the other order also works either without correcting incorrect results or by copying the correct result from the intermediate buffer over the output buffer at the end.

The Message Passing Interface MPI is one example of a standard which defines several reduce operations. They are implemented by one function per operation that each process in a communication context must call once to complete the operation. Each function is passed a buffer with the input data a buffer for the resulting data and additional information. One of these parameters determines which operation is to be applied to the data. Possible operations include MIN MAX SUM of integer and floating point values bit operations on integer values and transformations implemented by an application callback.

The different reduce operations have different semantics regarding how the data is processed and who receives the results. Some examples each of which may correspond to a different application programming interface API are MPI Reduce which applies the indicated operation to all input data and stores result in one root process MPI Allreduce which performs in the same memory and stores results on all processes MPI Scan which is prefix reduction i.e. for each process the operation is applied to the input data of all preceding processes and its own input and the result stored in the processes. Of course embodiments can be used in connection with other reduce operations.

Referring now to shown is a flow diagram of a method in accordance with one embodiment of the present invention. As shown in method may begin by intercepting a function call made by an application in each process block . A correctness checking library may intercept the call in one embodiment. Then a first e.g. an original implementation of a reduce operation may be executed block . Next it may be determined whether the operation was successful diamond . If not control passes to block where a warning may be generated regarding the failed operation. In various embodiments such warning message may be sent to an error log although in other implementations the warning may be sent to further locations such as a trace collector or analyzer for example. Next it may be determined if the problem is fatal diamond . If so execution of the method may conclude. Otherwise control passes to block discussed further below.

Referring still to if at diamond it is determined that the first reduce operation is successful the preliminary results may be copied from an output buffer in which the results are written into an intermediate buffer block . Then a second reduce operation e.g. a more reliable reduce operation may be executed. For example each process sends data from its input buffer along with a checksum to the root process the root process checks the received data and accumulates them using a specified operation. Then it may be determined whether the preliminary results are available in the intermediate buffer diamond . If not results of the second reduce operation may be returned block .

Referring still to if instead at diamond it is determined that preliminary results are available in the intermediate buffer control passes to diamond . At block the results of the second reduce operation present in the output buffer may be compared against the preliminary results in the intermediate buffer. The result of the original implementation in this intermediate buffer is checked after executing the reliable implementation by comparing the final output buffer against the intermediate buffer element by element. Based on the comparison it may be determined whether the results are equal or not. Two floating point values may be considered equal if they do not differ by more than a certain error delta whereas integer values should match exactly. If the results are equal the result may be returned immediately block . Otherwise a warning regarding a mismatch may be generated and sent block e.g. to the error log. Still further control may pass to block for returning results of the first or the second reduce operations.

While shown with this particular implementation in the embodiment of the scope of the present invention is not limited in this regard. For example in some embodiments in addition to the preliminary result the original value in the input buffer on which the reduce operation is performed may be copied to another buffer for later comparison if a certain function call is made for example if the MPI 2 MPI IN PLACE functionality is used. This may be done because with MPI IN PLACE the original MPI implementation will overwrite the input data in the input buffer with the result. Because they are only used internally these intermediate buffers can have an arbitrary organization as long as the order of all elements of the original buffer is preserved. Note that the steps necessary to handle MPI IN PLACE are not shown in for simplicity.

In this embodiment by executing the reliable implementation last the application s output buffer always contains the correct result at the end and a fatal error which prevents execution of the original implementation is detected sooner. Alternatively the order of the reduce operations could be reversed with one additional optional step at the end to overwrite incorrect results with correct ones if error correction is desired in addition to error detection.

Interception of MPI calls can be done by a separate library using the MPI Profiling Interface PMPI via an additional layer of indirection in an MPI implementation using binary instrumentation or in another such manner. shows an embodiment in which the reliable reduce operation is executed by exchanging data over an Ethernet interconnect. Shown in is a block diagram of the interrelation between multiple processes in accordance with an embodiment of the present invention. As shown in a plurality of processors generically processor are present. Each processor may include a process or application generically application . In some embodiments the example system of is an exemplary distributed application which is cooperatively implemented via generally contemporaneous execution of machine accessible instructions of multiple processors . In particular a first process i.e. software application may be executed on first processor and a second software application may be executed by second processor which cooperatively realize the example distributed application using any variety of distributed computing algorithms techniques and or methods. In the example system of the example software applications implement different machine accessible instructions. Alternatively the example software applications may implement similar and or identical machine accessible instructions.

For simplicity and ease of understanding the following disclosure references the example two processor system of . However distributed applications and or the methods and apparatus disclosed herein to perform distributed reduction operations may be implemented by systems incorporating any number and or variety of processors. For example one or more processes of a distributed application may be implemented by a single processor a single process may be implemented by each processor etc. Applications may be developed using any variety of programming tools and or languages and may be used to implement any variety of distributed applications. In the example system of processors may be implemented within a single computing device system and or platform or may be implemented by separate devices systems and or platforms. Further processors may execute any variety of operating system s .

As further shown in each application may make application programming interface API calls to a library. More specifically API calls and more particularly MPI calls may be made to a correctness checking library generically library . In various embodiments these libraries may perform reduction operations in accordance with an embodiment of the present invention. For example libraries may perform more rigorous reduce operations which may be generated by transmission over an interconnect which in one embodiment may be an Ethernet connection that communicates according to a transmission control protocol internet protocol TCP IP over Ethernet although the scope of the present invention is not limited in this regard.

Libraries thus intercept each API call made by an associated software application potentially modify the intercepted calls and then among other things call the API function specified by the intercepted API call. Further the example libraries of implement a second reduce operation for each API call utilized by applications .

When a software application e.g. process sends application data to another software application e.g. process via an MPI message that is associated with a reduce operation library associated with the software application intercepts the MPI call made by the sending process to a corresponding messaging interface also referred to as MPI modules generically interfaces of which facilitate the exchange of for example distributed application messages between applications . Library then calls the original MPI function specified by the intercepted MPI call and provided by the messaging interface to send the application data via a first MPI message to the receiving processor .

In addition libraries may also generate PMPI calls to MPI modules . In turn these MPI modules may perform reduce operations which may be transmitted via a second interconnect which in one embodiment may be a fast interconnect such as a point to point interconnect although the scope of the present invention is not limited in this regard.

Messaging interfaces may implement a library and or a run time system implementing messaging functions in accordance with a messaging passing interface MPI standard for distributed applications. However the messaging interface may implement any variety of additional and or alternative messaging interface s for distributed computing processes. In the example system of the example messaging interfaces provide APIs to allow applications to interact with each other.

Other implementations are possible for example by using the original MPI communicator and additional collective calls to transmit data or an additional communicator and point to point messages. Any number of communication contexts may be used to facilitate communications between the processes implementing a distributed application. In the example of MPI communicators may be used to define one or more communication contexts. MPI communicators specify a group of processes inside and or between which communications may occur such as to logically group the processes to form the example distributed application of i.e. application MPI communicators . A distributed application may include more than one MPI communicator for example an MPI communicator by which all of the processes of the distributed application may communicate i.e. a global MPI communicator an MPI communicator between two specific processes of the distributed application i.e. a point to point MPI communicator etc. Note that sending point to point messages on the original communicator might interfere with message operations started by the application and thus would change the semantic in an incorrect way.

As described above potential deadlocks exist in MPI applications because the standard does not specify whether some data transmission primitives block until the recipient is ready to receive the data or buffer the data and let the caller proceed. A typical example is a head to head send in which a first process issues a MPI Send to a second process and a second process issues a MPI Send to the first process. Accordingly a potential deadlock may exist between issuance of these send calls and a corresponding receive call on each process i.e. a MPI Recv call in the first process and a MPI Recv call in the second process. If the implementation of MPI Send or the network buffers the messages sent by that call then both processes continue to the MPI Recv call and the application proceeds. However if the MPI Send call waits for the recipient to enter its MPI Recv call then the application deadlocks. Other sources of non deterministic data transmission are collective operations such as a broadcast communication e.g. MPI Bcast where the sending process es may or may not proceed before their recipients are ready to receive.

Embodiments may enable interception of non deterministic message send calls and implement them using deterministic primitives which are guaranteed to wait for the recipient of the message. In addition a synchronizing collective call may be added to non deterministic collectives thus ensuring that they always block until all involved processes enter them. Then another component detects real deadlocks using one or more conventional methods such as timeouts progress monitoring etc.

Referring now to shown is a flow diagram of a method in accordance with an embodiment of the present invention. As shown in method may be used to detect the presence of potential deadlocks. As shown in method may begin by intercepting a non deterministic message send call block . For example an error correctness checking library may receive such a call from a first process to a second process. The library may then replace the non deterministic message send call with a deterministic primitive . Such primitive may guarantee that a waiting period occurs such that the recipient receives the message.

Referring still to it may be determined also whether a non deterministic collective call has been received diamond . Such a collective call may correspond to a broadcast message although the scope of the present invention is not limited in this regard. If such a message call is received the correctness checking library may add a synchronizing collective call to the non deterministic collective call block . For example the deterministic collective may ensure that other calls are blocked until all processes enter the collective call.

Referring still to normal execution may continue after insertion of these primitives and calls as indicated. Then it may be determined whether an actual deadlock has been detected diamond . While the scope of the present invention is not limited in this regard such detection may be via traditional deadlock detection mechanisms such as timers progress monitoring or so forth. If such an actual deadlock occurs the deadlock may be reported block . For example an error log may report the deadlock or a message may be sent to another location. Accordingly method concludes. While shown with this particular implementation in the embodiment of the scope of the present invention is not limited in this regard.

Table 1 below shows how embodiments may be applied to MPI communications. Note that a MPI Barrier call could be added to all collective operations using one to many or many to one operations instead is an optimization that can be done if the synchronization in the other direction is already guaranteed by the original call. Alternatively a combination of one to many and many to one calls could be used to achieve the same effect.

Note that in some embodiments a method such as that described with regard to may be implemented in the system of . In these embodiments correctness checking libraries may intercept MPI calls and insert the deterministic calls before forwarding to interfaces . Then interconnect may monitor progress e.g. via transmission of control messages between applications to detect when an actual deadlock exists during execution of code including the deterministic primitives. However other configurations are possible. For example call replacement may be done inside interfaces e.g. via a configuration option via dynamic function replacement of binary instrumentation.

Accordingly embodiments may reliably detect potential deadlocks in code. Still further embodiments may be implementation generic and may be used with empty messages. Embodiments thus provide flexibility that can enable dynamic changing of the code changes on a case by case basis. Thus embodiments may detect potential deadlocks by turning them into real deadlocks via function interception. Still further some embodiments may suppress triggering of a deadlock for specific send operations that a user has found already but cannot fix. Furthermore embodiments may be configurable such that only potential deadlocks for messages larger than a configurable size may be triggered.

Embodiments may be suited for many different types of platforms. Referring now to shown is a block diagram of a multiprocessor system in which embodiments of the present invention may be implemented. As shown in multiprocessor system is a point to point interconnect system and includes a first processor and a second processor coupled via a point to point interconnect . However in other embodiments the multiprocessor system may be of another bus architecture such as a multi drop bus or another such implementation. As shown in each of processors and may be multi core processors including first and second processor cores i.e. processor cores and and processor cores and although other cores and potentially many more other cores may be present in particular embodiments.

Still referring to first processor further includes a memory controller hub MCH and point to point P P interfaces and . Similarly second processor includes a MCH and P P interfaces and . As shown in MCH s and couple the processors to respective memories namely a memory and a memory which may be portions of main memory e.g. a dynamic random access memory DRAM locally attached to the respective processors.

First processor and second processor may be coupled to a chipset via P P interconnects and respectively. As shown in chipset includes P P interfaces and . Furthermore chipset includes an interface to couple chipset with a high performance graphics engine via a bus .

As shown in various I O devices may be coupled to first bus along with a bus bridge which couples first bus to a second bus . In one embodiment second bus may be a low pin count LPC bus. Various devices may be coupled to second bus including for example a keyboard mouse communication devices and a data storage unit which may include code in one embodiment. Further an audio I O may be coupled to second bus .

Embodiments may be implemented in code and may be stored on a storage medium having stored thereon instructions which can be used to program a system to perform the instructions. The storage medium may include but is not limited to any type of disk including floppy disks optical disks compact disk read only memories CD ROMs compact disk rewritables CD RWs and magneto optical disks semiconductor devices such as read only memories ROMs random access memories RAMs such as dynamic random access memories DRAMs static random access memories SRAMs erasable programmable read only memories EPROMs flash memories electrically erasable programmable read only memories EEPROMs magnetic or optical cards or any other type of media suitable for storing electronic instructions.

While the present invention has been described with respect to a limited number of embodiments those skilled in the art will appreciate numerous modifications and variations therefrom. It is intended that the appended claims cover all such modifications and variations as fall within the true spirit and scope of this present invention.

