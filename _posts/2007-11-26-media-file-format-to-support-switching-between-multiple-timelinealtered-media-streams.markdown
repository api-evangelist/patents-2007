---

title: Media file format to support switching between multiple timeline-altered media streams
abstract: Media content is streamed from a server computer to a client computer. A media file format is used to store data for multiple timeline-altered streams that provides support for switching between the different timeline-altered streams during their presentation. In one aspect, a user can switch between different timeline-altered streams. Upon receiving a user request to switch to a particular timeline-altered stream (the target stream), the client computer accesses a time code stream data object corresponding to the current data unit being presented. The time code stream data object identifies a primary stream presentation time corresponding to the data unit. The client then uses the primary stream presentation time to index into a table of mappings to byte offsets. The table provides a mapping of the primary stream presentation time to a corresponding byte offset of the target stream.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07472198&OS=07472198&RS=07472198
owner: Microsoft Corporation
number: 07472198
owner_city: Redmond
owner_country: US
publication_date: 20071126
---
This is a continuation of U.S. patent application Ser. No. 09 564 297 titled Media File Format to Support Switching Between Multiple Timeline Altered Media Streams filed on May 3 2000 which is hereby incorporated in its entirety by reference.

Multimedia streaming the continuous delivery of synchronized media data like video audio text and animation is a critical link in the digital multimedia revolution. Today streamed media is primarily about video and audio but a richer broader digital media era is emerging with a profound and growing impact on the Internet and digital broadcasting.

Synchronized media means multiple media objects that share a common timeline. Video and audio are examples of synchronized media each is a separate data stream with its own data structure but the two data streams are played back in synchronization with each other. Virtually any media type can have a timeline. For example an image object can change like an animated .gif file text can change and move and animation and digital effects happen over time. This concept of synchronizing multiple media types is gaining greater meaning and currency with the emergence of more sophisticated media composition frameworks implied by MPEG 4 Dynamic HTML and other media playback environments.

The term streaming is used to indicate that the data representing the various media types is provided over a network to a client computer on a real time as needed basis rather than being pre delivered in its entirety before playback. Thus the client computer renders streaming data as it is received from a network server rather than waiting for an entire file to be delivered.

The widespread availability of streaming multimedia enables a variety of informational content that was not previously available over the Internet or other computer networks. Live content is one significant example of such content. Using streaming multimedia audio video or audio visual coverage of noteworthy events can be broadcast over the Internet as the events unfold. Similarly television and radio stations can transmit their live content over the Internet.

A U.S. patent application entitled Multimedia Timeline Modification in Networked Client Server Systems filed Sep. 15 1998 Ser. No. 09 153 664 by inventors Anoop Gupta and Nosakhare D. Omoigui describes a system that allows a user to vary the playback speed of streaming multimedia content using time scale modification technology. It was noted that both linear and non linear timeline alteration techniques might be used.

When using linear techniques time modification is applied consistently in times and across all individual streams of a composite media stream. With non linear techniques on the other hand some segments of an individual or composite stream might be more highly expanded or compressed in time than other segments. This presents problems in switching and synchronizing between different versions of streams that have been non linearly altered by different amounts or through the use of different non linear techniques.

The invention described below addresses these problems providing a media file format that supports switching between different timeline altered streams.

In a networked client server system media content is streamed from a server computer to a client computer. Multiple timeline altered streams for the media content are stored using a media file format that provides support for switching between the different timeline altered streams during their presentation. In one aspect a user can switch between different timeline altered streams. Upon receiving a user request to switch to a particular timeline altered stream the target stream the client computer accesses a time code stream data object corresponding to the current data unit being presented. The time code stream data object identifies a primary stream presentation time corresponding to the data unit. The client then uses the primary stream presentation time to index into a table of mappings to byte offsets. The table provides a mapping of the primary stream presentation time to a corresponding byte offset of the target stream.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter

Server computer has access to streaming media content in the form of different composite media streams. Some composite media streams might be stored as files in a database or other file storage system . Other composite media streams might be supplied to the server on a live basis from other data source components through dedicated communications channels or through the Internet itself.

In this discussion the term composite media stream describes synchronized streaming data that represents a segment of multimedia content. The composite media stream has a timeline that establishes the speed at which the content is rendered. The composite media stream can be rendered to produce a plurality of different types of user perceivable media including synchronized audio or sound video graphics or motion pictures animation textual content command script sequences or other media types that convey time varying information or content in a way that can be sensed and perceived by a human. A composite media stream comprises a plurality of individual media streams representing the multimedia content. Each of the individual media streams corresponds to and represents a different media type and each of the media streams can be rendered by a network client to produce a user perceivable presentation using a particular presentation medium. The individual media streams have their own timelines which are synchronized with each other so that the media streams can be rendered simultaneously for a coordinated multimedia presentation. The individual timelines define the timeline of the composite stream.

There are various standards for streaming media content and composite media streams. Advanced Streaming Format ASF is an example of such a standard including both accepted versions of the standard and proposed standards for future adoption. ASF specifies the way in which multimedia content is stored streamed and presented by the tools servers and clients of various multimedia vendors. ASF provides benefits such as local and network playback extensible media types component download scalable media types prioritization of streams multiple language support environment independence rich inter stream relationships and expandability. Further details about ASF are available from Microsoft Corporation of Redmond Wash.

Regardless of the streaming format used an individual data stream contains a sequence of digital data sets or units that are rendered individually in sequence to produce an image sound or some other stimuli that is perceived by a human to be continuously varying. For example an audio data stream comprises a sequence of sample values that are converted to a pitch and volume to produce continuously varying sound. A video data stream comprises a sequence of digitally specified graphics frames that are rendered in sequence to produce a moving picture.

Typically the individual data units of a composite media stream are interleaved in a single sequence of data packets. Various types of data compression might be used within a particular data format to reduce communications bandwidth requirements.

The sequential data units such as audio sample values or video frames are associated with both delivery times and presentation times relative to an arbitrary start time. The delivery time of a data unit indicates when the data unit should be delivered to a rendering client. The presentation time indicates when the value should be actually rendered. Normally the delivery time of a data unit precedes its presentation time.

The presentation times determine the actual speed of playback. For data streams representing actual events or performances the presentation times correspond to the relative times at which the data samples were actually recorded. The presentation times of the various different individual data streams are consistent with each other so that the streams remain coordinated and synchronized during playback.

In the discussion below the invention will be described in the general context of computer executable instructions such as program modules being executed by one or more conventional personal computers. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Moreover those skilled in the art will appreciate that the invention may be practiced with other computer system configurations including hand held devices gaming consoles multiprocessor systems microprocessor based or programmable consumer electronics network PCs minicomputers mainframe computers and the like. In a distributed computer environment program modules may be located in both local and remote memory storage devices.

Computer includes one or more processors or processing units a system memory and a bus that couples various system components including the system memory to processors . The bus represents one or more of any of several types of bus structures including a memory bus or memory controller a peripheral bus an accelerated graphics port and a processor or local bus using any of a variety of bus architectures. The system memory includes read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within server computer such as during start up is stored in ROM .

Computer further includes a hard disk drive for reading from and writing to a hard disk not shown connected to bus via a hard disk drive interface e.g. a SCSI ATA or other type of interface a magnetic disk drive for reading from and writing to a removable magnetic disk connected to bus via a magnetic disk drive interface and an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM DVD or other optical media connected to bus via an optical drive interface . The drives and their associated computer readable media provide nonvolatile storage of computer readable instructions data structures program modules and other data for computer . Although the exemplary environment described herein employs a hard disk a removable magnetic disk and a removable optical disk it should be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer such as magnetic cassettes flash memory cards digital video disks random access memories RAMs read only memories ROM and the like may also be used in the exemplary operating environment.

A number of program modules may be stored on the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . A user may enter commands and information into computer through input devices such as keyboard and pointing device . Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are connected to the processing unit through an interface that is coupled to the system bus. A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor personal computers typically include other peripheral output devices not shown such as speakers and printers.

Computer operates in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be another personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet. In the described embodiment of the invention remote computer executes an Internet Web browser program such as the Internet Explorer Web browser manufactured and distributed by Microsoft Corporation of Redmond Wash.

When used in a LAN networking environment computer is connected to the local network through a network interface or adapter . When used in a WAN networking environment computer typically includes a modem or other means for establishing communications over the wide area network such as the Internet. The modem which may be internal or external is connected to the system bus via an interface e.g. serial port interface . In a networked environment program modules depicted relative to the personal computer or portions thereof may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

Computer also optionally includes one or more broadcast tuners . Broadcast tuner receives broadcast signals either directly e.g. analog or digital cable transmissions fed directly into tuner or via a reception device e.g. an antenna satellite dish etc. .

Generally the data processors of computer are programmed by means of instructions stored at different times in the various computer readable storage media of the computer. Programs and operating systems are typically distributed for example on floppy disks or CD ROMs. From there they are installed or loaded into the secondary memory of a computer. At execution they are loaded at least partially into the computer s primary electronic memory. The invention described herein includes these and other various types of computer readable storage media when such media contain instructions or programs for implementing the acts described below in conjunction with a microprocessor or other data processor. The invention also includes the computer itself when programmed according to the methods and techniques described below. Furthermore certain sub components of the computer may be programmed to perform the functions and acts described below. The invention includes such sub components when they are programmed as described. In addition the invention described herein includes data structures described below as embodied on various types of memory media.

For purposes of illustration programs and other executable program components such as the operating system are illustrated herein as discrete blocks although it is recognized that such programs and components reside at various times in different storage components of the computer and are executed by the data processor s of the computer.

As shown in a network system in accordance with the invention includes a network server from which a plurality of composite media streams are available. In the described embodiment of the invention the media streams are stored as files on some type of data storage device accessible by the server.

The system also includes network clients . Generally network clients are responsive to user input to select or request identified composite media streams. In response to a request for a composite media stream server streams the requested composite media stream to the requesting network client in accordance with some known format such as ASF. The client renders the data streams to produce the multimedia content.

In accordance with the invention a network client also accepts a speed designation or playback speed from a human user. The speed designation might be a speed factor relative to the original or default playback speed of the selected multimedia stream. For example a speed factor of 1.2 indicates that the composite media stream is to be rendered at 1.2 times its original or default speed thereby achieving time compression. A speed factor of 0.8 indicates that the composite media stream is to be rendered at 0.8 times its original or default speed thereby achieving time expansion.

In addition or alternatively the speed designation might indicate one of a plurality of different types or levels of non linear timeline compression. As an example such levels might include a type of non linear timeline compression that removes audio pauses from a spoken presentation. Another level perhaps referred to as summary compression might retain only short periods of a presentation that are marked by high energy levels in either audio or video portions of the content.

In response to the speed or playback designation from the user the client requests a composite media stream from the server indicating the desired type level or degree of timeline alteration. A plurality of composite streams are available at the server corresponding to different possible timeline alterations. In response to the request from the client the server begins streaming a composite stream that has already had its timeline altered in accordance with the speed designation.

With some types of media such as video streams timeline alteration involves either omitting selected frames or modifying the presentation times of the individual data units or video frames. In other cases such as with audio streams the time modification is more difficult simply changing the presentation times would alter the pitch of the original audio and make it unintelligible. Accordingly some type of audio processing technique is used to time compress or time expand audio streams while maintaining the original pitch of the audio thereby maintaining the intelligibility of the audio.

There are various known methods of audio time modification commonly referred to as time scale modification most of which concentrate on removing redundant information from the speech signal. In a method referred to as sampling short segments are dropped from the speech signal at regular intervals. Cross fading or smoothing between adjacent segments improves the resulting sound quality.

Another method referred to as synchronized overlap add method SOLA or OLA consists of shifting the beginning of a new speech segment over the end of the preceding segment to find the point of highest cross correlation i.e. maximum similarity . The overlapping frames are averaged or smoothed together as in the sampling method.

Sampling with dichotic presentation is a variant of the sampling method that takes advantage of the auditory system s ability to integrate information from both ears. In improves on the sampling method by playing the standard sampled signal to one ear and the discarded material to the other ear. Intelligibility and compression increase under this dichotic presentation condition when compared with standard presentation techniques.

More information regarding audio time modification is given in an article that appeared in the March 1997 issue of ACM Transactions on Computer Human Interaction Volume 4 Number 1 pages 3 38 1997 . For purposes of this disclosure it can be assumed that audio time modification involves some combination of changing individual data stream samples dropping certain samples and adjusting presentation times of any samples that are actually rendered.

The timeline alteration methods mentioned above are considered linear because all portions of the speech signal are compressed or expanded uniformly. That is timeline alteration is applied consistently in time and across all individual streams of a composite media stream. With non linear timeline alteration techniques on the other hand some segments of an individual or composite stream might be more highly expanded or compressed in time than other segments. Furthermore the respective individual streams of a composite stream might be expanded or compressed by different amounts relative to each other.

One example of a non linear time compression method is referred to as pause removal. When using this method a speech processing algorithm attempts to identify and remove any pauses in a recording. Similar techniques might be used in conjunction with video by identifying and removing periods of relative inactivity. Non linear timeline alteration presents special challenges when attempting to synchronize different streams having timelines altered by different techniques.

The need to synchronize between streams can occur when switching between different streams during playback. For example a user might view the first two minutes of a multimedia stream at a normal or 1.0 playback speed and then request a pause removal type of time compression. The system responds by streaming a new composite media stream having the requested time compression. However the user does not want to start over by again viewing the first two minutes of the presentation. Rather the user wants to resume playback at the same point in the content at which the request to change the playback speed was made. This point is two minutes into the original stream but is at some time less than two minutes into the time compressed stream.

Client computer has a demultiplexer component that receives composite media stream and separates out the individual media streams from the composite format in which the data is streamed such as ASF . Assuming for purposes of discussion that the composite media streams consist of audio and video streams this results in an audio media stream and a video media stream . The individual media streams are sent to and received by respective decoders and that perform in accordance with the particular data format being employed. For example the decoders might perform data decompression.

The decoded data streams are then sent to and received by respective renderers and . The rendering components and render the streams in accordance with their potentially modified timelines as the streams continue to be streamed from the network server.

For any particular multimedia segment the server creates and stores several versions of a composite media stream. A plurality of such composite media streams are shown in referenced by numeral . The illustrated media streams all correspond to the same content. One of the media streams is referred to as a primary or reference version of the media stream. A primary media stream is typically not a stream that has been timeline altered. In addition to the primary media stream however the server stores a number of timeline altered streams having timelines that have been altered in accordance with linear and or non linear techniques. In response to user s selection of a particular playback speed or time compression method the server selects and streams the appropriate one of the stored composite media streams to the client.

There is a known timeline correlation between the data units of the various media streams. The term timeline correlation as used herein refers to a correlation in content between two streams that differ in the degree and or manner in which their timelines have been modified. The timeline correlations for non linear timeline modification and alternatively for linear timeline modification as well are compiled and stored with the composite media streams and typically are generated as the timeline modification is performed. The stored timeline correlation data is then referenced by the system when it becomes necessary to find content in one stream corresponding to the same content in another stream.

Specifically server stores an index table of timeline correlations mapping presentation times of the primary media stream to byte offsets of each of the timeline altered media streams. Server further stores for each of the timeline altered media streams a time code stream mapping presentation times of the timeline altered media stream to presentation times of the primary media stream.

Also shown in are an index table and time code streams corresponding to the media streams. Index table associated with primary media stream is a cross reference containing mappings from presentation times of the primary media stream to timeline correlated offsets of the timeline altered media streams and . Table is indexed by presentation times of the primary media stream. Thus for any given presentation time of the primary media stream it is possible to quickly find a corresponding or timeline correlated offset into either of the two timeline altered media streams.

In one implementation the correlated offsets into the timeline altered streams are based on ranges of samples rather than specific samples. For example the correlations may be based on 100 millisecond ms ranges referred to as a 100 ms granularity . Thus a single offset would correspond to each 100 ms time period e.g. the offset corresponding to the time of 525 ms would be the same as corresponds to the time of 530 ms . Any of a wide range of granularities can be used balancing increased accuracy achieved from lower granularities against reduced storage space requirements achieved from higher granularities .

By itself table is useful when switching from primary media stream to one of the timeline altered media streams or . To transition for instance from primary media stream to timeline altered media stream the current presentation time of primary media stream is noted. This presentation time is used as an index into table to find the corresponding offset into the first media stream. This offset is a byte offset identifying a number of bytes into the data of timeline altered stream that corresponds to the presentation time of primary media stream . Presentation of the media stream is then initiated at the correlated offset as found in the table.

Time code streams and are associated respectively with first and second timeline altered media streams and and are used as references to the primary media stream. Each of these time code streams includes objects with data that maps presentation times of its associated media stream to presentation times in primary media stream at some specified fixed or variable granularity.

Index table and time code streams and can be stored and referenced by server of . Alternatively they can be stored by server and downloaded to client as needed. As a further alternative the time code streams and can be provided with individual data units of the timeline altered media streams and respectively. In accordance with this further alternative each data unit of the timeline altered media streams and is accompanied by a presentation time at which the data unit is to be rendered and also by a reference presentation time wherein the reference presentation time indicates a presentation time in the primary reference stream that corresponds to the presentation time of the data unit in the timeline altered media stream. This reference presentation time is then used as an index into table associated with primary stream .

Index object includes an object identifier an object size an index entry time interval an index specifier count an index specifiers identifier an index block count and one or more index blocks . Object identifier is a 128 bit globally unique identifier that uniquely identifies object as an index object rather than some other type of object. Object size is a 64 bit identifier that identifies the overall size e.g. in bytes of index object .

Index entry time interval is a 32 bit identifier of the granularity of each index entry. That is index entry time interval identifies a temporal range of the multimedia content that each index entry corresponds to as discussed in more detail below.

The index specifier count is a 16 bit identifier of the number of index specifier entries that exist in index specifier identifiers which identifies the different index specifiers that are used in index object . Examples of index specifiers include Nearest Clean Point the closest data unit containing an entire object that has the Clean Point Flag set identifying whether the object is a clean point e.g. a video key frame Nearest Object the closest data unit containing an entire object or first fragment of an object and Nearest Data Unit the data unit with a presentation time closest to the index entry time .

Index block count is a 32 bit identifier of the number of index blocks that exist in the index object .

Each index block includes a block position identifier an index entry count and one or more index entries . The block position identifier is a 64 bit block offset into the data stream.

Index entry count is a 32 bit identifier of the number of index entries included in block . Each index entry corresponds to a particular data unit of the composite data stream. The temporal range granularity of the multimedia content that the data units correspond to can vary between ASF files e.g. 10 millisecond or 100 millisecond samples or frames . The temporal range that the data units correspond to and thus the range that the index entries correspond to is identified by index entry time interval discussed above.

Each index entry includes one or more 32 bit offsets into the data stream. In the illustrated example each index entry includes one 32 bit offset for each of the different index specifiers in specifiers identifier . The 32 bit offset of an index entry in combination with the block position identifier identifies a byte offset into the corresponding stream that is associated with the presentation time of the index entry . A different index entry is associated with presentation time ranges equal to the granularity identified by interval .

Object identifier is a 128 bit globally unique identifier that uniquely identifies object as an index parameter object rather than some other type of object. Object size is a 64 bit identifier that identifies the overall size of index object . Index entry time interval is a 32 bit identifier of the granularity of each index entry analogous to index entry time interval of . Index specifier count is a 16 bit identifier of the number of index specifier entries that exist in index parameters object .

Each index specifier entry includes a stream number identifier and an index type . Stream number identifier identifies a particular composite stream in the ASF file that the specifier entry corresponds to. Index type identifies which index specifier type e.g. Nearest Clean Point Nearest Object or Nearest Data Unit the specifier entry corresponds to.

Each index specifier entry corresponds to an index entry of . Multiple index entries will be included in index object each corresponding to the same presentation time of the primary stream but corresponding to different timeline altered streams as identified by the corresponding index specifier entries . The combination of object and object provides a mapping from presentation time of the primary stream to corresponding byte offsets in each of the timeline altered streams.

By way of example the ASF file may include a primary stream that has not been timeline altered and two secondary streams one that has been timeline altered with a speedup factor of 1.5 e.g. 1.5 times faster than the primary stream and another that has been timeline altered with a speedup factor of 2.0 e.g. 2 times faster than the primary stream . If the byte offset into the 1.5 secondary stream that corresponds to 30 seconds into the primary stream is desired that is 45 seconds into the 1.5 stream then the index entry that corresponds to the primary stream presentation time of 30 seconds and which has an index specifier entry that indicates the entry corresponds to the 1.5 stream is identified. The offset included in this index entry is the byte offset into the 1.5 secondary stream corresponding to 30 seconds into the primary stream. Similarly if the byte offset into the 2.0 secondary stream that corresponds to 30 seconds into the primary stream is desired that is 60 seconds into the 2.0 stream then the index entry that corresponds to the primary stream presentation time of 30 seconds and which has an index specifier entry that indicates the entry corresponds to the 2.0 stream is identified. The offset included in this index entry is the byte offset into the 2.0 secondary stream corresponding to 30 seconds into the primary stream.

Time compressed stream properties object includes an object identifier an object size a speedup factor and a skimming level . Object identifier is a 128 bit globally unique identifier that uniquely identifiers object as a time compressed stream object rather than some other type of object. Object size is a 64 bit identifier that identifies the overall size of object .

Speedup factor is a 64 bit identifier of the speedup factor for the timeline altered stream. Speedup factor can identify the amount of linear timeline alteration with respect to primary stream of or some other stream or alternatively an effective speedup factor that is the result of nonlinear timeline alteration.

Skimming level is a 16 bit identifier of the skimming level or priority number of the timeline altered stream. The number of different timeline altered streams for particular media content as well as their relative skimming levels or priority numbers can vary in accordance with the author s or designer s wishes.

Time compressed stream data unit object includes an object identifier an object size an extension system identifier a data unit extension size an extension system information size and extension system information . Object identifier is a 128 bit globally unique identifier that uniquely identifies object as a time compressed stream data unit object of that the current stream is a timeline altered stream and accesses the time compressed stream object corresponding to the current data unit being presented act which is the data unit being presented when the user request is received. From that time compressed stream object client identifies the primary stream presentation time corresponding to the current data unit act .

Client then accesses an index table of to identify the appropriate byte offset into the target stream act . Client then forwards the byte offset to server in response to which server begins streaming the target stream to client based on the location identified by the byte offset act . Server may begin streaming the target stream at the location identified by the byte offset or alternatively at a point slightly before the location identified by the byte offset.

A media file format that supports switching between multiple different timeline altered media streams of the same media content has been described. The file format of the invention includes an index table mapping presentation times of a primary media stream to byte offsets into each of the different timeline altered media streams and a time code stream for each of the different timeline altered media streams that maps presentation times of the timeline altered media stream to presentation times of the primary media stream. These time code streams and index table advantageously allow switching between presentation of the different timeline altered streams.

Although the description above uses language that is specific to structural features and or methodological acts it is to be understood that the invention defined in the appended claims is not limited to the specific features or acts described. Rather the specific features and acts are disclosed as exemplary forms of implementing the invention.

