---

title: Semantic level gesture tool tracking and positioning
abstract: Various embodiments described herein include one or more of systems, methods, and software operable to identify a location of or position a gesture tool, such as a mouse pointer or cursor, within a web conference display. Some embodiments may communicate an identified location of a gesture tool within a user interface control of a web conference presenter to web conference participants. The communicated location of the gesture tool may cause the gesture tool to be displayed in a corresponding location within a display of a web conference participant despite differences between a view of the presenter and participant. The gesture tool may include a pointer under the control of a mouse, a cursor, or other gesturing tool. Some embodiments include a web conference recording module operable to record data associated with a web conference, including gesture tool positioning data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08990706&OS=08990706&RS=08990706
owner: Adobe Systems Incorporated
number: 08990706
owner_city: San Jose
owner_country: US
publication_date: 20071107
---
Use of network hosted conferencing such as over the Internet has grown considerably in recent years. There are many products on the market that allow a presenter to share views and audio over a central server with many conference participants. Some of these products may also be used in a collaborative environment such as between members of a development team. In such instances control of a computer or computer application on one computer may be shared over a network with other users. Such products offer such functionally in a very similar manner through a server that requires a software client such as a plug in or standalone application on each participant computer. Such client software is often tightly coupled to a server that receives data from one client and distributes the data to other participating clients.

A location of a gesture tool such as a cursor or pointer under control of a conference participant is often captured and transmitted to other participants so a position of the gesture tool within the displays of the other participants is essentially an identical location. Gesture tool locations are typically captured and transmitted only by an X and Y pixel or pixel percentage coordinate scheme with regard to an entire shared workspace.

Various embodiments provide one or more of systems methods and software operable to identify a location of a gesture tool such as a pointer location identifier or cursor within a display of a web conference presenter. Such embodiments may also communicate an identified location of a gesture tool to web conference participants to cause the gesture tool to be displayed in a corresponding location within a display of a web conference participant. Identifying the location of the gesture tool in some embodiments includes identifying a location of the gesture tool in the context of a shared application. In an example embodiment identifying the contextual location of a gesture tool may include identifying and specifying the location of the gesture tool relative to other objects icons or display components of a user interface of the shared application.

Identifying the location of the gesture tool in the context of a shared application may include identifying a pointer position within a control such as a control button within the user interface of a shared application. The location may be represented in a form such as 

Web conference participants often display a shared view of a web conference on a monitor of a different size and or different resolution than the presenter. Further web conference participants may resize reposition and even scroll user interface controls shared by the presenter. As a result gesture tool positions may not be accurately reflected or even displayed using a simple X and Y coordinate in the context of an entire shared workspace. Various embodiments that identify the gesture tool location in the context of a shared application allow participant systems to compensate for such differences between the views shared by a presenter and the view displayed to the participant. These and other embodiments are described in detail below.

In the following detailed description reference is made to the accompanying drawings that form a part hereof and in which is shown by way of illustration specific embodiments in which the inventive subject matter may be practiced. These embodiments are described in sufficient detail to enable those skilled in the art to practice them and it is to be understood that other embodiments may be utilized and that structural logical and electrical changes may be made without departing from the scope of the inventive subject matter. Such embodiments of the inventive subject matter may be referred to individually and or collectively herein by the term invention merely for convenience and without intending to voluntarily limit the scope of this application to any single invention or inventive concept if more than one is in fact disclosed.

The following description is therefore not to be taken in a limited sense and the scope of the inventive subject matter is defined by the appended claims.

The functions or algorithms described herein are implemented in hardware software or a combination of software and hardware in one embodiment. The software comprises computer executable instructions stored on computer readable media such as memory or other type of storage devices. Further described functions may correspond to modules which may be software hardware firmware or any combination thereof. Multiple functions are performed in one or more modules as desired and the embodiments described are merely examples. The software is executed on a digital signal processor ASIC microprocessor or other type of processor operating on a system such as a personal computer server a router or other device capable of processing data including network interconnection devices.

Some embodiments implement the functions in two or more specific interconnected hardware modules or devices with related control and data signals communicated between and through the modules or as portions of an application specific integrated circuit. Thus the example process flow is applicable to software firmware and hardware implementations.

In some embodiments a process of a presenter web conferencing application tracks the position of the pointer with regard to e.g. relative to controls within the user interface . For example such a process may identify that the pointer is located within the YES control button at position . The position may be represented within the YES control button in any number of ways such as an X axis and Y axis coordinate or height and width ratio within the YES control button. Some embodiments may include a user interface in addition to the illustrated user interface . In such embodiments the location of the pointer may be tracked in the context of a user interface a control within the user interface and a location with the control. . are described below and provide further detail of user interface context tracking of gesture tools within a workspace of a presenter and positioning of the gesture tool within participant workspaces.

The presenter user interface further includes a pointer at a location . In some embodiments a web conferencing application may identify the location of the pointer or other gesture tool such as a cursor within the context of the participants list window . For example the location of the pointer may be determined relative to the outer boundaries a corner or a center point of the participants list window . Some embodiments may also include identifying the location of the pointer with further regard to e.g. relative to an item within the participants list window such as a control or data item. For example the location of the pointer may be identified as pointing to the data item MIKE displayed within the participants list window .

In some embodiments the participants list window is part of the web conferencing application. In other embodiments the application of the participants list window is enabled to communicate with the web conferencing application via an application programming interface or other interface. In further embodiments the participants list window may be an application enabled to communicate directly with a web conferencing server to share a view of a user interface of the application such as the participants list window .

Returning now to the identification of the pointer position with regard to the data item MIKE the application of the participants list window may be enabled to report or otherwise provide the position of the pointer to the web conferencing application. The position of the pointer may be provided with regard to e.g. expressed in information providing a location relative to objects or components of the participants list window the portion of the participants list window within which the list of participants is provided and the record of data item MIKE. In some embodiments a web conferencing application may obtain the location information from the application of the participants list window through an application programming interface call or via other methods capable of providing the necessary information. An examples of such a method capable of providing the necessary information is illustrated and described below with regard to .

This location data may then be communicated over a network to web conference participants and the pointer within participant user views may be moved to the proper data record of the corresponding participants list window. This functionality may be useful in several scenarios such as if a participant is viewing the participants list window at a different resolution at a different size or even if the data items within a participants view of the participants list window is sorted differently. In such instances the data items in the participants list window of the participant may be scrolled to allow the pointer to be displayed at a corresponding position with regard to the MIKE data item. An example of such a web conference participant user interface is provided in .

The example method in some embodiments includes identifying an outer most item in the shared workspace within which the gesture tool of interest in displayed. As mentioned above the gesture tool may be a pointer such as a pointer under control of a pointing device such as a mouse. Other gesture tools are contemplated and relevant to the subject matter herein such as a cursor. The identifying of the outer most item in the shared workspace within which a gesture tool is displayed may be identified by requesting a display coordinate position of the gesture tool from an operating system on the presenter s computing device. The coordinates may then be provided back to the operating system via an application programming interface call that provides a reference or other handle that uniquely identifies the window or other user interface item of the coordinates. In a Microsoft Windows computing environment such an application programming interface call may include the WindowFromPoint function of the CWnd class of the Microsoft Foundation Class or WinForms.

The identifying of the outermost item in the shared workspace within which the gesture tool is displayed results in obtaining an identifier of the outer most window or other item within which the gesture tool is located. The method then determines if the identified item includes augmented data. Augmented data may be included in and provided by a window or control to be provided when requested by a web conferencing presenter application performing the method . In some embodiments the augmented data may be provided by a window or control of a collaboration enabled application. The augmented data in some embodiments includes data about how the identified item is displayed. This augmented data may include positioning data of where the gesture tool is located data identifying how the item is displayed such as a sort order of records and a displayed record. In some embodiments such as when the identified item is a data window the augmented data may identify a sort order of records in the data window and a record over which the gesture tool is located. This augmented data may be provided to web conference participants and will cause a corresponding item displayed to a participant to conform the item to the augmented data and move the gesture tool to the location identified in the augmented data such as over an identified data record.

If the method determines that the identified item does include augmented data the method retrieves the augmented data from the identified item and sends data identifying the identified item and the augmented data to web conferencing participants. If the method determines that the identified item does not include augmented data the method determines if the gesture tool is displayed within an item of the last identified item.

Note that the method as illustrated in provides the possibility for looping when identifying items. Thus at the first time through the loop the last identified item is the outer most identified item. In subsequent iterations through the loop the last identified item may be an item embedded within the identified outer most item such as a control button drop down list box or data window within a larger window.

The determination if the gesture tool is displayed within an item of the last identified item in some embodiments includes querying a display list of an application of the last identified item such as an operating system or other application of the last identified item. Most modern computing applications maintain a representation of items displayed within a user interface in a data structure commonly referred to as a display list. Data within a display list identifies items displayed in such as user interface and where such items are displayed. Some display lists are maintained in a hierarchical nature such that the data may include a representation of a control within a child window within a parent window. Thus an application display list may be queried repetitively such as through the looping portion of the method to identify a lowest level item such as a control within which the gesture tool of interest is located. Such applications including display lists usually include an application programming interface that may be utilized to query the display list. Applications created using the Microsoft Foundation Class may be queried using Microsoft Foundation Class function calls as discussed above. Other applications may constructed using other common application programming interfaces. For example all or most applications developed by a company may be compliant with a single application programming interface. Thus the web conferencing application on a presenter s computing device may include the ability to not only identify an application within which a gesture tool is located but also identify the specific application to allow a determination of which application programming interface calls may be used to communicate with the application. In some embodiments the web conferencing application may also or alternatively include an application programming interface standard that other applications may be developed to conform to facilitate web conferencing.

If the determination is that the gesture tool is displayed within an item of the last identified item the method includes identifying a next outermost item within which the gesture tool is displayed. This further identifying as discussed above may include querying a display list of an application within which the gesture tool is located. The identifying of the next outermost item in the shared workspace within which the gesture tool is displayed results in obtaining an identifier of the next outer most item. This reference is then used to once again determine if the identified item includes augmented data. The method then proceeds as discussed above.

If the determination is that the gesture tool is not displayed within an item of the last identified item such as when the method has identified the item at the lowest level of a display list hierarchy the method determines or obtains gesture tool location data within the last identified item. In some embodiments determining the gesture tool location data may be performed by converting the actual location of the gesture tool within the overall workspace obtained above into a coordinate space of the lowest level item. In some embodiments obtaining the gesture tool location data may include calling a function that may be available within an application programming interface of the last identified item or an application of the last identified items. The method then sends item identifying data and gesture tool location data to the web conference participants.

The participant user interface includes a presentation slide show window a whiteboard tool window and a participants list window . These windows correspond to and display the content of the windows shared by the presenter as illustrated and described with regard to . In some embodiments the windows may be rearranged and resized within the participant user interface as the participant desires. Resizing of the window may cause portions of the windows and shared by the presenter to be hidden. For example looking at the participants list window which has been relocated and resized compared to the participants list window of it can be seen that the data items SAMANTHA and JORDAN are scrolled out of view in the window . In addition the participant user interface may be displayed to a participant at a different resolution at a different aspect ratio e.g. 4 3 16 9 etc. and at a different size.

Conversion of shared views between resolutions aspect ratios and sizes is outside the scope of the present application but handling of gesture tool positioning between such differing views is within the scope. Gesture tool positioning such as positioning of pointer or a cursor is handled in some embodiments by receiving gesture tool positioning data from a presenter in the context of an application window such as the windows and . In such embodiments a window may be identified in the gesture tool positioning data such as by a reference to the participants list window . The gesture tool positioning data may also reference a position within the window such as by an X and Y pixel coordinate position or by X and Y ratios such as 20 percent across the X axis and 75 percent up the Y axis . In other embodiments the gesture tool positioning data may also identify a control within a window such as the control in the participants list window listing the participants. In such embodiments a location within the identified control may also be provided in the gesture tool positioning data. Such a location may be X and Y positioning data as mentioned above or with reference to a data item in the control such as through use of contextual augmented data. For example the gesture tool positioning data may identify a data item such as the MIKE data item in the participants list window . The gesture tool such as pointer may then be moved to the location identified in the gesture tool positioning data. Note that the position of the pointer corresponds to the position of the pointer in the participants list window of . These positions correspond with one another even though the corresponding participant list windows are sized and scrolled differently and may even be displayed at different aspect ratios different sizes and different resolutions.

In some embodiments the participant s display may be a multilayered display. One layer may be a standard layer and another layer an overlay layer. Such multilayered displays may be generated through use of one or both of operating system functions and a graphic output circuit such as a graphics card. Typically a standard layer is the layer within which most common computing applications such as word processing programs slide presentation programs and the like are displayed. In some embodiments a shared workspace view received from a web conference presenter is displayed in the standard layer and one or more gesture tool representations positioned and generated based on data received from the web conference presenter may be displayed in the overlay layer.

In some embodiments if the gesture tool positioning data received by the participant from the presenter such as augmented data identifies a location not currently displayed in the participant user interface the participant web conferencing application may cause the participant user interface or one of the windows to display the location to allow the gesture tool to be visible. For example if the gesture tool positioning data received by the participant identifies the JORDAN data item in the participant list window the web conferencing application of the participant may cause the participant list window to scroll in a direction to cause the JORDAN data item to become visible. The pointer may then be positioned with regard to the JORDAN data item.

The method is an example of a method that may be performed by a web conferencing application on a computing device of a web conference participant that receives web conference data over a network that originates with a web conference presenter. The method includes receiving gesture location data. In some embodiments the gesture tool location data may have been created and sent according to the method of as described above.

In some embodiments the gesture tool location data identifies an item within which to display the gesture tool and a location within the item. For example the gesture tool location data may identify a window a control within the window and even a control within the control. The gesture tool location data may also include further data such as X and Y coordinates within an identified item of where to display the gesture tool. The X and Y coordinates may be actual coordinates or other data that may be used to identified actual coordinates such as coordinate ratios. In some embodiments the gesture tool location data may also include augmented data as described above. The augmented data has meaning to the lowest level item identified as discussed above i.e. the control within the control of the window . The augmented data may cause an item such as a control to behave in a certain fashion such as sorting data records making a data record visible that is currently scrolled out of view in the workspace display of the web conference participant or other action. The augmented data when received and processed by an identified item may also cause the participant s web conferencing application to move the gesture tool in the overlay pane to a location within the item such as on top of a data record brought into view. Moving of the gesture tool may include redrawing a gesture tool representation in an overlay pane of the participant s display.

In some embodiments the method processes the gesture tool location data by identifying an item in a local workspace such as a display identified in the gesture tool location data. For example if the gesture tool location data is in the format of WINDOW.CONTROL.CONTROL. DATA where the DATA may be X and Y coordinates X and Y coordinate ratios or augmented data the identifying may include querying operating system and or application display lists as discussed above with regard to . However rather than identifying items with regard to coordinates the identifying identifies items by reference to item identifiers such as application and control identifiers. By identifying items in display lists locations and handles of the items within the participant s display may be obtained. The locations may be used to determine where to draw a gesture tool in the overlay pane. A handle to an item may be used to pass augmented data.

Once the item is identified based on the gesture tool location data the method includes determining if the gesture tool location data includes augmented data for the identified item. If the gesture tool location data does include augmented data the method sends the augmented data to the identified item. The identified item then processes the augmented data to cause the gesture tool to be relocated and or to cause the identified item to perform some other function such as brining an item into view by scrolling or moving the gesture tool over a specific data record.

If the gesture tool location data does not include augmented data the method includes identifying an area within which the identified item is located in the local workspace. The area identification may include querying item display lists as discussed above to locate an area where the item is displayed. Once this area is identified the method includes drawing the gesture tool in the local workspace at a location within the identified area as specified in the gesture tool location data.

In some embodiments the web conferencing server may include a recording module to record web conferencing data. In some such embodiments the recording module records not only shared views but also gesture tool positioning data. The recording module may store the recorded data in a data storage device such as a hard drive in a database or in another location or on another device suitable to store such data. In some further embodiments the web conferencing server is operable to receive and fulfill requests for web conferences recorded by the recording module .

Computer readable instructions stored on a computer readable medium are executable by the processing unit of the computer . A hard drive CD ROM and RAM are some examples of articles including a computer readable medium. For example the computer program may include one or more of a web conferencing program a slide presentation or word processing program such as the PowerPoint and Word applications available from Microsoft Corporation of Redmond Wash. and web conferencing enabled applications.

In some embodiments a web conference may include sharing of a document authoring or viewing application. In some such embodiments the gesture tool positioning data may identify a location with regard to a page and or character position in a document being viewed.

Some additional embodiments provide systems including a network interface a storage device and a web conference recording module. The web conference recording module may be operable to receive web conference data over the network interface including data representative of one or more user interfaces and data identifying one of the one or more user interfaces and a location within that user interface at which to display a gesture tool. The web conference recording module may be further operable to store the web conference data in the storage device as a recording of the web conference from which the data is received.

A system including a web conference recording module or other system may include a web conference transmission module to serve recorded web conferences to requesting participants. Such web conference transmission modules are typically operable to retrieve data of a recorded web conference from the storage device and transmit the retrieved data to one or more recorded web conference participants over the network interface.

Other embodiments may include a computer readable medium such as a removable disk a memory stick a networked data storage device or other medium. The computer readable medium may hold an instruction set such as software operable on a computer to cause the computer to receive a data structure including data identifying a user interface displayed during a web conference a control within the user interface and location within the control at which to display a gesture tool and to move the gesture tool to the location identified in the received data structure. Other computer readable medium may hold instructions sets operable to perform one or more of the methods described herein.

It is emphasized that the Abstract is provided to comply with 37 C.F.R. 1.72 b requiring an Abstract that will allow the reader to quickly ascertain the nature and gist of the technical disclosure. It is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims.

In the foregoing Detailed Description various features are grouped together in a single embodiment to streamline the disclosure. This method of disclosure is not to be interpreted as reflecting an intention that the claimed embodiments of the inventive subject matter require more features than are expressly recited in each claim. Rather as the following claims reflect inventive subject matter lies in less than all features of a single disclosed embodiment. Thus the following claims are hereby incorporated into the Detailed Description with each claim standing on its own as a separate embodiment.

It will be readily understood to those skilled in the art that various other changes in the details material and arrangements of the parts and method stages which have been described and illustrated in order to explain the nature of the inventive subject matter may be made without departing from the principles and scope of the inventive subject matter as expressed in the subjoined claims.

