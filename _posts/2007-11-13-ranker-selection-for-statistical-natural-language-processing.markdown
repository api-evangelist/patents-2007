---

title: Ranker selection for statistical natural language processing
abstract: Systems and methods for selecting a ranker for statistical natural language processing are provided. One disclosed system includes a computer program configured to be executed on a computing device, the computer program comprising a data store including reference performance data for a plurality of candidate rankers, the reference performance data being calculated based on a processing of test data by each of the plurality of candidate rankers. The system may further include a ranker selector configured to receive a statistical natural language processing task and a performance target, and determine a selected ranker from the plurality of candidate rankers based on the statistical natural language processing task, the performance target, and the reference performance data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07844555&OS=07844555&RS=07844555
owner: Microsoft Corporation
number: 07844555
owner_city: Redmond
owner_country: US
publication_date: 20071113
---
Statistical natural language processing SNLP which employs statistical techniques to automatically generate and analyze natural human languages often requires parameter estimation for various statistical models employed for performing SNLP tasks. To achieve this end various parameter estimation algorithms have been used. However each parameter estimation algorithm may perform differently when applied to different types of SNLP tasks. Further performance targets such as training time runtime speed memory footprint and accuracy may vary depending on the type of application under development. For example a web based application may utilize frequent updates of the statistical model and a large memory footprint while a mobile device application may utilize less frequent updates and a small memory footprint. These variations make it difficult for a software developer to select an appropriate parameter estimation algorithm for each project.

Selection of a parameter estimation algorithm that does not perform well for a particular SNLP problem can be undesirably time consuming resulting in wasted processing time. Current systems are unable to suitably predict performance of a parameter estimation algorithm for different types of SNLP task. Therefore it is difficult for developers to select a parameter estimation algorithm suitable to a particular SNLP task.

Systems and methods for selecting a ranker for statistical natural language processing are provided. One disclosed system includes a computer program configured to be executed on a computing device the computer program comprising a data store including reference performance data for a plurality of candidate rankers the reference performance data being calculated based on a processing of test data by each of the plurality of candidate rankers. The system further includes a ranker selector configured to receive a SNLP task and one or more performance targets and determine a selected ranker from the plurality of candidate rankers based on the natural language processing task the performance targets and the reference performance data.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

The computer program may include a data store and a ranker selector . The data store is configured to store either temporarily or in a nonvolatile manner a plurality of candidate rankers as well as reference performance data for each of the plurality of candidate rankers and a test data set to measure the relative performance of each of the candidate rankers . The test data set for example may include a sample of untranslated texts and corresponding verified translations also referred to as reference translations .

The candidate rankers may be any suitable rankers used for parameter estimation for statistical natural language models for performing natural language processing tasks. For example the plurality of candidate rankers may include 1 maximum entropy estimation with L2 regularization MEEL2 ranker using maximum entropy estimation with L2 regulation MEEL2 algorithm 2 maximum entropy estimation with L1 regularization MEEL1 ranker using maximum entropy estimation with L1 regulation MEEL1 algorithm 3 averaged perceptron AP ranker using an averaged perceptron AP algorithm 4 Boosting ranker using a Boosting algorithm and 5 BLasso ranker using a Boosting with Lasso with L1 regularization BLasso algorithm as explained in detail below.

The computer program may further include a test engine configured to calculate the reference performance data for each of the plurality of candidate rankers based on a processing of the test data set . The test engine may be configured to cause each candidate ranker to utilize its SNLP algorithms to output ranked translation alternatives. Each candidate ranker may be judged for accuracy memory footprint processing time and development time and other factors against a verified translation and the result saved as reference performance data .

It will be appreciated that the test engine may calculate the reference performance data at some point in time prior to when a user is selecting a candidate ranker with system and that the test engine and test data set may be located on a different computing device than computing device . For example the reference performance data may be preloaded data that is calculated using a test engine located at a manufacturer of computer program and distributed by download or CD ROMs with the computing program .

The ranker selector is configured to receive a statistical natural language processing SNLP task and one or more performance targets from the user and determine a selected ranker from the plurality of candidate rankers based on the SNLP task and the performance targets received from the user and the reference performance data that has been calculated by test engine .

The SNLP task may be any suitable task in statistical natural language processing that can be formulated as a ranking problem under the framework of a linear model. Example SNLP tasks include but are not limited to parse selection language model adaptation word segmentation part of speech tagging text categorization text clustering lexical acquisition word sense disambiguation word class induction syntactic parsing semantic interpretation grammar induction machine translation and combinations of the above.

The performance targets may include any suitable performance targets for statistical natural language processing including but not limited to accuracy memory footprint processing time development time model sparsity model training time etc.

The determination of the selected ranker by the ranker selector may be carried out for example by comparing the performance targets with the reference performance data for the plurality of candidate rankers . A candidate ranker of the plurality of candidate rankers having the reference performance data meeting the performance targets and or performing superiorly as compared to the other candidate rankers based on the performance targets may be selected as the selected ranker .

The computer program may be configured to display a graphical user interface GUI on a display associated with the computing device . The GUI may include a user input pane configured to receive user input of various parameters via a user input device an output pane and a recommend ranker selector . Upon selection of the recommend ranker selector by a user the computer program is configured to determine the recommended ranker based on the user input and to display the recommended ranker in the output pane .

The user input pane of the GUI may be configured to display an SNLP task input tool configured to receive user input indicating the SNLP task and a performance targets input tool configured to receive user input indicating one or more performance targets for the SNLP task . The SNLP task input tool may be configured to display an SNLP task dropdown list including one or more SNLP task options to be selected by the user. Alternatively a task input tool of another form may be used such as a text input field etc. SNLP task input tool may further include a load SNLP task tool by which a user may load a data file containing one or more stored SNLP tasks for example.

The load performance target tool may include a list of performance targets and associated user editable values corresponding to one or more of the listed performance targets. In the depicted embodiment the performance targets are illustrated as accuracy memory footprint processing time and development time. It will be understood that other suitable performance targets may also be utilized as listed above. A load performance targets tool may also be provided by which a user may load a data file containing one or more stored performance targets for example.

The user input pane of the GUI may also include a test data input tool configured to receive user input of the test data . The user input pane may further include an load candidate ranker tool configured to receive user input of the plurality of candidate rankers and a load reference performance data tool configured to receive user input of the reference performance data . Test data input tool load candidate ranker tool and load reference performance data tool are depicted as buttons which upon selection by a user present a browsing menu through which a user may select an appropriate data file to load. Alternatively other selection mechanisms may be utilized.

Upon input of the SNLP task via SNLP task input tool and performance targets via a targets input tool and input of any desired test data reference performance data or candidate rankers via load test data tool load reference performance data tool and load candidate ranker tool respectively the recommend ranker selector of the GUI may be selected by a user. Upon selection the GUI is configured to send a request to the ranker selector to cause the ranker selector to determine a selected ranker from the plurality of candidate rankers based on the SNLP task and the performance targets . The selected ranker selected by the ranker selector may be displayed in the output pane of the GUI .

Using such a system a software developer may efficiently select a ranker having a parameter estimation algorithm suitable to a particular SNLP task and particular performance targets.

The method may include at providing a plurality of candidate rankers. Each of the candidate rankers may include a parameter estimation algorithm for SNLP models that perform SNLP tasks. The plurality of candidate rankers may include predefined candidate rankers provided with the computer program and stored in the data store . In some examples the plurality of candidate rankers may include user defined candidate rankers received from user input via for example the GUI of the system in . The plurality of candidate rankers may include any number of suitable rankers for statistical natural language model parameter estimation including maximum entropy estimation with L2 regularization MEEL2 ranker using a maximum entropy estimation with L2 regulation MEEL2 algorithm averaged perceptron AP ranker using an averaged perceptron AP algorithm Boosting ranker using a Boosting algorithm and or BLasso ranker using a Boosting with Lasso with L1 regularization BLasso algorithm.

At the method may include providing reference performance data the reference performance data being calculated based on a processing of test data by each of the plurality of candidate rankers. The test data may include predefined test data provided by the manufacturer of computer program for example and stored in the data store and or may include user defined test data received from user input via a GUI as described above. Likewise the reference performance data may be predefined reference performance data provided by the manufacturer of computer program and stored in a data store of the computer program or the reference performance data may be user defined reference performance data received from user input via a GUI for example.

At the method may include receiving an SNLP task and one or more performance targets. The SNLP and performance targets may be received for example via a GUI as described above. Examples of suitable SNLP tasks and performance targets are provided above.

At the method may include receiving a user request to select a selected ranker from among the plurality of candidate rankers for example via a recommend ranker selection mechanism of a GUI. At the method may include determining the selected ranker via for example a ranker selector from the plurality of candidate rankers based on the SNLP task the performance target and the reference performance data.

Determining the selected ranker from the plurality of candidate rankers may include comparing a measured parameter from the reference performance data for each of the plurality of candidate rankers with a desired parameter from the performance targets. In one example the SNLP task may be received from user input received via an SNLP task input tool of a GUI and the performance target may be received from user input received via a performance targets input tool of a GUI as described above.

Determining the selected ranker at may further include comparing the performance target with the reference performance data of a candidate ranker of the plurality of candidate rankers in performing a particular SNLP task. A candidate ranker of the plurality of candidate rankers may be selected as the selected ranker if the reference performance data of that candidate ranker in performing one or more SNLP tasks meets the performance targets received the user input.

As the method may further include displaying the selected ranker on a display associated with the computing device.

The above described method may be utilized by a software developer to efficiently select a ranker having a parameter estimation algorithm suitable to a particular SNLP task and particular performance targets. The above described systems and methods may enable a user such as a software developer to select a ranker that is suited to a particular SNLP task based on the user s specific performance targets such as model training time runtime speed memory footprint and accuracy. Thus for example for applications that are web based and which have rapid model updates as a performance target the ranker selector may be configured to select a selected ranker that may be trained and updated quickly. The averaged perceptron ranker may be selected under these circumstances. For applications for which accuracy is a performance target the ME L2 ranker may be chosen and for applications for which a small memory footprint is a performance target the ME L1 may be chosen. Finally for applications that have a very small memory footprint as a performance target and that may be able to sacrifice some accuracy the ranker selector may be configured to choose the BLasso or Boosting ranker.

Examples of various example parameter estimation algorithms that may be used for performing parameter estimation in generating SNLP models are illustrated as follows and in reference to a hypothetical linear statistical natural language processing model F x for performing an SNLP task such as parsing.

where GEN X is a procedure for generating all candidate y for each input x x y is the various extracted features and w is a parameter vector that assigns a real valued weight to each of the extracted features x y .

The task of a parameter estimation algorithm is to use a set of training samples to choose a parameter w such that the mapping F x is capable of correctly classifying an unseen example.

The maximum entropy estimation with L2 regularization MEEL2 algorithm for parameter estimation operates by finding a parameter w where the sum of empirical loss on the training set as represented by L w and a regularization term as represented by R w is minimum with R w w. The MEEL2 algorithm may be represented by the following equation 

The maximum entropy estimation with L1 regularization MEEL1 algorithm used for parameter estimation operates by finding a parameter w where the sum of empirical loss on the training set as represented by L w and a regularization term as represented by R w is minimum but with R w w . The MEEL1 algorithm may be represented by the following equation 

An orthant wise limited memory quasi Newton OWL QN algorithm which is a modification of L BFGS may be used to iteratively minimize the objective function L w R w . In the OWL QN algorithm an L BFGS algorithm is used to approximate the Hessian of the loss function as indicated by L w which is then used to approximate the objective function L w R w for a given orthant. When the L BFGS algorithm is used to approximate the Hessian of the loss function L w the L BFGS algorithm maintains vectors of the change in gradient g gfrom the most iterations and uses them to construct an estimate of the inverse Hessian H. At each step a search direction is chosen by minimizing a quadratic approximation to the function 

where xis the current iterate and gis the function gradient at x. If H is positive definite the minimizing value of x can be computed analytically according to x x Hg.

The Boosting algorithm optimizes or minimizes a pairwise exponential loss function ExpLoss w which is defined as follows 

Given a training sample x y for each possible output yin GEN x the margin of the pair x y with respect to a model w M y y is provided by the following equation 

After initialization Steps 2 and 3 are repeated a predefined T number of times. At each iteration a feature is chosen and its weight is updated.

First define Upd w k is defined as an updated model with the same parameter values as w with the exception of w which is incremented by 

No regularization function is used in the Boosting algorithm but a small fixed step size may be used to as an implicit regularization to minimize over fitting and number of test errors.

The BLasso algorithm optimizes an Lregularized exponential loss function and may be represented as follows LassoLoss ExpLoss where .

An incremental feature selection procedure similar to that used by the Boosting algorithm is used to learn parameter vector w. At each iteration the BLasso algorithm takes either a forward step or a backward step. At each forward step a feature is selected and its weight is updated according to the following equations arg minExpLoss sign 

The exponential loss function LassoLoss w may be calculated with an update of either or i.e. grid search may be used for feature weight estimation.

At each backward step a feature is selected and the absolute value of its weight is reduced by if and only if it leads to a decrease of the exponential loss function LassoLoss w as shown in the following equations arg minExpLoss sign LassoLoss 

2 Take a forward step according to the following equations and the updated model is denoted by w arg minExpLoss w sign 

4. Take a backward step if and only if it leads to a decrease of LassoLoss according to the following equations arg minExpLoss sign w LassoLoss where 0 otherwise

5. Take a forward step according to Step 2 above update min ExpLoss w ExpLoss w and return to Step 4 above.

The averaged perceptron algorithm optimizes a minimum square error MSE loss function. The averaged perceptron algorithm may use the following incremental training procedure 

The averaged perceptron algorithm starts with an initial parameter setting and updates it for each training example. If wis the parameter vector after the itraining sample has been processed in pass t over the training data the averaged parameters are defined as

Example devices that may be used as computing device include devices that electronically execute one or more programs including but not limited to personal computers servers laptop computers hand held devices portable data assistant PDA cellular phones and other micro processor based programmable consumer electronics and or appliances routers gateways hubs and other computer networking devices etc. The computing device may typically include a processor connected via a bus to volatile memory e.g. Random Access Memory non volatile memory e.g. Read Only Memory and a mass storage device e.g. a hard drive . The computing device also may include user input devices such as a mouse and keyboard a display device and a media drive configured to read media such as a Compact Disk Read Only Memory CD ROM or Digital Video Disk Read Only Memory DVD ROM . Software programs including executable code for implementing the embodiments described herein may be stored and distributed on media loaded onto the computing device via the media drive saved on the mass storage device and executed using the processor and portions of volatile memory. The computer program may be an application programming interface API configured to be a communication intermediary between an application program and the ranker selector .

The computer program may generally include routines objects components data structures and the like that perform particular tasks or implement particular abstract data types. The computer program may be a single program or multiple programs acting in concert and may be used to denote both applications services i.e. programs running in the background and an operating system.

It should be understood that the embodiments herein are illustrative and not restrictive since the scope of the invention is defined by the appended claims rather than by the description preceding them and all changes that fall within metes and bounds of the claims or equivalence of such metes and bounds thereof are therefore intended to be embraced by the claims.

