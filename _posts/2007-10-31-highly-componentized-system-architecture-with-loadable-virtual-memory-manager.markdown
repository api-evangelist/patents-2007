---

title: Highly componentized system architecture with loadable virtual memory manager
abstract: The present invention is directed to a loadable virtual memory manager, and generally to a computer operating system capable of supporting application programs running in a computer having a working memory, the computer operating system including a kernel resident in the working memory at run time, and a loadable virtual memory manager resident at link time outside of the working memory and dynamically loadable into the working memory at run time upon demand of one of the application programs. The kernel includes a loader for loading the virtual memory manager into the working memory in response to a demand from one of the application programs. The computer is able to access a storage memory separate from the working memory, the loadable virtual memory manager residing at link time in the storage memory. The loader loads the virtual memory manager from the storage memory to the working memory. The loadable virtual memory manager is removable from the working memory upon lack of demand therefor by the application programs.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07584473&OS=07584473&RS=07584473
owner: Microsoft Corporation
number: 07584473
owner_city: Redmond
owner_country: US
publication_date: 20071031
---
This application is a divisional application of U.S. patent application Ser. No. 10 754 112 filed on Jan. 8 2004 and issued as U.S. Pat. No. 7 409 694 on Aug. 5 2008 which is a continuation of U.S. patent application Ser. No. 09 282 227 filed on Mar. 31 1999 and now abandon which claims priority from a provisional U.S. Patent Application No. 60 099 562 filed on Sep. 9 1998.

The invention is related to computer operating systems and in particular to a computer operating system which is highly componentized and has dynamically loadable operating features which may be loaded and unloaded during system run time.

The progressive computerization of society involves a number of diverse computing platforms beside the general purpose computer 

In all these cases the general purpose platform approach is either not applicable or it is prohibitively expensive. The microprocessor might be a DSP a VLIW or a micro controller the memory budget is severely restricted there might be no MMU the network connection might be sporadic and Real Time support is essential.

Current operating systems are either inflexible big lack Real Time support have complex hardware requirements or are so special purpose that good development tools are unavailable and code reusability is low.

Microkernels Black92 Engler95 attempt to modularize the operating system. But they confuse modularity with security by mandating that system services be in separate address spaces. Many of the services moved into separate server processes are still necessary for these systems to function and often the services have to trust each other.

C and Java provide objects at a very fine granularity level and they are extremely successful with application programmers. Unfortunately both languages confine their objects to a single address space. Object Linking and Embedding OLE Brockschmidt95 and other similar systems extend objects across address spaces and across machine boundaries. OLE seamlessly integrates independently developed components. When editing an Excel spreadsheet inside a Word document it is in fact the Excel process that operates on objects inside of Word s address space. Unfortunately it only works for user mode applications.

Modularity has always been an important paradigm in software design. By breaking a complex system into pieces the complexity becomes more manageable. Address spaces provide security by installing virtual memory based firewalls between applications. These two issues are orthogonal but the distinction has been lost in systems research that has been concentrating on so called microkernels. These issues have been discussed in the following publications 

Mach Black92 defined an interface for external memory managers Young89 and was able to split virtual memory into functionally distinct parts allowing part of the functionality to reside outside the privilege level component the kernel . Mach also separated part of the Unix operating system services out of the kernel Golub90 Helander94 achieving modularity but limited additional functionality. The multiserver project Julin91 went further in the modularization by splitting the Unix services into multiple independent servers. The componentization added structure and generality to the services. However keeping the services in multiple address spaces did not add any security or robustness since components had to be available and trusted in any case. The most interesting new functionality was in the ability to emulate multiple OS interfaces at the same time.

Contemporary research systems take the minimization of the kernel concept even further by defining even lower level abstractions and demonstrating the ability to split states across address space boundaries. None of these systems defines a new application programming interface API different from the Unix they emulate. The API that their predecessors Rashid87 Cheriton88 Rozier88 did define based on RPC and message exchanges were not very successful with programmers.

The Cache Kernel Cheriton94 uses Mach s external memory manager metaphor uniformly for the management of all kernel objects. Threads Address Spaces and User Kernels are all handled through this pagein pageout logical interface. An actual application is statically linked with a number of libraries which provide default implementations of the required User Kernel components VM scheduling IPC . This offers some flexibility by letting untrusted applications have their custom application kernel. Overall complexity is not decreased it seems an application kernel would have to be as complicated as any other operating system. The ability to write your own application kernel would seem useful for a limited number of users in teaching operating systems for instance.

Exokernel Engler95 goes along the same lines demonstrating further ability to run operating system code in user mode. While it is highly successful in this and offers some added flexibility it is questionable whether the premises differ from that of microkernels. The main contribution is in the mechanisms for application specific resource management.

 Liedtke95 argues that microkernels have failed exclusively on performance grounds and that poor performance is their only cause for inflexibility. Our argument is the opposite inflexibility is inherent in the design and leads to unavoidable inefficiencies that can only be mitigated by good implementations never eliminated.

Spin Bershad95 addresses the issue of expensive address space crossings by letting user code compiled by a trusted compiler run inside the kernel. This can be viewed as smart proxies that can do a lot of the work locally that otherwise would require communication. It is similar to loading packet filters into network drivers Mogul87 to running database application query language inside database engines reference or to sandboxing Java applets. Applying these techniques to operating systems is beneficial when a trust boundary must be crossed and the cost would otherwise be high. It does not address the issue of whether or not a trust boundary is necessary. Spin uses an object based language Modula3 to provide extensibility. The pointer safety property of the language is what permits execution of untrusted code in privileged mode. Trust relationships as in the user versus kernel separation should not dominate system decomposition. It is important to return to a global system view. The present invention addresses the issue of how to minimize the set of base services and how to dynamically extend them on demand.

 Ford97 shows how a base set of system components can be composed in different ways to build an operating system kernel. The granularity is fairly coarse and the techniques are limited to static linking. Components that should be of interest to OS researchers VM IPC scheduling etc. cannot be replaced or removed neither statically nor dynamically. The decomposition is otherwise limited to the OS component it is not meant as a whole system approach. This does not go far enough in the componentization. It provides a few convenient components such as bootstrap loader and filesystems but is mostly concerned with reusing existing device drivers and Unix code. It fails to componentize the core kernel services or extend the paradigm to applications.

Componentization and location independence has also been studied in the context of filesystems and network protocols Maeda93 and in a number of existing embedded systems such as pSOS ISI95 . In a typical embedded system there is no loader and components can only be chosen at static link time when the load image is built. Services are extremely limited sometimes exclusively to the scheduling component. The number and priority of threads might have to be specified statically as well.

A preferred embodiment of the invention is directed to a flexible system architecture that is suitable for a wide range of applications. The system is built out of minimal but flexible components which can be deployed as needed. Instead of mandating a fixed set of operating system services and hardware requirements the system preferably provides a menu of well defined components that can be chosen to compose a complete system depending on hardware capabilities security needs and application requirements.

Dynamic loading and unloading of components provides the flexibility that lets the system adapt to changing requirements.

The componentization makes it possible to change the implementation of a component without affecting the rest of the system. Minimalism makes it possible to use the system with severely restricted hardware budgets. It also forces the system to be understandable and flexible. Software components when possible are not tied to a particular layer of the system but can be reused. For example the same code that implements the system physical memory heap is used to provide application heaps over virtual memory. The key system building blocks are componentized. This includes the virtual memory system IPC and the scheduler in addition to filesystems networking drivers and protection policies. Preferred embodiments of the present invention extend object orientation both across address spaces and across protection levels.

In a preferred embodiment components are located in separate address spaces only when there is a real reason for it such as security or specific address space requirements. Thus the price of multiple address spaces and transitions thereof is paid only where needed.

The present invention is directed to a loadable virtual memory manager and generally to a computer operating system capable of supporting application programs running in a computer having a working memory the computer operating system including a kernel resident in the working memory at run time and a loadable virtual memory manager resident at link time outside of the working memory and dynamically loadable into the working memory at run time upon demand of one of the application programs. The kernel includes a loader for loading the virtual memory manager into the working memory in response to a demand from one of the application programs. The computer is able to access a storage memory separate from the working memory the loadable virtual memory manager residing at link time in the storage memory. The loader loads the virtual memory manager from the storage memory to the working memory. The loadable virtual memory manager is removable from the working memory upon lack of demand therefor by the application programs.

The kernel of the operating system further includes a virtual memory fault handler for handling virtual memory faults occurring in the absence of the virtual memory manager in the working memory. The kernel of the operating system includes a Namespace for registering the virtual memory manager upon the virtual memory manager being loaded into the working memory whereby the virtual memory manager becomes available to each application program through the Namespace. Preferably the Namespace includes an object supporting plural interfaces exposable by the application programs the plural interfaces including a query interface through which an application program invokes the virtual memory manager an add reference interface by which the Namespace manages each request for the virtual memory manager from any of the application programs and a release reference interface by which Namespace manages termination of the virtual memory manager from the working memory. The loader is responsive to the Namespace in maintaining the virtual memory manager in the working memory whenever the add reference interface has a reference to the virtual memory manager.

The virtual memory manager includes an object with plural interfaces exposable to other objects the plural interfaces of the virtual memory manager including a virtual memory space interface VMSpace a virtual memory map interface VMMap a virtual memory view interface VMView a query interface and a virtual memory factory interface VMFactory . The VMSpace interface provides plural methods which control access by the application programs to virtual memory locations of the virtual memory manager and preferably includes plural memory regions and a skip list linking the plural memory regions across areas of memory described by the regions.

The VMMap interface provides plural methods which control use by the application programs of virtual memory locations of the virtual memory manager. The VMView interface provides plural methods which control views by the application programs of virtual memory locations of the virtual memory manager. The VMView interface can provide different views of the same memory space to different ones of the application programs and can support context switching.

The VMFactory interface provides constructors of objects of the virtual memory manager. The VMFactory interface provides a Namespace interface exposable by applications which enumerates all the objects of the virtual memory manager independently of the Namespace.

In one embodiment the operating includes plural virtual memories resident outside of the working memory at link time the loader being capable of loading plural ones of the plural virtual memories into the working memory at run time.

In one embodiment the loadable virtual memory manager can include a default virtual memory associated with a local address space and plural virtual memories stacked with the default virtual memory each of the plural virtual memories being associated with respective external address spaces through which the default virtual memory provides access. The external address spaces can reside on external computers.

With reference to an exemplary system for implementing the invention includes a general purpose computing device in the form of a conventional personal computer including a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. The system memory includes read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic process that helps to transfer information between elements within the personal computer such as during start up is stored in ROM . The personal computer further includes a hard disk drive for reading from and writing to a hard disk not shown a magnetic disk drive for reading from or writing to a removable magnetic disk and an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM or other optical media. The hard disk drive magnetic disk drive and optical disk drive are connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical drive interface respectively. The drives and their associated computer readable media provide nonvolatile storage of computer readable instructions data structures program modules and other data for the personal computer . Although the exemplary environment described herein employs a hard disk a removable magnetic disk and a removable optical disk it should be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer such as magnetic cassettes flash memory cards digital video disks Bernoulli cartridges random access memories RAMs read only memories ROM and the like may also be used in the exemplary operating environment.

A number of program modules may be stored on the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . A user may enter commands and information into the personal computer through input devices such as a keyboard and pointing device . Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a serial port interface that is coupled to the system bus but may be connected by other interfaces such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor personal computers typically include other peripheral output devices not shown such as speakers and printers.

The personal computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be another personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the personal computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in offices enterprise wide computer networks intranets and Internet.

When used in a LAN networking environment the personal computer is connected to the local network through a network interface or adapter . When used in a WAN networking environment the personal computer typically includes a modem or other means for establishing communications over the wide area network such as the Internet. The modem which may be internal or external is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the personal computer or portions thereof may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

In a preferred embodiment of the invention the operating system components contain code and other metadata for classes of objects. When a component is loaded into an address space it is instantiated. The instantiated component creates object instances that communicate with other objects potentially in other components. The objects expose their methods through Component Object Model COM Brockschmidt95 interfaces. Threads execute code and synchronize through Mutexes and Condition variables. System components are typically written in C or C but there is no fundamental bias towards any particular language.

COM enables late binding version compatibility and checking transparency through proxies cross language support and is reasonably lightweight and efficient. Each object needs a method table pointer and a reference count. Each call adds one indirection for fetching the actual method pointer.

Component implementations in the preferred embodiment of the invention are rarely aware of their intended system layer. The same code can be used in different address spaces or contexts and can be nested. A filesystem can be applied to a file provided by another filesystem as well as to one provided by a disk driver. A heap can be applied to any memory physical memory memory allocated from another heap or memory provided by a virtual memory manager. The loader loads modules into any address space.

What components should be part of a deployed system depends upon the application itself and its interface requirements application memory requirements security requirements and the target hardware capabilities. Flexible loading of modules was an important design goal for the operating system described herein. The loading of components can be deferred until they are actually used by an application. Device drivers and runtime services typically fall into this category. Others can be loaded just prior to running an application such as virtual memory for untrusted applications. Most services will terminate themselves when they are no longer needed.

Drivers and virtual memory can not be used when the hardware to support them is not present. An application that tries to use them will look them up in the demand loading namespace. The lookup operation fails either because the driver is absent or it returns a NULL pointer.

Components have code static data a stack and a number of dynamic objects. A heap object allows dynamic memory allocations. The stack is pointed to by the stack pointer register it is allocated from the heap. In a physical memory system the initial size of the stack is also the maximum size of the stack every byte has to be paid for by real memory. Thus in an embedded application the stack size must be chosen carefully. Most compilers can generate stack checks at function entry to guard against stack overflows. In a virtual memory system the stack does not have to be backed by real memory which can be allocated on demand. The stack only consumes virtual address range and can thus be allocated liberally. A Real Time application might still want to pre allocate all memory in order to avoid run time fluctuations. In this case the existence of virtual memory does not affect the stack.

Memory for code and static data is also allocated from the heap. Code can be placed anywhere in memory if it is either position independent pc relative or relocatable. The Microsoft Visual C compiler for instance creates a compressed relocation table that the runtime loader uses to fix any references if the executable was placed in a different place in memory than it was linked for. All compilers for embedded use provide similar functionality although the specific image formats and relocation schemes differ.

On the other hand it is often found that most compilers do not support reentrancy. If the code in an image is not reentrant it is still possible to execute multiple instances of the same image in the same address space. The code and data are simply loaded multiple times each time relocated differently.

If the relocation information is not present and a component virtually overlaps with another component it cannot be executed in the same address space. In this case a new address space is required which in turn requires virtual memory.

An exemplary base set of system components in a preferred embodiment of the invention is now described.

Referring to an exemplary operating system in accordance with an embodiment of the invention has a kernel or link time component and a set of run time loadable resources . The kernel includes a set of software resources including preferably a HEAP physical memory manager a loader a support library a timer an interrupt control unit a scheduler thread support including synchronization primitives NameSpace filesystem and a startup program . The set of run time loadable resources are available to the system through the loader . The resources include preferably a virtual memory manager VMM inter process communication drivers applications and a network program . A minimal multi threaded kernel may be provided in accordance with the present invention having only the thread support the scheduler the library the timer and the startup . If multi threading is not desired the kernel may be further minimized to include only the library the timer and the startup .

As illustrated in the ICU interrupt control unit preferably includes the following software methods at link time install VMM virtual memory manager trap handler install IPC inter process communication trap handler . These resources are preferably included in the interrupt control unit because it is possible for such a system to take a VMM trap or an IPC trap or a page fault whether or not a VMM or IPC has been loaded.

Any one of the components contained in the set of loadable resources may be fetched by the loader and loaded into the operating system on a demand or as needed basis during run time. The loader registers the name of any such component that has been so loaded in NameSpace so that all users in the system can find the component by querying NameSpace .

In particular the VMM is loadable upon demand into the operating system and may be unloaded when all demand for it disappears.

Different implementations of a virtual memory manager may be selected for different purposes during run time from a VMM library storing a set of VMMs as shown in .

The Heap implements physical memory management allowing dynamic memory allocations with specifiable alignments. The constructor allows creating nested heaps or heaps over virtual memory.

The Loader is used to load additional components into a running system. Most embedded systems do not provide a loader and if not needed it can be eliminated at link time from this system as well. Multiple image formats are supported. The loader loads images into the same address space or given a flag and a virtual memory system it creates a new address space and loads the image in there.

No particular distinction is made herein between executables and DLLs shared libraries . An executable is simply a DLL that exports no entry points besides main .

The library is a shared support library and includes common base utilities like memcpy and other compiler support routines AtomicAdd CurrentThread etc. It is used by many system components and is available to applications.

Basic machine initialization code is used at startup and system reset. Most of the machine dependent code of the componentized operating system of the invention resides here.

A driver for the timer is used by the scheduler to keep track of time and for thread pre emption. A driver for the Interrupt Control Unit ICU dispatches interrupts and keeps a registry of interrupt routines which can be installed and removed by other components. The system has no particular notion of a device driver per se. It does enforce strict limits as to what an interrupt routine can do wakeup a thread.

The scheduler is a policy module that determines which thread should run at any given time. Low level management of blocking and switching between threads is handled by the thread and synchronization components .

The timer interrupt and thread and synchronization modules call into the scheduler possibly passing callback functions as arguments.

Three example schedulers have been implemented the null scheduler a round robin scheduler and a constraint based Real Time scheduler. The null scheduler is for systems that use only one thread. The round robin scheduler provides time sharing it can easily be extended to handle dynamically changing priorities. Constraint scheduling is for consumer Real Time applications and is described in Jones97 . The existence of these schedulers proves that the scheduling interface is necessary and sufficient to implement all of the prior art scheduling policies.

The thread support and synchronization components provide basic thread support and synchronization primitives. Each thread is run in one address space. A thread is usually created in the address space of the component in which it is started. If there is no virtual memory the address space is always the physical address space. Threads can be created in remote components as well as in local components that are part of the same address space. Threads can block on mutexes and conditions. They can inform the scheduler of their time constraints but these calls will fail if the scheduler is not a constraint scheduler. The constraint scheduler performs priority inheritance when threads block on mutexes. Preferably the thread support and scheduler are separated so that the scheduler and be changed while maintaining thread support. So a third party could change the scheduler without affecting applications so that the applications and the scheduler are isolated.

NamespacesA simple boot namespace where applications register objects may be provided. The Namespace is a namespace that cooperates with the loader in demand loading and caching of components. A namespace may be used for displaying the status e.g. running threads and performance parameters e.g. execution times of a system during development. Filesystems are also namespaces.

Filesystem is used to load additional components during runtime and as permanent data repository. RomFS is a filesystem for read only in memory images arbitrary files and the system can be merged into one image and FatFS is for reading writing disks. NetFile is a network filesystem client built on top of sockets.

Startup is a program that is started once the system has been initialized. It can be a simple command interpreter that configures the system and launches applications or the only application itself.

The Network Program provides the entire BSD4.4Lite network protocol code with minor adaptations. The interface is a COM interface that provides sockets. The protocols operate the network drivers through another interface.

A small Win32 compatibility library may be provided to make it easier to use WindowsNT code in some of the drivers and applications.

Namespaces are used to let applications gain access to objects provided by other components. A namespace is like a filesystem directory tree except it can hold any kind of objects not just files. Namespaces can themselves be implemented by different components including a filesystem that exports its directories as sub namespaces and files as registered objects. Namespaces can be registered into other namespaces extending the directory tree. Location transparency of all objects automatically makes namespaces distributed. Therefore it is easily possible to view some other machine s NameSpace as a sub Namespace of one s own machine. Namespaces can be filtered for access control or for providing different views for different applications. There is no limit as to the number of namespaces. A component can gain access to its namespace through a call to CurrentNamespace . In a minimal system all applications share the same boot namespace.

When an application looks up a name in the namespace it obtains a reference to the object a local direct reference in case the object is local or an automatically created proxy if the object is remote. For remote objects the interprocess communication IPC system described below in this specification is responsible for creating proxies handling the delegation to remote objects and reference counting. A namespace is free to only give access to previously registered objects or to create objects on demand as it sees fit. The namespace only handles the IUnknown interface. It is up to the application to obtain the proper interface from the object using the QueryInterface method.

The interface of Namespace includes a method called Bind. The Bind method is used to request an object. The Bind method finds whether the requested object has already been loaded and if not Bind obtains the IUnknown interface of the requested object and returns it as an argument. Bind returns a pointer to the IUnknown s pointer to the requested object. Bind is the method that looks up the requested object in Namespace while Register is the method for registering the object in Namespace. After the object has been loaded the Query Interface method may be used to query the object.

Objects can be made available to other components by registering them in a namespace. Every COM object has a virtual method table and at least the three methods derived from the base interface the IUnknown used with Namespace QueryInterface for agreeing on the interface protocols and AddRef and Release for reference counting. Specific interfaces have additional methods to do the actual work. In addition a constructor is usually provided.

Garbage collection is done through reference counting. When Release has called for the last reference the implementation can finalize and deallocate the object. Even if reference counting has limitations it is convenient in a system environment due to its simplicity.

Interaction with objects using other garbage collection models can be achieved through proxies that intercept the IUnknown methods to update their root sets.

Virtual memory provides virtual address spaces. Threads run in either a virtual address space or in the physical memory space. Components can be loaded into any address space. Component code may be shared between various address spaces like shared libraries. For instance any code loaded into the physical memory space is made visible to applications regardless of their address space. There is nothing secret in the system s code so there is no security problem. Virtual memory can be used to protect sensitive application code for instance to defend it against disassembly and theft of intellectual property. Unlike most existing operating systems in the preferred embodiment of the invention the support for virtual memory is not an integral part of the system. The system can function with or without it and it executes the same executable binary images. The virtual memory manager is a component like any other and is loaded dynamically on demand.

Loading or unloading of the virtual memory system does not interfere with applications already running or started later on in the physical memory space. Once the virtual memory system has been started new components can be loaded into any address space. Component code may be shared between different address spaces as is the case with shared libraries.

In accordance with preferred embodiments of the invention the virtual memory manager is a loadable component that provides multiple virtual address spaces. It can be viewed as a driver for MMU hardware. It creates virtual memory mappings using physical memory and MMU hardware. Loading and starting the virtual memory manager executable does not interfere with applications already running. Unloading can be done once all references to objects provided by the manager are released. A new one can be started if needed.

A virtual memory space looks like the physical memory space except it can be larger doesn t have to be contiguous can be paged protected replicated and can be recursively mapped to other objects.

The virtual memory manager exports a number of control interfaces that are used to create new address spaces VMSpace to map address spaces or files to address spaces VMMap to link threads to address spaces VMView to control state and protections VMSpace and to create instances of virtual memory objects VMFactory .

Realistically any MMU driver will need exclusive control of the MMU hardware. However other objects implementing the virtual memory interfaces can be interposed between an application and the MMU driver. In this way logical virtual memory systems can be arbitrarily composed or for instance stacked as in the Exokernel. A stacked virtual memory system relies on another one for its base functionality but add some specific functionality of its own. For example the bottom virtual memory manager in the stack could control the local or host machine while virtual memory managers stacked in higher layers would control other machines thereby providing an application running on top of multiple machines the illusion of running on a single shared memory multiprocessor system. What the present invention facilitates is multiple levels of virtual memories which are recursively stackable. Furthermore the invention provides transparency. The Exokernel approach was to have a library that implements a virtual memory so that there is in effect only a single level since one library cannot be stacked over another library. In the present invention the different virtual memories exist in different address spaces so that there is no corresponding limitation on stacking multiple levels and the stack is remotable. For example referring to the invention can be used to make a collection of different machines machine A and machine B appear as a single address space by employing a local virtual memory VM while other virtual memories VM and VM relating to the address spaces of the other machines but having the same interface as the local virtual memory are stacked over it.

Reserve reserves regions in the VMSpace Delete deletes them. Map maps VMMap objects to the space. Protect sets permanent attributes e.g. read only CacheControl controls transient attributes e.g. dirty and paging state e.g. present . QueryVM returns information about ranges CreateShadow creates a new mapping atomically moves ranges from the current mapping to the new one and maps the new one into the current one. It facilitates symmetric copy on write. A VMSpace also implements the VMMap interface returned by QueryInterface .

Read and Write are used for copy paging. Share is used to establish shared pages between two VMSpaces and to return pages to VMView Fault . QueryAccess and GetSize return information about the mapping. Clone creates a restricted mapping from the given VMMap. The constructors are used to turn files into mappings and to create memory with no backing store.

Process creation works as follows. A new VMSpace and a new VMView are created. The VMView is bound to the VMSpace. A temporary file is created as backing store for zero fill memory allocations. A VMMap is constructed with CreateFromFile and it is mapped into the VMSpace. A Heap is created from the resulting memory. The file for the executable is looked up from a namespace. A VMMap object is constructed from that file. The VMMap is mapped into the VMSpace copy on write with backing store for any copies coming again from the temporary file. The loader relocates the code if necessary. An IPC channel to the newly loaded component is created. A thread is created with the VMView associated to it. The thread is started by handing it to the scheduler.

Page fault handling works as follows. VMView Fault is invoked. This in turn calls Share on the associated VMSpace which also exports VMMap interface . Assuming the page is not present Share first calls VMSpace CacheControl which calls VMMap Read on the file s VMMap which in turn calls File Read on the file object. The VMSpace then adds the returned data to its page list and returns a reference to it to the VMView which adds it to the VTLB virtual translation look aside buffer which makes it available to the hardware.

Memory wiring works as follows. The application invokes VMSpace Protect with the wire flag set. Protect first calls VMSpace CacheControl to page in all the pages. VMSpace CacheControl may fail if the physical memory is exhausted. In this case Protect fails without wiring any pages. Otherwise it marks the pages wired and returns successfully. Any operation affecting permanent attributes is atomic. Those affecting transient attributes are not.

Certain advantages of virtual memory are realized by controlling the allocation of physical memory. For example in order to protect certain areas of memory from being written the page table entry for a particular physical address may include an indication that the address is available for read only. In order to hold a certain area in reserve or to delay the allocation of physical memory until an actual need arises the page table entry for a particular physical address may include an indication that the physical address is invalid . A pointer to the corresponding virtual memory address will cause the system to take a virtual memory trap as will be described below.

Referring to the virtual memory manager VMM includes the following interfaces IVMSpace IVMMap IVMView IUnknown and IVMFactory . The IUnknown interface preferably is included in every object. The purpose of this is to give every application the ability to query the object to determine if it supports a given interface. IUnknown refers to processes for querying for a given interface query for adding a reference to the object add and for releasing a reference to the object release . Thus each of the three primary interfaces of VMM includes the three processes of IUnknown as illustrated in .

VMFactory has an interface INamespace which it exports. Inamespace is used to enumerate all the objects that one virtual memory manager handles regardless of whether they have also been registered in the common Namespace.

The V table points to a particular interface which may be one of many interfaces available to the system. The interface lists a number of processes or methods associated with the particular object. Each method entry listed in the interface points to an implementation of that method. The implementation contains the code for carrying out the algorithm implementing the particular process or method listed in the interface . As illustrated in more than one object may point to the same interface. Of course it is to be expected that different objects have their own unique interfaces in many instances. For any application calling the object the object s interface provides a complete list of the processes or methods supported by the object.

The VMView provides a view into a VMSpace for one or more threads. It is limited by the hardware address size e.g. 32 bits . If the VMSpace it points to is indeed larger 64 bits then the view is a window into part of that space. A virtual translation look aside buffer VTLB is attached to the VMView. The VTLB contains machine dependent mapping information for the MMU hardware and a translation cache. The VTLB interface is common across all architectures. The rest of the system is unaware of the virtual memory component with a few exceptions. A thread must hold a pointer to its VMView so that page faults can be resolved within the correct context and the context switch path must check for a VMView change. If the context switch path detects an address space change it calls a VMView method to synchronize the MMU hardware with the change. The virtual memory manager registers its interrupt handler with the ICU driver. The Heap may choose to modify its behavior when running over virtual memory. The loader can only create new address spaces when a virtual memory system is present. The IPC system may utilize virtual memory mappings for data transfer.

Referring to different threads can contain pointers pointing to the same VMView object . The VMView object contains pointers pointing to a page of PTEs page table entries and to a VMSpace object . The VMSpace object points to defines Region Region and Region corresponding to different non contiguous memory regions linked by the skip list. These regions are mapped to other objects in the manner illustrated in the example of by pointers provided by the VMMap interface of VMSpace. Region is reserved no writing permitted and points to an empty space labelled Empty . Region has one pointer to a VMMap object corresponding to a region in memory containing all zeroes which is labelled ZeroVMMap. Region has another pointer to a page list . The page list points to a memory having allocated memory spaces in which writing is permitted. Region has one pointer to a VMMap object which is an implementation of VMMap for mapping files and is labelled FileVMMap. The FileVMMap has a pointer pointing to a file . Region has another pointer pointing to a VMSpace object which is different from the VMSpace object discussed above . The connection through Region between the two VMSpace objects supports a copy process. Region has yet another pointer pointing to a PageList . The PageList has a pointer pointing to a second PageList . The second PageList points to a Memory object . The linking of the two successive PageLists supports a copy on write function.

In summary the VMMap object can map a region to another VMMap object examples of which are illustrated in such as the pointer from Region to File VMMap and the pointer from Region to Zero VMMap . The mapping can be to a different portion of the VMMap object itself rather than another VMMap object. The VMMap object can map to the ZeroMap object providing zero filled physical pages as illustrated in by the pointer to the ZeroMap object . The VMMap object can map a region to a VMSpace object as illustrated by the pointer from Region to VMSpace . The VMMap object can map a region to a file as illustrated by the pointers from Region to the File VMMap and from thence to File . This may include the case of the system pager which handles the traditional paging file. Finally the VMMap object can map a region to a mapping filter CloneMap which for example restricts the protections allowed of a mapping as illustrated by the pointer from Region to CloneMap.

A PageList lists what pages have been called by the object. This is useful in case this information is forgotten by the PTE for example.

The state of an object such as the virtual memory object of consists of the pointer values of the various pointers in the object such as the pointers illustrated in .

A local constructor is a method in an object. In order to export it to another address space the constructor must be wrapped in a factory object of the type well known in the art. These objects are designated as XYFactory . For example VMFactory can create VM objects. There is a correspondence between C classes and factory objects. A C compiler could automatically create the factory of an object.

The virtual memory interfaces described here loosely correspond to the Mach external memory manager scheme Young89 . VMView and VMSpace replace Mach s task. Memory objects are replaced by VMSpaces. VMMap and VMSpace jointly implement the XMM interface although with synchronous interfaces only. The VTLB interface is a refinement of the Pmap interface.

In other implementations of the invention one could emulate Unix or Windows virtual memory APIs and the design would easily permit it including fork .

An IPC system is needed if applications are to be run in separate address spaces. Otherwise the applications can not talk to each other or to system services. An IPC system allows 

Cleanup involves releasing the memory held by an application. It also involves closing all references into and out of the application s objects. A level of indirection is needed for bookkeeping and for providing a cutoff point. This level of indirection is what an IPC system provides.

A preferred embodiment of the IPC system implements the COM model. It is possible however to replace it with another communication model for applications that expect a different model. Components implementing various communication paradigms can be loaded into the system as needed.

The preferred interprocess communication IPC manager is a run time loadable resource residing outside of the operating system kernel as illustrated in . The loader can load the Loadable IPC Manager at any time based upon need. The Loadable IPC Manager can also be unloaded whenever it is no longer required by any applications currently running.

The IPC process begins when THREAD signifies a need to go to another address space to access some resource in that other address space. In one implementation THREAD makes a remote procedure call directed to a resource controlled by THREAD in the other address space . Such a remote procedure call is transparent to the application running. Since THREAD is currently running in the current address space the thread takes an IPC trap.

The loadable IPC system of the invention hereinafter referred to as the LIS differs in structure from a non loadable one in the handling of the dependencies upon other subsystems such as the scheduler and the virtual memory . The LIS can only have dynamic dependencies and therefore cannot use any backdoor or make assumptions about the internals of other components. The LIS finds these components in the NameSpace most likely at initialization time. If a specific component is not found or cannot be loaded the LIS fails to initialize and unloads itself.

It is possible for the LIS to require specific interfaces from these other components which it asks for via the Query Interface method. This could mean that not all virtual memory managers would be suitable for a given LIS only those that implement the interface s the LIS requires. The converse is also true all virtual memory managers that implement the required interfaces should be suitable for LIS use. In the preferred embodiment of the LIS of the invention it is an interface definition error for a component to violate this rule.

Different LISs can depend on different sets of other components. Specifically it is possible for a simple LIS not to require a virtual memory manager and still be fully functional. For instance such a LIS would be useful for connecting two simple computers that do not possess a memory management unit MMU .

The LIS provides two classes of services administration services and communication services. Administrative services support the creation linking and destruction of communication endpoints and any other ancillary service. Communication services involve the transmission of the input and output arguments of an RPC and the creation and management of proxies and method signatures. An application requests these services from the LIS in an architectural and LIS dependent way. More specifically a processor usually provides special instructions to request system services system calls execution of such an instruction causes a processor trap. The LIS can be viewed as the system handler for such a trap. The LIS is handed the state of the thread at trap time. It is then LIS dependent what elements of the thread state are intended to convey information to the LIS. For example a certain processor register might contain the index of the service the application requires. Different embodiments of the LIS could offer different services and use different register use conventions for argument passing.

A thread is associated with a specific LIS. Different threads can be associated with different LIS s. If two LIS s do not communicate then their client threads also cannot communicate. It is not preferable to split a single computer into two or more non communicating subsystems except for the extreme case of highly secure systems. Therefore the most practical case is the one where multiple LIS s are able to communicate among each other. In the present invention this can be accomplished quite naturally by loading all LIS s in the same address space making them visible in a common NameSpace and using normal object invocation for their interaction.

A preferred embodiment of LIS.EXE has five internal not exported interfaces ILISFactory IPCSpace IEndPoint ISignature and IEndPointTable.

ILISFactory CreateIPCSpace creates an IPCSpace with one empty ExportTable and one empty ImportTable. Both tables are IEndPointTables.

ILISFactory CreateEndPoint IPCSpace ObjectPointer creates an EndPoint in the given IPCSpace to represent the object at virtual address ObjectPointer. The EndPoint has the IUnknown default signature associated with it. The EndPoint receives a new IPID which is a 128 bit universal identifier uniquely associated with the EndPoint.

ILISFactory CreateSignature IID ParsingString creates a type signature given an array of properly formed parsing strings. Each string describes the type signature of one method. There are as many strings as there are methods in the interface. IID is the 128 bit universal identifier for the interface.

In addition to the interfaces described above LIS.EXE makes use of Proxies inside the application address space. A Proxy is an object like any other but it merely acts as the representative of some other remote object. The application invokes methods on the proxy and the proxy s implementation for all methods simply traps to LIS.EXE. Two notable exceptions are the AddRef and Release methods which maintain a local reference count. Only the Release method traps and only when the local reference count goes to zero. Other embodiments of LIS might not require the use of proxies.

LIS.EXE handles the NameSpace specially for three reasons. LIS.EXE is responsible for exporting primitive kernel objects to its clients. These are the objects that are found in the boot NameSpace but for which LIS.EXE does not have an EndPoint. Other components that are loaded in the physical address space along with LIS.EXE can create and register objects in the boot NameSpace before and or while LIS.EXE is loaded and active. When an application looks up one such object in the NameSpace LIS.EXE automatically creates an EndPoint in the primitive IPCSpace. Secondly when an application calls INameSpace Bind to obtain access to a remote object LIS.EXE must be able to intervene and create a Proxy for the remote object in the application s address space. Similarly when an application wants to INameSpace Register an object LIS.EXE must be able to intervene and remember which VMSpace was associated with the object.

Finally when an application terminates abnormally LIS.EXE cleans up after it. Among other things LIS.EXE is responsible for removing from the NameSpace all objects that belonged to the dead application.

An application thread is associated with a given LIS at thread creation time. More specifically the LIS associates an IPCSpace instance to the VMSpace of the thread. This IPCSpace instance is the object passed to LIS.EXE at trap time. Other per thread information that is used at trap time is the service requested object IPID method number and the stack pointer register to access the arguments of the method call.

An application thread can find LIS.EXE in the NameSpace. An IPCSpace contains an ImportTable and an ExportTable each table containing pointers to EndPoints. The ExportTable points to EndPoints that the IPCSpace exports to other IPCSpaces. As a result the application associated with that IPCSpace fully implements the object the EndPoint represents. The ImportTable acts as a security filter it only allows a thread access to those remote objects that it was granted access. The ImportTable can also be used as a renaming table the application uses local names for remote objects that are only meaningful when used with the application s ImportTable.

An EndPoint has a unique ISignature. This provides an advantage in the effect of the QueryInterface method when an application invokes QueryInterface on a remote object it truly receives a new proxy for a new EndPoint.

In the example illustrated in Thread A creates an EndPoint EndP passing in a Signature Signature and a virtual address Object A. The EndPoint is entered in the ExportTable ETable A of the thread s IPCSpace A. A reference is taken on the thread s VMSpace A not shown . Thread A now registers the EndPoint in the NameSpace. One reference is taken on the object and one on the EndPoint to signify that the object is exported and visible in the NameSpace.

Generally threads do not explicitly create EndPoints they register objects in the NameSpace. It is LIS.EXE that automatically creates an EndPoint for the objects as part of its overriding of the INameSpace Register method. Alternatively a method invocation might require the passing of an object as argument or as return value. Again LIS.EXE automatically creates an EndPoint if necessary inserts it in the ExportTable if not already in there and inserts it in the remote party s ImportTable if not there already.

With reference to Thread B can either look up Object A in the NameSpace or invoke a method on some other object in VMSpace A that returns Object A as result. In either case LIS.EXE finds that EndP is the associated EndPoint and enters it in ITable B the ImportTable for Thread B s IPCSpace B. A Proxy for Object A is created in Thread B s VMSpace B not shown . In order to create the proxy Signature is used to find the size of the necessary VTable and for the loading or memory mapping of the proxy s marshalling methods. The proxy holds a copy of the EndPoint s IPID.

Thread B can now invoke a method on the proxy. In this case a pointer to the proxy s state is loaded in a register and a trap is taken. The proxy s IPID is used to find EndP in ITable B. The remaining arguments are on the stack A in VMSpace A. A new stack B is created in VMSpace B and is remapped in VMSpace A. Arguments are copied from stack A to stack B according to the EndPoint s signature. Thread B s VMSpace is now changed to VMSpace B and the stack pointer changed to point to stack B. The return address is set to special code that traps back to LIS.EXE. Thread B now jumps to executing the proper method on the real Object A.

The return path is symmetrical and it includes copying the return arguments back to stack A and switching back to VMSpace A.

If Thread B deletes the last reference on its proxy then a trap is taken to LIS.EXE which removes EndP from ITable B. A reference is Release d from EndP and the trap returns. The proxy is deleted.

Thread A removes Object A from the NameSpace. LIS.EXE deletes one reference from the object itself and one from EndP . If this was the last reference on EndP this indicates that the object is no longer in the ImportTable of any other IPCSpace. Moreover it indicates that the object is not in the NameSpace. Therefore the EndPoint can be safely destroyed.

At application cleanup time LIS.EXE walks the ImportTable and Release s all the EndPoints. It then walks the ExportTable and removes all EndPoints from the NameSpace. Each EndPoint is then Release d. If the reference count of one such object does not go to zero it means that some application is actively using the EndPoint. There are two equally valid alternatives for handling this case. LIS.EXE could prevent the application from terminating until all references are gone. Alternatively it could mark the EndPoint as dead and let the application terminate. If some other application tries to use a dead EndPoint it receives an exception.

Endpoint has a list of signatures iii which define the bits to be taken from the top of Proxy A s stack Stack A in order to obtain all the necessary arguments to be passed in the method call. Information is put onto Stack A as part of the call to the proxy of Object A. illustrates Object A as including a V Table pointer and a method table in which the second method points to the implementation code of Method . Endpoint contains an object address field containing the address 0X123 of Object A i.e. the pointer to Object A and a signature iii for Method in Object A s method table.

Proxy A has an index value of 3 into the import table . Upon the occurrence of an IPC trap IPCSpace points to the import table as a collection of objects that the IPC imports or exports. Stack B in address space is a free stack ready to accept incoming method calls. Upon occurrence of the IPC trap the IPC looks at Stack A and finds the import index i.e. 3 and therefore goes to the third entry in its import table. This entry points to EndPoint and EndPoint has the signature iii for Method of Object A. The following values are therefore copied to Stack B as part of the call arg arg arg method the object address 0X123 and the program counter for the code call . As a result Method of Object A is called with arg arg and arg as specified in Stack B of Proxy A and therefore the resulting communication has the appearance of a local call.

The Loadable IPC Manager is not only run time loadable from the run time resources into the kernel by the loader but is also unloadable. Moreover there may be more than one Loadable IPC Manager stored among the run time loadable resources of the operating system. For example a very simple Loadable IPC Manager which takes up less space in memory may be used in cases where the communication needed is within the same machine. A more powerful Loadable IPC Manager may be called whenever it is necessary to communicate with a thread running in another machine.

An object consists of an interface an instance pointer an implementation and some state. The interface is a list of methods. The instance pointers and interfaces are exposed to other objects the state and the implementation are not. Worker threads execute implementation code that accesses and modifies the state. Once an object instance has been created the instance pointer interface and implementation are traditionally immutable only the state can be changed by method calls.

The preferred embodiment of the invention allows run time changes to the ordinarily immutable part of an object even while the object is being used The term mutation as used in this specification refers to the act of atomically changing an ordinarily constant part of an object such as a method implementation. The thread performing the mutation is called a mutator.

A mutator must translate the state of the object from the representation expected by the old implementation to the one expected by the new implementation. It must also coordinate with worker threads and other mutators through suitable synchronization mechanisms. Transition functions capture the translations that are applied to the object state and to the worker thread s execution state. In order to limit the amount of metadata execution transitions only happen between corresponding clean points in the old and new implementations.

A number of mechanisms can be implemented using mutation. Interposition is done via replacement of the object with a filter object that points to a clone of the original object. A dynamic software upgrade would replace the incorrect implementation of a method with the corrected one. Run time code generation might use a stub implementation as a trigger. Mutation can be used to replace generic code with a specialized version that exploits partial evaluation by treating ordinarily non constant state as immutable. Once the optimistic conditions are no longer true mutation allows reverting back to the generic code. Execution profiling might indicate that a different implementation would perform better and trigger a mutation. Object mobility is realized by turning objects into proxies and vice versa.

One example where mutation in accordance with the present invention was found to be useful was in device drivers. In one configuration on the x86 the invention was implemented with minimal floppy and disk drivers that called BIOS ROM functions to do the work. A loadable driver would later take over and mutate the BIOS driver with a real driver transparently to the filesystem.

While only methods within an object can change the object s state in conventional operating systems the present invention provides a mutation object which during run time can dynamically change the state of other objects as desired. The state of an object includes the object s pointers. For example to change an implementation of a method listed in the object s interface the pointer from the interface for that method would be changed to point to a different implementation of that method the change in the pointer value being a change in the object s state relating to the fundamental structure of the object.

The MutateObject method is a general method enabling the user to change any pointer or register in an object. The MutateVTable method is a special case the method being directed specifically to changing the VTable pointer. One example of the general MutateObject method is illustrated in in which the MutateObject method changes the interface pointer for method i in the Object Interface from Implementation A to Implementation B.

One limitation of the synchronization by mutual exclusion is that there is a delay imposed while the system waits for all worker threads running with the object to finish. This delay can become unacceptable if one of those threads gets blocked before finishing by an event beyond its control.

One way of ameliorating such delays is to use transactional synchronization. illustrates how object mutation is synchronized by transactional synchronization. The first two steps of this method blocks are identical to that of blocks . What is different is that if there are worker threads still running YES branch of block instead of waiting the worker threads still running are rolled back to their starting points block and the object mutation is performed block . The threads are then reactivated block and access by other threads to the object is re enabled block .

One limitation of transactional synchronization is that rolling back the threads entails a delay. Synchronization by swizzling ameliorates such a delay because it does not require rolling back any running threads. illustrates how synchronization by swizzling operates. The first two steps blocks are identical with the steps of blocks and of . What is different in is that if there are threads still running YES branch of block then the still running threads are suspended temporarily block and their states are modified to reflect the mutation of the object block . At about the same time the object is mutated . Then the suspended threads are re activated block so that they continue their operations at the points at which they were suspended except that their subsequent operations are carried out in the mutated version of the object. Access by other threads to the object is re enabled at about this time block .

Preferably swizzling is not attempted except at clean points in the implementation that have possible mappings transition functions or return addresses. The definition of clean points is discussed in Asymmetric Real Time Scheduling on a Multimedia Processor by A. Forin A. Raffman J. Van Aken MSR TR 98 09 February 1998. Thus it is preferable to pre establish the locations of such clean points in an implementation and to pre compute their transition functions. The computation of such transition functions is not within the scope of the present invention and reference is made to the above cited publication.

One advantage of object mutation is that it enables significant changes to be made in the operating system in a manner that is transparent to the application or driver that is running. This advantage is apparent in considering various applications of object mutation.

The interpose method listed in the interface of the mutated object carries out the purpose of the interposition. For example the purpose of the interposition may be to provide a filter between any external thread e.g. the thread and the object . The interposition method and interposition implementation carries out the function of such a filter so that the mutated object is the filter object. For example the interposition method may entail determining whether the thread intends to write to the object and if so to block any such write operation so that the object is available to the external thread for read operations only.

Preferably the implementations of an object contain already compiled machine or object code for carrying out the corresponding method. However in an alternative embodiment the implementation is represented only by source code to save space for example and it is compiled by a compiler only as needed.

Aside from taking longer to execute the remote object call through a proxy looks exactly the same as a local call directly to the actual object. Not only is the implementation of the server transparent to the client but the location as well.

In the before portion of threads and in Address Space access an object in Address Space via a proxy object in Address Space . That is the threads in Address Space point to a proxy object in their own address space and the proxy object points to an object in Address Space . A thread in Address Space points directly to the object since both the object and the thread reside in the same address space.

Under certain conditions such as frequent calls by threads in Address Space to the object in Address Space accessing the object through the proxy is relatively inefficient. This problem is solved by mutating the proxy into a clone of the object and mutating the object into a clone of the proxy . This in effect moves the object from Address Space into Address Space . As a result calls to the object by the threads in Address Space are faster because they do not pass through an intermediate proxy. Leaving a proxy in Address Space from whence the object was removed is necessary so that the thread in Address Space can find the object by pointing to the proxy in Address Space .

Preferably Namespace is a demand loading object that supports the following new programming model. The main entry point for an image is a constructor that returns the object. When an application tries to bind to a name that does not exist the namespace invokes the loader which looks for and instantiates a component with the given name. The loader then invokes the component s entry point registers the resulting object in the namespace and returns it to the application. When the application releases its last reference to the component the namespace can unload the component or choose to keep it cached.

In accordance with programming model of the invention an application program or thread can access an object from any source such as a local area network a global network disk or working memory via the Namespace object. As will be shown in a working example described below this places the loading of resources such as plug and play device drivers under the exclusive control of the application thread. With the programming model of the invention the application thread includes calls to Namespace for each object on an as needed basis. One advantage is that working memory space is not occupied by unneeded resources. Another advantage is that the time penalty required to load a resource such as a device driver is not incurred except when necessary. A further advantage is that application thread controls when to load such resources and can therefore be allowed to do so in an optimal manner designed by the programmer. In the prior art the application thread or program did not control the loading of certain resources such as device drivers .

If it is not found on disk the Loader may be allowed to search other sources for the object such as memories accessible on a network local or global for example. The Loader loads the object into working memory block . NameSpace registers the object s name block and returns an IUnknown pointer specifying the object s location in memory to the application thread block .

One feature of this method is that the application thread is allowed to find and use objects which exist in any accessible location such as an unsaved document that exists only in working memory for example. This provides programming flexibility on a scale not possible prior to this invention.

Before the object is loaded into working memory space must be allocated in the working memory for the object s image. The image will contain one or more VTables Interfaces and Implementations block of . The image will also specify an EntryPoint which is the constructor of the object. Once the image is relocated and loaded in main memory the constructor is invoked block . Such a constructor is automatically accommodated in the C programming language. In a preferred embodiment the invention is carried out in C . The constructor allocates dynamic memory to hold the new object s state. The object s state is initialized including the object s VTable and Interface pointers block . An IUnknown pointer to the object is produced specifying the memory location of the object block . This is the pointer that NameSpace returns to the application thread in the operation illustrated in .

Examples of objects that are accessed in accordance with the foregoing programming model include NameSpace VirtualMemoryManager VMM InterProcessCommunication IPC VMSpaceVMViewsockets normal applications such as word processors and spreadsheets and the like as well as objects not stored on disk such as objects in other machines or available on a network or files or documents in working memory that have not yet been saved.

The present invention optimizes the loader to compile software to run on hardware other than that for which it was designed. In a conventional system a compiler produces an image and a linker puts it together. The image defines where each piece of code or data is loaded in main memory. With dynamically linked libraries an image defines what pieces in the library are desired for multiple images. But some compilers for example in embedded systems do not support dynamically linked shared libraries. Many embedded systems do not have loaders. So the compilers for these systems only produce a single image. As will be described later in this specification a loader embodying the invention is optimized for use in embedded systems by connecting multiple images in a more flexible way. In part this entails linking with a shared library after link time. For this purpose the invention preferably includes a program to manipulate the image produced by the compiler after link time.

When programs are compiled and linked they are targeted for some particular platform. Optimization decisions are made with that target in mind. If the program is run on a different platform the optimal decisions would be different. We describe here how those decisions can be delayed and the optimization choices changed after they have been made.

In embedded systems a small memory footprint is crucial and virtual memory either unnecessary for many application or completely unavailable. On a virtual memory system with multiple address spaces the optimization goal is to maximize sharing of memory. In a system where multiple address spaces is not the norm there is no reason to incur the cost of supporting memory sharing. The present invention eliminates this cost in such a system.

It is desirable to be able to run optimally the same program on multiple platforms. One alternative is to use source or intermediate representations such as bytecode. But those require compilers to be around at run time implying large memory and many cycles to do a good job at compiling or slow execution through badly optimized code or interpreters. Instead the present invention handles completely compiled runnable binaries and adapts them to the platform requirements.

New platforms are limited as to what the build tools can do as provided by hardware vendors. It is desirable to be able to use those tools but still have components that import and export items. The present invention accomplishes this by modifying the executable images of those components so that they can be bound at run time.

The present invention does this by first using the existing build tools up to a certain point i.e. link time and then post processing them with a munger program at post link time and a special loader at load and run time .

In order to be able to run multiple programs at once in a system that does not provide multiple address spaces the programs have to be placed at different addresses in the same space. When memory is allocated dynamically a program might not land at a predetermined address. But the program was previously linked for a predetermined address. The invention solves this problem by relocating the program at run time using a run time loader of the invention. Relocation is done by means of a relocation table that lists all the locations in the program that contain location dependent pointers. The run time loader reads the pointers from the locations indicated by the relocation table adjusts the pointer according to the manner in which the program got relocated and puts the adjusted value back into the program.

The relocation entries have a type e.g. call that indicates how the locations should be interpreted. The present invention takes advantage of this feature and the existence of the relocation table by defining a new relocation type e.g. call dll for importing from another component. When the run time loader goes through the relocation table and relocates other relocation entries as usual it treats the import entries specially. It uses the contents a number to determine the component to import from which export table within that component to import from and which ordinal within that table to use. It then replaces the contents with the pointer to the value found within the export table indexed by the ordinal.

The invention is capable of implementing dynamically linked shared libraries in a system whose compiler does not support dynamically linked libraries. For this purpose it is desirable to have a dangling reference left in an image compiled by such a compiler. This dangling reference enables a loader embodying the invention to support shared libraries without support from the compiler. In order to understand how the invention accomplishes all this it is necessary first to understand the current state of the art for implementing shared libraries with full support from the compiler. This will now be explained.

A conventional process of constructing an executable image from separate files is illustrated by an example shown in . A C language source file called FOO.C contains a statement T CurrentTime . The compiler compiles this to make an object file FOO.OBJ having a text section containing instructions including call 0X33 and a zero 0 instead of the address of the symbol CurrentTime . FOO.OBJ also has a relocation section or table and a symbol section. Since an implementation for CurrentTime has not been provided thus far the compiler produces the symbol section of FOO.OBJ with a location undefined for the symbol CurrentTime indicating that its location is to be determined later. The relocation table has a pointer to CurrentTime in the symbol table and to the 0 in the text section. This is pending work for the linker.

In the present tutorial example the symbol CurrentTime is defined in another file namely an object file called KERNEL.OBJ. This definition includes in this tutorial example 0X99 as the address of the first instruction of CurrentTime. The linker puts together the different sections of FOO.OBJ and KERNEL.OBJ to produce a single file FOO.EXE which is an executable image having no pending work for the linker. The new file FOO.EXE. has its own text section including the instructions 0X33 and 0X99 . 0X33 is in this example the machine language for call and was taken from the text section of FOO.OBJ while 0X99 address of the first instruction in CurrentTime was derived from the text section of KERNEL.OBJ. The linker in linking the objects together has changed the call for CurrentTime in the text section to 0X99 since that is where KERNEL.OBJ specifies the location of CurrentTime. Thus the linker looks at all undefined symbols and finds their locations and definitions or instructions.

If the linker starts linking a file at address the virtual memory system ensures that the addresses in the file are valid at execution time across multiple images that is . But if virtual memory is not available the linker must relocate rebase the addresses in the file before execution time because the memory range starting at address will probably not be available and in any event would only be available for one of the images. The list of these pointers is the relocation table and is created by the compiler at the time of creating the object file. Pointers can be in the text or data sections. The linker must load an object at a different location if in absence of virtual memory two different objects need to be loaded in the same location address. In this case one of the objects is displaced from location at which it was programmed to run. In this case it is necessary to find all the pointers in the file that must be changed.

The linker uses the relocation section to find unknown symbols and from the symbol sections of the objects FOO.OBJ and KERNEL.OBJ resolves the unknown symbols e.g. 0 to known symbols e.g. 0X99 in order to produce the executable image FOO.EXE. Once this is accomplished there is no further need for the relocation section and it therefore is not present in the final version of FOO.EXE.

A conventional program that uses a shared library or DLL works by keeping certain symbols undefined in the final linked image. Later some other program defines the symbols. But before that the image is not executable. Binding is the process of resolving the symbols. Deferred late binding involves postponing the resolving of certain symbols so that the file remains non executable. Such a process is illustrated in . Referring to in implementing shared libraries the linker is provided at link time with more refined information that instead of KERNEL.OBJ refers to a file KERNEL.LIB . The information in KERNEL.LIB in the present example indicates that the symbol CurrentTime is in the third entry of an export table of a shared library called KERNEL.DLL. The linker copies this information to an import table of FOO.EXE. The relocation table links this entry in the import table to the undefined entry in the text section.

Conventionally in using a dynamically linked library some linking is done after link time. When the library is created the symbol table which is large is thrown away and a list an export table is created of the items to be exported by the library which is an abbreviated version of the symbol table . In the present example CurrentTime is in the export table of KERNEL.DLL. The import table of FOO.EXE names KERNEL.DLL so in this example the linker refers to KERNEL.DLL and imports CurrentTime from it. The ordinal is the order of the item in the stack of the library and the linker preferably uses this rather than the symbol name since it is shorter.

The present invention enables the loader to be optimized for an operating system having a compiler which does not provide import or export sections and therefore provides no shared library support e.g. a non Microsoft compiler . The invention accomplishes this in part by postponing at least some of the linking or binding. This requires that the compiler can produce an object file which is not executable. Since it is not known beforehand where the object file will ultimately be allocated to what address the compiler must leave something for the linker to adjust.

In the case of an external call which is undefined one entry in the relocation table will have two pointers one pointing to the location of the instruction that has to be relocated the offset and the other pointing to the symbol that corresponds to that location. The entry also states the type of relocation. Thus each entry in the relocation table has three elements 1 the offset offset from the base of the file 2 the symbol which is an index into this table of symbols 3 the type of relocation for example call or data reference which indicates what type of instruction it is.

Symbols are either defined or undefined . Linking including the type of linking performed in the present invention by post link time late binding matches defined and undefined symbols in different object files until all symbols are defined resolved . This has to be completed before execution by a compiler. The present invention has a munger program to perform the post link time late binding a postlinker . The munger transforms to go from the nonexecutable object file FOO.OBJ to the executable image FOO.EXE .

One difference between the object file FOO.OBJ and the executable image FOO.EXE is that the object file FOO.OBJ has a text section data section relocation section but not an import table while FOO.EXE has an import table. Combining all the required objects produces the executable image FOO.EXE. The result of an executable in the dll case is that all the symbols are resolved split into sections including relocation and symbol sections.

The invention is useful in those case where the compiler is of the type that doesn t produce such a file. Some linkers get rid of the relocation table and symbols producing a file which can t be moved. It is best if the compiler can leave some symbols undefined. If the linker refuses to deal with undefined symbols the invention can generate or take a fake object that has the same location defined as the desired symbols so that the undefined symbols will refer to the same location.

The compiler is allowed to do the eager binding and the post link time linker of the invention the munger will undo it later to accommodate late binding. There are four phases compile time link time load time and run time. The post link time linking of the present invention late binding preferably occurs at or before load time.

Referring now to the munger refers to a text ascii file e.g. KERNEL.DEF which specifies the symbols to be imported from KERNEL.DLL. Files such as KERNEL.DEF have already been produced for programs running on existing machines as the precursors to the KERNEL.LIB files discussed earlier in this specification with reference to . KERNEL.DEF has a particular record record specifying the name KERNEL.DLL and a unique ID UUID e.g. OX123 . . . 9. There is a conventional tool to generate the UUID. The munger program uses KERNEL.DEF to access information to combine with FOO.OBJ to produce FOO.EXE with an import table without requiring the compiler to support import tables export tables or shared libraries. Record of KERNEL.DEF lists exports from KERNEL.DLL for example CurrentTime Last not listed in FOO.OBJ that must be included as entries in an import table in FOO.EXE. In record of KERNEL.DEF contains the information that export CurrentTime . The munger program looks at KERNEL.DEF and sees export CurrentTime . The munger program sees in the relocation table of FOO.OBJ that FOO.OBJ calls for CurrentTime which is undefined in FOO.OBJ or it may bound to a fake object and needs to be redefined . The munger program does the following for that relocation The relocation was of the type call and the munger changes the type to dll call which will be described below. The munger must keep the offset but it doesn t need to keep the symbol as the symbol is not as useful in the preferred embodiment. This is because the preferred embodiment support linking by ordinal not linking by name and the symbol table is therefore superfluous by this point.

The relocation type dll call is a relocation type of the present invention which captures two pieces of information the ordinal and the index. The ordinal refers to a particular record in the export table of KERNEL.DLL and in the present example the ordinal is . As a result the relocation entry reads dll call symbol where 0 is the index which contains a reference to an entry in the import table. This entry in the import table contains the name of the dynamic library i.e. KERNEL.DLL and the UUID of the export table in KERNEL.DLL. The munger does not change any existing relocations only those specified by KERNEL.DEF so the other symbols aren t shown in the drawing. KERNEL.DEF has a number of records and record names KERNEL.DLL and a UUID. The ordinal references a particular entry in the export section of KERNEL.DLL which will be described later in this specification. Other variations may be implemented depending upon the machine on which the system runs.

The UUID of records in KERNEL.DEF defines the specific export table present in KERNEL.DLL that is to be used by FOO.EXE. In the present invention a dll such as KERNEL.DLL can have many different export tables each one uniquely identified by its own UUID. Thus the UUID enables a specific choice among multiple export tables in the dll. The text file KERNEL.DEF can be generated mathematically using existing tools or by hand by the programmer and has been produced for systems running on existing computers. Such existing files may be used to carry out the present invention.

The object file FOO.OBJ of lacks an import table because the compiler that produced it did not support import or export tables in the present example . For an embedded system with very minimal compiler support the invention decreases the time to market because there is no need to reform such a compiler.

The foregoing describes how to produce import tables. How to create an export section for KERNEL.DLL will now be described. The generation from FOO.OBJ of FOO.EXE with an import table has been described and now the generation from KERNEL.OBJ of KERNEL.DLL with an export table will now be described.

Referring to KERNEL.DLL must have an export table. The export table is the one that looks at both the ordinals and the names. Where the system compiler does not support import export tables the munger program constructs the export table as follows It builds an array of ordinals. According to record of KERNEL.DEF the symbol CurrentTime has ordinal number while the symbol last has ordinal number . The munger counts ordinal number as the first export table entry and therefore writes the location X99 of CurrentTime in KERNEL.LIB as the second entry in the export table. In an alternative embodiment of the invention the munger knows the location X99 of CurrentTime because it is stated in record of KERNEL.DEF. In the preferred embodiment however the munger finds this location by inspecting KERNEL.DLL. The munger counts ordinal number as the fourth export table entry and therefore writes the location X66 of the symbol Last as the fourth entry in the export table. The first and second export table entries are left undefined in this example. The munger must put the definition of the symbol CurrentTime namely X99 into the export table as the second entry ordinal because otherwise the tool will fail. The symbol section of KERNEL.DLL defines the name CurrentTime with a pointer to the appropriate location in the text section i.e. X99 and the munger copies this pointer X99 to the corresponding entry ordinal in the new export table.

What goes into the relocation section of any image such as FOO.EXE or KERNEL.DLL is machine dependent. illustrates the object KERNEL.OBJ and the new export section constructed by the munger. The munger combines the two together and thereby produces a new object KERNEL.DLL which has a new export section in which there are four entries the first entry in the illustrated example is void ffff the next entry corresponds to ordinal and is X99 which is the defined symbol CurrentTime and a similar entry corresponding to ordinal for the symbol last . In resolving the unknown symbols and constructing the export table the munger looked up the values of the exported symbols and put them in the export section at the appropriate places ordinals as instructed by the definition file KERNEL.DEF.

Using the UUID permits the system to manage an array of multiples of export sections. In the multiple export tables illustrated in the first entry is the UUID 123 . . . 99 and a number 4 which equals the number of ordinals and then the four entries. A second export section has a UUID 456 . . . 999 and six as the number of ordinals. Thus there can be different versions of the export table designated by different UUID s. Two versions of the dll within the same dll are provided by having two tables. This is done by giving the two versions of the dll two different UUID s. The loader at load time looks for the table with the correct UUID.

The KERNEL.DLL file resembles a COM object analogous to performing a query interface at load time. The UUID is the interface to query for while the export table is the V table. The loader can make the query interface available to applications thus enabling binding at run time. This extends prior art functionality e.g. Windows GetProcAddress through precise versioning and increased flexibility.

In the prior art indirectly jumping through the import section confines all of the address transformations required for sharing of memory in a virtual memory system to a single section the import section . Such transformations allow a dll resource to land in different locations for different executables which it typically does in virtual memory systems. In virtual memory systems a single copy of a resource or code stored in one physical location may appear in different locations in the address spaces of different applications. The indirect jump enables each application to find the resource at the address which the application believes it to be without having to change every call to the DLL that appears in the application image.

In the foregoing example of the call for CurrentTime involves fetching the address to jump to from a specific entry in the import section then jumping to that address. This is an indirect call. In an alternative implementation the entries in the import section could be themselves instructions to jump to the DLL addresses. In this case the instructions in the image are direct calls and the import section acts as a redirector of sorts. Both implementations obtain the same result the call instruction in the executable image direct or indirect that it might be can be re directed simply by changing the import section entries.

In order to increase memory sharing those programs importing from shared libraries that are targeted for multiple address space systems do not themselves point directly to the items exported by the library. Instead they point indirectly through the import section. This way all the pointers pointing from one component to another are collected into a small area. Assuming the library lands in different locations in different address spaces the program can still be shared. In a system where multiple address spaces is not the norm such indirection is plainly overhead both in space and in performance. The import section wastes memory and the indirect memory access wastes cycles.

This problem is solved in the present invention by providing a jump short cutting feature in the loader. Jump short cutting in accordance with the invention requires the loader to go through the relocation table and determine whether the contents of the location pointed to by the relocation entry points to the import section. If so the loader finds the corresponding exported address in the exporting component. The loader looks at the machine instruction that uses the pointer and modifies it to use a direct access to the exported address that was found.

For instance on a typical 80386 or 80486 machine there is one machine instruction for an indirect jump and another for a direct jump both followed by an address. In the present invention the loader finds the address as it was pointed to by the relocation entry. It looks backward for the preceding machine language code that uses the address.

If the code is an indirect jump it is replaced by a direct jump otherwise it is left as it is. The address is replaced by the address found by looking at the import section entry and resolving that with regards to the exporter. Similar implementations are done for other machine instructions and other processors.

The jump short cutting of the present invention operates at or after load time in systems not requiring such indirect jumping by short cutting to a direct call by removing the intermediate jump. If the image is shared then an indirect jump an extra jump is necessary and this feature of the invention is not employed.

As described above the loader goes through the relocation section and finds pointers that need changing. It looks at the export section to see where they go which symbol they go to . If there is only a small amount of memory that can be shared the jump short cutting feature of the invention modifies the indirect jump instruction to a direct jump instruction. This entails changing pointers and instructions and eliminates the needs for an import section. By eliminating the import table section memory is saved. Thus there are two advantages memory is saved by discarding the import section and speed is increased by eliminating the middle jump .

While the jump short cutting feature of the invention is useful for fine tuning virtual memory applications for use in embedded systems having no virtual memory it also may be used for systems with virtual memory in those cases in which the dll resource consistently lands in the same location for different executables.

In order to increase memory sharing and variable protections in a system providing multiple address spaces programs are often linked in a way where different sections a program file contains headers and a number of sections containing machine instructions data etc. are aligned on page boundaries. In this way two sections never share a page instead there is padding between sections at the end of a section. On a system that does not utilize sharing between multiple address spaces and has no need to protect different sections differently the paddings simply amount to memory wastage. On such a system the post link time loader of the present invention removes the alignments pads by relocating each section separately in memory in a consecutive fashion. In general the loader is free to place each section wherever it pleases but the compaction is particularly useful because it can result in a significant memory saving when there are multiple components loaded into memory at once.

Conventionally an empty space at the end of a page is filled with zeros so that sections are aligned on page boundaries by the zero filled padding. Compaction is a process in which the zero filled padding is removed. Referring to a preferred embodiment illustrated in after load time block of compaction is performed block of . Compaction performed at or after load time is so thorough that the text and data sections may be merged block . A prior art linker performs compaction at link time. One embodiment of the invention also includes jump short cutting block . Jump short cutting eliminates the import section block while compaction eliminates padding between images.

Since the invention performs compaction at load time it uses a relocation table to adjust pointers to reflect changed locations. Prior art Win 98 and NT does this at link time not load time and as a result cannot compact text and data sections together so that compaction was incomplete. The indirect jump eliminated at load time in the present invention permits elimination of the import section. Since the relocation table disappears at run time by resolution of all the undefined symbols block and since text and data sections are merged by removing padding between them the load time compaction process of the invention leaves only a single section at run time a significant advantage.

The invention is capable of handing the reverse situation in which a program not originally written to exploit sharing of memory via the virtual memory system is to be loaded into a system that has virtual memory capability. The invention handles this by synthesizing at or before load time new code for the program to fully utilize the virtual memory capability of the platform on which it is loaded.

Imports that were optimized for direct access can be converted to indirect access at run time. This is done by generating the otherwise unnecessary import section on the fly filling it with pointers to the exporting entries and modifying the jump instruction code from direct to indirect. For jumps and calls it is also possible to make jumps and calls directly but into the generated import section instead of directly to the final target. In this case the import section contains code that jumps into the final destination. This is the reverse of the jump short cutting process.

The reverse of the load time compaction process of the invention may be performed at run time as a load time code synthesis where memory sharing is desired. Such a load time code synthesis would be useful where the executable was linked for non virtual memory use and therefore lacks padding to align its section along page boundaries and lacks an import table and indirect jumping. Such load time code synthesis would be useful to make a text section shareable if virtual memory is provided by providing an indirect jump and an import section that did not exist before. The post link time linker determines from the relocation table whether to jump directly or indirectly.

Such load time code synthesis is illustrated in . At load time the post link time munger determines from the relocation table of the linked file whether an indirect jump is required for a particular call block of . If so it adds an import table to the linked file block changes the direct jump to an indirect jump to the import table block and adds a jump block from the import table to the final destination e.g. an export table in a shared library file . The post link time linker further locates the boundaries block between successive sections of the linked file e.g. the boundary between the text and symbol sections and inserts padding at the end of each section so as to bring these boundaries in alignment with the page boundaries of the memory block .

In one aspect of the invention at link time selected code is taken out of an image and inserted into a separate dynamically linked library file. The code thus taken out of the image is now accessible to other images via the separate dll file containing that code. For example in order to reverse the process illustrated in in which three files FOO.OBJ KERNEL.DLL. and KERNEL.DEF are synthesized into a single image FOO.EXE the code synthesis feature of the invention starts with the single image e.g. FOO.EXE and extracts code therein to form a separate dll file e.g. KERNEL.DLL a separate object file FOO.OBJ and so on.

