---

title: Automatic load balancing of a 3D graphics pipeline
abstract: A device has a processor for processing a vertex processing stage, a sub-screen dividing stage and a pixel rendering stage of a three-dimensional (3D) graphics pipeline. The processor includes processing threads which balance the work load of the 3D graphics pipeline by prioritizing processing for the pixel rendering stage over other stages. Each processing thread, operating in parallel and independently, checks a level of tasks in a Task list of sub-screen tasks. If the level is below a threshold value, empty or the sub-screen tasks are all locked, the processing thread loops to the vertex processing stage. Otherwise, the processing thread processes a sub-screen task during the pixel rendering stage.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07940261&OS=07940261&RS=07940261
owner: Qualcomm Incorporated
number: 07940261
owner_city: San Diego
owner_country: US
publication_date: 20070110
---
The present disclosure relates generally to image processing and more specifically to techniques for load balancing a three dimensional 3D graphics pipeline for quick pixel rendering processing processed by an interleaved multi threaded processor.

Converting information about 3D objects into a bit map that can be displayed is known as pixel rendering and requires considerable memory and processing power. In the past 3D graphics were available only on powerful workstations but now 3D graphics accelerators are commonly found in personal computers PC . The hardware graphics accelerator contains memory e.g. instruction random access memory IRAM and a specialized microprocessor to handle many of the 3D rendering operations. Open GL Open Graphics Library for desktops defines an application programming interface API for writing applications that produce 3D and 2D computer graphics. The API includes hundreds of functions for drawing complex three dimensional scenes from primitives.

OpenGL ES is a subset of the desktop OpenGL which creates an interface between software and graphics. The 3D Graphics Engine OpenGL ES is implemented into generally two parts. The first part includes those functions which process the vertex and is typically implemented in the digital signal process DSP firmware. The second part includes those functions for pixel rendering and are implemented in a dedicated hardware graphics accelerator. The second part which performs the pixel rendering is the last pipeline stage of a conventional 3D graphics engine. The last pipeline stage processes input triangle sets to produce a pixel representation of the graphics image. However the last pipeline stage is typically the performance bottle neck of the entire 3D graphics pipeline in the engine. Therefore it is very important to improve the performance in pixel per second of the last pipeline stage for pixel rendering.

Typically during pixel rendering operations each input triangle needs to be processed sequentially in the same order as the triangles are input. Thus a processor with multi threads is prevented from utilizing interleaved parallel processing to process an input triangle.

Furthermore the hardware graphics accelerators are not generally flexible or easily scalable. Thus the hardware graphics accelerators cannot easily add new features support higher versions of the 3D graphics standard such as OpenGL ES 1.0 1.1 . . . support different application configurations and customize requirements. Furthermore the hardware graphics accelerators are not easily scaled for different performance requirements frame rate screen size pixel rate triangle rate etc. . . . to optimize silicon cost and system power consumption.

As can be readily seen a dedicated hardware graphics accelerator takes up silicon area in small handheld computing devices such as a mobile or cellular telephone. Accordingly a dedicated hardware graphics accelerator increases the overall cost of a handheld computing device by the inclusion of the dedicated hardware graphics accelerator and IRAM used. The use of a dedicated hardware graphics accelerator also produces data traffic with the DSP which adds overhead and consumes power.

There is therefore a need in the art for techniques to load balance a three dimensional 3D graphics pipeline to provide quicker pixel rendering processing.

Techniques for a three dimensional 3D graphics pipeline which provide quicker pixel rendering processing without a dedicated hardware graphics accelerator are described herein. In an aspect a processor is implemented comprising a plurality of processing threads. Each processing thread determines whether a sub screen task for pixel rendering operations is available in a task list. Each processing thread further performs the pixel rendering operations on the sub screen task if the sub screen task is available. However if the sub screen task is not available each processing thread performs a vertex processing operation to balance a work load of a three dimensional 3D graphics pipeline.

In another aspect a wireless device is implemented comprising a processor having a plurality of processing threads. Each processing thread prioritizes the pixel rendering operations of a three dimensional graphics pipeline over the vertex processing operations when data is available for the pixel rendering operations. The processor is coupled to memory.

The word exemplary is used herein to mean serving as an example instance or illustration. Any embodiment or design described herein as exemplary is not necessarily to be construed as preferred or advantageous over other embodiments or designs.

Many game applications require three dimensional 3D graphics applications with display 3D objects in a two dimensional 2D space e.g. a display screen . The pixels in a 2D graphics have the properties of position color and brightness while a 3D pixel adds a depth property that indicates where the point lies on an imaginary Z axis. Texture is created as 3D pixels are combined each with its own depth value.

Referring now to an embodiment of a 3D imaging apparatus generally designated at is shown. The 3D imaging apparatus includes a communication unit a digital signal processor DSP a screen with a display area a memory and input output I O units . The shared memory may store game applications or other applications i.e. for two way communications with wired or wireless networks and other software applications as desired by the user or to support the feature set of the apparatus . The I O units may include a keypad keyboard or data communication ports. The screen is operable to display in the display area 2D information as well as 3D graphics.

The 3D imaging apparatus may include one of a personal digital assistant PDA and a mobile cellular or satellite telephone a laptop Notebook Tablet PC Palm Pilot wireless communications device or the like.

Referring now to in the exemplary embodiment the DSP includes an interleaved multi threading processor . The interleaved multi threading processor has a plurality of processing threads PT PT PT . . . PTX. Each processing thread PT PT PT . . . PTX shares the same memory denoted as shared memory . Each processing thread PT PT . . . PTX includes a respective one set of instructions . . . a core . . . processing unit and a register file . . . . The output of each core . . . communicates with the shared memory . The instructions . . . include the programming code for carrying out the operations defined below and other operations for carrying out the feature set such as multi media of the 3D imaging apparatus . The core . . . executes the instructions . . . .

The register file . . . is a set of general purpose registers and is the center stage of the DSP or a microprocessor. These register files . . . hold all the operands typically loaded from memory that is hold all the results from all operations such as arithmetic op logic op etc. before storing the results into the shared memory .

Some DSP architectures have four threads. Nevertheless the DSP can have more than four threads such as without limitation six processing threads which run in parallel. In the exemplary embodiment each thread PT PT PT . . . PTX in parallel provides 100 million instruction packets per second MIPS . Each instruction packet can be four 4 instructions two 2 instructions Sup scalar or just one instruction. However one instruction is not recommended for efficiency because the architecture of the DSP removes the inefficiency caused by inter instruction data dependency.

The terms thread or multi threading are used to describe concurrent task execution. Instead of a single path of execution a program Operations may be split into multiple execution threads which execute simultaneously. In the exemplary embodiment there is a starting thread which requires a function call or instruction and usually requires at least two arguments 1 the address of the start instruction and 2 a context argument. While a thread is operating and or exiting the thread needs to be able to do two basic jobs in relation to other processing threads 1 acquire a shared resource and block other threads from using such resource and 2 safely send messages to other threads e.g. done ready etc. 

Referring now to a graph of the interleaved multi threading parallel processing is shown. In this example there are six 6 processing threads PT PT PT PT PT and PT. The first processing thread PT processes a first instruction set . This is represented by the first top row of the execution time line for the core pipeline. The core pipeline is denoted by cores . . . . While the first instruction set is processed by the first processing thread PT the second processing thread PT processes its first instruction set . This is represented by the second row of the execution time line. Thus the first instruction sets are being parallel processed.

The third processing thread PT processes its first instruction set while the first and second processing threads PT and PT process their first instruction sets . This is represented by the third row of the execution time line for the core pipeline. The fourth processing thread PT processes its first instruction set . Meanwhile the first second and third processing threads PT PT and PT continue processing their associated first instruction sets . This is represented by the fourth row of the execution time line for the core pipeline.

The fifth processing thread PT processes its first instruction set while the first second third and fourth processing threads PT PT PT and PT continue processing their first instruction sets . This is represented by the fifth row of the execution time line for the core pipeline. The sixth processing thread PT processes its first instruction set while the first second third fourth and fifth processing threads PT PT PT PT and PT continue processing their first instruction sets . This is represented by the sixth row of the execution time line for the core pipeline. Thus the processing of instructions by the processing threads is interleaved.

Referring now to the seventh bottom row of assuming that the first processing thread PT has completed its first instruction set the first processing thread PT begins processing a second instruction set while the second third fourth fifth and sixth processing threads PT PT PT PT and PT continue processing their first instruction sets . Hence the processing of each of the processing threads PT PT . . . PTX are in parallel and interleaved.

Describing the interleaved processing for all processing threads is prohibitive. Thus for illustrative purposes the interleaved processing using instructions and is shown in as it relates to a mutex. A mutex is a tool that is owned by only one processing thread at a time. When a processing thread tries to acquire a mutex it LOCKS the mutex. However if the mutex is already LOCKED that processing thread is halted. When the owning thread UNLOCKS the mutex the halted thread is restarted and acquires owner ship of the mutex. This process is shown in .

Starting with the first processing thread PT instructions beings with step SA where non critical code is executed. Step SA is followed by step SA where the first processing thread PT executes a LOCK mutex instruction assuming the mutex is UNLOCKED . Thus the first processing thread PT now owns the mutex . Step SA is followed by step SA where critical code is executed. Step SA is followed by step SA where after the critical code is completed the first processing thread PT executes an UNLOCK mutex instruction. Thereafter the first processing thread PT resumes execution of non critical code at step SA.

In parallel with the first processing thread PT the second processing thread PT begins instructions at step SB where non critical code is executed. Step SB is followed by step SB where the second processing thread PT wants to LOCK the mutex at step SB. However the mutex is in a LOCKED state. Thus the operations of the second processing thread PT are halted until the first processing thread PT UNLOCKS the mutex at step SA. Then step B commences where the critical code may be executed. Step SB is followed by step SB where after the critical code is completed the second processing thread PT executes an UNLOCK mutex instruction. Other instructions may continue thereafter.

The mutex tool or another token tool is used to guarantee serial execution of critical sections in different processing threads only as needed. This is also serializing execution which means that certain code may not be executed in parallel when it could conflict with the execution of code by other threads. The mutex tool is helpful because a shared memory shared resource is used.

Referring now to there is shown an embodiment of a general flow and block diagrams of the 3D graphics pipeline generally designated at . The 3D graphics pipeline divides the entire task of 3D representation in the display area of screen into generally three 3 pipeline stages a vertex processing VP stage a screen sub dividing SSD stage and a pixel rendering PR stage . In operation the vertex processing VP stage includes all the functions or a subset of the functions currently implemented in the OpenGL or OpenGL ES and is processed by a digital signal processor DSP . The line to the screen is shown in phantom because the screen is not part of the 3D graphics pipeline .

The VP stage includes model view transform operations projection operations culling operations lighting and coloring operations primitive assembly operations clipping i.e. user defined clipping operations and perspective division and viewport operations . Each of these operations of the VP stage are well defined in the OpenGL or OpenGL ES.

In general the model view transform operations use math operations to place object models into desired positions and orientations. The projection operations use math operations that make close things large and far things smaller. Occlusion draws near objects in front of far ones. Culling and clipping operations and discard things that are not in view. Lighting operations calculate the effects of lights on surfaces.

In the exemplary embodiment the VP stage can be implemented with one processing thread . The vertex output information includes vertex information to define a triangle and its location in the display area . The vertex output information is superimposed on the display area in that the pixels of the display area include the vertex output information to define triangles in accordance with the OpenGL OpenGL ES or other graphics libraries.

The screen sub dividing SSD stage includes screen sub dividing operations which divide the display area into M N sub screens. The display area is made up of a plurality of pixels P with the vertex output information superimposed. The vertex information from the VP stage provides vertex information such as V V and V of defining triangles such as T and T of for superposition in the display area . The vertex information may include vertex coordinates and edge information. In general the vertex output information for each triangle is just a set of mathematical descriptions to define a closed area. This set of math descriptions is stored in the shared memory so that each processing thread PT PT . . . PTX can use the set of math descriptions to compute each pixel P within its own sub screen task and decide if the pixel is inside a triangle or not.

In the embodiment shown in the display area is divided into M N sub screens wherein M 1 and N 1 to create a grid. For illustrative purposes shows the display area divided into M N sub screens wherein M 1 and N 1. The arrows illustrate the scan or work flow direction. With reference to the display area is divided into M N sub screens wherein M 1 and N 1. Thus the sub screens of display area form a series of columns.

The pixel rendering PR stage includes rasterization blending and texture application operations and hidden surface removal operations . Nevertheless the pixel rendering stage may include other operations defined by OpenGL or OpenGL ES. The PR stage converts the information about 3D objects from the VP stage into a bit map that can be displayed in the display area of screen . The PR stage processes input triangle sets to produce a pixel representation of a 3D graphics image.

A typical pixel rendering PR stage may first take a triangle from a list of the vertex output information. Next the PR stage would take a pixel from the display area and compute the pixel against the triangle to see if it is inside the triangle. If the pixel under evaluation is inside the triangle the PR stage may perform coloring of the pixel with the corresponding color from the triangle. If the pixel under evaluation is not inside the triangle the pixel is skipped. The PR stage would then pick the next pixel in the display area . The PR stage repeats the above process for other pixels in the display area until all pixels have been evaluated or processed for a triangle. Thus pixels are processed one at a time.

Then the typical PR stage would move to the next triangle in the list of vertex output information and repeat the evaluation of the pixels for the current triangle.

The PR stage works in a similar manner with multiple sub screens or sub screen tasks. The difference is that the sub screens have a smaller number of pixels to evaluate or process and multiple sub screens can be processed independently and in parallel by the processing thread PT PT . . . PTX . Thus the processing time for the PR stage is much quicker then a typical PR stage because less pixels are in each sub screen and multiple sub screens can be processed in parallel with each processing thread working independently towards processing the pixels in a respective one sub screen .

In the exemplary embodiment the PR stage is processed using a set of the multiple processing threads PR PR . . . PRX of the interleaved multi threading processor . The number of threads in the set used for the PR stage may be 2 or more with a maximum of X threads.

In operation each processing thread PR PR . . . PRX assigned to the pixel rendering stage seizes an available sub screen task from the Task list and removes it from the Task list . The set of processing threads PR PR . . . PRX process in interleaved parallel operations input triangles to render the pixels in the sub screens convert the input triangle information into a bit map for display in the sub screens . After a respective one processing thread has completed the pixel rendering operations for the seized sub screen task the processing thread moves to the next available sub screen task in the Task list . This operation is repeated until all sub screens have been processed and the pixel rendering stage is complete.

With reference to and the interleaved multi threading processor allows the multi thread processing to be scalable and homogeneous. An operation can be defined by

In a block of four sub screens with a single triangle T is shown for pixel rendering. The operation processes sub screen tasks S S Sand Srepresented as four i sub screens each with a sub divided portion i of a triangle T. The operation is thus equal to operation of the sub screen Splus operation of the sub screen Splus operation of the sub screen Splus operation of the sub screen S. If all of the operations and are processed in parallel the overall peak performance for processing the pixel rendering stage is thus the peak performance for a processing thread multiplied by the number of processing threads used. The sub screen Shas a sub divided portion Tof pixels for triangle T. The sub screen Shas a sub divided portion Tof pixels for triangle T. The sub screen Shas a sub divided portion Tof pixels for triangle T. The sub screen Shas a sub divided portion Tof pixels for triangle T. For illustrative purposes the number of threads is four 4 . Hence in this example the performance would be the performance for one processing thread multiplied by the number of the processing threads. Thus the PR stage is a quick pixel rendering stage by virtue of its ability to process in parallel pixels from multiple sub screens.

In addition the numbers of M and N can be configured after profiling with real application so that the performance can be further optimized for different situations. Configuring M and N provides another dimension of greater flexibility and scalability. Profiling includes identifying the loading tick count of the processing thread or the size or complexity of the operational tasks. Profiling may also include evaluating other components such as parameters associated with the transfer of data and memory capacity from the shared memory . With profiling and adjustment frame rate screen size pixel rate triangle rate etc. could be used to change or vary M and N and or to vary the number of processing threads PR PR . . . PRX for use in the PR stage . With profiling and adjustment the 3D pipeline stages and can be balanced to optimize the entire performance. The remaining processing threads PR PR . . . PRX are used for other applications which are running concurrently such as game audio.

Referring now to the flowchart of the 3D graphics pipeline method for use by the 3D graphics pipeline is shown. The method begins with step S where the vertex processing is performed to create vertex output information. Step S is followed by step S where the display area having the vertex output information superimposed therein is sub divided into M N sub screens. For example as best seen in the triangle T expands across the sub screens S Sand Sand is sub divided into its respective sub divided portions T T Tshown in . Thus the Task list in illustrates the sub divided portions of triangles T and T only two triangles shown for illustrative purposes . As can be appreciated those entries in the Task list from the vertex output information that does not have associated therewith a triangle or has a smaller sub divided portion of a triangle may be processed quicker. Hence before the pixel rendering stage displays a 3D image representative of the triangle on the display area the processing for all sub divided portions of the triangle should be complete.

Step S is followed by step S where the sub screen tasks with or without sub portions of the triangles are created and placed in the Task list . Step S is followed by step S and where Y is the number of the processing threads 2 or more in the set used for the pixel rendering stage . At step S the first processing thread hereinafter referred to as thread gets the first available sub screen task and processes each pixel in the sub screen task at step S especially those pixels determined to be within or inside of a triangle or triangle portion associated with the task. Step Sis followed by step Swhere a determination is made whether it is the end of the Task list . If the determination is YES the processing by thread is ended. Otherwise if the determination is NO step Sreturns to step S. The operation of the second processing thread hereinafter referred to as thread is essentially the same. Thread gets or seizes the next available sub screen task in the Task list . Step Sis followed by step Swhere the sub screen task is processed. Step Sis followed by step S. Step Sis followed by step S. At step S a determination is made whether there are any more tasks in the Task list . If the determination at step Sis NO the method ends. Otherwise if the determination is YES step Sreturns to step S.

Step Sgets or seizes the Yavailable sub screen task by thread Y. Step Sis followed by step Swhere the sub screen task is processed. Step Sis followed by step Swhere a determination is made whether there are any more tasks in the Task list . If the determination is NO the method ends. Otherwise if the determination is YES step Sreturns to step S.

The processing carried out during step S Sand Sperforms the rasterization blending texture application operations and the hidden surface removal operations . With specific reference to the squares with a center dot denote pixels P. Some of the pixels P are inside of the triangle T while some pixels are outside of the triangle T. Each vertex V V and V has a color value attached with smooth shading. Linear interpolation is used to calculate the color values at each pixel P. The vertexes V V and V are used to form triangle T and locate such triangle within the display area . The colors are calculated at each pixel center denoted by the black dot in the center of the square. Various parameters are interpolated including a Z depth alpha fog and texture.

Referring again to in this example there are six 6 threads PT PT PT PT PT and PT. The first thread PT can be used to process the VP stage . The second thread PT can be used to process the SSD stage . The remaining four threads PT PT PT and PT would be used to process sub screen tasks from the Task List in parallel. Here the processing thread PT would get the first available sub screen task and process the pixels in the seized first sub screen task . The processing thread PT would get the next 2 available sub screen task and process the pixels in the seized sub screen task . The processing thread PT would get the next 3 available sub screen task and process the pixels in the seized sub screen task assuming M is greater than 3 .

Assuming M is 4 the processing thread PT would get the next 4 available sub screen task M and process the pixels in the seized sub screen task M. As the processing threads PT PT PT and PT complete their each sub screen task additional sub screen tasks would be seized and processed in parallel until the Task list is empty.

In the embodiment described in for load balancing of the operations of the 3D graphics pipeline at least one of the processing threads used by the 3D graphics pipeline may be employed to process all three of the 3D pipeline stages and . For illustrative purposes only thread may be employed to perform steps S S S as well as steps S and

If one processing thread performs 3 Mpixel sec MIPS rendering it would take approximately 30 instruction packets to process one pixel. This is about 100 instructions per pixel in average. Reserving two of the six threads for the VP stage and the SSD stage and the remaining four processing threads for the PR stage would support a VGA resolution which is four times the performance 12 Mpixel sec of a dedicated hardware graphics accelerator.

Because all processing threads share the same memory the processing threads can all process the same set of input triangle data sub screen tasks very efficiently without duplication using the mutex tool.

The pixel rendering stage is the last pipeline stage of the 3D graphics pipeline . The PR stage processes the input triangle list to produce a pixel representation of a 3D graphics image. The 3D graphics pipeline described above improves the performance in pixel per second of the PR stage . The interleaved multi thread processor increases the performance by a multiple of the number of the processing threads running in parallel to process the Task list .

An advantage of the 3D graphics pipeline architecture is its flexibility in allowing adjustment of the numbers M and N. By increasing the number M and N the MIPS requirement decreases for the pixel rendering stage . Because each sub screen becomes smaller the rendering task becomes simpler. This helps to increase the performance of multiple processing threads. The processing threads can also be used for other concurrent applications such as audio.

As can be readily seen the software implementation described herein for rendering 3D graphics images has a higher performance than hardware implementation of a dedicated graphics accelerator. In comparison to a hardware implementation of a graphics accelerator the embodiment described herein is flexible and scalable. Because the embodiment is flexible it is easy to extend the software code for adding new features support higher versions of the 3D graphics standard such as OpenGL ES 1.0 1.1 . . . and support different application configurations and custom requirements. The scalable feature of the embodiment allows for different performance requirements frame rate screen size pixel rate triangle rate etc. . . . to optimize silicon cost and system power consumption

This embodiment also enables the software implementation to be used with a low cost and low power processor instead of using a high end processor with multi GHz clock speed to reach the same performance.

Referring now to the shared memory includes a variety of queues for the 3D graphics pipeline . The queues include a vertex array a primitive queue and a Task queue . Nevertheless additional queues or buffers may be provided for the tiers or layers of the VP stage . As previously described in relation to the VP stage includes model view transform operations projection operations culling operations lighting and coloring operations primitive assembly operations clipping i.e. user defined clipping operations and perspective division and viewport operations . The operations in the VP stage are tiered or layered such that a lower layer or tier such as primitive assembly operations and clipping operations are dependent on a higher tier or layer such as model view transform operations .

The vertex array includes the vertex coordinates from the model view transform operations . The vertex array contains attributes for each vertex such as vertex positions in model coordinates color for each vertex and texture coordinates. The primitive queue is populated by the primitive assembly operations . The Task queue is populated with the Task list from the SSD stage . However tiers or layers of the VP stage below the primitive assembly operations depend on data populated in the primitive queue to create the vertex output information needed by the SSD stage . The SSD stage creates the necessary Task list for use by the PR stage . However at the same time the primitive assembly operations is dependent on data from a higher tier or layer such as the model view transform operations . The description above related to the primitive assembly operations and the model view transform operations is for illustrative purposes only and applies to other tiers or layers in the VP stage .

Referring now to a flowchart of a method for load balancing the 3D graphics pipeline on a per processing thread basis is shown. In this embodiment processing the PR stage by one or more of the processing threads PT PT . . . PTX is given priority over the VP and SSD stages and in the 3D graphics pipeline . The processing threads PT PT . . . PTX or a subset of processing threads PT PT . . . PTX assigned to process the operations of the 3D graphics pipeline are operable to process in parallel and independently operations of the 3D graphics pipeline . The method would be performed individually and independently by one or more of the processing threads PT PT . . . PTX or sub set of processing threads assigned to the operations of the 3D graphics pipeline .

The method begins with step S where one of the processing threads PT PT . . . PTX initially checks the number of sub screen tasks in the Task list in the Task queue of the shared memory created during the SSD stage . The operations of the SSD stage correspond to steps S and S of . Step S is followed by step S where a determination is made whether the Task queue is empty or all of the remaining sub screen tasks in the Task list are locked by other processing threads. If the determination is NO at step S then step S is followed by step S where the processing thread performs the operations of the PR stage such as steps S and to consume or process one sub screen task. Thereafter step S loops back to step S.

However if the determination is YES at step S then step S is followed by step S where a determination is made whether there are any more 3D graphics operations. If the determination at step S is NO and the Task queue is empty or being emptied Step S by the last pipeline stage PR stage the operations of the 3D graphics pipeline are essentially complete. Thus the method ends. Step S is just one example of the criteria used to end the method . Thus other criteria may be used and placed in the method accordingly.

If the determination at step S is YES step S is followed by step S where vertex processing in the VP stage is performed to produce vertex output information that represents at least one triangle. Step S is followed by step S where the vertex information created at step S is sent to the SSD stage for addition to the Task list in the Task queue . Step S then loops back to step S where the processing thread checks the Task queue again. Generally at step S the processing thread would call a function of the VP stage .

As a further note the evaluating criteria at step S may be varied. For example in the beginning the evaluation criteria at step S may compare the number of sub screen tasks to a watermark or a threshold value indicating the number of sub screen tasks in the Task queue for use by the PR stage . If the number of sub screen tasks is lower than or below the watermark i.e. indicating that there are not many sub screen tasks in the Task queue for pixel rendering then step S is followed by step S. However if the number of sub screen tasks is greater than or above the watermark then the processing thread would perform the operations of the PR stage at step S.

However as the number of sub screen tasks in the Task queue remains below the watermark level after a predetermined number of loops the evaluation criteria may be changed lowered . For example the evaluation criteria may be set to empty and or all sub screen tasks are locked. Accordingly the evaluation criteria of S may be varied back and forth to balance the loading between the PR stage and the VP stage with preference toward the PR stage .

Regarding the tiers or layers of the VP stage alternately at step S of tier checks for data in various queues may be evaluated. By way of example the processing thread during step S may first check the primitive queue or other intermediary tier or layer before checking any of the other higher tiers or layers in the VP stage . If data in an intermediary tier or layer is in a corresponding queue then the processing thread may process data from the tier or layer for use by the lower tiers or layers to produce the vertex output information.

For VP stage balancing a processing thread would seize and lock data in any of the queues in a similar manner as described above in relation to .

The method allows every processing thread PT PT . . . PTX to be created equal and run identical program code which is easier to maintain and add features. The method may also avoid switching overhead between the processing threads.

The method automatically balances the work load between the stages of the 3D graphics pipeline with priority for the PR stage . Furthermore the load balancing automatically balances the work load between each of the pipeline stages and without a manager thread. The load balancing is scalable by adding or removing threads from processing operations of the 3D graphics pipeline . The load balancing requires little communication between each of the processing threads with minimal overhead.

In exemplary embodiments the method may be implemented in hardware software firmware or any combination thereof in a form of a computer program product comprising one or more computer executable instructions. When implemented in software the computer program product may be stored on or transmitted using a computer readable medium which includes computer storage medium and computer communication medium.

The term computer storage medium refers herein to any medium adapted for storing the instructions that cause the computer to execute the method. By way of example and not limitation the computer storage medium may comprise solid sate memory devices including electronic memory devices e.g. RAM ROM EEPROM and the like optical memory devices e.g. compact discs CD digital versatile discs DVD and the like or magnetic memory devices e.g. hard drives flash drives tape drives and the like or other memory devices adapted to store the computer program product or a combination of such memory devices.

The term computer communication medium refers herein to any physical interface adapted to transmit the computer program product from one place to another using for example a modulated carrier wave an optical signal a DC or AC current and the like means. By way of example and not limitation the computer communication medium may comprise twisted wire pairs printed or flat cables coaxial cables fiber optic cables digital subscriber lines DSL or other wired wireless or optical serial or parallel interfaces or a combination thereof.

The previous description of the disclosed embodiments is provided to enable any person skilled in the art to make or use the disclosure. Various modifications to these embodiments will be readily apparent to those skilled in the art and the generic principles defined herein may be applied to other embodiments without departing from the spirit or scope of the disclosure. Thus the disclosure is not intended to be limited to the embodiments shown herein but is to be accorded the widest scope consistent with the principles and novel features disclosed herein.

