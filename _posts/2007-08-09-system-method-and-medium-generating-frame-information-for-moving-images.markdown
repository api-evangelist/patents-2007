---

title: System, method and medium generating frame information for moving images
abstract: A system, method and medium playing a moving image, which includes various content objects is described. The system includes a script parser identifying a plurality of objects which form the moving image, a play-time calculation unit determining a framing time position, from among a total play time of the moving image, and a frame-information record unit recording attributes of the objects which exist in the framing time position.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08559792&OS=08559792&RS=08559792
owner: Samsung Electronics Co., Ltd.
number: 08559792
owner_city: Suwon-Si
owner_country: KR
publication_date: 20070809
---
This application claims priority from Korean Patent Application No. 10 2006 0117796 filed on Nov. 27 2006 in the Korean Intellectual Property Office the disclosure of which is incorporated herein by reference in its entirety.

One or more embodiments of the present invention relate generally to playing a moving image and more particularly to a system method and medium playing a moving image that includes various content objects.

Generally a slideshow is used to show a plurality of contents such as photographs pictures images or videos. In such a slideshow predetermined contents are displayed and the next contents are displayed after a predetermined time interval lapses. Here since the slideshow displays the contents in a stopped state for a predetermined time period the contents are statically expressed so that the user cannot construct the contents based on his her memory or preference. Therefore such a slideshow scheme cannot satisfy the need of users to create a show of their own contents to dynamically express themselves.

Further since the slideshow displays contents one by one it is difficult for the user to instinctively recognize the correlation between contents which are currently displayed contents which have already been displayed and contents which will be displayed at the next stage. Furthermore since the slideshow statically displays images there is a disadvantage in that the images cannot be expressed in a variety of different ways. In addition since the slideshow statically displays predetermined contents for a predetermined time period it is difficult for the user to instinctively recognize the correlation between a plurality of contents for example even the correlation between contents such as photographs which are taken at the same place.

Therefore in order to eliminate the monotony of the slideshow additional effects such as stickers and captions have been added to contents and various dynamic effects such as zoom pan and tilt have been added to the contents. However the slideshow still retains the conventional monotony and displayed contents retain the same general style so that it is impossible to meet various users demands.

Although image production using personal contents is now being actively promoted technical knowledge is required for image production using conventional tools and significant labor is required for converting produced images into formats suitable for various apparatuses in order to enable the produced image to be transmitted to or shared with the apparatuses after the image production. In order to solve such problems many technologies have been developed to enable the user to easily produce a moving image using contents. With the technologies the user can produce a moving image by gathering a plurality of contents enabling the moving picture to be applied in a home server or the like through a process of transmitting and sharing the moving image.

In order to produce such a moving image although it is not apparent to the user operations that allow the structuring of contents into a moving image so as to meet users demands and add an effect suitable for the moving image thereto are required.

The apparatus plays a moving image with reference to a play start point indicated by a dotted line of each content. That is the contents are displayed for a predetermined duration from the playback start point. In addition a dynamic effect may be added to the each of the contents. Therefore although it is possible to access a moving image at each play start point it is impossible to access a moving image at a random time point. For example in t corresponds to a time point at which random access of the user is possible and t corresponds to a time point at which random access of the user is impossible. Also even if random access at tis possible it is impossible to display a scene constructed with objects to which a dynamic effect is applied at the position.

The video frame play procedure of a conventional video play apparatus is performed as shown in . As used herein the term video is distinguished from a moving image. For example a moving image includes a plurality of contents each of which can be individually controlled. In contrast a video includes a plurality of video frames to having various images however the images consist only of pixel information and cannot be individually controlled. In fact video belongs to a category of contents that can be included in a moving image in addition to those already described such as photographs images and sounds. As an example of a moving image there is a ShockWave Flash SWF file produced by software named FLASH of Macromedia Inc.

Referring to video frames to are sequentially displayed at a time interval based on a frame rate i.e. based on the number of frames displayed per second . For example when a frame rate is 30 the video frames are sequentially displayed for 1 30 second for each frame. Therefore the user can randomly access a desired video frame among the overall video frame as desired. Depending on the video coding mode the frames may be divided into those which can be accessed arbitrarily e.g. frame I MPEG and those which cannot be accessed arbitrarily frames P and B MPEG . However this may not be a serious problem when searching for a desired scene.

Therefore the present inventors have determined it desirable to develop a method of enabling random access to a position desired by the user in a moving image.

Accordingly one or more embodiments of the present invention have been made to solve the above mentioned problems occurring in the prior art and aspects of the present invention allow simple control of the play of a moving image including various independent contents.

One or more embodiments of the present invention also enable a dynamic effect to be smoothly realized regardless of the performances of devices playing a moving image.

One or more embodiments of the present invention also provide a method for easily video coding the moving image.

Additional aspects and or advantages will be set forth in part in the description which follows and in part will be apparent from the description or may be learned by practice of the invention.

To achieve at least the above and or other aspects and advantages embodiments of the present invention include a system creating frame information of a moving image the system including a script parser identifying a plurality of objects which form the moving image a play time calculation unit determining a framing time position from among a total play time of the moving image and a frame information record unit recording attributes of the objects which exist in the framing time position.

To achieve at least the above and or other aspects and advantages embodiments of the present invention include a system for playing a moving image the system including a frame information parser reading attributes of objects recorded frame by frame an object loader loading the recorded objects among stored objects and a play unit creating a frame image by applying the attributes corresponding to the loaded objects and displaying the created frame image.

To achieve at least the above and or other aspects and advantages embodiments of the present invention include a method creating frame information of a moving image the method including identifying a plurality of objects which form the moving image determining a framing time position from among a total play time of the moving image and recording attributes of the objects which exist in the framing time position.

To achieve at least the above and or other aspects and advantages embodiments of the present invention include a method for playing a moving image the method including reading attributes of objects recorded frame by frame loading the recorded objects among stored objects creating a frame image by applying the attributes corresponding to the loaded objects and displaying the created frame image.

To achieve at least the above and or other aspects and advantages embodiments of the present invention include a moving image playing system including a frame information parser generating frame metadata including identifiers and attributes of objects included in a corresponding frame and a play controller playing the moving image frame by frame using the frame metadata generated by the frame information parser.

Reference will now be made in detail to embodiments examples of which are illustrated in the accompanying drawings wherein like reference numerals refer to like elements throughout. Embodiments are described below to explain the present invention by referring to the figures. A system according to the present invention may include a moving image creating system shown in a frame information creating system shown in and a moving image playing system shown in .

The moving image creating system may include for example a script creation unit a dynamic effect application unit an object arrangement unit an object storage unit and a user interface .

The user interface may receive a user command to create a moving image according to a user s tastes. Such a user interface may include at least one predefined template. The template may be regarded as a tool for arranging a plurality of objects. Since the template predefines arrangements of objects and dynamic effects thereof the user may easily create a moving image by selecting contents to be used as objects from the template.

Such dynamic effects may include for example transition which shows a screen transition effect through appearance or disappearance of an object animation which changes the location and size of an object at various speeds depending on time and camerawork which shows an effect where a camera rather than an object seems to move.

The object storage unit may include for example a memory and or database which stores various objects used as the components of a moving image and in an embodiment preferably includes a nonvolatile storage medium such as a hard disk or flash memory.

The object arrangement unit and the dynamic effect application unit may function to arrange objects forming a moving image and to apply dynamic effects to the arranged objects according to the user commands input through the user interface .

The object arrangement unit may divide a moving image into a plurality of scenes e.g. see and arrange objects stored in the object storage unit scene by scene according to a template or according to direct user commands. Since one moving image may include a plurality of scenes it is possible to edit and control the moving image by individually editing and controlling each scene.

The object arrangement unit may arrange visible objects and may also arrange audible objects e.g. a background sound an effect sound etc. in synchronization with the visible objects.

The dynamic effect application unit may apply dynamic effects such as transition animation camerawork etc. to objects arranged according to each scene.

Owing to the dynamic effects for objects which are implemented by the dynamic effect application unit the playing of a moving image may be recognized as the playing of a general video from the viewpoint of the user.

The final products of the moving image creating system may include the script which may define objects forming a moving image and the attributes of each object and the execution module which may define dynamic effects for the defined objects while being coupled with the script .

The script may be expressed using a markup language such as Hypertext Markup Language HTML Extensible Markup Language XML etc. and the execution module may be implemented using an Adobe Inc. Macromedia SWF file.

The execution module may modularize each of the objects used e.g. a scene a background image a sticker a text etc. and construct each object as an independent file. In an embodiment the execution module for a scene may be constructed to include execution modules for objects included in the scene.

The script creation unit may record objects that have been determined according to each scene by the object arrangement unit and the attributes of the objects in the type of script .

The term attribute may refer to quantified values indicating the characters of an object at a particular moment. For example the attribute may include the X coordinate Y coordinate depth rotated angle width height and transparency of a corresponding object. The X coordinate and Y coordinate may be based on the left top point of the background image forming a scene. For instance the object of illustrates an example in which the X coordinate Y coordinate rotated angle width and height of the object may change and the object of shows an example in which the X coordinate Y coordinate and transparency of the object may change.

The depth of an object may refer to values representing a display sequence of objects when the objects occupy the same space e.g. in a displayed image. For example in the depth of a picture object has the lowest value i.e. the highest priority for display on the screen and sticker objects and have the highest values i.e. the lowest priority for display on the screen . Thus if the picture object and the sticker objects and should occupy the same space in the displayed image the picture object may appear opaque and obscure the sticker objects to some degree based on the respective display priorities.

The IDs of the objects and the initial values of various attributes may be recorded in the script and changed attributes of the objects may be recorded in the execution module .

The script parser may parse the script created by the moving image creating system and may identify scenes included in a moving image objects included in the scenes and the attributes of the objects.

The play time calculation unit may calculate a total play time period during which the moving image is played by parsing the execution module which represents the dynamic effects for the objects parsed by the script parser . The total play time period may be calculated as the sum of durations of scenes forming the moving image the duration of each scene may be identified by parsing the durations of objects belonging to a corresponding scene.

However depending on the attributes of objects included in one scene the play time periods of other objects may be influenced to change. Generally a display time may be determined based on for example the number of contents objects input by the user included in a scene the attributes of the contents and applied effects. For example when a transition to a next scene is performed after objects belonging to a first scene have been all displayed with applied effects the display of the first scene may end even though a display time for a corresponding object remains.

Also the play time calculation unit may determine a frame rate used to frame the moving image based on the total calculated play time period. The frame rate may be determined as a value input by the user or a predetermined default value. For example the frame rate may be determined by dividing the total play time period by a fixed number or may be determined as a constant frame rate regardless of the total play time period. The former may allow the moving image to have a number of frames proportional to the total play time period and the latter may allow the moving image to have a constant number of frames regardless of the total play time period.

The frame information record unit may record objects e.g. object IDs required according to each frame based on the determined frame rate and the attributes of the objects thereby creating frame metadata . For example when there is a moving image defined to be played as shown in the frame information record unit may record the IDs and attributes of objects required according to each frame position.

In it may be understood that frame fincludes Object a Object b and a sound object frame fincludes Object b and a sound object and frame fincludes only a sound object. In addition since the execution module may store the dynamic effects of the objects it is possible to calculate the attribute of each object in a specific frame. For example when it is assumed that an object has a dynamic effect of moving from coordinates 0 0 which represents that values of X and Y coordinates all are zero to coordinates 5 7 and that the moving time period of the object corresponds to a three frame interval herein a frame interval represents the reciprocal number of a frame rate the coordinates of the object at the position of frame fmay be calculated as 5 3 7 3 and the coordinates of the object at the position of frame fmay be calculated as 10 3 14 3 . Through such a method it may be possible to estimate all the attributes of the object belonging to each frame position.

The frame metadata of a moving image shown in may be recorded in a format as shown in for example. Frame information about frame fmay include the ID and attributes of Object a the ID and attributes of Object b and the ID and attributes of a sound object. Frame information about frame fmay include the ID and attributes of Object b and the ID and attributes of a sound object. Frame information about frame fmay include the ID and attributes of a sound object. Unlike the visible objects the sound object tusually does not include a dynamic effect so that the attribute of the sound object usually includes only time information at each corresponding frame position e.g. synchronization information . This is because a random access to the sound object according to specified time information is already possible.

Meanwhile although in principle dynamic effects are independently applied to objects included in one scene dynamic effects may be assigned only to high level objects in the execution module when dependency between objects exists. illustrates an example of one scene which includes three independent Objects a b and c and one dependent Object d. The execution module may assign a dynamic effect to each of independent Objects a b and c and may not assign any dynamic effect to Object d. In this case Object d may succeed to the dynamic effect of Object a without any change because of the dependency on Object a.

For example in it is assumed that Objects and do not have dependency therebetween Objects and have dependency therebetween Object may be assigned with a dynamic effect of rotation and Object may be assigned with a dynamic effect of movement. Then although Object may not be assigned with a separate dynamic effect Object moves together with the object . In contrast rotation of Object does not exert any influence on Object .

Therefore when the frame information record unit creates frame metadata according to each frame it may be necessary to check if there is dependency between objects belonging to each corresponding frame and to record the attributes of a dependent object with the attributes of a high level object of the dependent object.

Although the frame information creating system is described as a separate system based on the function thereof the frame information creating system may be included in the moving image creating system .

The script parser may parse the script created by the moving image creating system thereby identifying scenes included in a moving image and objects included in the scenes that is identifying the structure of the moving image.

The object storage unit may include a memory and or database which stores various objects used as the components of a moving image and in an embodiment preferably includes a nonvolatile storage medium such as a hard disk or flash memory.

The object loader may read an object requested by the play unit from the object storage unit and load the read object into a main memory. The main memory may include a volatile storage medium such as a random access memory RAM . In this case the object loader may first load a background image object for forming a scene and then load the other objects included into the corresponding scene.

The play controller may provide an interface for controlling the playing operation of the play unit according to a user s command. The control for the playing operation may include normal play stop pause fast forward fast rewind random access etc. illustrates an example of a user interface for enabling the user to input user s commands to the play controller and a play screen for a moving image. Through such an interface the user may command the play controller to perform various control operations for a corresponding moving image.

The play controller may receive commands from the user as described above and also may output a current play state performed by the play unit to the user. In order to receive commands from the user and to output a play state the play controller may provide various application programming interface API functions.

The frame information parser may parse frame metadata of a frame requested by the play unit and provide the parsed frame metadata to the play controller . In detail the frame information parser may read the IDs and attributes of objects included in a corresponding frame and provide the IDs and attributes of the objects to the play controller .

The play unit may play the moving image frame by frame according to the control of the play controller . To this end the play unit may request the frame information parser to provide frame metadata for each frame and receive the frame metadata for each corresponding frame from the frame information parser . The frame metadata may include the IDs and attributes of objects included in a corresponding frame. The play unit may read corresponding objects by requesting the IDs of the objects to the object loader and create one frame image e.g. a still image by applying the attributes corresponding to the read objects to a corresponding frame. The created frame may be provided to and displayed through the display unit during a predetermined frame interval which corresponds to the reciprocal number of a corresponding frame rate. The play unit may divide a moving image including various objects into frames as described above so that the play unit may perform operations based on various controls according to each frame which are requested by the play controller . The play unit may include a sound object play function so that the play unit may output a sound object through a speaker in synchronization with visible objects while framing and playing the visible objects.

The video encoder is an additional component in the moving image playing system . The video encoder may apply a predetermined codec or compression algorithm such as MPEG H.264 etc. to frames created by the play unit thereby easily creating a compressed video.

As described above the moving image playing system according to an embodiment of the present invention may control a moving image including various objects frame by frame. Unlike a video sequence including only pixel information a moving image may maintain information about components thereof without any changes. Therefore it may be possible to realize various arrangements and dynamic effects of the components even with a relatively small storage capacity and to omit complex encoding and decoding procedures. Unlike the conventional moving image which has a problem in that it is difficult or impossible to control the moving image frame by frame embodiments of the present invention enable play control i.e. play control frame by frame while maintaining the advantage of the moving image as it is.

The components shown in and may be implemented by software such as a task a class a sub routine a process an object an execution thread and a program which are performed in a predetermined region of a memory or by hardware such as a Field Programmable Gate Array FPGA and an Application Specific Integrated Circuit ASIC . Further the components may also be realized by a combination of the software and hardware.

In addition to the above described embodiments embodiments of the present invention may also be implemented through computer readable code instructions in on a medium e.g. a computer readable medium to control at least one processing element to implement any above described embodiment. The medium can correspond to any medium media permitting the storing and or transmission of the computer readable code.

The computer readable code may be recorded transferred on a medium in a variety of ways with examples of the medium including recording media such as magnetic storage media e.g. ROM floppy disks hard disks etc. and optical recording media e.g. CD ROMs or DVDs and transmission media such as carrier waves as well as through the Internet for example. Thus the medium may further be a signal such as a resultant signal or bitstream according to embodiments of the present invention. The media may also be a distributed network so that the computer readable code is stored transferred and executed in a distributed fashion. Still further as only an example the processing element could include a processor or a computer processor and processing elements may be distributed and or included in a single device.

According to one or more embodiments of the present invention a user can control a moving image which includes a plurality of objects having various attributes such as time a compression scheme a file type etc. frame by frame in real time. In addition such a frame based control scheme can be applied to a system for creating or playing a moving image and to a system for encoding the moving image into a video sequence and transmitting and distributing the video sequence.

Although a few embodiments have been shown and described it would be appreciated by those skilled in the art that changes may be made in these embodiments without departing from the principles and spirit of the invention the scope of which is defined in the claims and their equivalents.

