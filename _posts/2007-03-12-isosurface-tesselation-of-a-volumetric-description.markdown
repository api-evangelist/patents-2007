---

title: ISO-surface tesselation of a volumetric description
abstract: A multi-threaded graphics processor is configured to generate a tessellated iso-surface from a volumetric description using slices of values that are stored in render targets. The volumetric description can be a complex mathematic equation, a sum of metaballs, a pre-computed scalar field represented as a 3D volume texture, or a rendered volume. Slices are aligned along an axis and spaced before being intersected with the volume to determine iso-surface intersections for the x, y, and z axes. The intersections are stored in render targets and are processed by a shader program to produce a tessellated iso-surface.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07724254&OS=07724254&RS=07724254
owner: NVIDIA Corporation
number: 07724254
owner_city: Santa Clara
owner_country: US
publication_date: 20070312
---
The present invention generally relates to tesselating iso surfaces and more specifically to using a graphics processor to produce a tessellated iso surface from a volumetric description.

Iso surfaces are used to visually represent a set of points from a scalar three dimensional 3D field that have a constant value such that a function of coordinates x y and z f x y z equals a constant. Iso surfaces have applications in medical imaging computational fluid dynamics astrophysics molecular modeling weather forecasting oil exploration and finite element analysis. Iso surfaces also have many potential applications in 3D graphics games and special effects for film production. Iso surfaces may represent a surface of constant pressure temperature velocity or density.

Conventionally tessellated iso surfaces are generated using a central processing unit CPU and consume substantial CPU resources. Volumetric data is represented as a sequence of slices of scalar field data. illustrates a conceptual diagram of prior art slices of values sampled from volumetric data including objects and . A slice intersects object and resulting in object slice values and that are sampled by a two dimensional grid represented by slice . Similarly slice intersects object resulting in object slice values .

Conventional techniques known to those skilled in the art such as the marching cubes algorithm are used to sample the volume data and produce the slices. A lattice of two dimensional cube arrays is used to sample volumetric data where each cube has eight sample locations i.e. a sample at each cube corner. The marching cubes algorithm determines the polygon s required to represent the iso surface that passes through each cube.

As previously described tessellated iso surfaces generated using the marching cubes algorithm consume substantial CPU resources. Accordingly what is needed in the art is a high performance system and method for generating a tessellated iso surface from a volumetric description and the ability to offload the tessellation computations from the CPU.

A multi threaded graphics processor is configured to generate a tessellated iso surface from a volumetric description using slices of values that are stored in render targets in order to offload the tessellation computations from the CPU. The volumetric description can be a complex mathematic equation a sum of metaballs a pre computed scalar field represented as a 3D volume texture or a rendered volume. The multi threaded graphics processor may be used to pre compute the scalar field and store it as a 3D volume texture. Similarly the multi threaded graphics processor may combine mathematical functions including meatballs to produce the volumetric description.

Slices are aligned along an axis and spaced before being intersected with the volume to determine sample values for the slices. The computations needed to determine the sample values may be reduced by using bounding boxes to define regions of the volumetric description where data exists. The computations for multiple cube positions within adjacent slices may be performed for three axes in parallel by the multi threaded graphics processor. The intersection positions for the iso surface and the cube edges are computed in parallel by the multi threaded graphics processor and stored in render targets. Storing the intersections avoid redundant computations since the intersection positions can be used for shared cube edges. The intersection pattern is determined and encoded for the cubes formed by the slices. The intersections and intersection pattern are processed by a shader program to produce a tessellated iso surface. The multi threaded graphics processor can be used to render the tessellated iso surface for visualization purposes.

Various embodiments of a method of the invention for generating a tessellated iso surface from a volumetric description include preparing the volumetric description to provide volumetric data computing and storing weights in a render target in graphics memory determining iso surface intersection patterns for a cube array constructing triangles using the weights and the intersection patterns to produce the tessellated iso surface and storing the triangles in a manner allowing retrieval of the tessellated iso surface. The computed weights correspond to edges between vertices positioned at intersections of the volumetric data and edges of cubes in the cube array that are formed by a first slice intersecting the volumetric data and a second slice intersecting the volumetric data.

Various embodiments of the invention for generating a tessellated iso surface from a volumetric description include a memory and a parallel processing unit coupled to the memory. The memory is configured to store a first gradient render target a second gradient render target a weight render target and a tessellated iso surface render target. The parallel processing unit is configured to simultaneously process volumetric data representing the volumetric description by preparing the volumetric description to provide volumetric data computing and storing weights in a render target in graphics memory determining iso surface intersection patterns for a cube array constructing triangles using the weights and the intersection patterns to produce the tessellated iso surface and storing the triangles in the tessellated iso surface render target. The parallel processing unit is further configured to compute the weights using the first gradient render target and the second gradient render target where the weights corresponding to edges between vertices positioned at intersections of the volumetric data and edges of cubes in the cube array formed by a first slice intersecting the volumetric data and a second slice intersecting the volumetric data.

In the following description numerous specific details are set forth to provide a more thorough understanding of the present invention. However it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details. In other instances well known features have not been described in order to avoid obscuring the present invention.

The volumetric description can be represented as a complex mathematic equation such as a scalar field s F x y z that is a pure mathematic equation or a sum of metaballs. A fragment shader program executed by the multi threaded graphics processor can be configured to compute the complex mathematic equation. Alternatively the volumetric description can be represented as a pre computed scalar field such as a set of scanned scalar values that are packed in a 3D volume texture. Finally 3D volume textures and or primitives can be combined by the multi threaded graphics processor to produce the volumetric description using shading and blending capabilities accessed via a shader program. Additionally a related vector field such as vectors used to compute normals of an iso surface may be included with the volumetric description V F x y z . In other embodiments of the present invention functions for additional parameters are also included with the volumetric description.

In step the multi threaded graphics processor reads the first second and third render targets and computes a first and second gradient slice where the gradient field stored in the first gradient slice is the difference between the second and first slices and the gradient field stored in the second gradient slice is the different between the third and second slices. The gradient slices are stored as gradient render targets. The multi threaded graphics processor is configured to compute gradient slices using a fragment shader program to simultaneously process the scalar fields. In some embodiments of the present invention gradient fields are provided as the volumetric description and step is omitted.

In step the multi threaded graphics processor uses the two gradient fields computed in step to compute weights corresponding to the intersections of the iso surface with each axis x y and z. The weights specify intersection positions of the iso surface between adjacent sample positions i.e. cube corners of an array of cubes formed by the pair of gradient slices. Valid weight values lie between 0 and 1 inclusive. A weight that is not a valid value less than 0 or greater than 1 indicates that a valid intersection does not exist between the two sample positions. The weights for each axis are computed using the following equations Wx axis isolevel 0 0 Wy axis isolevel 0 0 and Wz axis isolevel 0 0 where isolevel is the slice v is the vertex of the cube corner and vx vy and vz are the edge intersections. As described further herein the weights are used to determine vertex values for the tessellated iso surface where each value is a vertex position along one of the axes. The intersection positions where the iso surface intersects an edge of a cube formed by adjacent sample positions become vertices of the tessellated iso surface.

The weights for each axis are stored in separate weight render targets such that a first render target stores x axis intersections a second render target stores y axis intersections and a third render target stores z axis intersections. In other embodiments of the present invention the weights are stored as different components for example in three color component channels red green blue within a single render target. The multi threaded graphics processor is configured to compute the weights using a fragment shader program to simultaneously process each axis for multiple cubes. Processing the samples and slices in parallel allows for adjacent cubes to share computations for common edges reducing redundant computations and improving processing efficiency.

In step the multi threaded graphics processor computes the iso surface intersection pattern the patterns are shown in for each cube defined by the sample positions of the first and second slices determined in step according to the marching cube algorithm. Specifically the scalar values for each cube corner are used to determine the intersection pattern for each cube. The scalar values indicate which side of the iso surface each of the eight cube corners lies. The inside outside state of the iso surface are encoded and used to read the corresponding iso surface intersection pattern from a table. The pattern specifies the number of triangles that are needed to tessellate the intersection of the iso surface and the cube. In some embodiments of the present invention the intersection patterns for an array of cubes defined by the first and second slices are stored in a render target. The combination of triangle vertices for all of the cubes in a 3D volume including the volumetric data forms the tessellated iso surface. A fragment shader program is executed by the multi threaded graphics processor to compute the intersection pattern.

In step the fragment shader program constructs triangles using the intersection pattern weights and scalar field values for the first and second slices to produce the tessellated iso surface. Triangles are constructed by using the intersection pattern to select any edges of a cube that are intersected by the iso surface. A triangle vertex is computed for each intersected edge by using the weights to interpolate between scalar field values from the first and second slices of the edge endpoints for each axis. The selected vertices are stored as a list of triangles in a render target producing a render target that stores the tessellated iso surface. As described in conjunction with the list of triangles may be processed to cull degenerate triangles before being stored in the render target.

In step the multi threaded graphics processor determines if another slice should be processed for the volumetric description and if so in step the multi threaded graphics processor effectively shifts the third and second render targets storing scalar values so that they are used as the second and first render targets respectively. In step the multi threaded graphics processor also shifts the second gradient render target so that it is used as the first gradient render target and returns to step to produce a new third render target and a new second gradient render target. In this manner the computed scalar values for half of the cube corners in the cube array formed by the first and second slices is reused to form a subsequent cube array in a cube lattice. Similarly half of the gradient values are also reused for each subsequent cube array.

In step samples for the third scalar slice are determined by the multi threaded graphics processor and stored as the third render target overwriting the no longer needed first render target. In step the multi threaded graphics processor reads the second and third render targets and computes a second gradient slice where the gradient field stored in the second gradient slice is the difference between the third and second scalar slices. The second gradient field is stored as a second gradient render target overwriting the no longer needed first gradient render target. The method then proceeds to step to process the scalar render targets and gradient render targets and generate additional triangles for the iso surface.

If in step the multi threaded graphics processor determines that another slice should not be processed for the volumetric description then in step the multi threaded graphics processor renders the tessellated iso surface to produce an image. In other embodiments of the present invention the tessellated iso surface is stored in graphics memory or system memory. The tessellated iso surface can be read and rendered at a later time by the multi threaded graphics processor or another processing device.

System memory also includes a device driver that is configured to provide an instruction stream buffer that specifies the location of data such as volumetric description and program instructions to parallel processing subsystem . The program instructions and data are produced by 3D application and may be stored in system memory or memory within other devices of system . Device driver is executed by CPU to translate instructions for execution by parallel processing subsystem based on the specific capabilities of parallel processing subsystem . The instructions may be specified by an application programming interface API which may be a conventional graphics API such as Direct3D or OpenGL.

Memory bridge which may be e.g. a Northbridge chip is connected via a bus or other communication path e.g. a HyperTransport link to an I O input output bridge . I O bridge which may be e.g. a Southbridge chip receives user input from one or more user input devices e.g. keyboard mouse and forwards the input to CPU via path and memory bridge . A parallel processing subsystem is coupled to memory bridge via a bus or other communication path e.g. a PCI Express Accelerated Graphics Port or HyperTransport link in one embodiment parallel processing subsystem is a graphics subsystem that delivers pixels to a display device e.g. a conventional CRT or LCD based monitor . A system disk is also connected to I O bridge . A switch provides connections between I O bridge and other components such as a network adapter and various add in cards and . Other components not explicitly shown including USB or other port connections CD drives DVD drives film recording devices and the like may also be connected to I O bridge . Communication paths interconnecting the various components in may be implemented using any suitable protocols such as PCI Peripheral Component Interconnect PCI Express PCI E AGP Accelerated Graphics Port HyperTransport or any other bus or point to point communication protocol s and connections between different devices may use different protocols as is known in the art.

An embodiment of parallel processing subsystem is shown in . Parallel processing subsystem includes one or more parallel processing units PPUs each of which is coupled to a local parallel processing PP memory . An instruction stream buffer that specifies the location of volumetric description and program instructions determined by 3D application for execution by each PPU may be stored in each PP memory . In general a parallel processing subsystem includes a number U of PPUs where U 4. Herein multiple instances of like objects are denoted with reference numbers identifying the object and parenthetical numbers identifying the instance where needed. PPUs and PP memories may be implemented e.g. using one or more integrated circuit devices such as programmable processors application specific integrated circuits ASICs and memory devices.

As shown in detail for PPU each PPU includes a host interface that communicates with the rest of system via communication path which connects to memory bridge or in one alternative embodiment directly to CPU . In one embodiment communication path is a PCI E link in which dedicated lanes are allocated to each PPU as is known in the art. Other communication paths may also be used. Host interface generates packets or other signals for transmission on communication path and also receives all incoming packets or other signals from communication path and directs them to appropriate components of PPU . For example commands related to processing tasks may be directed to a front end unit while commands related to memory operations e.g. reading from or writing to PP memory may be directed to a memory interface . Host interface front end unit and memory interface may be of generally conventional design and a detailed description is omitted as not being critical to the present invention.

Each PPU advantageously implements a highly parallel processor. As shown in detail for PPU a PPU includes a number C of cores where C 4. Each processing core is capable of executing a large number e.g. tens or hundreds of threads concurrently where each thread is an instance of a program one embodiment of a multithreaded processing core is described below. Cores receive processing tasks to be executed via a work distribution unit which receives commands defining processing tasks from a front end unit . Work distribution unit can implement a variety of algorithms for distributing work. For instance in one embodiment work distribution unit receives a ready signal from each core indicating whether that core has sufficient resources to accept a new processing task. When a new processing task arrives work distribution unit assigns the task to a core that is asserting the ready signal if no core is asserting the ready signal work distribution unit holds the new processing task until a ready signal is asserted by a core .

Cores communicate with memory interface to read from or write to various external memory devices. In one embodiment memory interface includes an interface adapted to communicate with local PP memory as well as a connection to host interface thereby enabling the cores to communicate with system memory or other memory that is not local to PPU . Memory interface can be of generally conventional design and a detailed description is omitted.

Cores can be programmed to execute processing tasks relating to a wide variety of applications including but not limited to linear and nonlinear data transforms filtering of video and or audio data modeling operations e.g. applying laws of physics to determine position velocity and other attributes of objects image rendering operations e.g. vertex shader geometry shader and or pixel shader programs and so on. PPUs may transfer data from system memory and or local PP memories into internal on chip memory process the data and write result data back to system memory and or local PP memories where such data can be accessed by other system components including e.g. CPU or another parallel processing subsystem .

Referring again to in some embodiments some or all of PPUs in parallel processing subsystem are graphics processors with rendering pipelines that can be configured to perform various tasks related to generating pixel data including iso surfaces from volumetric data supplied by instruction stream buffer via memory bridge and bus interacting with local PP memory to store and update pixel data delivering pixel data to display device memory bridge and the like. In addition to system memory or other storage resources within parallel processing subsystem local PP memory can be used as graphics memory including one or more render targets e.g. a conventional frame buffer rendered texture maps rendered volumetric data and the like. Local PP memory can also store instruction stream buffer texture maps and the like. In some embodiments PP subsystem may include one or more PPUs that operate as graphics processors and one or more other PPUs that are used for general purpose computations. The PPUs may be identical or different and each PPU may have its own dedicated PP memory device s or no dedicated PP memory device s .

In operation CPU is the master processor of system controlling and coordinating operations of other system components. In particular CPU issues commands that control the operation of PPUs . In some embodiments CPU writes a stream of commands for each PPU to a pushbuffer not explicitly shown in that is specified by instruction stream buffer or and which may be located in system memory PP memory or another storage location accessible to both CPU and PPU . PPU reads the command stream from the pushbuffer and executes commands asynchronously with operation of CPU .

It will be appreciated that the system shown herein is illustrative and that variations and modifications are possible. The connection topology including the number and arrangement of bridges may be modified as desired. For instance in some embodiments system memory is connected to CPU directly rather than through a bridge and other devices communicate with system memory via memory bridge and CPU . In other alternative topologies parallel processing subsystem is connected to I O bridge or directly to CPU rather than to memory bridge . In still other embodiments I O bridge and memory bridge might be integrated into a single chip. The particular components shown herein are optional for instance any number of add in cards or peripheral devices might be supported. In some embodiments switch is eliminated and network adapter and add in cards connect directly to I O bridge .

The connection of PPU to the rest of system may also be varied. In some embodiments PP system is implemented as an add in card that can be inserted into an expansion slot of system . In other embodiments a PPU can be integrated on a single chip with a bus bridge such as memory bridge or I O bridge . In still other embodiments some or all elements of PPU may be integrated on a single chip with CPU .

A PPU may be provided with any amount of local PP memory including no local memory and may use local memory and system memory in any combination. For instance a PPU can be a graphics processor in a unified memory architecture UMA embodiment in such embodiments little or no dedicated graphics PP memory is provided and PPU would use system memory exclusively or almost exclusively. In UMA embodiments a PPU may be integrated into a bridge chip or processor chip or provided as a discrete chip with a high speed link e.g. PCI E connecting the PPU to system memory e.g. via a bridge chip.

As noted above any number of PPUs can be included in a parallel processing subsystem. For instance multiple PPUs can be provided on a single add in card or multiple add in cards can be connected to communication path or one or more of the PPUs could be integrated into a bridge chip. The PPUs in a multi PPU system may be identical to or different from each other for instance different PPUs might have different numbers of cores different amounts of local PP memory and so on. Where multiple PPUs are present they may be operated in parallel to process data at higher throughput than is possible with a single PPU.

Systems incorporating one or more PPUs may be implemented in a variety of configurations and form factors including desktop laptop or handheld personal computers servers workstations game consoles embedded systems and so on.

In one embodiment each core includes an array of P e.g. 8 16 etc. parallel processing engines configured to receive SIMD instructions from a single instruction unit . Each processing engine advantageously includes an identical set of functional units e.g. arithmetic logic units etc. . The functional units may be pipelined allowing a new instruction to be issued before a previous instruction has finished as is known in the art. Any combination of functional units may be provided. In one embodiment the functional units support a variety of operations including integer and floating point arithmetic e.g. addition and multiplication comparison operations Boolean operations AND OR XOR bit shifting and computation of various algebraic functions e.g. planar interpolation trigonometric exponential and logarithmic functions etc. and the same functional unit hardware can be leveraged to perform different operations.

Each processing engine uses space in a local register file LRF for storing its local input data intermediate results and the like. In one embodiment local register file is physically or logically divided into P lanes each having some number of entries where each entry might store e.g. a 32 bit word . One lane is assigned to each processing engine and corresponding entries in different lanes can be populated with data for different threads executing the same program to facilitate SIMD execution. In some embodiments each processing engine can only access LRF entries in the lane assigned to it. The total number of entries in local register file is advantageously large enough to support multiple concurrent threads per processing engine .

Each processing engine also has access to an on chip shared memory that is shared among all of the processing engines in core . Shared memory may be as large as desired and in some embodiments any processing engine can read to or write from any location in shared memory with equally low latency e.g. comparable to accessing local register file . In some embodiments shared memory is implemented as a shared register file in other embodiments shared memory can be implemented using shared cache memory.

In addition to shared memory some embodiments also provide additional on chip parameter memory and or cache s which may be implemented e.g. as a conventional RAM or cache. Parameter memory cache can be used e.g. to hold state parameters and or other data e.g. various constants that may be needed by multiple threads. Processing engines also have access via memory interface to off chip global memory which can include e.g. PP memory and or system memory with system memory being accessible by memory interface via host interface as described above. It is to be understood that any memory external to PPU may be used as global memory . Processing engines can be coupled to memory interface via an interconnect not explicitly shown that allows any processing engine to access global memory .

In one embodiment each processing engine is multithreaded and can execute up to some number G e.g. 24 of threads concurrently e.g. by maintaining current state information associated with each thread in a different portion of its assigned lane in local register file . Processing engines are advantageously designed to switch rapidly from one thread to another so that instructions from different threads can be issued in any sequence without loss of efficiency.

Instruction unit is configured such that for any given processing cycle a single instruction INSTR is issued to all P processing engines such that core implements a P way SIMD microarchitecture. Since each processing engine is also multithreaded supporting up to G threads concurrently core in this embodiment can have up to P G threads executing concurrently. For instance if P 16 and G 24 then core supports up to 384 concurrent threads. When executing shader programs that are configured to process volumetric data and produce tessellated iso surfaces each thread can compute scalar values gradient values iso surface intersections and intersection patterns for one or more slices in parallel.

Operation of core is advantageously controlled via a core interface . In some embodiments core interface receives data to be processed e.g. primitive data vertex data and or pixel data as well as state parameters and commands defining how the data is to be processed e.g. what program is to be executed from work distribution unit . Core interface can load data to be processed into shared memory and parameters into parameter memory . When execution of a program is completed core advantageously notifies core interface . Core interface can then initiate other processes e.g. to retrieve output data from shared memory and or to prepare core for execution of additional programs.

It will be appreciated that the core architecture described herein is illustrative and that variations and modifications are possible. Any number of processing engines may be included. In some embodiments each processing engine has its own local register file and the allocation of local register file entries per thread can be fixed or configurable as desired. In particular entries of local register file may be allocated for processing each program. Further while only one core is shown a PPU may include any number of cores which are advantageously of identical design to each other so that execution behavior does not depend on which core receives a particular processing task. Each core advantageously operates independently of other cores and has its own processing engines shared memory and so on.

In some embodiments multithreaded processing core of can execute general purpose computations using thread arrays. As used herein a thread array is a group consisting of a number n0 of threads that concurrently execute the same program on an input data set to produce an output data set. Each thread in the thread array is assigned a unique thread identifier thread ID that is accessible to the thread during its execution. The thread ID controls various aspects of the thread s processing behavior. For instance a thread ID may be used to determine which portion of the input data set a thread is to process and or to determine which portion of an output data set a thread is to produce or write.

In some embodiments the thread arrays are cooperative thread arrays or CTAs. As with other types of thread arrays a CTA is a group of multiple threads that concurrently execute the same program referred to herein as a CTA program on an input data set to produce an output data set. In a CTA the threads can cooperate by sharing data with each other in a manner that depends on thread ID. For instance in a CTA data can be produced by one thread and consumed by another. In some embodiments synchronization instructions can be inserted into the CTA program code at points where data is to be shared to ensure that the data has actually been produced by the producing thread before the consuming thread attempts to access it. In some embodiments threads in a CTA share input data such as cube corner scalar values and or intermediate results with other threads in the same CTA using shared memory of . The extent if any of data sharing among threads of a CTA is determined by the CTA program thus it is to be understood that in a particular application that uses CTAs the threads of a CTA might or might not actually share data with each other depending on the CTA program.

For example a CTA program might include an instruction to compute an address in shared memory to which particular data is to be written with the address being a function of thread ID. Each thread computes the function using its own thread ID and writes to the corresponding location. The address function is advantageously defined such that different threads write to different locations as long as the function is deterministic the location written to by any thread is predictable. The CTA program can also include an instruction to compute an address in shared memory from which data is to be read with the address being a function of thread ID. By defining suitable functions and providing synchronization techniques data can be written to a given location in shared memory by one thread of a CTA and read from that location by a different thread of the same CTA in a predictable manner. Consequently any desired pattern of data sharing among threads can be supported and any thread in a CTA can share data with any other thread in the same CTA.

CTAs or other types of thread arrays are advantageously employed to perform computations that lend themselves to data parallel decomposition. As used herein a data parallel decomposition includes any situation in which a computational problem is solved by executing the same algorithm multiple times in parallel on input data to generate output data for instance one common instance of data parallel decomposition involves applying the same processing algorithm to different portions of an input data set in order to generate different portions an output data set. Examples of problems amenable to data parallel decomposition include scalar field value computations gradient field value computations matrix algebra linear and or nonlinear transforms in any number of dimensions e.g. Fast Fourier Transforms and various filtering algorithms including convolution filters in any number of dimensions separable filters in multiple dimensions and so on. The processing algorithm to be applied to each portion of the input data set is specified in the CTA program and each thread in a CTA executes the same CTA program on one portion of the input data set. A CTA program can implement algorithms using a wide range of mathematical and logical operations and the program can include conditional or branching execution paths and direct and or indirect memory access.

For example as is known in the art an array of data values e.g. pixels can be filtered using a 2 D kernel based filter algorithm in which the filtered value of each pixel is determined based on the pixel and its neighbors. In some instances the filter is separable and can be implemented by computing a first pass along the rows of the array to produce an intermediate array then computing a second pass along the columns of the intermediate array. In one CTA implementation of a separable 2 D filter the threads of the CTA load the input data set or a portion thereof into shared memory then synchronize. Each thread performs the row filter for one point of the data set and writes the intermediate result to shared memory . After all threads have written their row filter results to shared memory and have synchronized at that point each thread performs the column filter for one point of the data set. In the course of performing the column filter each thread reads the appropriate row filter results from shared memory and a thread may read row filter results that were written by any thread of the CTA. The threads write their column filter results to shared memory . The resulting data array can be stored to global memory or retained in shared memory for further processing. Where shared memory can be accessed with lower latency and or greater bandwidth than global memory storing intermediate results in shared memory advantageously improves processor throughput.

In one embodiment a driver program executing on CPU of writes commands defining the CTA to a pushbuffer not explicitly shown in memory e.g. system memory from which the commands are read by a PPU . The commands advantageously are associated with state parameters such as the number of threads in the CTA the location in global memory of an input data set to be processed using the CTA the location in global memory of the CTA program to be executed and the location in global memory where output data is to be written. The state parameters may be written to the pushbuffer together with the commands. In response to the commands core interface loads the state parameters into core e.g. into parameter memory then begins launching threads until the number of threads specified in the CTA parameters have been launched. In one embodiment core interface assigns thread IDs sequentially to threads as they are launched. More generally since all threads in a CTA execute the same program in the same core any thread can be assigned any thread ID as long as each valid thread ID is assigned to only one thread. Any unique identifier including but not limited to numeric identifiers can be used as a thread ID. In one embodiment if a CTA includes some number n of threads thread IDs are simply sequential one dimensional index values from 0 to n 1. In other embodiments multidimensional indexing schemes can be used. It should be noted that as long as data sharing is controlled by reference to thread IDs the particular assignment of threads to processing engines will not affect the result of the CTA execution. Thus a CTA program can be independent of the particular hardware on which it is to be executed.

Data assembler is a fixed function unit that collects vertex data for high order surfaces primitives and the like and outputs the vertex data to vertex processing unit . Data assembler receives a stream of shader program instructions and parameters for processing. For example data assembler can receive a stream of shader program instructions and parameters associated with a volumetric description and produce a render target storing volumetric data . Graphics memory includes system memory and or PP memory and is used to store one or more render targets produced by a PPU configured to perform one or more functions of graphics processing pipeline . For example graphics memory stored render targets containing volumetric data slice scalar field gradient field weights tessellated iso surface and rendered iso surface .

Vertex processing unit is a programmable execution unit that is configured to execute vertex shader programs transforming vertex data as specified by the vertex shader programs. For example vertex processing unit may be programmed to transform the vertex data from an object based coordinate representation object space to an alternatively based coordinate system such as world space or normalized device coordinates NDC space. Vertex processing unit may read data that is stored in PP memory such as a tessellated iso surface stored in a render target through memory interface for processing according to a vertex shader program.

Primitive assembler receives processed vertex data from vertex processing unit and constructs graphics primitives e.g. points lines triangles or the like for processing by geometry processing unit . Geometry processing unit is a programmable execution unit that is configured to execute geometry shader programs transforming graphics primitives received from primitive assembler as specified by the geometry shader programs. For example geometry processing unit may be programmed to subdivide the graphics primitives into one or more new graphics primitives and calculate parameters such as plane equation coefficients that are used to rasterize the new graphics primitives. Geometry processing unit outputs the parameters and new graphics primitives to rasterizer . Geometry processing unit may read data that is stored in PP memory such as tessellated iso surface or volumetric data through memory interface for use in processing the geometry data.

Rasterizer scan converts the graphics primitives and outputs fragments and coverage data to fragment processing unit . Fragment processing unit is a programmable execution unit that is configured to execute fragment shader programs transforming fragments received from rasterizer as specified by the fragment shader programs. For example fragment processing unit may be programmed to perform operations such as perspective correction texture mapping shading blending and the like to produce shaded fragments that are output to raster operations unit . Specifically fragment processing unit can be configured to compute slice sample values gradients and weights.

Fragment processing unit may read data that is stored in PP memory such as slice scalar field gradient field weights and volumetric data through memory interface for use in processing the fragment data. Memory interface produces read requests for data stored in graphics memory decompresses any compressed data and performs texture filtering operations e.g. bilinear trilinear anisotropic and the like. Fragment processing unit may also write data to render targets in graphics memory such as slice scalar field gradient field weights and volumetric data and tessellated iso surface .

Raster operations unit is a fixed function unit that optionally performs near and far plane clipping and raster operations such as stencil z test and the like and outputs pixel data as processed graphics data for storage in graphics memory. Raster operations unit writes the data to one or more render targets in graphics memory including volumetric data and rendered iso surface . In some embodiments of the present invention data output by fragment processing unit is written to a render target via raster operations unit such as slice scalar field gradient field weights and volumetric data and tessellated iso surface . The processed graphics data stored in graphics memory can be output for display on display device .

The processing effort required to produce scalar slices and gradient slices can be reduced by only processing portions of the volumetric data where objects are present. illustrates a conceptual diagram of using bounding boxes to produce slices of values sampled from volumetric data including objects and in accordance with one or more aspects of the present invention. Bounding boxes and are determined using techniques known to those skilled in the art. Bounding boxes and are used to limit the processing of the volumetric description containing objects and to those portions of slices and that lie within a boundary of bounding boxes or . Therefore in order to produce object slice values and of slice only the portions of volumetric data that lie within bounding boxes and are processed. Bounding boxes and define clipping rectangles for slice and bounding box defines a clipping rectangle for slice . Similarly slice intersects object resulting in object slice values . Again in order to produce object slice values of slice only the portions of volumetric data that lie within bounding box are processed. In other embodiments of the present invention bounding spheres or other bounding surfaces are used to indicate portions of the volumetric data that should be processed.

Although the slices are typically positioned with regular spacing along the z axis in world space to produce the scalar slices and gradient slices in some cases it is desirable to position the slices along a different axis or with varying spacing. A slice can be defined as functions of x y and z coordinates by any plane equation. For example the slices can be aligned along the z axis in camera space to produce a view dependent iso surface tessellation. The spacing between the slice can increase as the distance from the camera increases to produce more detail near the camera and less detail further from the camera. Varying the spacing in this manner is particularly useful when real time tessellation is performed that requires a different tessellation for each frame. In other embodiments of the present invention the x and y scale of each slice varies increasing as the distance from the camera increases to produce a perspective corrected tessellation in order to provide more detail close to the viewpoint and less detail further from the viewpoint.

In step a slice alignment is selected and specified by a shader program for processing of the volumetric data. As previously described the z axis can be aligned according to the world space camera space or another space. In step a slice spacing is selected and specified by the shader program for processing of the volumetric data. A regular equal spacing can be used or the spacing may vary as a function of z or another variable.

In step samples for first second and third scalar slices are determined by parallel processing subsystem and stored as first second and third render targets e.g. slice scalar field as described in conjunction with step of . In step parallel processing subsystem also reads the first second and third render targets and computes a first and second gradient slice e.g. gradient field as described in conjunction with step of . In step parallel processing subsystem computes weights corresponding to the intersections of the iso surface with each axis x y and z e.g. weights and computes the iso surface intersection pattern according to the marching cube algorithm as described in conjunction with steps and .

As previously described in conjunction with degenerate triangles are produced for each cube that has fewer than 5 triangles according to the pattern shown in . The generate triangles don t appear in a rendered image. For example when the pattern specifies that 2 triangles are needed for the iso surface intersection with the cube 3 degenerate triangles are produced. Removing the degenerate triangles reduces the number of triangles stored in tessellated iso surface . Removing the degenerate triangles prior to rendering may improve the processing throughput of triangles that contribute to the final image since the degenerate triangles are not processed prior to culling them following primitive assembly. Therefore processing efficiency for rendering the triangles is improved since less data needs to be read and processed to produce the rendered iso surface . In step parallel processing subsystem executes a geometry shader program to construct triangles using the intersection patterns scalar fields e.g. slice scalar field and weights to produce tessellated iso surface that does not include degenerate triangles. Execution of the geometry shader program effectively removes the degenerate triangles from the tessellated iso surface . In some embodiments of the present invention tessellated iso surface without the degenerate triangles is stored in system memory for use at a later time.

In step parallel processing subsystem determines if another slice should be processed for the volumetric description and if so in step parallel processing subsystem effectively shifts the third and second render targets storing scalar values e.g. slice scalar field so that they are used as the second and first render targets respectively. In step parallel processing subsystem also shifts the second gradient render target so that it is used as the first gradient render target. In step parallel processing subsystem determines a new scalar and gradient slice and returns to step to produce a new third render target and a new second gradient render target.

If in step parallel processing subsystem determines that another slice should not be processed for the volumetric description then in step parallel processing subsystem renders tessellated iso surface to produce rendered iso surface that is stored in a render target. In other embodiments of the present invention tessellated iso surface is stored and output for rendering at a later time by parallel processing subsystem or another processing device.

A multi threaded graphics processor is configured to generate a tessellated iso surface from a volumetric description using slices of values that are stored in render targets in order to offload the tessellation computations from the CPU. The volumetric description can be a complex mathematic equation a sum of metaballs a pre computed scalar field represented as a 3D volume texture a combination of many small 3D volumes or a rendered volume. A rendered volume can be the result of combining several 3D volumes and storing scalar fields. The volumetric description may also include other parameters such as vectors used to compute normals of an iso surface. The multi threaded graphics processor may be used to process the volumetric description and produce the volumetric data.

Slices are aligned along an axis and spaced before being intersected with the volume to determine sample values for the slices. The computations needed to determine the sample values may be reduced by using bounding boxes to define regions clipping rectangles of the volumetric data where the iso surface exists. The computations for multiple cube positions within adjacent slices may be performed in parallel by the multi threaded graphics processor and stored in render targets. Slice alignment dimensions and spacing may be varied according to a shader program.

The invention has been described above with reference to specific embodiments. Persons skilled in the art however will understand that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The foregoing description and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

