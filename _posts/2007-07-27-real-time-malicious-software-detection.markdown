---

title: Real time malicious software detection
abstract: A method, system, computer program product and/or computer readable medium of instructions for detecting malicious software, comprising intercepting a request to perform an activity in a processing system; determining an entity associated with the activity, wherein the entity comprises at least one of: a requesting entity of the activity; and a target entity of the activity; analysing the entity and the activity to determine if the request is associated with malicious software; and in the event that the request is determined to be associated with malicious software, restricting the request to perform the activity in the processing system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07877806&OS=07877806&RS=07877806
owner: Symantec Corporation
number: 07877806
owner_city: Mountain View
owner_country: US
publication_date: 20070727
---
This application claims the benefit of priority from U.S. Provisional Patent Application No. 60 833 858 filed Jul. 28 2006 and is incorporated by referenced.

The present invention generally relates to a method system computer readable medium of instructions and or computer program product for detecting malicious activity in a processing system.

As used herein a threat comprises malicious software also known as malware or pestware which comprises software that is included or inserted in a part of a processing system for a harmful purpose. The term threat should be read to comprise possible potential and actual threats. Types of malware can comprise but are not limited to malicious libraries viruses worms Trojans adware malicious active content and denial of service attacks. In the case of invasion of privacy for the purposes of fraud or theft of identity malicious software that passively observes the use of a computer is known as spyware .

A hook also known as a hook procedure or hook function as used herein generally refers to a callback function provided by a software application that receives certain data before the normal or intended recipient of the data. A hook function can thus examine or modify certain data before passing on the data. Therefore a hook function allows a software application to examine data before the data is passed to the intended recipient.

An API Application Programming Interface hook also known as an API interception as used herein as a type of hook refers to a callback function provided by an application that replaces functionality provided by an operating system s API. An API generally refers to an interface that is defined in terms of a set of functions and procedures and enables a program to gain access to facilities within an application. An API hook can be inserted between an API call and an API procedure to examine or modify function parameters before passing parameters on to an actual or intended function. An API hook may also choose not to pass on certain types of requests to an actual or intended function.

A process as used herein is at least one of a running software program or other computing operation or a part of a running software program or other computing operation that performs a task.

A hook chain as used herein is a list of pointers to special application defined callback functions called hook procedures. When a message occurs that is associated with a particular type of hook the operating system passes the message to each hook procedure referenced in the hook chain one after the other. The action of a hook procedure can depend on the type of hook involved. For example the hook procedures for some types of hooks can only monitor messages others can modify messages or stop their progress through the chain restricting them from reaching the next hook procedure or a destination window.

In a networked information or data communications system a user has access to one or more terminals which are capable of requesting and or receiving information or data from local or remote information sources. In such a communications system a terminal may be a type of processing system computer or computerised device personal computer PC mobile cellular or satellite telephone mobile data terminal portable computer Personal Digital Assistant PDA pager thin client or any other similar type of digital electronic device. The capability of such a terminal to request and or receive information or data can be provided by software hardware and or firmware. A terminal may comprise or be associated with other devices for example a local data storage device such as a hard disk drive or solid state drive.

An information source can comprise a server or any type of terminal that may be associated with one or more storage devices that are able to store information or data for example in one or more databases residing on a storage device. The exchange of information ie. the request and or receipt of information or data between a terminal and an information source or other terminal s is facilitated by a communication means. The communication means can be realised by physical cables for example a metallic cable such as a telephone line semi conducting cables electromagnetic signals for example radio frequency signals or infra red signals optical fibre cables satellite links or any other such medium or combination thereof connected to a network infrastructure.

A system registry is a database used by operating systems for example Windows platforms. The system registry comprises information needed to configure the operating system. The operating system refers to the registry for information ranging from user profiles to which applications are installed on the machine to what hardware is installed and which ports are registered.

An entity can comprise but is not limited to a file an object a class a collection of grouped data a library a variable a process and or a device.

There are currently a number of techniques which can be used to detect malicious software in a processing system.

One technique comprises using database driven malicious software techniques which detect known malicious software. In this technique a database is used which generally comprises a signature indicative of a particular type of malicious software. However this technique suffers from a number of disadvantages. Generating and comparing signatures for each entity in a processing system to the database can be a highly process intensive task. Other applications can be substantially hampered or can even malfunction during this period of time when the detection process is performed. Furthermore this technique can only detect known malicious software. If there is no signature in the database for a new type of malicious software malicious activity can be performed without the detection of the new type of malicious software.

Therefore there exists a need for a method system computer readable medium of instructions and or a computer program product which can more effectively detect malicious activity in a processing system which addresses or at least ameliorates at least one of the problems inherent in the prior art.

The reference in this specification to any prior publication or information derived from it or to any matter which is known is not and should not be taken as an acknowledgment or admission or any form of suggestion that that prior publication or information derived from it or known matter forms part of the common general knowledge in the field of endeavour to which this specification relates.

In a first broad form there is provided a method of detecting malicious software wherein the method comprises 

analysing the entity and the activity to determine if the request is associated with malicious software and

in the event that the request is determined to be associated with malicious software restricting the request to perform the activity in the processing system.

filtering using a filter module the activity according to determine if the activity is suspicious and

in the event that the activity is determined to be suspicious performing the analysis to determine if the request is associated with malicious software.

In one particular form the filter module comprises a list of filter rules to determine if at least one of the target entity and the requesting entity are suspicious or non suspicious wherein the method comprises determining an order of the list according to a frequency of instances each filter rule has been previously satisfied wherein the filter module is used at least partially based on the determined order.

In another particular form the filter module comprises a list of susceptible target entity filter rules wherein the step of determining if the activity is suspicious comprises determining if the target entity satisfies one of the susceptible target entity filter rules and in response to one of the susceptible target entity filter rules being satisfied the activity is identified as being suspicious.

In an optional form the filter module comprises a list of non susceptible target entity filter rules wherein the step of determining if the activity is non suspicious comprises determining if the target entity satisfies one of the non susceptible target entity filter rules and in response to one of the non susceptible target entity filter rules being satisfied the activity is identified as being non suspicious.

In another optional form the filter module comprises a list of non trusted requesting entity filter rules wherein the step of determining if the activity is suspicious comprises determining if the requesting entity satisfies one of the non trusted requesting entity filter rules and in response to one of the non trusted requesting entity filter rules being satisfied the activity is identified as being suspicious.

Optionally the filter module comprises a list of trusted requesting entity filter rules wherein the step of determining if the activity is non suspicious comprises determining if the requesting entity satisfies one of the non trusted requesting entity filter rules and in response to one of the non trusted requesting entity filter rules being satisfied the activity is identified as being non suspicious.

determining an entity threat value for the entity the entity threat value being indicative of a level of threat that the entity represents to the processing system wherein the entity threat value is determined based on one or more characteristics of the entity and

comparing the entity threat value to an entity threat threshold determine if the request is associated with malicious software.

In another embodiment each of the one or more characteristics of the entity is associated with a respective characteristic threat value wherein the method comprises calculating the entity threat value using at least some of the characteristic threat values for the one or more characteristics of the entity.

determining one or more related entities to the entity wherein each related entity has an associated entity threat value and 

calculating the entity threat value for the entity using the entity threat value for at least some of the one or more related entities.

determining one or more related entities to the entity wherein each related entity has an associated entity threat value and 

calculating a group threat value for the entity and one or more related entities using the entity threat value for at least some of the one or more related entities and the entity.

performing a fuzzy logic analysis in relation to the one or more values to determine if the request is associated with malicious software.

In a second broad form there is provided a system to detect malicious software wherein the system is configured to 

analyse at least one of the requesting entity the target entity and the action to determine if the activity is associated with malicious software and

restrict the request to perform the activity in the processing system in the event that the request is determined to be associated with malicious software.

In a third broad form there is provided a computer program product comprising a computer readable medium having a computer program recorded therein or thereon the computer program enabling detection of malicious software wherein the computer program product configures the processing system to 

analyse at least one of the requesting entity the target entity and the action to determine if the activity is associated with malicious software and

restrict the request to perform the activity in the processing system in the event that the request is determined to be associated with malicious software.

According to another broad form the present invention provides a computer readable medium of instructions for giving effect to any of the aforementioned methods or systems. In one particular but non limiting form the computer readable medium of instructions are embodied as a software program.

The following modes given by way of example only are described in order to provide a more precise understanding of the subject matter of a preferred embodiment or embodiments.

In the figures incorporated to illustrate features of an example embodiment like reference numerals are used to identify like parts throughout the figures.

A particular embodiment of the present invention can be realised using a processing system an example of which is shown in . The processing system illustrated in relation to can be used as a client processing system and or a server processing system .

In particular the processing system generally comprises at least one processor or processing unit or plurality of processors memory at least one input device and at least one output device coupled together via a bus or group of buses . In certain embodiments input device and output device could be the same device. An interface can also be provided for coupling the processing system to one or more peripheral devices for example interface could be a PCI card or PC card. At least one storage device which houses at least one database can also be provided. The memory can be any form of memory device for example volatile or non volatile memory solid state storage devices magnetic devices etc. The processor could comprise more than one distinct processing device for example to handle different functions within the processing system . Input device receives input data and can comprise for example a keyboard a pointer device such as a pen like device or a mouse audio receiving device for voice controlled activation such as a microphone data receiver or antenna such as a modem or wireless data adaptor data acquisition card etc. Input data could come from different sources for example keyboard instructions in conjunction with data received via a network. Output device produces or generates output data and can comprise for example a display device or monitor in which case output data is visual a printer in which case output data is printed a port for example a USB port a peripheral component adaptor a data transmitter or antenna such as a modem or wireless network adaptor etc. Output data could be distinct and derived from different output devices for example a visual display on a monitor in conjunction with data transmitted to a network. A user could view data output or an interpretation of the data output on for example a monitor or using a printer. The storage device can be any form of data or information storage means for example volatile or non volatile memory solid state storage devices magnetic devices etc.

In use the processing system can be adapted to allow data or information to be stored in and or retrieved from via wired or wireless communication means the at least one database . The interface may allow wired and or wireless communication between the processing unit and peripheral components that may serve a specialised purpose. The processor receives instructions as input data via input device and can display processed results or other output to a user by utilising output device . More than one input device and or output device can be provided. It should be appreciated that the processing system may be any form of terminal server processing system specialised hardware or the like.

The processing system may be a part of a networked communications system. The processing system could connect to network for example the Internet or a WAN. The network can comprise one or more client processing systems and one or more server processing systems refer to wherein the one or more client processing systems and the one or more server processing systems are forms of processing system . Input data and output data could be communicated to other devices via the network. The transfer of information and or data over the network can be achieved using wired communications means or wireless communications means. The server processing system can facilitate the transfer of data between the network and one or more databases. The server processing system and one or more databases provide an example of an information source.

Referring to there is shown a block diagram illustrating a request . Generally the request comprises an activity a target entity and a requesting entity . In particular the requesting entity causes the activity to be performed in relation to the target entity .

For example an executable object in a processing system may request to download data from a web site on the Internet. In this example the executable object would be considered the requesting entity the activity would be considered the act of downloading data and the target entity would be the web site on the Internet. The requesting entity is a starting point in the processing system or network of processing systems which requests the action to be performed and the target entity is an end point in the processing system or network of processing systems which the action is performed in relation to.

As will be described in more detail an request is analysed to determine at least one of the requesting entity and the target entity . By determining at least one of the requesting entity and the target entity an accurate and efficient process of detecting malicious software in a processing system can be performed.

Referring to there is shown an example of a method of intercepting an activity in a processing system .

At step an event occurs in the processing system . The event can be a request by a requesting entity to perform an action in relation to a target entity . At step an operating system running in the processing system registers the occurrence of the event. At step the operating system passes the registered event to the hook chain. At step the event is passed to each hook in the hook chain such that different applications processes and devices may be notified of the registered event. Once the event has propagated throughout the hook chain the method comprises at step an application receiving notification of the event being registered by the processing system .

At step the method comprises the application initiating an API call to an API procedure so as to carry out a response to the registered event wherein the response may be the execution of the action in relation to the target entity . If an API hook has been established between the API call and the API procedure the API call is intercepted before it reaches the API procedure at step . Processing can be performed by an API hook function once the API call has been intercepted prior to the API procedure being called. The API call may be allowed to continue calling the API procedure at step such that the action is performed in relation to the target entity .

Referring to there is shown a method of detecting malicious software. At step the method comprises intercepting a request to perform an activity in the processing system . At step the method comprises determining at least one of the requesting entity associated with the activity and the target entity associated with the activity . At step and the method comprises analysing at least one of the requesting entity the target entity and the activity to determine if the request is associated with malicious software. In the event that the request is determined to be associated with malicious software the method comprises restricting the request to perform the activity in the processing system at step . In the event that the request is not associated with malicious software the method proceeds to step which comprises allowing the request to perform the activity in the processing system .

Referring now to there is shown a system to detect malicious software. In particular at least some requests to perform an activity in the processing system are intercepted by an interception module using the technique outlined in . The intercepted requests are then analysed to determine at least one of the requesting entity and the target entity and the activity . The results can optionally be passed onto the filter module as will be explained in more detail later or can be passed to an analysis module to analyse at least one of the requesting entity the target entity and the activity of the request to determine whether the request is malicious. Malicious requests are restricted by a restriction module . As will be explained in more detail the restriction module can perform a number of different processes in order to restrict the request being performed as well as restricting similar future requests being performed in the processing system .

The method and system advantageously allow the detection of the malicious software prior to the malicious activity being performed in the processing system ie. real time detection thus restricting the processing system being compromised.

The system can be implemented in a single processing system . Alternatively as will be discussed in more detail below the system can be implemented using one or more client processing systems and one or more server processing systems referred to as a distributed system . In this form the system determines whether there is a request to perform an activity which is associated with malicious software in the one or more client processing systems .

At step the method comprises determining at least one of the requesting entity and the target entity of the activity of the request. This determination can be performed by the interception module in the form of a hook function which is used to intercept the activity in the processing system .

At steps and the method comprises using a filter module and one of the target entity and or the requesting entity and the activity to determine if the request is suspicious . In the event that the request is identified as being suspicious the method proceeds to step .

At step the method comprises using an analysis module to analyse at least one of the target entity the requesting entity and the activity of the request. At step the method comprises determining based on the results of the analysis performed at step whether the request to perform the activity is associated with malicious software.

In response to a positive determination the method proceeds to step where the request to perform the activity associated with the malicious software is restricted. This can comprise failing to call the API procedure. Alternatively parameters passed to the API procedure are modified such that the malicious activity associated with the request is restricted.

In response to a negative determination the method proceeds to step where the request to perform activity is satisfied. This may comprise passing the parameters to the procedure as outlined in .

Optionally the method can comprise informing a user of the processing system of the detection of the malicious activity prompting the user of the processing system regarding the detected malicious activity and optionally receiving input from the user regarding steps to deal with the malicious activity ie. deny the action or allow the action . In the event that the processing system in this example is a client processing system the method can optionally comprise reporting the detection of malicious activity to the server processing system .

By using the filter module the number of false positives which subsequently require analysis are reduced. For example if the filter module filters out system calls caused by the user interacting with the processing system then such non suspicious activities are not analysed thereby reducing the amount of analysis to be performed. Furthermore by filtering the activity based on the target entity and or the requesting entity using the filter module a more accurate filtering process can be performed. As will be further described the order in which the filtering is performed by the filter module can also substantially reduce the amount of processing performed when determining if an activity is suspicious.

To further illustrate the advantages of using the filter module the following example is provided. An activity of transferring data over a network may be monitored as an activity of interest in the processing system as this activity is commonly associated with malicious software. Throughout a particular period of time the processing system may record one hundred instances when the processing system transferred data over the network. A large number of these instances are likely to be non suspicious activities such as a user requesting to transfer data over the network. Performing an analysis of one hundred activities which are likely to not be suspicious can waste valuable processing and storage resources. However by filtering the activities based on the target entity and or the requesting entity suspicious activities which require analysis can be determined thereby substantially reducing the number of activities which require analysis to determine if malicious activity being performed or is going to be performed in the processing system . Filtering intercepted activities in the processing system can eliminate non suspicious activity which is not considered to be associated with malicious activity such as a user initiated activity to transfer data over the network.

Referring now to there is shown a block diagram illustrating the filter module . In particular the filter module comprises a number of lists of filter rules for filtering activity intercepted in the processing system . The filter module can comprise at least one of a susceptible target entity filter list a non susceptible target entity filter list a trusted requesting entity filter list and a non trusted requesting entity filter list .

The susceptible target filter list comprises one or more target entity filtering rules which determine if the target entity relating to the intercepted activity is of interest thereby identifying that the activity is considered suspicious . For example a common back door entity in a processing system may generally be known to be susceptible to malicious software attacks. One of the target entity filtering rules may require a comparison of the name of the target entity to the name of the common back door entity and if the susceptible target entity rule is satisfied the target entity is considered of interest therefore identifying the request as being suspicious . Another susceptible target entity may be one or more registry keys of the system registry of the processing system . Another type of target entity filtering rule may determine whether the target entity matches one of the susceptible registry keys and if satisfied the target entity is considered of interest thereby identifying the request as being suspicious .

The non susceptible target entity filter list comprises one or more target entity filtering rules which can be used to filter out target entities which are not susceptible to malicious activity and thus are not considered of interest thereby identifying the activity as being non suspicious . By using the non susceptible target entity filter list an activity that occurs in relation to a non susceptible target entity can be dismissed as being associated with malicious activity and thus an analysis does not need to be performed in relation to the activity .

The trusted requesting entity filter list is similar to the non susceptible target entity list except this list comprises one or more filtering rules to filter out trusted requesting entities which are not considered of interest ie. there is a high probability that the requesting entity is not associated with malicious request thereby identifying that the activity as being non suspicious . For example the requesting entity of an operating system web site attempting to transfer an operating system update to an update application stored in a processing system may be such an instance of a trusted requesting entity . The trusted requesting entity filter list can comprise a requesting entity filter rule to filter out such activity associated with this type of requesting entity such that an analysis does not need to be performed in relation to the activity . By determining a trusted requesting entity the request is identified as being non suspicious .

The non trusted requesting entity filter list is similar to the susceptible target entity filter list except this list comprises filter rules to determine requesting entities which are of interest ie. there is a high probability that the requesting entity is associated with a malicious request . For example a requesting entity attempting to open a specific port in the processing system may be an example of a non trusted requesting entity . The non trusted requesting entity filter list can comprise a requesting entity filter rule which determines whether the requesting entity is located outside a particular network domain and if the filter rule is satisfied the requesting entity is identified as being of interest which thereby identifies the activity as being suspicious .

Each filter rule in each list can have an associated filter rule identity. When a filter rule is satisfied an identity of the satisfied filter rule can be recorded. Over time particular filter rules may be satisfied on a higher frequency than other filter rules. The frequency of satisfaction for each rule can then be used to determine a filtering rating indicative of the frequency of satisfaction for the respective filter rule. As will be described in more detail below the filtering rating can be used to determine an order which filter rules are used when filtering intercepted requests such that on average the number of filter rules used prior to a filter rule being satisfied is reduced. This process of determining an order which the filter rules can be performed by a single processing system or alternatively in a networked system comprising a plurality of client processing systems and at least one server processing system can be performed by the at least one server processing system as will be explained in more detail below.

In some instances a request may have been identified as being non suspicious using one of the lists of the filter module whereas a different list of the filter module may have identified the same request as being suspicious. In this instance the worst case scenario can be considered which can be to assume that the request is suspicious. One approach to is to use the susceptible target filter list and the non trusted requesting entity filter list first prior to the non susceptible target entity filter list and the trusted requesting entity filter list such that the worst case scenario is given priority.

In other instances a request may not be identified as being suspicious nor non suspicious. In this instance a default identification can be assigned to the request . Therefore the default may be to identify the request as being suspicious such that an analysis can be performed on one of the associated entities . However a more lenient approach may be to set the default identification as being non suspicious . In one form the default identification can be defined by the user of a processing system .

Referring to there is shown a flow diagram representing an example method to facilitate the detection of malicious activity in a processing system .

In particular at step the method comprises in the processing system determining an order of a list of filter rules according to a filter rating associated with each filter rule in the list. At step the method comprises using the order of the filter rules to determine a suspicious request in the processing system .

Referring now to there is shown another flow diagram representing an example method performed by a server processing system to facilitate the detection of a malicious request in a client processing system .

In particular at step the method comprises in a server processing system determining an order of a list of filter rules according to a filter rating associated with each filter rule in the list. At step the method comprises transferring the determined order of the list of filter rules from the server processing system to the client processing system to allow the client processing system to use the order of the filter rules to determine a suspicious request in the client processing system .

As will be appreciated below using a distributed system a plurality of processing systems and at least one server processing system advantageously allows the generation of the filter ratings and order of the filter rules using a larger number of samples from the plurality of client processing systems . However in single processing system forms the filter ratings and the order of the filter rules is advantageously customised for that particular processing system .

Referring now to there is shown a block diagram illustrating the process of determining an order of a list of filter rules.

In particular the block diagram comprises a list of filter rules . Each filter rule has a respective associated filter rating . Each filter rating is at least indicative of the frequency that the respective filter rule has been previously satisfied that a target entity and or a requesting entity is of interest. In this example Rule 1 has an associated filter rating of 70 and Rule 2 has an associated filter rating of 10 . This indicates that Rule 1 has been satisfied more frequently than Rule 2 in relation to a target entity and or a requesting entity being identified as being of interest ie. the activity has been identified as being suspicious .

As shown in ordered list the filter rules are ordered in descending order according to the respective filter ratings for each filter rule in the list . Thus Rule 4 has the highest filter rating and therefore this filter rule is positioned at the start of the list. Rule 1 has the next highest filter rating and is therefore positioned second followed by Rule 3 and then Rule 2 .

By determining an order of the filter rules according to the filter rating rules which have been satisfied more frequently are used first when determining if the requesting entity and or target entity is considered of interest prior to less frequently satisfied filter rules in the list . This order of use can on average reduce the number of filter rules that need to be used prior to one of the filter rules being satisfied. Order data indicative of the order of the list can be transferred to one or more client processing systems such that the order indicated by the order data can be used when applying the filter rules to determine suspicious requests .

It will be appreciated that the order data may be transferred to the plurality of client processing systems in response to feedback filter data being received from one of the client processing systems . Additionally or alternatively one of the client processing systems may transfer a request for an updated order of the filter rules and in response the server processing system transfers the order data to the requesting client processing system . Updated filter rules may also be transferred to one or more client processing systems . In another additional or alternative form the server processing system may be scheduled to periodically transfer the order data to the plurality of the client processing systems . This for example could be accomplished through e mail as well as other known data transferal techniques.

In particular each client processing system transfers to the server processing system filter feedback data indicative of frequencies that one or more filter rules has been satisfied. The server processing system updates a satisfaction frequency stored for each relevant filter rule using the filter feedback data . The server processing system then updates relevant filter ratings for each rule based on the filter feedback data and then orders the filter rules in each list according to the updated filter ratings. Order data indicative of the order of the filter rules in each list is then transferred to the client processing systems such that each client processing system can use filter rules in the order represented by the order data when determining if a target entity and or requesting entity is of interest thereby on average reducing the number of rules which are required to be used.

As previously indicated each filter rule stored in the server processing system comprises an associated frequency indicative of the number of times the filter rule has been satisfied in the plurality of client processing systems . The frequency can be split into a number of portions. In this example the frequencies are split into two portions a first portion being the frequency that the filter rule had been satisfied within the past ten days and a second portion being the frequency that the filter rule had been satisfied outside the past ten days. As seen from Rule 1 has been satisfied ten times within the past ten days and has also been satisfied one hundred times outside the past ten days. Rule 4 has been satisfied forty five times within the past ten days and has also been satisfied twenty times outside the past ten days.

This distribution of frequencies between the frequency portions can indicate a trend of malicious requests in relation to the plurality of client processing systems . For example in regard to Rule 1 which may be a susceptible target entity filter rule there may have been a software patch that has been recently distributed amongst client processing systems that has resulted in Rule 1 being satisfied less often compared to past frequencies that occurred outside the ten day period. In regard to Rule 4 which may also be a susceptible target entity filter rule there may have been an outbreak of malicious software which is targeting particular susceptible entities and accordingly Rule 4 has recently been satisfied more often compared to past frequencies that occurred outside this ten day period as indicated by the rise of the frequency within the past ten days.

In order to take into account trends in malicious activity such as outbreaks of specific malicious requests and distributions of software patches a filter rating formula is used to weight the distribution of frequencies for each filter rule. In this example the filter rating formula is shown below FilterRating 2 recentFreq 0.5 olderFreq Where 

It will be appreciated that differing weights can be used. Furthermore it will be appreciated that a larger breakdown of frequency distribution can be used.

As can be seen from the filter rating formula the frequency of instances when the filter rule was satisfied within the past ten days is weighted more heavily in order to take into account trends of malicious requests. Thus the filter rating for Rule 1 and Rule 4 are calculated to be FilterRatingRule1 2 10 0.5 100 20 50 70 FilterRatingRule4 2 45 0.5 20 90 10 100

As can be seen from the respective filter ratings for Rule 1 and Rule 4 even though Rule 1 has been satisfied more often in the past as indicated by frequency it appears that Rule 4 has recently been satisfied more often indicated by frequency due to an outbreak of malicious software targeting susceptible entities which Rule 4 determines to be of interest. Thus Rule 4 receives a higher filter rating compared to the filter rating of Rule 1 due to the recent trend in malicious requests. When this list of filter rules is ordered Rule 4 is ranked higher in the list compared to Rule 1 and therefore Rule 4 is used prior to Rule 1 when determining suspicious activity . As Rule 4 has recently been satisfied more often due to the trend in malicious activity it is more likely that an activity would be identified as being suspicious using Rule 4 rather than Rule 1 . Therefore Rule 4 can be used first when filtering an intercepted request so as to reduce the number of instances that Rule 1 is used by the filter module . On average this ordering of the filter rules can reduce the number of applications of rules by the filter module thereby resulting in an efficient filtering process.

Referring now to there is shown another more detailed example of the method of . For simplicity purposes the filter module in this example comprises only a single filter list that being a susceptible target entity filter list . However it will be appreciated that the filter module can use more than one filter list as previously indicated.

At step the method comprises the server processing system receiving feedback filter data indicative of frequencies that the susceptible target entity filter rules have been satisfied. At step the method comprises the server processing system generating filter ratings for the relevant susceptible target entity filter rules in the list. At step the method comprises determining an order of the list of susceptible target entity filter rules according to the associated filter ratings. At step the method comprises the server processing system transferring order data indicative of the order of the list of susceptible target entity filter rules to the client processing system .

At step the method comprises performing steps and of method . At step the method comprises retrieving a susceptible target entity filter rule according to the order data from the susceptible target entity filter list and then applying the susceptible entity filter rule in relation to the target entity of the intercepted activity . The application of the susceptible target entity filter rule may comprise comparing the target entity name to a known susceptible target entity however more complex comparisons may be performed by each susceptible target entity filter rule such as comparing cryptographic hash values of the susceptible target entity to that of the target entity .

At step in the event that the susceptible target entity filter rule is satisfied such that the target entity for the intercepted activity is considered of interest which thereby identifies the activity as being suspicious the method proceeds to step where the analysis module is used to analyse at least one of the target entity the requesting entity and the activity .

In the event that the susceptible target entity filter rule is not satisfied the method proceeds to step where the method determines whether the end of the list of susceptible target entity filter rules has been reached. If the end of the list has not been reached the method proceeds to step which comprises incrementing to the next susceptible entity target filter rule in the list. For example in regard to the example in Rule 4 would have been used first and then in the event that Rule 4 was not satisfied Rule 1 would then be applied next as this filter rule has the next highest filter rating according to the order data .

Steps and are iteratively performed until either the end of the list is reached or a filter rule is satisfied. Due to the filter rules in the list being ordered according to the filter rating on average the number of rules which are applied prior to a filter rule being satisfied is reduced.

As shown in the analysis module can comprise a number of further sub modules to determine a malicious request .

In particular the analysis module can comprise the sub modules of a cryptographic hash module a checksum module a disassembly module a black list white list module a relationship analysis module and a pattern matching module and a threat assessment module . The analysis module can be used to determine if the request by the requesting entity to perform the activity in relation to the target entity is associated with malicious software.

The analysis module can be configured to use one or more of these sub modules exclusively or in combination to detect malicious activity in the processing system . The analysis module can be used to analyse at least one of the target entity the requesting entity and the activity to determine if request is malicious.

The cryptographic hash module of the analysis module is configured to generate a cryptographic hash value of an entity. As the cryptographic hash value can be used an identity the cryptographic hash value can be used in comparisons with the blacklist whitelist module to determine whether the entity is malicious.

The checksum module of the analysis module is configured to determine a checksum of an entity of the processing system . The checksum can be compared to a database blacklist whitelist module to determine whether the entity is malicious.

The pattern matching module of the analysis module is configured to search an entity for particular patterns of strings or instructions which are indicative of malicious activity. The pattern matching module may operate in combination with the disassembly module of the analysis module .

The disassembly module is configured to disassemble binary code of an entity such that the disassembly module determines processing system instructions for the entity. The processing system instructions of the entity can then be used by the pattern matching module to determine whether entity is malicious. Although strings of instructions can be compared by the pattern matching module the pattern matching module may be configured to perform functional comparisons of groups of instructions to determine whether the functionality of the entity is indicative of malicious software.

The blacklist whitelist module of the analysis module comprises a list of malicious and or non malicious entities. The blacklist whitelist module may be provided in the form of a table or database which comprises data indicative of malicious and non malicious entities. The table may comprise checksums and cryptographic hash values for malicious and non malicious entities. The data stored in the blacklist whitelist module can be used to determine whether an entity in the processing system is malicious or non malicious.

The relationship analysis module can be used to detect related entities based on a starting entity . As shown by example in once a target entity or requesting entity has been determined to be of interest using the filter module the target entity or requesting entity can be treated as the starting entity and then using the relationship analysis module a web of entities related to the starting entity can be determined. A detailed explanation of detecting related one or more related entities is described in the Applicant s co pending U.S. patent application Ser. No. 11 707 425 and co pending Australian Patent application AU2007200605 entitled Determination of related entities the content of which is herein incorporated by cross reference.

In some instances malicious software can comprise a bundle of malicious entities. By only considering a single entity by itself it may not be accurately possible to determine if a target entity or requesting entity is malicious. However by determining related entities to the target entity or requesting entity a more accurate assessment can be made in relation to whether or not the suspicious activity is malicious . Furthermore removing a single malicious entity may not necessarily disable the malicious software from performing some malicious activity. Some particular forms of malicious software can perform repairs in relation to a single malicious entity being removed or disabled. Therefore detecting a group of related entities can be beneficial for disabling malicious software.

Referring now to there is illustrated a flow diagram illustrating an example method of determining a group of related entities in a processing system . The method represents the operation of the relationship analysis module .

In particular at step the method comprises recording the target entity and or requesting entity which was determined to be of interest as the starting entity . At step the method comprises determining using a related entity rule at least one related entity relative to the starting entity . The related entities can then each be analysed to determine if the request to perform an activity is associated with malicious software.

Referring now to there is shown a method of determining related entities relative to the starting entity . Method determines a group of suspicious related entities relative to the starting entity . However it will be appreciated that method can be adapted to determine any form of related entities such as trusted related entities relative to the starting entity .

At step the method comprises recording the starting entity . This generally comprises the processing system recording the starting entity in the processing system memory such as a data store. The starting entity may be stored in the form of a table or list.

At step the method comprises determining an entity property associated with the starting entity . The entity property may be an entity type of the entity such as whether the starting entity is an executable entity a run key entity or a dynamic linked library entity. The entity property may also be a time that the starting entity was created or modified. The entity property may comprise the directory which the starting entity is contained within. The entity property may also be a vendor name associated with the starting entity . The entity property may also be a particular network address from which the starting entity was downloaded.

It will be appreciated that more than one entity property may be determined for the starting entity . However for the purposes of simplicity throughout this example it will be assumed that one entity property has been determined for the starting entity .

At step the method comprises obtaining based on the entity property of the starting entity one or more related entity rules. In this particular example the one or more related entity rules take the form of one or more rules for determining one or more suspicious entities related to the starting entity . Step may comprise selecting based on the entity property the one or more related entity rules from a larger set of related entity rules. Each related entity rule is associated with a particular entity property and as such a selection of a related entity rules can be performed based on the entity property of the starting entity . An example list of entity properties and corresponding related entity rules is shown below in List 1.

It will be appreciated that a more detailed list of entity properties and corresponding related entity rules can be obtained using the above general rules. An example of a more detailed list of entity properties and corresponding related entity rules are provided below.

It will be appreciated that a starting entity having a trigger entity property could be any one of the following entities run keys Appinit Uninstall Key Service Hooks protocol filter and a startup list. It will further be appreciated that a starting entity having an executable entity property could be any one of the following entities executables dynamic linked libraries and other modules.

It will be appreciated from List 1 that the general entity properties and related entity rules can be extended to specific entity types such as the entity types shown in Table 1 for example INF entities Cookies entity windows instance entity and the like shown above. The more specific rules in Table 1 allow for a more specific selection of rules based on the more specific entity property which can therefore result in accurately determining the relevant suspicious related entity rules.

It will also be appreciated from Table 1 that more than one related entity rule can be obtained based on the one or more entity properties of the starting entity. As shown above in Table 1 if the entity property indicates that the starting entity is an executable entity then nine separate types of related entity rules can be applicable for determining the related entities to the starting entity which are considered suspicious.

Additionally or alternatively the processing system may transfer to a server processing system one or more entity properties of the starting entity and receive from the server processing system the one or more related entity rules. In this step the server processing system may select the one or more related entity rules using the entity property from a server set of related entity rules and then transfer the one or more related entity rules to the processing system .

At step the method comprises determining using the one or more related entity rules the at least one related entity . In this particular example the related entity rules determine one or more related suspicious entities. For simplicity purposes the following example is presented using one related entity rule however it will be appreciated that more than one related entity rule can be used. Using an example entity of Spywarz.exe which has a vendor name of Spywarz Software Enterprises the following related entity rule can be obtained 

This related entity rule is then used to determine any entities in the processing system which satisfy this rule. Once a scan has been performed using the related entity rule it is determined that Spywarz.dll also shares a vendor name of Spywarz Software Enterprises . As the related entity rule has been satisfied Spywarz.dll is considered a related entity to the starting entity Spywarz.exe . As such a group of suspicious related entities has been determined which comprises Spywarz.exe and Spywarz.dll .

Steps to represent a single iteration to determine a group of suspicious related entities . However if a more detailed group of related entities is required it is possible to perform multiple iterations of steps to as will now be discussed.

At step the at least one related entity is recorded. This may involve adding the at least one related entity to a list or a table which comprises the starting entity recorded at step . Furthermore the list or table may comprise data indicative of the relationship between the at least one related entity and entities which have been previously recorded.

At step the method comprises determining if an end condition has been met. For example the end condition may be satisfied when no other related entities are determined when no other related entities are determined in a period of time when the current starting entity has an entity type which is indicative of the end condition and or when a selected number of repetitions have been performed. If the end condition has not been met the method continues to step .

At step the method comprises setting the at least one related entity as the starting entity . This may be performed in memory by reassigning the value of the starting entity . By setting the at least one related entity as the starting entity steps to can be repeated until an end condition is met as will be discussed in more detail below. As will be appreciated in this example there are now two starting entities due to two related entities being determined in the first iteration.

Once the end condition is satisfied the determination of the group of suspicious related entities has been completed. Optionally the recordings can be presented to a user of the processing system . The group of related entities may be presented in a tabular form or may be presented in a graphical representation. Additionally the group of related entities may presented indicating direct or indirect links between entities in the group. For example Spywarz.exe and Spywarz.dll for the above example would have a direct link. However if a subsequent related entity to Spywarz.dll was determined to be a system variable SPYWARZ VARIABLE then there would be an indirect link between Spywarz.exe and SPYWARZ VARIABLE .

Referring now to there is shown a flow diagram illustrating an example method of identifying malicious activity at the server processing system .

In particular at step the method comprises receiving in the server processing system the suspicious related entity data from the one or more client processing systems described above. The suspicious related entity data may comprise measurements and or properties associated with each suspicious related entity in the group .

Additionally or alternatively the suspicious related entity data may be the actual entities which are transferred from the one or more client processing systems to the server processing system . The server processing system may also receive a suspicion identifier indicative of behaviour associated with the suspicious entities . For example the suspicious identifier may be indicative of the suspicious entities being associated with a pop up window being displayed at the client processing system at regular intervals. The suspicious related entity data may also comprise data indicating the starting entity in the group . The suspicious related entity data may also be indicative of one or more relationships direct or indirect between entities of the group similar to that of a linked list.

At step the server processing system determines using the suspicious related entity data one or more common suspicious entities. This step comprises determining if the suspicious entity data received from the client processing system comprises one or more suspicious entities in common with other records of suspicious entity data received from other client processing systems . If suspicion identifiers were received from the client processing systems in relation to the suspicious entity data the server may use the suspicion identifier to narrow the selection of common suspicious entities. By determining the common suspicious entities the group of suspicious entities which may be malicious can be reduced and further significantly increases efficiency in determining the one or entities associated with the malicious activity. Furthermore this step provides a filter system of determining which suspicious entities are in common with different records of suspicious entities.

At step the method comprises the server processing system analysing the one or more common suspicious entities to determine one or more malicious entities . The server processing system can comprise a malicious assessment module configured to determine whether one or more of the common related entities are malicious .

The malicious analysis module can comprise a set of malicious assessment rules to determine a level of maliciousness of the common suspicious entities. The level of maliciousness can then be compared to a maliciousness limit and in the event of a successful comparison at least some of the common suspicious related entities are identified as malicious .

In one form if a common suspicious entity satisfies a particular malicious assessment rule the common suspicious entity is associated with a value or weight indicating how malicious the entity is considered. If the same common suspicious entity satisfies a number of particular malicious assessment rules the values or weights associated with the entity are totaled. The total value or weight can be compared to a maximum limit to determine whether the common suspicious related entity is a malicious entity.

The malicious assessment rules are generally considered to be a stricter set of rules comparatively to the related entity rules used at the client processing system . The related entity rules can be used as a first filter. The determination of common suspicious related entities can then be used as a second filter. The malicious assessment rules can then be used as a third filter to determine a malicious entity at one of the client processing systems.

As the malicious assessment rules are generally more complex and considered more complete comparative to the related entity rules a number of the suspicious entities may not satisfy the malicious assessment rules and are therefore not identified as malicious. For example a legitimate printer driver may have been identified as a common suspicious entity due to a particular malicious entity using the printer driver to perform malicious activities using the one of the client processing systems . However after the malicious assessment rules are applied the printer driver is determined to not be malicious. The remaining common suspicious entities which satisfy the malicious assessment rules are identified as being malicious to the one or more client processing systems .

At step the method comprises the server processing system recording in a database the one or more malicious entities identified in step . This process is particularly useful for early detection of new or modified malicious software so that instructions can be generated as early as possible to restrict malicious activity being performed in the future by the identified malicious entity or entities in the client processing systems .

At step the method comprises transferring from the server processing system to one or more of the plurality of client processing systems instructions to restrict malicious activity being performed by the one or more malicious entities . The instructions may be computer executable instructions which can be transferred from the server processing system to the one or more client processing systems which can be executed to quarantine the one or more malicious entities. In one form this may comprise quarantining the one or more malicious entities . In one embodiment quarantining the one or more malicious entities may comprise removing the one or more malicious entities from the one or more client processing systems . In another embodiment quarantining the one or more malicious entities may comprise modifying the one or more malicious entities in the one or more client processing systems . In an additional or alternate form the modification of the one or more identified entities may comprise injecting executable instructions in the one or more identified entities or associated entities in order to at least partially disable the malicious activity.

Referring to there is shown a block diagram illustrating the threat assessment module which comprises an entity threat value module configured to determine an entity threat value ETV for an entity . The ETV is indicative of a level of threat that the entity represents to the processing system . The ETV is determined based on one or more characteristics of the entity . The threat assessment module also comprises a comparison module configured to compare the ETV to an entity threat threshold ETT to identify if the entity is malicious .

By identifying malicious entities by calculating a level of threat based on characteristics of entities in or in communication with the processing system new or modified malicious entities can be identified.

Referring now to there is shown a block diagram illustrating a more detailed example of identifying a malicious entity using the threat analysis module .

In particular an entity is passed to the entity threat value module . The entity threat value module can comprise a characteristic analysis module which is configured to determine characteristics of the entity . The characteristic analysis module can query a behaviour recordal module and or an attribute determinator in order to determine characteristics of the entity .

The characteristics of the entity are then transferred to a characteristic threat module of the entity threat module . The characteristic threat module is configured to determine a characteristic threat value CTV for at least some of the characteristics using a CTV formula .

The characteristic threat module then transfers one or more CTVs to an entity threat determinator of the entity threat module . The entity threat determinator comprises an ETV formula . The entity threat determinator can use the ETV formula to determine the ETV for the entity .

The entity threat module then transfers the ETV to the comparison module to determine whether the entity is a malicious entity . The comparison module comprises an entity threat threshold ETT which is used in comparisons of the ETV to determine whether the entity is a malicious entity .

Referring to there is shown an example method to detect malicious entities using the threat analysis module .

In particular at step the method comprises determining the ETV for the entity based on the one or more characteristics of the entity . The characteristics of the entity can comprise but are not limited to behaviour of the entity and or attributes of the entity . At step the method comprises comparing the ETV to the ETT to identify if the entity is a malicious entity .

In particular at step the method comprises identifying a starting entity in the processing system . The starting entity is at least one of the target entity and or the requesting entity .

At step the method comprises determining one or more characteristics of the starting entity . The one or more characteristics of the starting entity can comprise behaviour performed by the starting entity and or attributes of the starting entity .

For example the behaviour performed by the starting entity may comprise but is not limited to performing self duplication ie. the starting entity making a copy of itself connecting the processing system to a remote network address and downloading data from the remote network address. Each of these behaviours of the entity is a characteristic of the entity.

The processing system can comprise a behaviour recordal module which uses API interception to monitor and record behaviours performed by the processing system . The behaviours can be legitimate and illegitimate behaviours. The behaviour performed and the entity associated with the behaviour can be recorded in memory of the processing system . In one form the behaviour and associated entity are recorded in a database. When determining the characteristics of the starting entity the database can be queried using the name of the starting entity to determine behaviours that have been performed by the starting entity .

In regard to attributes of the starting entity examples comprise a discrepancy in a checksum for the starting entity a size of the entity bytes a hidden property of the starting entity and file permissions ie read write execute .

The processing system can comprise an attribute determinator which when invoked by the processing system can determine the one or more attributes of the starting entity . For example the attribute determinator can determine whether the starting entity is configured to be hidden in the processing system .

At step the method comprises determining a characteristic threat value CTV for at least some of the one or more characteristics of the starting entity .

In one form at least one of the one or more characteristics of the starting entity is associated with a CTV formula . The method can comprise calculating using the CTV formula the CTV .

In one form a CTV formula can be configured to assign a constant CTV for the respective characteristic . For example if the starting entity has a hidden property attribute the associated CTV formula may be simply a constant value indicative of a level of threat that the hidden property attribute represents to the processing system as shown below CTV 0.3

In additional or alternative forms CTV formulas can be configured to use a recorded frequency as an input when calculating the CTV . For example if the starting entity has previously caused the processing system to connect to a remote network address on ten instances the CTV is adjusted according to the frequency of the behaviour being recorded in the processing system as shown below CTV 0.01 freq 0.01 10 0.1

The frequency may also be determined for a period of time. For example if the starting entity connected to the remote network address on ten instances within the past five minutes then the CTV is adjusted accordingly for this frequency within this period of time.

In further additional or alternative forms at least one CTV is temporally dependent. The CTV formula can be configured to calculate the CTV using a temporal value. For example a starting entity may have connected to a remote network ten days ago. This period of time is used by the CTV formula in determining the CTV as shown below 

In the event that the starting entity caused the processing system to connect to the remote network address one day ago the CTV would be calculated as 

As can be seen from the above CTVs the CTV is adjusted according to how recent the behaviour was recorded. CTVs can increase or decrease in response to the temporal value used by the CTV formula . Furthermore the rate at the CTV increases and decreases may be constant or variable.

As previously discussed characteristics can comprise legitimate characteristics indicative of non malicious activity and illegitimate characteristics indicative of malicious activity. An example of a legitimate characteristic of a starting entity comprises having trusted vendor name attribute ie. a trusted vendor attribute may be Microsoft Corporation . An example of an illegitimate characteristic comprises the starting entity having full read write and execute permissions.

CTVs for legitimate characteristics and illegitimate characteristics can be calculated using the associated CTV formulas . In one form illegitimate characteristics have a positive CTV and illegitimate characteristics have a negative CTV . However it will be appreciated that this is not essential.

At step the method comprises determining the ETV for the starting entity using one or more of the CTVs determined for at least some of the characteristics of the starting entity .

Referring to the above CTVs four characteristics of the starting entity were determined. Three of the characteristics are illegitimate as indicated by the positive CTVs and one of the characteristics is legitimate as indicated by the negative CTV . The ETV can be determined by summing the CTVs for the starting entity . In this example the ETV would be calculated as 

In instances where the CTV is not indicative of whether the characteristic is legitimate or illegitimate the ETV can be calculated by determining a difference between the CTVs for the one or more legitimate characteristics of the entity and the CTVs for the one or more illegitimate characteristics of the entity where the difference is indicative of the ETV .

In some instances an ETV may have been previously calculated for the starting entity and recorded in the processing system s memory. In this event the new ETV can be determined by using the CTVs and the previously stored ETV .

At step the method comprises comparing the ETV of the starting entity to the ETT to determine if the starting entity is a malicious entity . In one form if the ETV is greater than or equal to the ETT the starting entity is identified as being malicious .

For example the ETT may be equal to 0.85 . In this instance the ETV equals 0.9 which is greater than the ETT . Therefore the starting entity is identified as being a malicious entity .

In another form the ETV can be used as an input to a fuzzy logic system wherein the fuzzy logic system determines whether the starting entity is considered malicious using the ETV .

At step the method comprises restricting the request to perform malicious activity . In one form this may comprise quarantining the malicious entity . In another form this may comprise removing or modifying the malicious entity .

Referring now to there is shown block diagram illustrating the identification of a malicious entity using the relationship analysis module .

In particular related entities can be determined relative to the starting entity . Related entities may be directly or indirectly related to the starting entity . ETVs associated with each related entity can be used to determine whether the starting entity is malicious . In other forms the ETVs of the group of related entities can be used to determine whether at least part of the group is malicious . Each entity is represented as a node. Links between nodes illustrate the relatedness of the entities. For example there is a direct link between starting entity and entity . There is also an indirect link between the starting entity and entity via entity .

Once a group of related entities relative to the starting entity has been determined a threat value can be determined based on the group of related entities .

The threat value for the starting entity can be calculated based on the related entities to the starting entity as shown in . This type of threat value which is determined for the starting entity using the group of related entities is referred to as a relational entity threat value RETV . The RETV can be used to determine whether the starting entity is malicious to the processing system based additionally upon the related entities to the starting entity .

Additionally or alternatively a threat value can be calculated for the group of related entities which comprises the starting entity to determine whether the group of related entities is malicious to the processing system as shown in . This type of threat value which is determined for the group of related entities is referred to as a group threat value GTV . The GTV can be used to determine whether the group of related entities or at least a part of the group of related entities is malicious to the processing system .

The RETV can be calculated by summing the ETVs for each entity in the group of related entities and adjusting each ETV according to the relatedness of the respective related entity relative to the starting entity .

In one form the number of links between one of the related entities and the starting entity can be used as an indicator of the relatedness of the related entity . This number of links between the starting entity and a related entity in the group is referred to herein as the link distance . A related entity which has a direct link ie. a low link distance to the starting entity is given more weight compared to a related entity which has an indirect link ie. a higher link distance to the starting entity . The higher the link distance the less weight is provided for the ETV of the related entity when calculating the RETV . An example RETV formula to calculate the RETV is provided below RETV ETV 0.5 Where 

For example the RETV for the group of related entities illustrated in would be calculated as RETV ETV 0.5 RETV 0.9 0.5 0.2 0.4 0.5 0.6 0.3 0.7 0.5 RETV 0.9 0.1 0.05 0.85

The RETV can then be compared to a relational entity threat threshold RETT to determine whether the starting entity based on the related entities is malicious . In this example the RETT may be 0.8 . Therefore the RETV is greater than RETT thereby identifying the starting entity as a malicious entity .

Similarly to the process of calculating the RETV the GTV can be calculated by summing the ETVs for each entity in the group of related entities and then averaging the sum over the number of entities in the group . An example GTV formula to calculate the GTV is provided below 

The GTV can then be compared to a group threat threshold GTT to determine whether the group of related entities is malicious or whether at least a portion of the related entities is malicious . In this example the GTT may be 0.5 . In this instance the GTV is less than the GTT which indicates that the group of related entities is not malicious.

Referring now to there is shown a flow diagram illustrating a method of determining one or more malicious entities using the example system of .

In particular at step the method comprises identifying a starting entity . At step the method comprises determining a group of suspicious related entities . At step the method comprises determining the GTV of the group of related entities . At step the method comprises comparing the GTV to the GTT to determine whether the group of suspicious related entities represents a possible threat to the client processing system .

In the event that the group of suspicious related entities represents a possible threat to the client processing system the client processing system transfers suspicious related entity data indicative of the group of suspicious entities to the server processing system at step . At step the method comprises the server processing system determining common suspicious related entities with other records received from other client processing systems . At step the method comprises the server processing system analysing the common suspicious related entities to determine if one or more of the suspicious related entities is malicious . Optionally at step the method comprises restricting malicious activity performed by one or more malicious entities .

It will be appreciated from method that there is a distinction between suspicious and malicious entities. A suspicious entity represents a possible threat to the client processing system . A malicious entity represents a threat to the client processing system . A more detailed analysis of one or more suspicious entities can be performed at the server processing system such as to determine any malicious entities . As the detailed analysis can be performed at a central location such as the server processing system the risk of one of the client processing systems failing to identify a malicious entity due to an outdated dictionary is reduced.

Referring now to there is shown a flow diagram illustrating a method of identifying a malicious entity in a processing system using fuzzy logic.

In particular the method comprises at step determining one or more input values indicative of an entity . At step the method comprises performing a fuzzy logic analysis using the one or more input values to identify if the entity is malicious .

Referring to there is shown a block diagram illustrating a fuzzy logic module to perform the fuzzy logic analysis.

In particular the fuzzy logic module comprises a set of logic rules and a number of membership functions . The fuzzy logic module receives at least one input value indicative of the entity . The at least one input value can comprise at least one of an entity threat value a group threat value a frequency of an event occurring a number of related entities to the entity and a number of child processes created by the entity. However it will be appreciated that other input values of the entity can be used to determine whether the entity is malicious.

The fuzzy logic module is configured to use the at least one input value the one or more membership functions and the set of logic rules to determine an output value. The fuzzy logic module comprises a defuzzification module configured to perform a defuzzification process to identify if the entity is malicious .

In additional or alternative forms the method and system can be adapted to determine a response to the identification as to whether an entity is malicious. For example possible responses in relation to the entity may comprise allow the entity to continue functioning in the processing system report the entity to the user of the processing system and optionally the output value and restrict the entity in the processing system .

It will be appreciated that in a networked system the fuzzy logic module can be located at the client processing system or at the server processing system .

In particular the input variables are the number of instances the entity has invoked the processing system to download data from a remote network address in the past twenty four hours and the number of related entities in relation to the entity . The output is one of the following responses allow the entity to function in processing system allow prompt the user of the processing system about the entity prompt and restrict the entity from functioning in the processing system restrict .

In this example for B C D and E the frequency is equal to five instances in the past twenty four hours and the number of related entities is equal to nine.

The fuzzy logic magnitudes are then used in a defuzzification process. In this example a maximum method is used where the output with the highest fuzzy output response magnitude is selected. In this instance the allow output membership function has a the highest fuzzy output response magnitude equalling 0.6 . In this instance the output is to allow the entity to continue functioning in the processing system . It will be appreciated that other methodologies can be used in the defuzzification process such as a centroid method as well as other known methods for performing the defuzzification process.

Optionally the one or more client processing systems may receive one or more updated filter rules and or related entity rules. The one or more client processing systems may receive updated rules from the server processing system or via a data store such as a compact disk or the like. The one or more client processing systems can then update the existing rules with the updated rules.

Optionally the one or more client processing systems may receive one or more updated formulas. The updated formulas can comprise one or more updated CTV formulas ETV formulas RETV formulas and GTV formulas . Each client processing system can then update the respective formulas.

In another optional form the one or more client processing systems may receive one or more updated thresholds. The updated thresholds can comprise one or more updated ETT RETT and GTT . Each client processing system can then update the respective thresholds.

In one form statistical processes fuzzy logic processes and or heuristical processes can be used in combination with filter rules the related entity rules and or the malicious assessment rules to determine whether a rule has been satisfied.

Optionally the related entities can be presented to a user of one of the client processing systems. The group of related entities may be presented in a tabular form or may be presented in a graphical representation. Additionally the group of related entities may presented indicating direct or indirect links between entities in the group .

It will be appreciated that although in some of the above examples the server processing system generates the instructions to quarantine the malicious entity associated with the malicious request the one or more client processing systems may alternatively generate the instructions.

Additionally or alternatively different weighting values may be assigned to different malicious assessment rules. The weighting values may be summed or used in a calculation and if the result is above a maximum limit then at least some of the group is determined to be associated with malicious activity .

It is noted that a request which is suspicious is not always identified as being associated with malicious software .

The related entity rules are generally less complex such as a reduced number of rules compared to the malicious assessment rules in order to reduce the processing performed by the client processing systems . The malicious assessment rules can be used by the server processing system to determine which related are associated with malicious activity. By using this configuration the server processing system preferably performs the processing related to determining the malicious entities thus the client processing systems can utilise the processing system resources more effectively.

The embodiments discussed may be implemented separately or in any combination as a software package or component. Such software can then be used to pro actively notify restrict and or prevent malicious activity being performed. Various embodiments can be implemented for use with the Microsoft Windows operating system or any other modern operating system.

In one optional form although four types of filter lists have been herein described for the filter module these filter lists can be used separately or in combination.

In another optional form the user may define user defined filter rules. For example there may be an activity is the client processing system which is being analysed by the analysis module . However the user is aware that the activity is not associated with malicious activity . As such the user is able to define a user defined rule such as to prevent the request being analysed by the analysis module . In one form user defined filter rules are positioned at the start of the list of filter rules such that the user defined filter rules are applied first prior to the remaining filter rules.

In another optional form the analysis module may comprise as activity sequence sub module which analyses a sequence of activities that occurred prior to and after an identified suspicious activity in a processing system . The system may comprise an activity recordal module which records each intercepted event in the processing system . When the filter module identifies an activity which is suspicious activities which occurred prior to and after the identified suspicious activity can be analysed using the activity sequence sub module module to determine whether a sequence of activities are indicative of a particular behaviour associated with malicious software.

In one optional form the suspicious related entities may be used as a form of feedback to adjust the thresholds used by the one or more client processing system . For example if the server processing system determines that ninety percent of suspicious entities are not being determined to be malicious then one or more thresholds may be adjusted so that an optimum level of filtering is obtained. In one form this optimum level of filtering may be obtained using a fuzzy logic system which determines whether one or more of the thresholds need to be increased or decreased.

Other processes may be used separately or in combination with the malicious assessment rules to determine which part of the group is malicious. For example the method may comprise using a white list to divide the group into the one or more sub groups. For example a group of related entities may comprise operating system files and non operating system files. The method may therefore comprise using a white list to separate the group of related entities into a cluster of operating system files and a cluster of non operating system files. Based on this separation it may be determined that the non operating system files are malicious .

In optional forms a mode of operation of an entity may be used to weight the ETV the RETV or the GTV . For example an entity may be operating in an administrative mode when it was recorded connecting to a remote network address. The entity is therefore considered a high threat and therefore the ETV for the entity is weighted accordingly to indicate this high risk threat.

In other optional forms the method of installation for an entity or installation files associated with an entity can be analysed to determine one or more characteristics of an entity to allow the identification of a malicious entity. Such analysis may comprise determining whether an installation file was automatically executed without user input whether the installation file is designed to delete itself after execution whether the installation file is not an executable file whether the installation file does not create a new sub directory in the processing system whether the installation file does not install itself in add and remove wizards of the operating system whether the installation file uses hidden or deceptive methods to install the entity such as using run keys whether the installation file is configured to install the entity in a directory which comprises a large number of other entities whether the installation file was not initially downloaded using an Internet browser whether the installation file does not download ongoing updates using an Internet browser and or requesting user input and whether the installation file uses social engineering to install the entity ie SCVHOST.exe instead of SVCHOST.exe .

Other characteristics that can be determined regarding an entity can comprise where the entity was downloaded from ie which country run key changes performed by the entity contents of the entity whether the entity creates auto startup points the type of packer compression means used in relation to the entity. Associated CTV formulas can be used to calculate an appropriate CTV indicative of the severity of the threat which the characteristic represents to the processing system . For example if the entity was downloaded from the US a small CTV may be calculated which contrasts to an entity which was downloaded from Russia which may result in a large CTV being calculated due to entities being downloaded from Russia being considered to represent a more severe threat to the processing system .

The embodiments described throughout can be implemented via hardware software or a combination of both.

It will be appreciated that the term malware has been used in an abbreviated sense for malicious software which comprises many types of processing system threats such as pestware spyware and other forms of threats as discussed above.

Optional embodiments of the present invention may also be said to broadly consist in the parts elements and features referred to or indicated herein individually or collectively in any or all combinations of two or more of the parts elements or features and wherein specific integers are mentioned herein which have known equivalents in the art to which the invention relates such known equivalents are deemed to be incorporated herein as if individually set forth.

Although a preferred embodiment has been described in detail it should be understood that various changes substitutions and alterations can be made by one of ordinary skill in the art without departing from the scope of the present invention.

