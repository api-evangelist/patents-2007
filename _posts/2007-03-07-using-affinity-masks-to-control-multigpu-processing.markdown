---

title: Using affinity masks to control multi-GPU processing
abstract: One embodiment of the present invention sets forth a set of application programming interface (API) extensions that enable a software application to control the processing work assigned to each GPU in a multi-GPU system. The software application enumerates a list of available GPUs, sets an affinity mask from the enumerated list of GPUs and generates an affinity device context associated with the affinity mask. The software application can then generate and utilize an affinity rendering context that directs rendering commands to a set of explicitly selected GPUs, thus allocating work among specifically selected GPUs. The software application is empowered to use domain specific knowledge to better optimize the work assigned to each GPU, thus achieving greater overall processing efficiency relative to the prior art techniques.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08253749&OS=08253749&RS=08253749
owner: NVIDIA Corporation
number: 08253749
owner_city: Santa Clara
owner_country: US
publication_date: 20070307
---
The present application claims the priority benefit of U.S. Provisional Patent Application Ser. No. 60 780 901 titled USING AFFINITY MASKS TO CONTROL MULTI GPU PROCESSING filed on Mar. 8 2006.

Embodiments of the present invention generally relate to graphics processing and more specifically to using affinity masks to control multi GPU graphics processing.

Computer graphics image data typically undergoes several processing steps before each graphics frame is completely rendered for display or storage. Each processing step typically operates on graphics image data utilizing programming steps defined through an application programming interface API enabling the graphics application to utilize high performance hardware such as a graphics processing unit GPU to execute a set of processing steps with minimal real time supervision from a host CPU. For example a software application executing on a host central processing unit CPU may use an API to program processing steps in a GPU that may perform physics graphics rendering and other related computations. The API is typically implemented within a software driver. The software driver processes the commands received from the application and uses the result of that processing to control the GPU in a system.

Historically computing devices have included only one GPU that was responsible for both processing graphics commands and displaying the resulting images. With only one GPU questions about how to distribute work among multiple processing devices never really arose. By default all such decisions have traditionally been left up to the software driver and conventional APIs adhering to this architectural model provide little opportunity to the software application to assign processing work. Such an approach however is problematic in systems with more than one GPU known as multi GPU systems because the software driver distributes work among the various GPUs without any domain specific knowledge which oftentimes results in inefficient work distribution among the GPUs.

As the foregoing illustrates what is needed in the art is a mechanism for enabling applications to have greater control over which GPUs in a multi GPU system process specific sets of commands.

One embodiment of the present invention sets forth a method for controlling the allocation of processing work in a system having a plurality of graphics processing units available for processing. The method includes the steps of receiving an affinity mask reflecting which graphics processing units in the plurality of graphics processing units have been selected to process work associated with a current rendering context generating an affinity device context based on the affinity mask and including each graphics processing unit that has been selected to process work associated with the current rendering context and generating an affinity rendering context from the affinity device context where the affinity rendering context inherits the affinity mask from the affinity device context.

One advantage of the disclosed method is that it allows a software application to utilize domain specific knowledge to select which GPUs in a multi GPU system are assigned specific rendering work. In this way graphics processing work may be allocated to the GPUs more efficiently relative to the work allocations that software drivers typically achieve in prior art multi GPU systems. Another advantage is that existing API models may be preserved since they operate orthogonally to the GPU selection process described herein making the disclosed method cost effective.

In the following description numerous specific details are set forth to provide a more thorough understanding of the present invention. However it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details. In other instances well known features have not been described in order to avoid obscuring the present invention.

An application program is loaded into system memory for execution by the CPU . A graphics library such as the OpenGL Utility Toolkit GLUT implements certain high level system independent and well known graphics related functions. An API may include support for a graphics language GL API such as OpenGL or D3D . The GL API implements common lower level features and maps these features to access functions that control the GPUs . The API may also include interface functions for managing OpenGL within the context of a specific operating system. For example the WGL API is a well known set of API calls that specifies an interface for managing OpenGL within the Microsoft Windows operating system. The graphics library calls the API to access specific processing features in the GPUs . The application program may use a combination of features in the graphics library and the API to invoke certain graphics functions for generating the graphics images requested to be rendered by the application program .

As shown a given application program may use more than one rendering context for example to execute more than one type of GPU processing. The present invention enables rendering commands related to a particular rendering context to be directed to a specific set of GPUs selected by the application program for processing. More specifically and as described in greater detail in the application program is able to access various extensions from API that allow the application program to create an affinity device context that includes only the specified set from the available GPUs and that the application program wants to use to process the work associated with a current rendering context. The extensions also allow the application program to create an affinity rendering context that is specifically associated with the affinity device context meaning that any processing work related to the affinity rendering context is automatically directed by the software driver to only the specified set of GPUs included in the associated affinity device context. Finally the extensions allow the application program to designate the affinity rendering context as the current rendering context. With this last step all processing work related to the current affinity rendering context is directed by the software driver to the GPUs included in the affinity mask associated with the current affinity rendering context for processing. One should note that with this approach to the extent the affinity rendering context includes two or more GPUs the software driver is responsible for allocating work among those GPUs. The approach however allows the application program to choose and limit which GPUs in the overall system perform the processing associated with a particular rendering context.

For example suppose affinity mask within affinity device context includes GPUs and but not GPU affinity rendering context is specifically associated with affinity device context and affinity rendering context is designated as a first current rendering context. In such a scenario affinity mask is inherited by affinity rendering context as affinity mask which then includes handles to GPUs and . Rendering work associated with affinity rendering context is allocated according to affinity mask . In this scenario GPUs and would process all of the work associated with the first current rendering context and the software driver would determine the specific work allocation between GPUs and . Similarly if affinity mask within affinity device context includes only GPU and affinity rendering context is specifically associated with affinity device context then affinity mask is inherited from affinity mask . In this scenario if affinity rendering context is designated as a second current rendering context then the software driver would direct all of the work associated with the second current rendering context to GPU processing.

The method of establishing an affinity rendering context begins in step where the application program creates an enumerated list of available GPUs using a first API extension. In WGL for example the first API extension wglEnumGpusNV takes as input an integer index and a pointer to a GPU descriptor handle. By calling wglEnumGpusNV in a loop and incrementing the integer index for each iteration until wglEnumGpusNV fails the application program iterates through the number of GPUs in the system and a first array of GPU descriptor handles is built that corresponds to the available GPUs in the system and forms the enumerated list of available GPUs.

In step the application program sets an affinity mask based on domain specific knowledge that enables the application program to determine which GPUs in the system are best suited for the particular type of processing the application program needs to have performed. The application program examines the enumerated list of available GPUs and selects which GPUs should process the work associated with a current rendering context. The application program then builds a second array of GPU handles based on the first array of GPU handles where the GPU handle for each GPU selected to process the work associated with the current rendering context is copied from the first array to a corresponding location in the second array. This second array of GPU handles which is terminated with a NULL value forms the affinity mask.

In step the application program creates an affinity device context using a second API extension. In WGL for example the API extension wglCreateAffinityDCNV takes the affinity mask generated in step as an input and generates an affinity device context data structure as an output. The API extension also returns a handle to the affinity device context data structure to the application program . Importantly the affinity device context includes an affinity mask that lists each GPU in the multi GPU system selected by the application program to process work associated with the current rendering context. Thus referring back to affinity device context includes an affinity mask that lists which of the GPUs and that the application program wants to process work associated with the current rendering context.

In step the application program creates an affinity rendering context using a third API extension. In WGL for example wglCreateContext may be extended to accept the affinity device context generated in step as an input. An affinity rendering context data structure which includes an inherited copy of the affinity mask within the affinity device context is then created by wglCreateContext . The API extension also returns a handle to the affinity rendering context data structure to the application program . Importantly the affinity rendering context is specifically associated with the affinity device context generated in step meaning that the GPUs included in the affinity device context generated in step are designated to process the work associated with the affinity rendering context generated in this step . Referring back to if in step the affinity device context is input into the third API extension to produce the affinity rendering context then the GPUs included in the affinity mask within the affinity device context are inherited by the affinity mask . Affinity mask then designates which GPUs should process the work associated with the affinity rendering context .

In step the application program uses a fourth API extension to designate the affinity rendering context generated in step as the current rendering context thereby instructing the API to direct all work related to the current affinity rendering context to the GPUs included in the affinity mask of the current affinity rendering context. In WGL for example wglMakeCurrent may be extended to accept an affinity rendering context handle from step as input or it might be extended to accept both an affinity device context handle from step and an affinity rendering context handle from step as inputs. These API extensions in turn establishes the affinity rendering context generated in step as the current rendering context. Importantly establishing the affinity rendering context as the current rendering context causes the software driver to direct all processing for the current rendering context to the GPUs included in the affinity device context generated in step that is specifically associated with the affinity rendering context generated in step . Referring again to if the affinity rendering context is designated as the current rendering context then the software driver directs all processing work associated with the current rendering context to the GPUs included in the affinity mask since this is the affinity mask specifically associated with the affinity rendering context in step .

In step the application program establishes a render target such as a display surface or a render surface for the current affinity rendering context using a standard API call. In OpenGL for example glBindFramebufferEXT may be used to establish the render target for the current affinity rendering context. The method then terminates in step .

Suppose further that an application program is designed to use two different GPUs. One GPU needs to render frames of graphics data and display the resulting frames on an attached display device. The other GPU needs to perform physics calculations in support of the real time dynamics involved in the application. The optimal assignment of work to the GPUs may be based on for example the display resolution display refresh rate or the amount of attached frame buffer memory associated with each of the GPUs . The application may choose optimizations that are not entirely obvious without domain specific knowledge. For example the application may preferentially assign the graphics rendering task to the GPU with the most frame buffer memory GPU so long as the display has adequate resolution and a refresh rate of 60 Hz or better. In such a scenario the application program would choose to assign physics computations to GPU and graphics rendering to GPU although a well meaning software driver may otherwise assign the graphics rendering and display responsibilities to GPU because this GPU is attached to the better display .

To specifically select GPU for graphics rendering and display the application program would define an affinity mask that includes only GPU . The application program would generate an affinity device context using the affinity mask for GPU . The application program would then generate an affinity rendering context and designate it as the graphics rendering context. Similarly to specifically select GPU for physics rendering the application program would use an affinity mask that includes only GPU to generate affinity device context and affinity rendering context and then designate the affinity rendering context as the physics rendering context. Designating the affinity rendering context as the graphics rendering context and the affinity rendering context as the physics rendering context would cause the software driver to direct all graphics rendering commands solely to GPU via affinity rendering context and to direct all physics rendering commands solely to GPU via affinity rendering context . Communication between the two GPUs would be accomplished using any technically feasible technique.

In sum a set of API extensions are added to an existing API such as WGL that enable a software application to specify which GPUs should be involved in rendering a given set of graphics commands. The software application uses one API extension to generate an affinity device context that includes only those GPUs specifically selected by the software application to process the set of graphics commands. The software application uses a second API extension to generate the affinity rendering context based on the affinity device context. Then the software application uses yet another API extension to designate this affinity rendering context as the current rendering context used by the application to issue rendering commands. This technique allows the software application to utilize domain specific knowledge to select which GPUs in a multi GPU system are assigned specific rendering work. In this way graphics processing work may be allocated to the GPUs more efficiently relative to the work allocations that software drivers can achieve in prior art multi GPU systems. Another advantage is that existing API models such as OpenGL and D3D may be preserved since they operate orthogonally to the GPU selection process described herein making the disclosed techniques cost effective. In other words the API extensions described herein do not alter the use of legacy API calls found in conventional API libraries.

One embodiment of the present invention is implemented as a computer readable medium that includes a set of instructions. When the set of instructions executed by a processor causes a computing device to allocate processing work among a plurality of graphics processing units available for processing by performing the steps of receiving an affinity mask reflecting which graphics processing units in the plurality of graphics processing units have been selected to process work associated with a current rendering context generating an affinity device context based on the affinity mask and including each graphics processing unit that has been selected to process work associated with the current rendering context and generating an affinity rendering context from the affinity device context wherein the affinity rendering context inherits the affinity mask from the affinity device context.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof and the scope thereof is determined by the claims that follow. The foregoing description and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense. The listing of steps in method claims do not imply performing the steps in any particular order unless explicitly stated in the claim.

