---

title: Acoustic ranging
abstract: Acoustic ranging may involve determining a distance between a first device and at least one other device using one or more acoustic signals. In an example embodiment, a first device emits a first acoustic signal and then receives the first acoustic signal at a first time. The first device also receives a second acoustic signal at a second time, with the second acoustic signal having been emitted by a second device. The first device ascertains a first value that reflects a difference between the first time and the second time. Responsive to at least the ascertained first value, the first device determines a distance between the first device and the second device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07729204&OS=07729204&RS=07729204
owner: Microsoft Corporation
number: 07729204
owner_city: Redmond
owner_country: US
publication_date: 20071007
---
This patent application claims priority to U.S. Provisional Patent Application No. 60 942 739 to Shen et al. entitled Mobile Device Collaboration filed Jun. 8 2007 and incorporated herein by reference.

Acoustic ranging may entail detecting proximity and or distance between a first device and a one or more other devices using at least one acoustic signal. Existing approaches usually involve using specialized hardware especially hardware that includes an extensive fixed infrastructure. Existing techniques usually involve a reliance on local clock times at individual devices. Thus existing approaches do not enable spontaneous acoustic ranging in ad hoc environments or with general commercial off the shelf COTS devices. Furthermore the use of local clock times in existing techniques introduces temporal uncertainties that lead to large ranging errors.

Acoustic ranging may involve determining a distance between a first device and at least one other device using one or more acoustic signals. In an example embodiment a first device emits a first acoustic signal and then receives the first acoustic signal at a first time. The first device also receives a second acoustic signal at a second time with the second acoustic signal having been emitted by a second device. The first device ascertains a first value that reflects a difference between the first time and the second time. Responsive to at least the ascertained first value the first device determines a distance between the first device and the second device.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. Moreover other method system apparatus device media procedure API arrangement etc. embodiments are described herein.

High accuracy ranging using a basic set of commodity hardware capabilities e.g. a speaker a microphone and some form of inter device communication can enable the implementation of ad hoc widespread and readily available acoustic ranging procedures. Such implementations can enable the wide spread use of range sensing in mobile applications. This is true because the above identified set of hardware capabilities can be considered a common denominator of many sensor platforms and mobile devices including many commercial off the shelf COTS devices like cell phones PDAs MP3 players and so forth. Compared to conventional alternatives that require special purpose hardware and or the pre existence of precision location infrastructure a commodity based approach can potentially enable wider applications and cost less. To further enable widespread use especially with COTS devices an example embodiment can be implemented in software including partially or even fully in the user space. COTS devices as used herein refers to those off the shelf devices that are not specially designed to perform acoustic ranging. However certain principles as described herein may also be employed in addition to COTS devices in devices that are specially designed to perform ranging procedures.

High accuracy ranging is traditionally achieved through measuring time of arrival TOA information of acoustic or radio signals. The distance is the product of the signal speed and the time of flight of the signal traveling between two devices. The ranging accuracy thus depends on the signal speed and the precision of the TOA measurement. To elevate the accuracy of the distance determination acoustic signals are usually selected because of their relatively slow speed. Nevertheless the precision of TOA measurement remains a big challenge in any system implementation if ranging accuracy is desired.

In practice TOA measurement is often performed with both sides taking a timestamp of their respective local clock at the moment the signal is emitted or received. Unfortunately there are three intrinsic uncertainties in this technique that can contribute to inaccuracy in the ranging results. These uncertainties include the possible clock skew and drift between devices the possible misalignment between the sender timestamp and the actual signal emission and the possible delay of a sound signal arrival being recognized at the receiver. In general many factors can cause the latter two uncertainties in a real system such as the lack of real time control software delay interrupt handling delay system loads and so forth. These uncertainties if not controlled can seriously affect the ranging accuracy. For example our tests on two COTS mobile devices reveal that these two delays can easily add up to several milliseconds on average which translates to several feet of ranging error.

It is therefore challenging to provide high accuracy ranging in a software only and device agnostic especially commodity type device solution using the minimum commodity hardware set that is identified above. For the solution to be applicable to many standard COTS mobile devices there are additional constraints. For example it cannot be assumed that there is a real time operating system OS or that the kernel or driver can be changed. In fact many COTS devices like cell phones are built on closed platforms and many often have operator imposed locks that prevent changing the OS. Thus to operate on these types of commodity devices the ranging mechanism is to be executed in the user space. Consequently conventional timestamping approaches cannot provide sufficiently high accuracy.

In contrast for certain example embodiments high accuracy acoustic ranging mechanisms may be implemented in software and or with COTS devices including mobile COTS devices. One or more of the following example techniques may be employed two way sensing self recording and sample counting. In an example embodiment two devices each in turn first emit a specially designed acoustic signal within one second of each other. Meanwhile each device also records a few seconds of continuous sound from its microphone. Each recording then contains exactly two received special signals that are picked up by its microphone one emitted from the other device and one from itself. Next each device counts the number of sound samples between the two acoustic signals and divides the number by the sampling rate to get the elapsed time between the two signal TOA events. The devices further exchange the elapsed time information with each other. The differential of these two elapsed times is related to the sum of the time of flight of the two acoustic signals and hence the two way distance between the two devices.

By using sample counting instead of timestamping a ranging mechanism may mitigate the software hardware interface uncertainties as listed above. It also avoids the source of some of the inaccuracies present in traditional timestamp approaches. In fact certain example embodiments have no notion of a local clock or timestamp at all. The granularity of certain described embodiments is inversely proportional to the sound sampling rate the higher the sampling rate the lower the granularity. By way of example only under today s prevailing hardware standard of a 44.1 KHz sampling rate a ranging accuracy of 0.8 cm can be achieved.

Other general and specific example embodiments are described herein below. It should be understood that certain example embodiments as described herein may be employed with COTS devices mobile fixed wireless wired combinations thereof etc. and or with special purpose devices that are designed to perform ranging procedures. Also although certain example aspects may be described herein in a specific context of hardware or software such description is by way of example only. In other words the example embodiments described herein may be implemented fully or partially in hardware software firmware fixed logic circuitry combinations thereof and so forth.

High accuracy ranging and localization systems are applicable to more platforms and suitable for more applications if the systems are implementable in software and executable on commodity hardware. They may also reduce the costs to perform ranging in sensor networks.

Besides sensor networks accurate ranging and or proximity information can be applied in everyday mobile applications. Examples include but are not limited to multi device applications like precision asset location and touch to connect pairing in ad hoc networking collocated multi users applications like spontaneous interaction and collaboration simultaneous photo sharing and better together video viewing. With high accuracy ranging fine grained spatial control can be provided and context aware systems can be developed. For example sharing can be automatically terminated once a party goes outside a certain proximity in a co located sharing scenario. Similarly video playback can be dynamically expanded to two screens or shrunk to one screen as the other device approaches and leaves in a better together viewing scenario.

Time of arrival TOA based systems estimate the distance D between the sender and the receiver to be the product of the time of flight i.e. the time t it takes a signal such as sound radio or light wave to reach the receiver and the propagation speed c of the signal which is usually assumed to be a constant that is known a priori. 1 

Given that precision is typically considered important an acoustic signal is usually chosen because the speed of radio or light signals is so fast that a small timing error can lead to an unacceptably large ranging error. However even if the relatively slower acoustic signal is used the precision requirements on TOA estimations are still very stringent. For example a one millisecond error in a TOA estimation translates to more than a 30 centimeter error in the ranging result.

Traditionally TOA measurement is performed with both sides taking a timestamp of their respective local clock at the moment the signal is emitted or received. There are several intrinsic uncertainties in this process that contribute to the TOA measurement error. A first uncertainty is a clock synchronization uncertainty the possible clock skew and drifting between the two devices. Many approaches have been proposed to address the clock synchronization uncertainty. Some rely on GPS for time synchronization and some others implement a work around by using round trip time measurement which assumes a symmetric propagation path so that all time readings refer to the same clock. Most of these solutions have resorted to dedicated mechanisms.

A second uncertainty is a sending uncertainty the possible misalignment between the timestamp and the actual signal emission. For example there is often a small yet arbitrary delay after an output command is issued until the sound is actually projected from the speaker. Similarly a third uncertainty is a receiving uncertainty the possible delay of an acoustic signal arrival being recognized. In general many factors can cause these two sending and receiving uncertainties in a real system such as the lack of real time control software delay interrupt handling delay system loads and so forth.

There has been relatively little work in addressing the sending and receiving uncertainties in software. Most previous work managed to reduce them by resorting to customized hardware design so that the system can precisely control and obtain the exact instant when a signal is sent or received. This hardware approach is clearly inapplicable to software implementations that are executed on commodity hardware.

We have conducted an experiment using COTS mobile phones to understand how large these two sending and receiving uncertainties can be in a general purpose mobile device. The experiment was designed to ascertain a lower bound for a sum of the two uncertainties given as equation 2 below 2 if a TOA measurement is performed in software. The results indicate that appears to be very random and affected heavily by the CPU load. Both the average and deviation increases when the load becomes heavy such as when playing a video even if we assign the test program the highest priority. Regardless the experiment indicates that the uncertainties can easily add up to several milliseconds. These several milliseconds of uncertainty translate to several feet of ranging error when the TOA measurement is performed in software.

Certain example embodiments can provide accurate ranging results even while relying on the capability of COTS devices. Each of the three aforementioned uncertainties i.e. clock synchronization uncertainty sending uncertainty and receiving uncertainty can at least be ameliorated if not avoided. In this section example embodiments for a ranging mechanism as well as the underlying concepts that can provide precision results are described.

Without loss of generality we focus initially on ranging procedures with two devices say device A and device B. The principles and techniques are expanded to multiple devices further below e.g. Section 4.4 .

In an example embodiment speakers and microphones are integrated with their respective devices . However they may alternatively be otherwise coupled thereto. Furthermore speakers and microphones may be positioned at different locations on each device from those locations that are illustrated. Each device may also have a different number of speaker s and or microphone s from what is illustrated in .

In an example embodiment each device emits an acoustic signal in any order but usually at different times. Specifically device A A causes its speaker A A to emit acoustic signal A. Acoustic signal A is then received at microphone A A of device A A and at microphone B B at device B B. Similarly device B B causes its speaker B B to emit acoustic signal B. Acoustic signal B is then also received at microphone A A of device A A and at microphone B B at device B B. How a ranging procedure may be performed using these two acoustic signals A and B and the four receptions thereof is described below.

An example embodiment of the basic ranging scheme may be characterized as having three steps. In a first step a two way sensing is performed as shown in . Assume both devices are in recording state. Device A first emits an acoustic signal through its speaker S. This signal is recorded via its own microphone e.g. a self recording is performed as well as that of the other device B. Then device B emits another acoustic signal back through its speaker S. This other acoustic signal is also recorded via both microphones at the two devices A and B.

In a second step both devices A and B examine their recorded data and locate the sample points when the previously emitted two acoustic signals arrived. We denote the time difference between these two acoustic signal arrivals as elapsed time between the two time of arrivals ETOA . We use the term ETOA herein so as to differentiate from the well defined term DTOA differential times of arrival or TDOA time differences of arrival which usually refers to the differential between two TOAs measured at two different receivers using the same sound source. In a third step the two devices A and B exchange their locally measured ETOA values. The distance between the two devices can then be computed responsive to these two values.

We denote t the time when device A instructs its speaker Sto emit the sound signal. However due to the sending uncertainty the actual time when the speaker physically emits may be t. The time of the acoustic signal arrival at the microphones Mand Mof devices A and B respectively are marked as tand t respectively. Due to the receiving uncertainty respective applications on devices A and B may not obtain these signal data until respective times t and t .

Similarly we denote t and tas the time when device B instructs its speaker Sto send out a sound signal and when the signal is physically emitted respectively. Variables tand tdenote the times when the acoustic signal from device B arrives at the microphones Mand Mof devices A and B respectively. The time variables t and t denote the times when the respective applications on devices A and B actually detect the arrival of the acoustic signal data.

We denote das the distance between the device x s speaker and the device y s microphone. From equation 1 above the following four distance equations 3 6 can be derived 3 4 5 6 where c is the speed of sound.

Using equations 1 and 3 6 the distance between the two devices D can be approximated as shown below in equation 7 

In equation 7 the latter two terms are the distances between the speaker and microphone of each of the two devices B and A. This distance is a constant in a given device and may be measured a priori. Consequently the distance D between the two devices can be determined responsive to the first two terms which are actually the ETOA values measured by device A and B respectively.

It should be noted that the ETOA may be calculated by each individual device independently i.e. without referring to any timing information from the other device. Hence no clock synchronization between the devices needs be established. Moreover due to the self recording strategy each time measurement is associated with the arrival instants of the acoustic signals consequently the sending uncertainty is also ameliorated. In the next subsection we show how a relatively precise ETOA may be obtained.

In a typical computing system that has multiple layers of hardware and or software obtaining the exact time instance when a signal arrives is difficult due to the indeterministic latency introduced by the hardware and software i.e. the receiving uncertainty . In an example embodiment this receiving uncertainty may be at least ameliorated by not referring to any local clock but instead inferring timing information directly from recorded sound samples.

Realizing that the received sound signal is usually sampled at a fixed frequency which is represented herein by sampling frequency f by the analog to digital A D converter we can directly obtain an ETOA by counting the sample number between the two TOAs of the acoustic signals from the recorded data. Interaction with the local clock of the end system may therefore be avoided. In other words we need not rely on the end system to set the timestamp to a value that it thinks the signal has arrived. Rather we turn to the fidelity of the recording module. Because the sound signals are recorded we can check the recorded data and identify the first sample point of each signal. The ETOA can thus be obtained at least in part by counting the number of samples between the first samples of the two corresponding received acoustic signals.

It should be noted that this technique can also avoid having to perform an instantaneous signal detection it may instead shift the signal detection task out of the sensing stage. Because the received acoustic signals are sampled and recorded the signal detection may be conducted at a subsequent time or even offline. As a consequence more complex signal processing techniques can be utilized in certain embodiments without requiring special hardware support or critical speed optimization.

With sample counting to reflect the time differences as described above equation 7 can be rewritten as follows 

By using sample counting instead of timestamping example mechanisms as described herein can avoid the source of inaccuracies found in traditional timestamp approaches. In fact when such mechanisms are employed certain example embodiments need have no notion of a local clock or timestamp. From equation 8 the measurement granularity is positively proportional to the sound speed c and inversely proportional to the sampling frequency f. With typical settings of c 340 meters per second and f 44.1 kHz the distance granularity is approximately 0.77 centimeters. The granularity can be further improved if higher sampling frequencies can be afforded.

Flow diagram includes seven 7 primary blocks plus blocks and . The description of flow diagram includes references to other figures such as and . In an example embodiment of flow diagram at block a first device initiates a ranging procedure with a second device. For example device A A may initiate a ranging procedure with device B B using a transmission on a wireless communication channel.

The initiation may be effectuated for example via some wireless medium using one or more messages over a given communication channel. Any communication technology may be used by the two devices. Examples include but are not limited to Wi Fi BLUETOOTH UWB other radio frequency RF communication channels infrared IR communication channels acoustic communication channels combinations thereof and so forth. Moreover such messages may also be transmitted and or received via one or more wired communication channels. The application can select a desired communication channel. A same or different communication channel can be used to effectuate the other communications among the devices participating in the ranging procedure.

At block the ranging procedure initiation may entail the specification of parameters. By way of example only device A can trigger a proximity determination by sending a request to other device s . The parameters can be set to default values or be selected through a hand shaking protocol. Examples of variable proximity determination parameters include by way of example but not limitation source sound e.g. chirp or pseudo noise sound sound frequency band signal length etc. rough sound A s playtime B s playtime strategy e.g. immediately or otherwise prior to A at a predefined time window after detection of A s acoustic signal etc. recorder stop condition e.g. pre defined recording duration waiting for a stop signal etc. and so forth. Device B may affirmatively acknowledge the proximity determination request. After a successful hand shaking the recorders at both of the devices may be started.

At block the first device emits a first acoustic signal. For example device A A may emit a first acoustic signal A from a speaker A A. At block the first device receives the first acoustic signal at a first time. For example device A A may receive first acoustic signal A at its microphone A A at a first time.

At block the first device receives a second acoustic signal at a second time with the second acoustic signal having been emitted by the second device. For example after device B B has emitted a second acoustic signal B device A A may receive second acoustic signal B at its microphone A A at a second time. The times may be implemented in any manner. Examples include but are not limited to timestamps from a local or global clock index sample points numbers at a predetermined sampling frequency of an A D converter and so forth.

At block the first device ascertains a first value reflecting a difference between the first time and the second time. For example device A A may ascertain a first value that reflects a difference between the first and second times. For instance the first value may represent an elapsed time between the two time of arrivals ETOA as ascertained at device A A.

At block the first device receives from the second device at least a second value reflecting a difference between when the second device received the first and second acoustic signals. For example device A A may receive in a wireless or wired transmission from device B B at least a second value that reflects a difference between when device B B received first acoustic signal A and when it received second acoustic signal B. For instance the second value may represent the ETOA as ascertained at device B B.

At block the first device may also receive from the second device a distance between a speaker and a microphone of the second device. For example device A A may also receive from device B B a distance between speaker B B and microphone B B of device B B. This speaker microphone distance dmay be provided during the initiation handshaking of blocks and or during the communication of the second value of block . Alternatively device A A may be programmed with this speaker microphone distance information fore each of multiple different types of devices which type may be identified during the initiation handshaking of blocks and .

At block the first device determines a distance between the first device and the second device responsive to at least the first value and the second value. For example device A A may determine a distance D between device A A and device B B responsive to at least the first ETOA as ascertained at device A A and the second ETOA as ascertained at device B B. At block the first device may further determine the distance between the first and second devices responsive to one or more of the following the speaker microphone distances of the first and second devices the speed of sound or at least one sampling frequency. For example the distance D may further be determined responsive to a first dimension reflecting a speaker microphone distance dof the first device a second dimension reflecting a speaker microphone distance dof the second device the speed of sound c or at least one sampling frequency of f f or fbased on one or more of equations 7 8 or 9 .

Achieving high ranging precision usually entails attempting to precisely locate the first signal sample in recorded acoustic signal samples. This can be particularly challenging for COTS mobile devices because in general the speakers and microphones in such devices have only a limited capability e.g. they often have a narrow spectrum support . Furthermore when working in an indoor environment acoustic signals can arrive at a microphone destination through multiple paths with different delays. This multipath effect may cause ambiguous ETOA detection and therefore significantly reduce the detection accuracy if it is not handled well. Signal design and detection is addressed further herein below particularly in Section 4.

Possible sources of errors are summarized in this subsection. According to equation 9 there are three possible sources of errors relating to the following three parameters sound speed c sampling frequency f and TOA detection e.g. various sample indices n . For example the propagation speed of sound c in the air varies with temperature and humidity and the sampling frequency fmay drift. Fortunately their impacts are usually negligible in practice and their impacts can be mitigated by taking temperature and humidity into consideration using well established sound speed models and by shortening the sensing interval respectively.

For certain example embodiments while implementing ETOA avoids associating the TOA of an acoustic signal to the local clock of the device there are still other factors that may influence the detection precision of the TOA. These other factors include signal to noise ratio multipath effects and signal distortion. They are discussed separately below.

Signal to noise ratio SNR the received acoustic signal will likely be attenuated and distorted by the communication channel. Furthermore the environmental noise may be usually colored. SNR may also be affected by the energy used when transmitting the signal from the sender.

Multipath effects the acoustic signal may reach the receiver via different paths due to reverberation. The received signal is thus a combination of signals from a number of the possible paths that traverse the position of the microphone.

Signal distortion the hardware e.g. the microphone and speaker of a mobile device usually has good support for only a relatively limited spectrum band e.g. around 3 kHz because their primary targeted usage is for voice communication. Attenuation differs at different frequency bands. The dynamic range of the speaker s volume is also very limited. It can be relatively easy to reach saturation and thus cause large waveform distortion.

Unlike traditional ranging or localization systems certain embodiments as described herein may be implemented as a pure software solution that does not require specialized hardware design or modifications to the commercial OS. In fact example software embodiments may be implemented completely at the application layer including on many ordinary COTS mobile devices. Moreover the software system may be architected as a ranging service so that it can be readily used by other applications. However it should be understood that embodiments for acoustic ranging as described herein may generally be implemented fully or partially in hardware firmware fixed logic circuitry software some combination thereof and so forth.

In an example embodiment software architecture includes three major parts the interface to other applications e.g. API the core logic part e.g. acoustic ranging controller and modules and underlying physical device related function modules e.g. modules . The physical device related function modules include actuating module that emits the acoustic signal that is generated by signal generator . Sensing module records e.g. continuously the received sounds into a local buffer and feeds the buffered data to signal detector . Communication module enables information e.g. light weight information exchange between participating devices. By way of example only such information may include the ETOA data scheme specific parameters speaker microphone distances and so forth.

The core logic part of software architecture includes acoustic ranging controller signal generator signal detector and distance calculation module . Acoustic ranging controller controls and orchestrates the actions of the other modules to perform the acoustic ranging functions described herein. It also interacts with other applications by receiving requests and sending back responses through API . A local timer may be maintained in acoustic ranging controller for ranging signal scheduling.

Signal generator generates the waveform of the ranging signals based on provided parameters and feeds the generated signal to actuating module . The generated signals are also stored as reference signals and provided to detector for signal detection. Signal detector implements the signal detection algorithms and determines the indices of the first samples i.e. the TOAs of other participants signals as well as its own. Ranging signals are detected by matching the recorded data from the sensing module against their respective reference signal templates. Distance calculation module calculates the distance D to other participants after receiving the respective ETOAs in accordance with at least one of equations 7 8 9 .

By way of example only software architecture may be implemented in conjunction with a mobile oriented operating system such as WINDOWS MOBILE 5.0. For instance example embodiments of acoustic ranging as described herein may be developed as a user mode dynamic linkable library DLL that other applications can load and use for ranging services. The multimedia services that are embedded in WINDOWS MOBILE can be used to control the microphones and speakers. WINSOCK can be used for communications over Wi Fi wireless communication channels. However acoustic ranging generally and software architecture specifically may be realized in other environments and or in alternative manners including fully or partially in hardware firmware fixed logic circuitry combinations thereof and so forth.

To facilitate detection the acoustic signal may be designed to have a good autocorrelation property which permits accurate signal detection when receiving ambient noise along with the signal. One signal design that is appropriate is the linear chirp signal but the range of its spectrum is to be adjusted to abide by the constraints of the hardware capabilities of the speaker and microphone in COTS devices if the system is to operate well on such COTS devices. Because most of these speaker and microphone hardware items are designed knowing that the primary application is voice conversation it is natural that they have better frequency response around the narrow spectrum band of the human voice. For typical COTS devices the sound signal is often greatly attenuated when the frequency is higher than 8 kHz which is the upper bound of the human voice. Consequently we select the frequency range of the linear chirp signal to be between 2 6 kHz.

Another potential problem with COTS devices is distortion. One issue that we identified is that the acoustic waveform when played out has a very large distortion in the first few milliseconds. To address this issue the chirp signal is preceded with a five millisecond 2 kHz cosine waveform to warm up the speaker. In an example implementation we selected the length of the acoustic signal to be 50 milliseconds which strikes a good compromise between suppressing multipath effects and noise resistance. It should be understood that the real world numerical values and acoustic signal types presented in this paragraph and elsewhere herein are given by way of example only other alternative values and acoustic signal types may be implemented instead.

In an example embodiment the acoustic signal may be detected by correlation with the reference signal in the time domain. In one example implementation the same acoustic e.g. chirp signal is used by all ranging participants. Because of this multi use of a single chirp signal each acoustic signal is associated with an individual device in order to calculate ETOAs. To differentiate these signals we employ a schedule based protocol that allocates a specific respective time window to emit the acoustic signal for each respective participant in a ranging procedure.

In an example embodiment schedule based protocol involves assigning respective devices to respective time windows . The initiating device such as device A determines e.g. randomly acoustic signal order . Time window length may be determined responsive to the length of the acoustic signal. Each time window is set equal to time window length . As described further herein below device A may communicate each devices B . . . N respectively assigned time window B . . . N by sending each device both acoustic signal order and time window length .

Alternatively instead of using a time windowing protocol with the same acoustic signals being emitted by multiple devices a pseudo noise or other coded signal may be used to obviate the schedule based protocol but at the likely cost of significantly increased signal detection complexity. In other words scheduling overhead and or delays can be avoided and the length of the signal communication portion of the procedure may be reduced by using individually identifiable acoustic signals but the signal detection complexity increases. With coded e.g. pseudo noise PN signals even if the coded signals are overlapped they can still usually be individually identified robustly. This can obviate the use of schedules. For example in the initiation stage an initiating device assigns a unique code e.g. a code according to which a PN signal can be uniquely generated and identified to each other device that is to participate in the acoustic ranging procedure. Each device then emits an acoustic signal in accordance with its assigned code. The individual respective acoustic signals can be individually identified using the assigned code.

Continuing with schedule based protocol if the participating devices are not tightly synchronized temporally time windows are sized appropriately. For example the scheduled time window length may be set sufficiently large so as to reliably separate acoustic signals from different participating devices. We denote N as the number of samples for the selected acoustic e.g. chirp signal. Thus if the signal length is 50 ms and the sound sampling rate is 44.1 kHz N equals 2205 sample points.

In an example embodiment to detect an acoustic signal the recorded data are correlated with the reference signal and the maximum peak is located. This maximum peak is concluded to be the temporal location of an acoustic signal if its cross correlation value is significantly larger as compared to with background noise. In an example implementation we calculate the L norm of the cross correlation values within a small window of wsamples around the peak L S . Then we calculate the L norm of the correlation values in a wwindow that is at least N samples before the peak L N where it is considered to contain only noise. A signal is considered to be detected when L S L N TH. If no such quantified point is located we conclude that the detection failed. Failure may occur because for example the signal energy is too weak or the noise level is too high. In an example implementation we set TH 2 i.e. 3 dB and w 100.

Especially with an indoor environment reflection from a secondary path may overlap with the signal from the line of sight LOS path. Such signal combination may cause the maximum peak to appear at the secondary path which is slightly temporally lagging as compared to the signal that travels in the primary path. In an example embodiment the multipath effects are addressed by locating the earliest sharp peak in the shadow window. Sharpness characterizes the level of a peak with respect to its surrounding side lobes. Because cross correlation values of a signal from different paths likely have similar sharpness we conclude that the first peak that has sharpness that is comparable to the maximum peak is the TOA of the signal.

In particular an example process to address multipath may be implemented as follows First we calculate the sharpness of a peak as the ratio of the peak value to the average absolute cross correlation values in its wvicinity. Second we compute all peaks in the shadow window before the maximum peak and find the first one whose sharpness is larger than TH where THis a threshold. In an example implementation we empirically set TH 85 and w 100.

Generally there may be significant work to acquire an accurate TOA in noisy and reverberant environments. As noted above a typical approach is to locate the peak in the cross correlation of the received signal and the original acoustic signal reference source. However the cross correlation has a large computational cost and it is wasteful to compute for all received signals. In contrast for certain example embodiments signal detection combines signal energy detection and cross correlation analysis to provide a coarse grained to fine grained detection scheme using different scales of the received acoustic signals to relatively rapidly and accurately detect the TOA.

Firstly we make use of window energy to roughly locate the possible TOA. In other words with reference to diagram A of we find n with the maximal window energy and the next window energy. It should be noted that we shift the N window without any overlapping each time to reduce a great amount of the computation. Secondly we adjust the size of the window energy. For example with reference to diagram B of the former window size may be halved to be N 2. It may be halved until a satisfactorily accurate position nis attained from the window energy.

Thirdly we calculate s sampled cross correlation in a possible window nearby the above attained rough location. With reference to diagram C of the down sampling option s is used to reduce the correlation computation too. A finer TOA i.e. n can be obtained from the sampled cross correlation curve. Fourthly as indicated by diagram D of the sampled cross correlation computation is repeated by reducing the window size 2 W and the sampling ratio until a final TOA nis obtained at s 1.

In an example implementation we adopt a hierarchical scheme of using both window energy and cross correlation in different scales because although the sharp cross correlation peak of some acoustic signals e.g. chirp and PN signals indeed facilitate an accurate TOA detection even in noisy environments they can decrease rapidly after shifting even a few sampling points from the actual TOA. It becomes incomparable to the correlation of non reference signals. On the other hand the signal window energy can be used to indicate a rough temporal location of the TOA.

In this subsection a ranging protocol of an example embodiment is described. Ranging protocol of is referenced for the sake of clarity. It is assumed that each device has a radio e.g a Wi Fi radio and that the devices A . . . N are therefore coordinated via wireless communications. The protocol can support multiple devices in one ranging procedure where each of N N 2 devices is attempting to measure the distances to each of the other devices simultaneously in one overall ranging procedure. The protocol generates N acoustic signals to obtain the pair wise distance measurements between any two devices for each of the devices in the procedure. This property provides scalability for the ranging mechanism even when N is large.

In an example embodiment the ranging protocol includes three steps First is Initiation A ranging procedure is started by an initiating device A which calculates and disseminates a schedule in an initiation message sent to each of the other devices B . . . N that is to participate in the ranging procedure. The schedule of the initiation message may include acoustic signal order and time window length . Alternatively the schedule of the initiation message may directly assign time windows with a respective time offset for each device.

Second is Sensing Each device calculates a delay according to the schedule and sets a timer. Upon expiration of the timer the device emits an acoustic signal. Third is ETOA Exchanging After the last device N has emitted its acoustic signal each device processes the recorded signals and determines a respective ETOA between its own signal and respective signals from each of the other devices. These ETOA values may be packed into one packet and broadcast to the other devices. Upon receiving ETOA information from each of the other devices each individual device can calculate the distance to each of the other devices using at least one of equations 7 8 or 9 .

In the Initiation step the initiating device randomly chooses an order e.g. acoustic signal order for each device to emit an acoustic signal and specifies a time interval e.g. time window length between two consecutive transmissions of acoustic signals. Defining such a schedule can have two purposes 1 it schedules each device to emit an acoustic signal at a different time to prevent possible collisions and 2 it also helps to identify the acoustic signal of each device. When acoustic signals are identical for all participating devices the correct calculation of the ETOA is facilitated when each device has a one to one mapping between respective detected signals and respective ranging peers.

After receiving the schedule each device starts recording with its microphone. It also calculates a proper delay e.g. the time window length interval between signals multiplied by its order in the schedule starting from the instant when the initiating message is received before it is to emit its acoustic signal. Because the delay is calculated by each device based on its own local clock it is possible that the schedules calculated by different devices have slight skews. To accommodate this possibility the interval between two consecutive acoustic signals e.g. time window length can be set sufficiently large so as to prevent or at least significantly reduce the likelihood of signal overlaps from different devices. In an example implementation an interval of one second has been found to reliably separate acoustic signals of different devices.

After the last device has emitted its acoustic signal each of the devices processes its recorded data and searches for received acoustic signals. An acoustic signal is related to a device if the signal is detected within the time window that is assigned to that device according to the pre defined schedule. It is possible that the signal detection process fails. For example the corresponding device may be too far away for an acoustic signal to reach but still within in the range of the wireless communication channel. The measured ETOAs between each device and each of the other devices including detection failures can be exchanged in the third step using a broadcast communication. After receiving the broadcasts from each of the other devices an individual device can calculate its distance to the other devices or re initiate a new ranging procedure if one or more failures have occurred.

In a real world scenario there may be multiple groups of devices that want to conduct ranging procedures simultaneously and may therefore contend for the acoustic channel. In an example embodiment such contention may be resolved by preventing two nearby initiators from starting ranging procedures simultaneously. Each device listens to initiation messages from other devices. If a would be initiator receives an initiation message from a nearby device it is to defer the transmission of its own initiation message until the end of the other ranging procedure. In some relatively rare cases it is still possible for two ranging procedures to happen concurrently if one initiator fails to reliably receive a broadcast initiation message of another. As a consequence multiple acoustic signals may be found in a single time window of a collision is thus detected. Because a given participating device cannot differentiate which acoustic signal is from a corresponding ranging peer versus from a contending nearby device it should report a failure. The two initiators can then restart their respective ranging procedures at a later time such as after a random back off period.

In an example embodiment each device emits two acoustic signals L R. Specifically device A A causes its left speaker AL to emit acoustic signal AL and its right speaker AR to emit acoustic signal AR. Acoustic signals AL and AR are then received at microphone A of device A A and at microphone B at device B B. Similarly device B B causes its left speaker BL to emit acoustic signal BL and its right speaker BR to emit acoustic signal BR. Acoustic signals BL and BR are then also received at microphone A of device A A and at microphone B at device B B. How a ranging procedure may be performed to determine relative left right positioning using these four acoustic signals AL R and BL R is described below.

For devices with more than one speaker and or microphone such devices can obtain multiple different distances like D in the same manners as described herein above. Thus they may determine each of the devices relative positions. In each device includes two speakers L R and one microphone . Based on the proximity detection scheme described herein above the following left right distances may be derived D d d 2 and D d d 2. The relative left right positions may be determined from a comparison of Dand D. If D D device A is on the left of device B and vice versa.

Relative left right positioning of two devices A and B can also be determined by using the received signal energy. For example the left and right speakers of device A may each emit the same e.g. chirp acoustic signal. Both acoustic signals are received at and sensed by the microphone of device B. In this example the left speaker emits the acoustic signal first. At device B after detecting the positions of the two signals the signal energy of each may be computed. If the energy of the first left received signal is smaller than the energy of the second right received signal then we can determine that device A is positioned at the left side of device B. Similarly if the energy of the first left received signal is greater than the energy of the second right received signal then we can determine that device A is positioned at the right side of device B. This technique is generally effective because the energy of a sound signal decreases rapidly e.g. proportional to the square of the distance against the propagation distance this technique is therefore likely to be especially useful in a close proximity situations. This signal energy based left right positioning technique can also be applied to cases in which a device has two microphones.

Generally a device may represent any computer or processing capable device such as a server device a workstation or other general computer device a data storage repository apparatus a personal digital assistant PDA a mobile phone a gaming platform an entertainment device a router computing node a mesh or other network node a wireless access point some combination thereof and so forth. However devices are typically mobile devices of some type. As illustrated device includes one or more input output I O interfaces at least one processor and one or more media . Media include processor executable instructions .

In an example embodiment of device I O interfaces may include i a network interface for communicating across network ii a display device interface for displaying information on a display screen iii one or more human device interfaces and so forth. Examples of i network interfaces include a network card a modem one or more ports a network communications stack a radio and so forth. Examples of ii display device interfaces include a graphics driver a graphics card a hardware or software driver for a screen or monitor a screen and so forth. Examples of iii human device interfaces include those that communicate by wire or wirelessly to human device interface equipment e.g. a keyboard a remote a mouse or other graphical pointing device etc. as well as a speaker microphone and so forth.

Generally processor is capable of executing performing and or otherwise effectuating processor executable instructions such as processor executable instructions . Media is comprised of one or more processor accessible media. In other words media may include processor executable instructions that are executable by processor to effectuate the performance of functions by device . Processor executable instructions may be embodied as software firmware hardware fixed logic circuitry some combination thereof and so forth.

Thus realizations for acoustic ranging may be described in the general context of processor executable instructions. Generally processor executable instructions include routines programs applications coding modules protocols objects components metadata and definitions thereof data structures application programming interfaces APIs etc. that perform and or enable particular tasks and or implement particular abstract data types. Processor executable instructions may be located in separate storage media executed by different processors and or propagated over or extant on various transmission media.

Processor s may be implemented using any applicable processing capable technology and one may be realized as a general purpose processor e.g. a central processing unit CPU a microprocessor a controller etc. a graphics processing unit GPU a special purpose processor a derivative or combination thereof and so forth. Media may be any available media that is included as part of and or accessible by device . It includes volatile and non volatile media removable and non removable media storage and transmission media e.g. wireless or wired communication channels hard coded logic media combinations thereof and so forth. Media is tangible media when it is embodied as a manufacture and or as a composition of matter. For example media may include an array of disks or flash memory for longer term mass storage of processor executable instructions random access memory RAM for shorter term storing of instructions that are currently being executed and or otherwise processed link s on network for transmitting communications and so forth.

As specifically illustrated media comprises at least processor executable instructions . Generally processor executable instructions when executed by processor enable device to perform the various functions described herein. Such functions include but are not limited to i those acts that are illustrated in flow diagram of ii those acts for implementing ranging procedures and of iii those acts performed to realize the items on timeline of iv those acts performed by the modules of software architecture of v those features relating to schedule based protocol of vi those steps involving acoustic signal detection of vii those functions represented by equations 7 8 and or 9 combinations thereof and so forth.

The devices acts aspects features functions procedures nodes modules techniques protocols etc. of are illustrated in diagrams that are divided into multiple blocks and other elements. However the order interconnections interrelationships layout etc. in which are described and or shown are not intended to be construed as a limitation and any number of the blocks and or other elements can be modified combined rearranged augmented omitted etc. in any manner to implement one or more systems methods devices procedures media apparatuses arrangements etc. for acoustic ranging.

Although systems media devices methods procedures apparatuses mechanisms schemes approaches processes arrangements and other example embodiments have been described in language specific to structural logical algorithmic and functional features and or diagrams it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claimed invention.

