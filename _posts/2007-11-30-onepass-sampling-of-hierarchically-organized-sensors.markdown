---

title: One-pass sampling of hierarchically organized sensors
abstract: One-pass sampling is employed within a hierarchically organized structure to efficiently and expeditiously respond to sensor inquires. Identification of relevant sensors and sampling of those sensors is combined and performed in a single pass. Oversampling can also be employed to ensure a target sample size is met where some sensors fail or are otherwise unavailable. Further yet, sensor data can be cached and utilized to hasten processing as well as compensate for occasional sensor unavailability.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07933919&OS=07933919&RS=07933919
owner: Microsoft Corporation
number: 07933919
owner_city: Redmond
owner_country: US
publication_date: 20071130
---
Sensors are devices that monitor and or detect real world conditions. Most traditional sensors operate by converting energy of one form to another. There are several categories of simple sensors delineated as a function of the energy they detect including thermal mechanical optical and acoustic among others. For example thermometers measure temperature barometers gauge pressure image sensors detect light and microphones sense sound. These and other sensors can be combined and or processed in various manners to produce more complex sensors. For example images sensors and microphones are combined to produce video cameras and such cameras can further be modified to perform specific tasks. Further yet location sensors or systems such as global positioning satellite GPS systems can be employed in conjunction with other sensors to contextualized data with geographical location information.

Large scale sensor network deployment is increasing rapidly. For example camera and or inductive loop sensor networks are being employed to monitor motor vehicle traffic and weather sensor networks are affording live weather conditions. Such networks generate tremendous volumes of useful data that can be utilized by applications to facilitate interaction by users among other things. For instance an application can provide a web portal that can host data generated by hundreds of sensors and enable users to query live data.

One emerging category of applications overlays sensor and other information on top of a map. Further this data can be aggregated at multiple levels of granularity or resolution. This allows users to zoom in and out to obtain more or less detailed data from a geographic area of interest. For example a user can acquire real time data from a local camera traffic sensor or weather station.

Coupling data collection with query process presents a few challenges. First collecting data from sensors on demand is expensive in terms of latency and bandwidth especially when the query involves a large number of sensors. Second sensors are largely heterogeneous in terms of their availability. Some sensors can be probed for data almost anytime and some others can only be probed when they are connected working properly and have resources to sense and communicate. Furthermore dynamically aggregating sensor data at various levels of resolution is computation intensive resulting in high end to end latency.

The following presents a simplified summary in order to provide a basic understanding of some aspects of the disclosed subject matter. This summary is not an extensive overview. It is not intended to identify key critical elements or to delineate the scope of the claimed subject matter. Its sole purpose is to present some concepts in a simplified form as a prelude to the more detailed description that is presented later.

Briefly described the subject disclosure pertains to efficient processing of sensor queries utilizing one pass sampling over hierarchically organized structures. To efficiently and quickly collect and aggregate data over a multitude of sensors a sample or subset of sensors are probed rather than attempting to acquire data from every relevant sensor in a query area. Moreover in accordance with an aspect of the disclosure sampling is performed within a hierarchically organized structure wherein sensors relevant to a query are identified and sampled in a single pass. In accordance with another aspect of the disclosure over sampling is employed to provide a probabilistic guarantee that a target sample size will be met in the presence of occasionally unavailable sensors. According to yet another aspect caching can be utilized to expedite processing as well as aid satisfying a target sample size.

To the accomplishment of the foregoing and related ends certain illustrative aspects of the claimed subject matter are described herein in connection with the following description and the annexed drawings. These aspects are indicative of various ways in which the subject matter may be practiced all of which are intended to be within the scope of the claimed subject matter. Other advantages and novel features may become apparent from the following detailed description when considered in conjunction with the drawings.

Systems and methods described hereinafter pertain to efficient collection and processing of sensor data utilizing one pass sampling. Rather than requiring data from all sensors within a query region to compute aggregate results only a subset of the sensors are employed to bound data collection cost per query. Moreover sampling is incorporated with range lookup in a hierarchically organized structure so that both are accomplished in a single pass. Techniques are also provided addressing occasionally unavailable sensors and leveraging cached data.

Various aspects of the subject disclosure are now described with reference to the annexed drawings wherein like numerals refer to like or corresponding elements throughout. It should be understood however that the drawings and detailed description relating thereto are not intended to limit the claimed subject matter to the particular form disclosed. Rather the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the claimed subject matter.

Referring initially to a query processing system is depicted in accordance with an aspect of the claimed subject matter. The query processing system pertains to collecting processing and reporting of sensor data across various areas and or resolutions. In one embodiment the system can form at least part of a system that presents sensor data and multi resolution aggregates on top of a map or other spatial representation. For example the system can be a sensor data web portal that affords sensor data provided by multiple entities e.g. individuals groups companies governments . . . in accordance with spatial queries of various resolutions. While the system is not limited to aforementioned embodiment discussion will center on this embodiment to facilitate clarity and understanding with respect to various aspects of the claimed subject matter.

As shown system includes an interface component communicatively coupled to a one pass sample component also referred to simply as sample component . The interface component receives retrieves or otherwise obtains or acquires a user query and optionally a target sample size. A query can correspond to a spatial view and or resolution among other things. The target sample size identifies a number of sensors to be utilized in generating aggregate values. This can be defined by a user with a query or provided as part of application preferences policies and or default settings. The interface component can be embodied as an application programming interface API and or a graphical user interface GUI amongst others. An acquired query and or target sample size can be transmitted or otherwise made available to the sample component by the interface component .

The sample component provides sensor data results in accordance with a query. Where a query requests high resolution data from a particular sensor the sample component can simply retrieve and return data from that sensor . At lower resolutions or levels of granularity query results can be aggregates. For example temperature can be aggregated at various resolutions including state city and region. In other words regional sensors can be aggregated to provide city temperature and city temperatures can be aggregated to provide state temperature.

Various granularities are captured by a hierarchically organized structure . The structure can be a b tree an r tree a colr tree or any other structure capable of recording data hierarchically. Each node represents a spatial area and identifies the number of sensors in that area. It is to be appreciated that the root can be the lowest level of granularity desired such as a country continent world etc. The highest level of granularity can be sensors or groups of sensors. For example the root can be the United States of America and the leaves can correspond to cities and sensors groups associated with the city.

The sample component can employ information provided by the hierarchical structure to fetch data from the sensors for aggregation. More specifically the sample component can navigate the hierarchical structure in response to a query to identify sensors to ping. Consider temperature sensors and a state resolution for example. While all sensors in the state could be pinged and data aggregated to provide an average temperature for the state this would be computationally intensive and require long wait times for system users. Accordingly sample component can acquire data from a sample or subset of state sensors to reduce end to end latency.

In one implementation sampling can be accomplished in two steps. First the hierarchical structure can be utilized to identify sensors associated with a query area. Once all the sensors are identified a random subset of sensors can be selected and data fetched from the sensors wherein the subset is bound in size by default or provided target sample size. Sampling data in this manner is a vast improvement over acquiring data from all spatially relevant sensors. However further improvement is possible. In particular latency can be further reduced by performing actions in a single pass rather than utilizing multiple passes as previously described. In accordance with an aspect of the claimed subject matter sample component operates in a single pass mode.

Turing attention to a representative one pass sample component is illustrated in accordance with an aspect of the claimed subject matter. Sample component includes a layer process component that processes a hierarchical structure layer by layer or level by level from root to leaves. At each layer layer process component can invoke the partition component to partition or divide a target sample size amongst children of a parent node relevant to a query. Weight component can be employed to identify a weight associated with each child node to enable partitioning based thereon. In a simple instance weight can correspond to the number of sensors associated with each node. The partition component can then divide the target sample size in proportion to the number of sensors attributed to each child node. Upon reaching one or more leaves one or more sensors are identified as well as their determined sample size. The layer process component can identify the determined number of sensors at random from those identified and provide them to sensor probe component to fetch data from the sensors. This data can subsequently be aggregated and reported in response to the query.

To aid understanding consider the partial hierarchical tree structure of and a query for temperature for Seattle Wash. and San Jose Calif. with a target sample size of 100. The root of the structure is the United States including a total of 200 000 sensors. There is a sample size of 100 at the root that is to be redistributed amongst relevant children within a query area. Of all the child states only Washington and California are relevant to the example query. Washington has a total of 1 000 sensors and California has 3 000 sensors. Accordingly there is a 1 3 ratio of sensors between Washington and California. The target sample size can be split proportionally resulting in 25 sensors for Washington and 75 sensors for California. The target size can then be split further at each level until the leaf nodes are reached. In the case of Seattle the leaf nodes are Redmond and Bellevue. At this point the target sample size and associated sensors are known for each region Redmond has a target sample size of 17 and 20 total sensors and Bellevue has a target sample size of 8 and 10 total sensors. Consequently 17 sensors will be selected at random from Redmond s 20 and information fetched from those sensors. Similarly 8 sensors from Bellevue s 10 sensors will be selected at random and information fetched from those sensors. The retrieved values can then be processed to produce an average temperature for Seattle. A similar process can be followed with respect to San Jose. Overall sensors are selected uniformly randomly to both distribute sensing load on sensors and provide more sensors from relevant areas with denser deployment.

Referring to another representative sample component is depicted in accordance with an aspect of the claimed subject matter. In addition to the components previously described with respect to including the layer process component partition component weight component and sensor probe component the sample component includes oversample component . An assumption was made with respect to the above description that if ten sensors are identified then data could be collected from all ten sensors. In practice however this may not be the case. Some sensor may be faulty while others may be dead or disconnected from a network. Therefore probing a target number of sensors may not be sufficient since some sensors may be unavailable. Oversample component addresses this issue by increasing the target size by a margin to increase the likelihood of acquiring data from at least the target sample size. For example where a target sample size is one hundred the oversample component can scale the size up to one hundred and twenty. Alternatively where one hundred sensors are partitioned between two states as above rather than identifying twenty five and seventy five as the distribution it could be increased to thirty and eight five.

Turning briefly to a representative oversample component is illustrated in accordance with an aspect of the claimed subject matter. As shown the oversample component includes a margin component to identify a margin to be added to a target sample size to compensate for potentially unavailable sensors. In one instance the margin component could simply identify a default margin e.g. increase by 25 . For optimal performance however the margin selected should be as small as possible. Context component can provide contextual information to the margin component to facilitate margin identification or generation. For instance the context component can collect and provision historical availability associated with one or more sensors. By way of example suppose it is known for a particular region that a portion e.g. 10 of sensors is always dead or otherwise unavailable. In this case a margin can be produced of that portion. More complex techniques can also be employed such as machine learning. For example the margin component can infer or predict how many sensors will be available or alternatively unavailable as a function of time date day of week and or number of people trying to access data among other things.

It is to be noted that while the probability that a randomly probed sensor will be available to produce readings could be computed by performing a query over the entire hierarchical structure this would result in a two pass process first computing the probability of a query region and then using that probability during lookup. Instead the target sample size can be scaled up at nodes within the query region. In one implementation the sample size can be scaled up once in any path from the root to a node probing sensors. Of course the claimed subject matter is not limited thereto.

Returning to the sample component also includes a redistribution component communicatively coupled to the layer process component . Oversampling provides probabilistic guarantees for achieving a target sample size. However sometimes the target may still fail to be reached due to non deterministic sensor unavailability among other things. Where the sample size is less than a target size for some nodes redistribution component can compensate for this by redistributing this difference among nodes yet to be probed. For example where one path or branch is not able to acquire data with in a threshold level the difference can be transferred to another branch. This increases the probability that a target sample size is achieved in the presence of irregularities.

Turning attention to yet another representative sample component is depicted in accordance with an aspect of the claimed subject matter. In addition to the components previously described with respect to the sample component also includes a cache component . The layer process component need not request retrieval of all data from sensors via the sensor probe component . Rather previously fetched data can be cached and utilized to expedite processing where appropriate with cache component .

Some sensor data is less transient that other data. In this case it can be housed for a set period of time prior to requiring re retrieval from a sensor. For example temperature is not likely to change much if at all within a fifteen minute time period or window. Accordingly once it is acquired it can be stored temporarily for reference. After expiration of an associated time period this stale data is removed replaced or otherwise not referenced during processing.

In addition to expediting processing the cache component can impact oversampling and redistribution. Since some data can be retrieved from cache rather than directly from sensors this increases the likelihood a target sample size can be achieved. Consequently redistribution is less likely to be needed.

Furthermore it is to be appreciated that the cache component can cache and provide from cache more than raw sensor data. Aggregate data can also be cached. For example aggregate temperature for the state of Washington can be cached for fifteen minutes. This improves query processing efficiency even further.

The aforementioned systems architectures and the like have been described with respect to interaction between several components. It should be appreciated that such systems and components can include those components or sub components specified therein some of the specified components or sub components and or additional components. Sub components could also be implemented as components communicatively coupled to other components rather than included within parent components. For instance the sensor probe component can be external to the sample component . Further yet one or more components and or sub components may be combined into a single component to provide aggregate functionality. For example the interface component could be provided within the sample component . Communication between systems components and or sub components can be accomplished in accordance with either a push and or pull model. The components may also interact with one or more other components not specifically described herein for the sake of brevity but known by those of skill in the art.

Furthermore as will be appreciated various portions of the disclosed systems above and methods below can include or consist of artificial intelligence machine learning or knowledge or rule based components sub components processes means methodologies or mechanisms e.g. support vector machines neural networks expert systems Bayesian belief networks fuzzy logic data fusion engines classifiers . . . . Such components inter alia can automate certain mechanisms or processes performed thereby to make portions of the systems and methods more adaptive as well as efficient and intelligent. By way of example and not limitation the sample component can employ such mechanism to improve sampling though intelligent partitioning oversampling and or caching among other things.

In view of the exemplary systems described supra methodologies that may be implemented in accordance with the disclosed subject matter will be better appreciated with reference to the flow charts of . While for purposes of simplicity of explanation the methodologies are shown and described as a series of blocks it is to be understood and appreciated that the claimed subject matter is not limited by the order of the blocks as some blocks may occur in different orders and or concurrently with other blocks from what is depicted and described herein. Moreover not all illustrated blocks may be required to implement the methodologies described hereinafter.

Referring to a method of sensor sampling for query processing is depicted in accordance with an aspect of the claimed subject matter. At reference numeral a query and target sample size are acquired. Utilizing a hierarchically organized structure such as but not limited to a tree e.g. r tree b tree colr tree . . . the method descends to the next level along nodes relevant to the query at . From the root this corresponds to navigation to children of the root. A determination is made at as to whether a relevant node is entirely inside a query area or space or partially within the query area.

Nodes can be in one of three states generally entirely inside the query area partially within the query area or outside the query area. A node is completely within the query area where no part of it is outside the query area. In other words every part in the node area is within the query area. A node is partially within a query area when some part of it is inside the query area and another part is outside the query area. Stated differently the node area and the query area intersect. This is the case where samples are split among children nodes. A node is outside the query area occurs when the node area and the query area do not share any parts. These nodes can be ignored.

If a node is not entirely inside the query area but is rather partially within the query area the method continues at reference where weight is determined amongst relevant children. The weight can correspond to the number of sensors associated with a node among other things. The target sample size at that point is split amongst relevant nodes as a function of the weight at . The method can then continue at reference where the next level or layer is identified.

If at it is determined that the area represented by the node is entirely inside the query area the method proceeds to reference numeral where data is fetched from a designated number or sensors at random where the number corresponds to the target sample size for that node. Subsequently the method can terminate or proceed with processing other branches not shown . In the end fetched data can be aggregated e.g. min max sum average . . . or otherwise processed and presented in response to the query.

If a node is partially within the query area e.g. some part of it is inside the query area and some part is outside the query area a weight for each node is determined amongst relevant children at . The target size is split as a function of the weight and associated with the relevant children at numeral . A determination is made at reference as to whether over sampling has been applied to a node directly or indirectly e.g. same path . If sampling has been applied the method can continue at . Otherwise the method proceeds to where the target size is increased by an over sampling margin before continuing at .

If at reference the node or nodes are entirely inside a query area the method continues at where a determination is made as to whether over sampling should be applied. This could correspond to determining whether oversampling has been previously applied among other things. If yes the target size is increased by an over sampling margin at and the method proceeds to . If no the method proceeds directly to reference where the data is fetched from a designated number of sensors at random and the method terminates.

Referring to a sampling method associated with sensor query processing is illustrated in accordance with an aspect of the claimed subject matter. At reference numeral a query and target sample size are acquired or otherwise identified. From the root the method descends to the next level or layer for processing at . A determination is made at numeral concerning whether a relevant node is entirely inside a query space or alternatively is partially within the query space.

If a relevant node is partially within a query space or area the method proceeds at where weight is determined for relevant nodes and target size is split as a function of this weight at . If over sampling is determined to have been applied directly or indirectly for a node at the method continues at . Otherwise the target size is increased by a margin at prior to continuing at .

If at the relevant node is entirely inside the query space the method continues at where another determination is made as to whether oversampling should be applied. If yes the target size is increased by an over sampling margin at and the method proceeds to . Alternatively the method continues directly at where a determination is made as to whether any data associated with the node or sensors related thereto is cached If yes randomly identified data that satisfies the query is retrieved from the cache at where available and the method proceeds to to retrieve other data. If no data is cached as determined at the method continues to reference numeral where data is fetched from a designated number of random sensors minus that retrieved from cache . Data acquired from sensors is cached for a period of time for later use at and the method terminates.

What follows are specific implementations of at least a few aspects of the aforementioned the claimed subject matter. It is to be appreciated that this is only one implementation. Other implementations are also possible and contemplated. Accordingly the claims are not intended to be limited be the below implementation details.

Consider the sampling algorithm or pseudo code provided in . Input includes a number R 0 of sensors to probe an area of interest A an over sampling level O and a result threshold level T. From this input a sample is output. The algorithm employs a plurality of variables and or operators as shown in Table 1 below.

Provided in is a redistribution algorithm or pseudo code Redistribute N F . Required input includes a priority queue N of tree nodes with priority as the number of sensor probes assigned to the nodes and a number of additional probes F to distribute amongst the given tree nodes. Priority i denotes the priority for a node i N.

The algorithm in shows pseudo code of a sampling algorithm that performs layered sampling. In addition to a target sample size R and a query region A it takes two threshold levels O and T the root is level . In the implementation one sample or aggregate computed over the sample is returned for each non leaf node at level T and it can be adjusted based on the zoom level of on a map for instance. For simplicity the pseudo code returns the union of all the samples. The other threshold O is used during over sampling described infra . The algorithm has the following the following features 

The algorithm employs weighted partitioning of sample size. Layered sampling allows siblings in a hierarchical tree to independently choose their samples from their descendents. The difficulty with independent sampling lies in the ability to precisely control the size of the resulting sample. The following strategy is employed. Starting at the root with a sample target size specified by the user the algorithm descends along nodes relevant to the query splitting the target size recursively amongst children. Thus each child is asked to return a sample smaller than the original target size so that consequently when the samples from each child are combined the target size is met. Line of the pseudo code shows how a node partitions its sample size among its children. Each child node i gets a target size that is proportional to its weight wnormalized by the fraction of its bounding box overlapping with the query region. The weight wcan be defined to suit the desired semantics of the sampled answer. Here it is assumed applications want uniformity over sensors and wis set as the number of sensors descendent of node i.

The algorithm also provides for over sampling. To cope with sensor unavailability a non leaf tree node scales up the target sample size to R R such that when random R of its descendent sensors are probed R sensors are found to be available to provide data. To reduce probing complexity R should be as small as possible. However an absolute guarantee of R out of R successful probes is not feasible in practice since non leaf nodes scale up the target size before sensors are actually probed and individual sensors may be found unavailable in nondeterministic ways. Moreover nodes independently scale up their target sizes and do not block while other sensors are accessed by other nodes. Therefore a probabilistic guarantee is provided R is chosen such that when all of them are probed an expected number of R sensors will be available to provide data.

To determine R historical availability of individual sensors can be used which has proved to be effective in predicting the future availability of the sensor. Suppose the target sample size is R over m sensors s s . . . s with availabilities p p . . . p . Then the probability that a randomly probed sensor will be available to produce readings is

The value of a could be computed with a range query on a tree built over sensor availability information. However this would result in a two pass algorithm first computing a over the query region and then using it during lookup. Instead during lookup the target size can be scaled up by computing a at nodes whose bounding boxes BB are entirely within A line . Such scaling up is done at nodes within a threshold level O such that the nodes have enough sensors under them to over sample. Finally it is ensured that the sample size is scaled up exactly once in any path from the root to a node probing sensors either at the first node below level T whose bounding box is entirely inside A or the node at level O if no node above level O has its bounding box entirely inside A. This ensures correctness.

The above over sampling algorithm provides a probabilistic guarantee of achieving a target sample size and may sometimes fail to provide the target size. This may happen due to nondeterministic sensor unavailability and holes and non uniform distribution of sensors in bounding boxes. In such cases if the sample size lags behind the target size for some nodes of the tree the lag is compensated by the redistribute subroutine provided in by evenly distributing it among nodes yet to be probed. This increases the probability that a target sample size is achieved even in the presence of sensor deployment irregularity.

Leaf and non leaf caches can also be exploited. Before probing sensors a node checks its cache for sensors that satisfy the query predicate. Only the additional number of sensors required to satisfy the target sample size are probed line and line .

The word exemplary or various forms thereof are used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as preferred or advantageous over other aspects or designs. Furthermore examples are provided solely for purposes of clarity and understanding and are not meant to limit or restrict the claimed subject matter or relevant portions of this disclosure in any manner. It is to be appreciated that a myriad of additional or alternate examples of varying scope could have been presented but have been omitted for purposes of brevity.

As used herein the term inference or infer refers generally to the process of reasoning about or inferring states of the system environment and or user from a set of observations as captured via events and or data. Inference can be employed to identify a specific context or action or can generate a probability distribution over states for example. The inference can be probabilistic that is the computation of a probability distribution over states of interest based on a consideration of data and events. Inference can also refer to techniques employed for composing higher level events from a set of events and or data. Such inference results in the construction of new events or actions from a set of observed events and or stored event data whether or not the events are correlated in close temporal proximity and whether the events and data come from one or several event and data sources. Various classification schemes and or systems e.g. support vector machines neural networks expert systems Bayesian belief networks fuzzy logic data fusion engines . . . can be employed in connection with performing automatic and or inferred action in connection with the subject innovation.

Furthermore all or portions of the subject innovation may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed innovation. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device or media. For example computer readable media can include but are not limited to magnetic storage devices e.g. hard disk floppy disk magnetic strips . . . optical disks e.g. compact disk CD digital versatile disk DVD . . . smart cards and flash memory devices e.g. card stick key drive . . . . Additionally it should be appreciated that a carrier wave can be employed to carry computer readable electronic data such as those used in transmitting and receiving electronic mail or in accessing a network such as the Internet or a local area network LAN . Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

In order to provide a context for the various aspects of the disclosed subject matter as well as the following discussion are intended to provide a brief general description of a suitable environment in which the various aspects of the disclosed subject matter may be implemented. While the subject matter has been described above in the general context of computer executable instructions of a program that runs on one or more computers those skilled in the art will recognize that the subject innovation also may be implemented in combination with other program modules. Generally program modules include routines programs components data structures etc. that perform particular tasks and or implement particular abstract data types. Moreover those skilled in the art will appreciate that the systems methods may be practiced with other computer system configurations including single processor multiprocessor or multi core processor computer systems mini computing devices mainframe computers as well as personal computers hand held computing devices e.g. personal digital assistant PDA phone watch . . . microprocessor based or programmable consumer or industrial electronics and the like. The illustrated aspects may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. However some if not all aspects of the claimed subject matter can be practiced on stand alone computers. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

With reference to an exemplary environment for implementing various aspects disclosed herein includes a computer e.g. desktop laptop server hand held programmable consumer or industrial electronics . . . . The computer includes a processing unit a system memory and a system bus . The system bus couples system components including but not limited to the system memory to the processing unit . The processing unit can be any of various available microprocessors. It is to be appreciated that dual microprocessors multi core and other multiprocessor architectures can be employed as the processing unit .

The system memory includes volatile and nonvolatile memory. The basic input output system BIOS containing the basic routines to transfer information between elements within the computer such as during start up is stored in nonvolatile memory. By way of illustration and not limitation nonvolatile memory can include read only memory ROM . Volatile memory includes random access memory RAM which can act as external cache memory to facilitate processing.

Computer also includes removable non removable volatile non volatile computer storage media. illustrates for example mass storage . Mass storage includes but is not limited to devices like a magnetic or optical disk drive floppy disk drive flash memory or memory stick. In addition mass storage can include storage media separately or in combination with other storage media.

The computer also includes one or more interface components that are communicatively coupled to the bus and facilitate interaction with the computer . By way of example the interface component can be a port e.g. serial parallel PCMCIA USB FireWire . . . or an interface card e.g. sound video network . . . or the like. The interface component can receive input and provide output wired or wirelessly . For instance input can be received from devices including but not limited to a pointing device such as a mouse trackball stylus touch pad keyboard microphone joystick game pad satellite dish scanner camera other computer and the like. Output can also be supplied by the computer to output device s via interface component . Output devices can include displays e.g. CRT LCD plasma . . . speakers printers and other computers among other things.

The system includes a communication framework that can be employed to facilitate communications between the client s and the server s . The client s are operatively connected to one or more client data store s that can be employed to store information local to the client s . Similarly the server s are operatively connected to one or more server data store s that can be employed to store information local to the servers .

Client server interactions can be utilized with respect with respect to various aspects of the claimed subject matter. For example a sensor query application can be afforded by server s and accessed by client s over the communication framework . Additionally or alternatively the client s can correspond to sensors that are accessed over the communication framework by server s .

What has been described above includes examples of aspects of the claimed subject matter. It is of course not possible to describe every conceivable combination of components or methodologies for purposes of describing the claimed subject matter but one of ordinary skill in the art may recognize that many further combinations and permutations of the disclosed subject matter are possible. Accordingly the disclosed subject matter is intended to embrace all such alterations modifications and variations that fall within the spirit and scope of the appended claims. Furthermore to the extent that the terms includes contains has having or variations in form thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising as comprising is interpreted when employed as a transitional word in a claim.

