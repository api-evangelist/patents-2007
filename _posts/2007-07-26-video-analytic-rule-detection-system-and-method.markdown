---

title: Video analytic rule detection system and method
abstract: A video surveillance system is set up, calibrated, tasked, and operated. The system extracts video primitives and extracts event occurrences from the video primitives using event discriminators. The extracted video primitives and event occurrences may be used to create and define additional video analytic rules. The system can undertake a response, such as an alarm, based on extracted event occurrences.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08564661&OS=08564661&RS=08564661
owner: ObjectVideo, Inc.
number: 08564661
owner_city: Reston
owner_country: US
publication_date: 20070726
---
This application is a continuation in part of U.S. patent application Ser. No. 11 167 218 filed Jun. 28 2005 entitled Video Surveillance System Employing Video Primitives which claims the priority of 11 098 385 filed on Apr. 5 2005 which is a continuation in part of U.S. patent application Ser. No. 11 057 154 filed on Feb. 15 2005 which is a continuation in part of U.S. patent application Ser. No. 09 987 707 filed on Nov. 15 2001 which claims the priority of U.S. patent application Ser. No. 09 694 712 filed on Oct. 24 2000 all of which are incorporated herein by reference.

This application is also a continuation in part of U.S. patent application Ser. No. 11 057 154 filed on Feb. 15 2005 entitled Video Surveillance System which claims the priority of 09 987 707 filed on Nov. 15 2001 which claims the priority of U.S. patent application Ser. No. 09 694 712 filed on Oct. 24 2000

For the convenience of the reader the references referred to herein are listed below. In the specification the numerals within brackets refer to respective references. The listed references are incorporated herein by reference. The following references describe moving target detection 

1 A. Lipton H. Fujiyoshi and R. S. Patil Moving Target Detection and Classification from Real Time Video Proceedings of IEEE WACV 98 Princeton N.J. 1998 pp. 8 14.

2 W. E. L. Grimson et al. Using Adaptive Tracking to Classify and Monitor Activities in a Site CVPR pp. 22 29 June 1998.

3 A. J. Lipton H. Fujiyoshi R. S. Patil Moving Target Classification and Tracking from Real time Video IUW pp. 129 136 1998.

4 T. J. Olson and F. Z. Brill Moving Object Detection and Event Recognition Algorithm for Smart Cameras IUW pp. 159 175 May 1997. The following references describe detecting and tracking humans 

5 A. J. Lipton Local Application of Optical Flow to Analyze Rigid Versus Non Rigid Motion International Conference on Computer Vision Corfu Greece September 1999.

6 F. Bartolini V. Cappellini and A. Mecocci Counting people getting in and out of a bus by real time image sequence processing IVC 12 1 36 41 January 1994.

8 C. R. Wren A. Azarbayejani T. Darrell and A. Pentland Pfinder Real time tracking of the human body Vismod 1995.

9 L. Khoudour L. Duvieubourg J. P. Deparis Real Time Pedestrian Counting by Active Linear Cameras JEI 5 4 452 459 October 1996.

13 Niels Haering and Niels da Vitoria Lobo Visual Event Detection Video Computing Series Editor Mubarak Shah 2001.

14 Collins Lipton Kanade Fujiyoshi Duggins Tsin Tolliver Enomoto and Hasegawa A System for Video Surveillance and Monitoring VSAM Final Report Technical Report CMU RI TR 00 12 Robotics Institute Carnegie Mellon University May 2000.

15 Lipton Fujiyoshi and Patil Moving Target Classification and Tracking from Real time Video 98 Darpa IUW Nov. 20 23 1998.

16 C. R. Wren A. Azarbayejani T. Darrell and A. P. Pentland. Pfinder Real Time Tracking of the Human Body PAMI vol 19 pp. 780 784 1997.

17 M. Allmen and C. Dyer Long Range Spatiotemporal Motion Understanding Using Spatiotemporal Flow Curves Proc. IEEE CVPR Lahaina Maui Hi. pp. 303 309 1991.

18 L. Wixson Detecting Salient Motion by Accumulating Directionally Consistent Flow IEEE Trans. Pattern Anal. Mach. Intell. vol. 22 pp. 774 781 August 2000.

Video surveillance of public spaces has become extremely widespread and accepted by the general public. Unfortunately conventional video surveillance systems produce such prodigious volumes of data that an intractable problem results in the analysis of video surveillance data.

A need exists to reduce the amount of video surveillance data so analysis of the video surveillance data can be conducted.

A need exists to filter video surveillance data to identify desired portions of the video surveillance data.

In an exemplary embodiment the invention may be a video surveillance system comprising a video sensor for receiving a video a processing unit for processing the received video a rule detector for creating a rule from the processed video an event detector for detecting an event of interest based on the rule and output means for outputting information based on the detected event of interest.

In another exemplary embodiment the invention may be an apparatus for video surveillance configured to perform a method comprising receiving a video processing the received video creating a rule from the processed video detecting an event of interest in the video based on the rule and outputting information based on the detected event of interest.

In another exemplary embodiment the invention may be a method of rule detection in a video surveillance system comprising receiving a video processing the received video creating a rule from the processed video detecting an event of interest in the video based on the rule and outputting information based on the detected event of interest.

Further features and advantages of the invention as well as the structure and operation of various embodiments of the invention are described in detail below with reference to the accompanying drawings.

A video refers to motion pictures represented in analog and or digital form. Examples of video include television movies image sequences from a video camera or other observer and computer generated image sequences.

An object refers to an item of interest in a video. Examples of an object include a person a vehicle an animal and a physical subject.

An activity refers to one or more actions and or one or more composites of actions of one or more objects. Examples of an activity include entering exiting stopping moving raising lowering growing and shrinking.

A location refers to a space where an activity may occur. A location can be for example scene based or image based. Examples of a scene based location include a public space a store a retail space an office a warehouse a hotel room a hotel lobby a lobby of a building a casino a bus station a train station an airport a port a bus a train an airplane and a ship. Examples of an image based location include a video image a line in a video image an area in a video image a rectangular section of a video image and a polygonal section of a video image.

An event refers to one or more objects engaged in an activity. The event may be referenced with respect to a location and or a time.

A computer may refer to one or more apparatus and or one or more systems that are capable of accepting a structured input processing the structured input according to prescribed rules and producing results of the processing as output. Examples of a computer may include a computer a stationary and or portable computer a computer having a single processor multiple processors or multi core processors which may operate in parallel and or not in parallel a general purpose computer a supercomputer a mainframe a super mini computer a mini computer a workstation a micro computer a server a client an interactive television a web appliance a telecommunications device with internet access a hybrid combination of a computer and an interactive television a portable computer a tablet personal computer PC a personal digital assistant PDA a portable telephone application specific hardware to emulate a computer and or software such as for example a digital signal processor DSP a field programmable gate array FPGA an application specific integrated circuit ASIC an application specific instruction set processor ASIP a chip chips or a chip set a system on chip SoC a multiprocessor system on chip MPSoC a programmable logic controller PLC a graphics processing unit GPU an optical computer a quantum computer a biological computer and an apparatus that may accept data may process data in accordance with one or more stored software programs may generate results and typically may include input output storage arithmetic logic and control units.

 Software may refer to prescribed rules to operate a computer or a portion of a computer. Examples of software may include code segments instructions applets pre compiled code compiled code interpreted code computer programs and programmed logic.

A computer readable medium may refer to any storage device used for storing data accessible by a computer. Examples of a computer readable medium may include a magnetic hard disk a floppy disk an optical disk such as a CD ROM and a DVD a magnetic tape a flash removable memory a memory chip and or other types of media that can store machine readable instructions thereon.

A computer system may refer to a system having one or more computers where each computer may include a computer readable medium embodying software to operate the computer. Examples of a computer system may include a distributed computer system for processing information via computer systems linked by a network two or more computer systems connected together via a network for transmitting and or receiving information between the computer systems and one or more apparatuses and or one or more systems that may accept data may process data in accordance with one or more stored software programs may generate results and typically may include input output storage arithmetic logic and control units.

A network may refer to a number of computers and associated devices e.g. gateways routers switches firewalls address translators etc. that may be connected by communication facilities. A network may involve permanent connections such as cables or temporary connections such as those that may be made through telephone or other communication links. A network may further include hard wired connections e.g. coaxial cable twisted pair optical fiber waveguides etc. and or wireless connections e.g. radio frequency waveforms free space optical waveforms acoustic waveforms etc. . Examples of a network may include an internet such as the Internet an intranet a local area network LAN a wide area network WAN a metropolitan area network MAN a body area network MAN and a combination of networks such as an internet and an intranet. Exemplary networks may operate with any of a number of protocols such as Internet protocol IP asynchronous transfer mode ATM and or synchronous optical network SONET user datagram protocol UDP IEEE 802.x etc.

The automatic video surveillance system of the invention is for monitoring a location for for example market research or security purposes. The system can be a dedicated video surveillance installation with purpose built surveillance components or the system can be a retrofit to existing video surveillance equipment that piggybacks off the surveillance video feeds. The system is capable of analyzing video data from live sources or from recorded media. The system is capable of processing the video data in real time and storing the extracted video primitives to allow very high speed forensic event detection later. The system can have a prescribed response to the analysis such as record data activate an alarm mechanism or activate another sensor system. The system is also capable of integrating with other surveillance system components. The system may be used to produce for example security or market research reports that can be tailored according to the needs of an operator and as an option can be presented through an interactive web based interface or other reporting mechanism.

An operator is provided with maximum flexibility in configuring the system by using event discriminators. Event discriminators are identified with one or more objects whose descriptions are based on video primitives along with one or more optional spatial attributes and or one or more optional temporal attributes. For example an operator can define an event discriminator called a loitering event in this example as a person object in the automatic teller machine space for longer than 15 minutes and between 10 00 p.m. and 6 00 a.m. Event discriminators can be combined with modified Boolean operators to form more complex queries.

Although the video surveillance system of the invention draws on well known computer vision techniques from the public domain the inventive video surveillance system has several unique and novel features that are not currently available. For example current video surveillance systems use large volumes of video imagery as the primary commodity of information interchange. The system of the invention uses video primitives as the primary commodity with representative video imagery being used as collateral evidence. The system of the invention can also be calibrated manually semi automatically or automatically and thereafter automatically can infer video primitives from video imagery. The system can further analyze previously processed video without needing to reprocess completely the video. By analyzing previously processed video the system can perform inference analysis based on previously recorded video primitives which greatly improves the analysis speed of the computer system.

The use of video primitives may also significantly reduce the storage requirements for the video. This is because the event detection and response subsystem uses the video only to illustrate the detections. Consequently video may be stored or transmitted at a lower quality. In a potential embodiment the video may be stored or transmitted only when activity is detected not all the time. In another potential embodiment the quality of the stored or transmitted video may be dependent on whether activity is detected video can be stored or transmitted at higher quality higher frame rate and or bit rate when activity is detected and at lower quality at other times. In another exemplary embodiment the video storage and database may be handled separately e.g. by a digital video recorder DVR and the video processing subsystem may just control whether data is stored and with what quality. In another embodiment the video surveillance system or components thereof may be on a processing device such as general purpose processor DSP microcontroller ASIC FPGA or other device on board a video management device such as a digital video camera network video server DVR or Network Video Recorder NVR and the bandwidth of video streamed from the device can be modulated by the system. High quality video high bit rate or frame rate need only be transmitted through an IP video network only when activities of interest are detected. In this embodiment primitives from intelligence enabled devices can be broadcast via a network to multiple activity inference applications at physically different locations to enable a single camera network to provide multi purpose applications through decentralized processing.

There may be other software components residing on computational platforms at other nodes of a network to which communications channel connects. Block shows a rule management tool which is a user interface for creating video surveillance rules. Block shows an alert console for displaying alerts and reports to a user. Block shows a storage device such as DVR NVR or PC for storing alerts primitives and video for further after the fact processing.

Components on the hardware platform block may be implemented on any processing hardware general purpose processor microcontroller DSP ASIC FPGA or other processing device on any video capture processing or management device such as a video camera digital video camera IP video camera IP video server digital video recorder DVR network video recorder NVR PC laptop or other device. There are a number of different possible modes of operation for this configuration.

In one mode the system is programmed to look for specific events. When those events occur alerts are transmitted via the communication channel block to other systems.

In another mode video is streamed from the video device while it is analyzing the video data. When events occur alerts are transmitted via the communication channel block .

In another mode video encoding and streaming is modulated by the content analysis and activity inference. When there is no activity present no primitives are being generates no video or low quality bit rate frame rate resolution is being streamed. When some activity is present primitives are being generated higher quality bit rate frame rate resolution video is streamed. When events of interest are detected by the event inference very high quality bit rate frame rate resolution video is streamed.

In another mode of operation information is stored in the on board storage device block . Stored data may consist of digital video raw or compressed video primitives alerts or other information. The stored video quality may also be controlled by the presence of primitives or alerts. When there are primitives and alerts higher quality bit rate frame rate resolution video may be stored.

There may also be other software components residing on computational platforms at other nodes of this network block . Block shows a rule management tool which is a user interface for creating video surveillance rules. Block shows an alert console for displaying alerts and reports to a user. Block shows a storage device that could be physically located on the same hardware platform such as a hard disk floppy disk other magnetic disk CD DVD other optical disk MD or other magneto optical disk solid state storage device such as RAM or FLASH RAM or other storage device or may be a separate storage device such as external disk drive PC laptop DVR NVR or other storage device .

Components on the hardware platform block may be implemented on any processing platform general purpose processor microcontroller DSP FPGA ASIC or any other processing platform on any video capture processing or management device such as a video camera digital video camera IP video camera IP video server digital video recorder DVR network video recorder NVR PC laptop or other device. Components on the back end hardware platform block may be implemented on any processing hardware general purpose processor microcontroller DSP FPGA ASIC or any other device on any processing device such as PC laptop single board computer DVR NVR video server network router hand held device such as video phone pager or PDA . There are a number of different possible modes of operation for this configuration.

In one mode the system is programmed on the back end device or any other device connected to the back end device to look for specific events. The content analysis module block on the video processing platform block generates primitives that are transmitted to the back end processing platform block . The event inference module block determines if the rules have been violated and generates alerts that can be displayed on an alert console block or stored in a storage device block for later analysis.

In another mode video primitives and video can be stored in a storage device on the back end platform for later analysis.

In another mode stored video quality bit rate frame rate resolution can be modulated by alerts. When there is an alert video can be stored at higher quality bit rate frame rate resolution.

In another mode video primitives can be stored on the video processing device block in block for later analysis via the communication channel.

In another mode the quality of the video stored on the video processing device in block in block may be modulated by the presence of primitives. When there are primitives when something is happening the quality bit rate frame rate resolution of the stored video can be increased.

In another mode video can be streamed from the video processor via the encoder to other devices on the network via communication channel .

In another mode video quality can be modulated by the content analysis module . When there are no primitives nothing is happening no or low quality bit rate frame rate resolution video is streamed. When there is activity higher quality bit rate frame rate resolution video is streamed.

In another mode streamed video quality bit rate frame rate resolution can be modulated by the presence of alerts. When the back end event inference module block detects an event of interest it can send a signal or command to the video processing component block requesting video or higher quality bit rate frame rate resolution video . When this request is received the video compression component block and communication layer block can change compression and streaming parameters.

In another mode the quality of video stored on board the video processing device block in block can be modulated by the presence of alerts. When an alert is generated by the event inference module block on the back end processor block it can send a message via the communication channel block to the video processor hardware block to increase the quality bit rate frame rate resolution of the video stored in the on board storage device .

In block the primitive stream from the intelligent camera network is analyzed for physical security applications to determine if there has been a perimeter breach vandalism and to protect critical assets. Of course these applications are merely exemplary and any other application is possible.

In block the primitive stream from the intelligent camera network is analyzed for loss prevention applications to monitor a loading dock to watch for customer or employee theft to monitor a warehouse and to track stock. Of course these applications are merely exemplary and any other application is possible.

In block the primitive stream from the intelligent camera network is analyzed for public safety and liability applications to monitor for people or vehicle moving too fast in parking lots to watch for people slipping and falling and to monitor crowds in and around the facility. Of course these applications are merely exemplary and any other application is possible.

In block the primitive stream from the intelligent camera network is analyzed for business intelligence applications to watch the lengths of queues to track consumer behavior to learn patterns of behavior to perform building management tasks such as controlling lighting and heating when there are no people present. Of course these applications are merely exemplary and any other application is possible.

Hardware platform may be connected to a sensor . Sensor may be implemented in hardware firmware software or combinations thereof. Sensor may serve as an interface between hardware platform and network . Sensor may include a server layer or a server layer may be implemented elsewhere for example between sensor and network or as part of network .

There may be other software components residing on computational platforms at other nodes of network . Block shows a rule management tool which again is a user interface for creating video surveillance rules. Block shows an alert console for displaying alerts and reports to a user.

Components on the hardware platform block may be implemented on any processing hardware general purpose processor microcontroller DSP ASIC FPGA or other processing device on any video capture processing or management device such as a video camera digital video camera IP video camera IP video server digital video recorder DVR network video recorder NVR PC laptop or other device. There are a number of different possible modes of operation for this configuration as discussed above.

In the configuration of alerts may be handled at the DSP level and API framework may include alert API support. This may support use of alerts for various command and control functions within the device.

For example in some embodiments of the invention main DSP application may take an alert and send it to another algorithm running on hardware platform . This may for example be a facial recognition algorithm to be executed upon a person based rule being triggered. In such a case the handoff may be made if the alert contains an object field that indicates that the object type is a person.

Another example that may implemented in some embodiments of the invention is to use the alert to control video compression and or streaming. This may for example be simple on off control control of resolution etc. however the invention is not necessarily limited to these examples. Such control may for example be based upon presence of an alert and or on details of an alert.

In general alerts may be used for a variety of command and control functions which may further include but are not limited to controlling image enhancement software controlling pan tilt zoom PTZ functionality and controlling other sensors.

Hardware platform may be connected to a sensor . Sensor may be implemented in hardware firmware software or combinations thereof. Sensor may serve as an interface between hardware platform and network . Sensor may include a server layer or a server layer may be implemented elsewhere for example between sensor and network or as part of network .

As before there may be other software components residing on computational platforms at other nodes of network . Block shows an alert console for displaying alerts and reports to a user. Block shows a partner rule user interface coupled to a rule software development kit SDK and appropriate sensor support for the SDK . Sensor support may remove dependency on a server as discussed in the immediately preceding paragraph which may thus permit standalone SDK capability.

The components may be used to permit users or manufacturers to create rules for the system which may be communicated to event inference module as shown. Components may be hosted for example on a remote device such as a computer laptop computer etc.

Rule SDK may actually take on at least two different forms. In a first form rule SDK may expose to a user fully formed rules for example person crosses tripwire. In such a case a user may need to create a user interface UI on top of such rules.

In a second form SDK may expose to a user an underlying rule language and or primitive definitions. In such a case the user may be able to create his her own rule elements. For example such rule language and primitive definitions may be combined to define object classifications e.g. truck or animal new types of video tripwires video tripwires are discussed further below or new types of areas of interest.

Components on the hardware platform block may be implemented on any processing hardware general purpose processor microcontroller DSP ASIC FPGA or other processing device on any video capture processing or management device such as a video camera digital video camera IP video camera IP video server digital video recorder DVR network video recorder NVR PC laptop or other device. There are a number of different possible modes of operation for this configuration as discussed above.

Components on the hardware platform block may be implemented on any processing hardware general purpose processor microcontroller DSP ASIC FPGA or other processing device on any video capture processing or management device such as a video camera digital video camera IP video camera IP video server digital video recorder DVR network video recorder NVR PC laptop or other device. There are a number of different possible modes of operation for this configuration as discussed above.

As discussed above the configuration of is designed to permit interaction of the system with remote devices via the Internet. While such remote devices are not to be thus limited shows a web browser which may be hosted on such a remote device. Via web browser a user may communicate with the system to create new rules using rule SDK . Alerts may be generated by the system and communicated to one or more external devices not shown and this may be done via the Internet and or via some other communication network or channel.

As another example the system of the invention provides unique system tasking. Using equipment control directives current video systems allow a user to position video sensors and in some sophisticated conventional systems to mask out regions of interest or disinterest. Equipment control directives are instructions to control the position orientation and focus of video cameras. Instead of equipment control directives the system of the invention uses event discriminators based on video primitives as the primary tasking mechanism. With event discriminators and video primitives an operator is provided with a much more intuitive approach over conventional systems for extracting useful information from the system. Rather than tasking a system with an equipment control directives such as camera A pan 45 degrees to the left the system of the invention can be tasked in a human intuitive manner with one or more event discriminators based on video primitives such as a person enters restricted area A. 

Using the invention for market research the following are examples of the type of video surveillance that can be performed with the invention counting people in a store counting people in a part of a store counting people who stop in a particular place in a store measuring how long people spend in a store measuring how long people spend in a part of a store and measuring the length of a line in a store.

Using the invention for security the following are examples of the type of video surveillance that can be performed with the invention determining when anyone enters a restricted area and storing associated imagery determining when a person enters an area at unusual times determining when changes to shelf space and storage space occur that might be unauthorized determining when passengers aboard an aircraft approach the cockpit determining when people tailgate through a secure portal determining if there is an unattended bag in an airport and determining if there is a theft of an asset.

An exemplary application area may be access control which may include for example detecting if a person climbs over a fence or enters a prohibited area detecting if someone moves in the wrong direction e.g. at an airport entering a secure area through the exit determining if a number of objects detected in an area of interest does not match an expected number based on RFID tags or card swipes for entry indicating the presence of unauthorized personnel. This may also be useful in a residential application where the video surveillance system may be able to differentiate between the motion of a person and pet thus eliminating most false alarms. Note that in many residential applications privacy may be of concern for example a homeowner may not wish to have another person remotely monitoring the home and to be able to see what is in the house and what is happening in the house. Therefore in some embodiments used in such applications the video processing may be performed locally and optional video or snapshots may be sent to one or more remote monitoring stations only when necessary for example but not limited to detection of criminal activity or other dangerous situations .

Another exemplary application area may be asset monitoring. This may mean detecting if an object is taken away from the scene for example if an artifact is removed from a museum. In a retail environment asset monitoring can have several aspects to it and may include for example detecting if a single person takes a suspiciously large number of a given item determining if a person exits through the entrance particularly if doing this while pushing a shopping cart determining if a person applies a non matching price tag to an item for example filling a bag with the most expensive type of coffee but using a price tag for a less expensive type or detecting if a person leaves a loading dock with large boxes.

Another exemplary application area may be for safety purposes. This may include for example detecting if a person slips and falls e.g. in a store or in a parking lot detecting if a car is driving too fast in a parking lot detecting if a person is too close to the edge of the platform at a train or subway station while there is no train at the station detecting if a person is on the rails detecting if a person is caught in the door of a train when it starts moving or counting the number of people entering and leaving a facility thus keeping a precise headcount which can be very important in case of an emergency.

Another exemplary application area may be traffic monitoring. This may include detecting if a vehicle stopped especially in places like a bridge or a tunnel or detecting if a vehicle parks in a no parking area.

Another exemplary application area may be terrorism prevention. This may include in addition to some of the previously mentioned applications detecting if an object is left behind in an airport concourse if an object is thrown over a fence or if an object is left at a rail track detecting a person loitering or a vehicle circling around critical infrastructure or detecting a fast moving boat approaching a ship in a port or in open waters.

Another exemplary application area may be in care for the sick and elderly even in the home. This may include for example detecting if the person falls or detecting unusual behavior like the person not entering the kitchen for an extended period of time.

The video sensors provide source video to the computer system . Each video sensor can be coupled to the computer system using for example a direct connection e.g. a firewire digital camera interface or a network. The video sensors can exist prior to installation of the invention or can be installed as part of the invention. Examples of a video sensor include a video camera a digital video camera a color camera a monochrome camera a camera a camcorder a PC camera a webcam an infra red video camera and a CCTV camera. Video sensors may include a hardware mechanism e.g. push button dip switch remote control or the like or a sensor to receive a signal e.g. from a remote control a cell phone a wireless or a wired signal to put the video surveillance system into a configuration mode discussed further below.

The video recorders receive video surveillance data from the computer system for recording and or provide source video to the computer system . Each video recorder can be coupled to the computer system using for example a direct connection or a network. The video recorders can exist prior to installation of the invention or can be installed as part of the invention. The video surveillance system in the computer system may control when and with what quality setting a video recorder records video. Examples of a video recorder include a video tape recorder a digital video recorder a network video recorder a video disk a DVD and a computer readable medium. The system may also modulate the bandwidth and quality of video streamed over a network by controlling a video encoder and streaming protocol. When activities of interest are detected higher bit rate frame rate or resolution imagery may be encoded and streamed.

The I O devices provide input to and receive output from the computer system . The I O devices can be used to task the computer system and produce reports from the computer system . Examples of I O devices include a keyboard a mouse a stylus a monitor a printer another computer system a network and an alarm.

The other sensors provide additional input to the computer system . Each other sensor can be coupled to the computer system using for example a direct connection or a network. The other sensors can exit prior to installation of the invention or can be installed as part of the invention. Examples of another sensor include but are not limited to a motion sensor an optical tripwire a biometric sensor an RFID sensor and a card based or keypad based authorization system. The outputs of the other sensors can be recorded by the computer system recording devices and or recording systems.

In block the video surveillance system is set up as discussed for . Each video sensor is orientated to a location for video surveillance. The computer system is connected to the video feeds from the video equipment and . The video surveillance system can be implemented using existing equipment or newly installed equipment for the location.

In block the video surveillance system is calibrated. Once the video surveillance system is in place from block calibration occurs. The result of block is the ability of the video surveillance system to determine an approximate absolute size and speed of a particular object e.g. a person at various places in the video image provided by the video sensor. The system can be calibrated using manual calibration semi automatic calibration and automatic calibration. Calibration is further described after the discussion of block .

In block of the video surveillance system is tasked. Tasking occurs after calibration in block and is optional. Tasking the video surveillance system involves specifying one or more event discriminators. Without tasking the video surveillance system operates by detecting and archiving video primitives and associated video imagery without taking any action as in block in .

In an exemplary embodiment tasking may include detecting rules or components of rules directly from a video stream by processing the incoming video for example in the video surveillance system. Detecting a rule directly from the video stream may be in addition to instead of or partially instead of receiving a rule from a system operator for example through a graphical user interface. An exemplary video surveillance system may include a hardware mechanism e.g. push button dip switch remote control or the like to put the system into a configuration mode. Exemplary rules that may be detected from observation include for example tripwires uni directional or bi directional areas of interest AOIs directions for flow based rules such as described in U.S. application Ser. No. 10 766 949 speeds or other rules that may be detected or set by analysis of a video stream.

When in this configuration mode the system may be used to track a configuration object or trackable object which may be for example a person a vehicle a watercraft in a water scene a light emitting diode LED emitter an audio emitter a radio frequency RF emitter e.g. an RF emitter publishing GPS info or other location information an infrared IR device a prescribed configuration or tracker pattern such as fiducial marks printed on a piece of paper or otherwise recordable by the video recorder or other objects observable by the video recorder. The configuration object may be observed by the video surveillance system as the object moves around or is displayed in the scene and can thus be used to configure the system.

Tracking a trackable object in the scene can be used as a method of creating a rule or creating part of a rule. For example tracking such an object can be used to create a tripwire or area of interest. This component may be a stand alone rule with the surveillance system assigning default values to other parts of the rule. For example if an AOI is created via this method the system may by default create the complete rule to detect that any object enters the AOI at any time .

A rule component created this way may also be used in conjunction with a user interface or other configuration methods to create a complete rule specification. For example as in the case mentioned previously if an AOI is created the system may require an operator to specify what type of object human vehicle watercraft etc is performing what kind of activity loitering entering exiting etc within that area and at which time all the time between 6 pm and 9 am on weekends etc . These extra rule components may be assigned by the surveillance system by default as in the case mentioned above or may be assigned by an operator using a user interface which could be a GUI or a set of dip switches on the device or a command line interface or any other mechanism.

In block video is received. In block the system may detect and observe a trackable object in the scene in the video. As discussed above a trackable object may be any object that can be detected and tracked by the system in the video scene.

In block the end of the configuration event may be detected. For example the system may detect that the trackable object has stopped moving for a minimum period of time. In another example the system may detect that an emitter device has stopped emitting or is emitting a different signal. In another example the system may detect that a configuration pattern is no longer in view.

In block the detected rule may be created and provided to the video surveillance system. The rule may include for example but not limited to a trip wire or an area of interest. In block the system may exit configuration mode and may enter or return to video surveillance using the created rule.

Real time extraction of the video primitives from the video stream is desirable to enable the system to be capable of generating real time alerts and to do so since the video provides a continuous input stream the system cannot fall behind.

The video primitives should also contain all relevant information from the video since at the time of extracting the video primitives the user defined rules are not known to the system. Therefore the video primitives should contain information to be able to detect any event specified by the user without the need for going back to the video and reanalyzing it.

A concise representation is also desirable for multiple reasons. One goal of the proposed invention may be to extend the storage recycle time of a surveillance system. This may be achieved by replacing storing good quality video all the time by storing activity description meta data and video with quality dependent on the presence of activity as discussed above. Hence the more concise the video primitives are the more data can be stored. In addition the more concise the video primitive representation the faster the data access becomes and this in turn may speed up forensic searching.

The exact contents of the video primitives may depend on the application and potential events of interest. Some exemplary embodiments are described below

An exemplary embodiment of the video primitives may include scene video descriptors describing the overall scene and video. In general this may include a detailed description of the appearance of the scene e.g. the location of sky foliage man made objects water etc and or meteorological conditions e.g. the presence absence of precipitation fog etc. For a video surveillance application for example a change in the overall view may be important. Exemplary descriptors may describe sudden lighting changes they may indicate camera motion especially the facts that the camera started or stopped moving and in the latter case whether it returned to its previous view or at least to a previously known view they may indicate changes in the quality of the video feed e.g. if it suddenly became noisier or went dark potentially indicating tampering with the feed or they may show a changing waterline along a body of water for further information on specific approaches to this latter problem one may consult for example co pending U.S. patent application Ser. No. 10 954 479 filed on Oct. 1 2004 and incorporated herein by reference .

Another exemplary embodiment of the video primitives may include object descriptors referring to an observable attribute of an object viewed in a video feed. What information is stored about an object may depend on the application area and the available processing capabilities. Exemplary object descriptors may include generic properties including but not limited to size shape perimeter position trajectory speed and direction of motion motion salience and its features color rigidity texture and or classification. The object descriptor may also contain some more application and type specific information for humans this may include the presence and ratio of skin tone gender and race information some human body model describing the human shape and pose or for vehicles it may include type e.g. truck SUV sedan bike etc. make model license plate number. The object descriptor may also contain activities including but not limited to carrying an object running walking standing up or raising arms. Some activities such as talking fighting or colliding may also refer to other objects. The object descriptor may also contain identification information including but not limited to face or gait.

Another exemplary embodiment of the video primitives may include flow descriptors describing the direction of motion of every area of the video. Such descriptors may for example be used to detect passback events by detecting any motion in a prohibited direction for further information on specific approaches to this latter problem one may consult for example co pending U.S. patent application Ser. No. 10 766 949 filed on Jan. 30 2004 and incorporated herein by reference .

Primitives may also come from non video sources such as audio sensors heat sensors pressure sensors card readers RFID tags biometric sensors etc.

A classification refers to an identification of an object as belonging to a particular category or class. Examples of a classification include a person a dog a vehicle a police car an individual person and a specific type of object.

A size refers to a dimensional attribute of an object. Examples of a size include large medium small flat taller than 6 feet shorter than 1 foot wider than 3 feet thinner than 4 feet about human size bigger than a human smaller than a human about the size of a car a rectangle in an image with approximate dimensions in pixels and a number of image pixels.

Position refers to a spatial attribute of an object. The position may be for example an image position in pixel coordinates an absolute real world position in some world coordinate system or a position relative to a landmark or another object.

A color refers to a chromatic attribute of an object. Examples of a color include white black grey red a range of HSV values a range of YUV values a range of RGB values an average RGB value an average YUV value and a histogram of RGB values.

Rigidity refers to a shape consistency attribute of an object. The shape of non rigid objects e.g. people or animals may change from frame to frame while that of rigid objects e.g. vehicles or houses may remain largely unchanged from frame to frame except perhaps for slight changes due to turning .

A texture refers to a pattern attribute of an object. Examples of texture features include self similarity spectral power linearity and coarseness.

An internal motion refers to a measure of the rigidity of an object. An example of a fairly rigid object is a car which does not exhibit a great amount of internal motion. An example of a fairly non rigid object is a person having swinging arms and legs which exhibits a great amount of internal motion.

A motion refers to any motion that can be automatically detected. Examples of a motion include appearance of an object disappearance of an object a vertical movement of an object a horizontal movement of an object and a periodic movement of an object.

A salient motion refers to any motion that can be automatically detected and can be tracked for some period of time. Such a moving object exhibits apparently purposeful motion. Examples of a salient motion include moving from one place to another and moving to interact with another object.

A feature of a salient motion refers to a property of a salient motion. Examples of a feature of a salient motion include a trajectory a length of a trajectory in image space an approximate length of a trajectory in a three dimensional representation of the environment a position of an object in image space as a function of time an approximate position of an object in a three dimensional representation of the environment as a function of time a duration of a trajectory a velocity e.g. speed and direction in image space an approximate velocity e.g. speed and direction in a three dimensional representation of the environment a duration of time at a velocity a change of velocity in image space an approximate change of velocity in a three dimensional representation of the environment a duration of a change of velocity cessation of motion and a duration of cessation of motion. A velocity refers to the speed and direction of an object at a particular time. A trajectory refers a set of position velocity pairs for an object for as long as the object can be tracked or for a time period.

A scene change refers to any region of a scene that can be detected as changing over a period of time. Examples of a scene change include an stationary object leaving a scene an object entering a scene and becoming stationary an object changing position in a scene and an object changing appearance e.g. color shape or size .

A feature of a scene change refers to a property of a scene change. Examples of a feature of a scene change include a size of a scene change in image space an approximate size of a scene change in a three dimensional representation of the environment a time at which a scene change occurred a location of a scene change in image space and an approximate location of a scene change in a three dimensional representation of the environment.

A pre defined model refers to an a priori known model of an object. Examples of a pre defined model may include an adult a child a vehicle and a semi trailer.

Referring now to once the video and if there are other sensors the non video primitives are available the system may detect events. The user tasks the system by defining rules and corresponding responses using the rule and response definition interface . In an exemplary embodiment the rule response and definition interface may receive rules detected directly from incoming video as described above with reference to . The areas of interest tripwires direction speed etc. detected rules may be available to the user in tasking the system. The rules are translated into event discriminators and the system extracts corresponding event occurrences . The detected event occurrences trigger user defined responses . A response may include a snapshot of a video of the detected event from video storage which may or may not be the same as video storage in . The video storage may be part of the video surveillance system or it may be a separate recording device . Examples of a response may include but are not necessarily limited to the following activating a visual and or audio alert on a system display activating a visual and or audio alarm system at the location activating a silent alarm activating a rapid response mechanism locking a door contacting a security service forwarding or streaming data e.g. image data video data video primitives and or analyzed data to another computer system via a network such as but not limited to the Internet saving such data to a designated computer readable medium activating some other sensor or surveillance system tasking the computer system and or another computer system and or directing the computer system and or another computer system.

The primitive data can be thought of as data stored in a database. To detect event occurrences in it an efficient query language is required. Embodiments of the inventive system may include an activity inferencing language which will be described below.

Traditional relational database querying schemas often follow a Boolean binary tree structure to allow users to create flexible queries on stored data of various types. Leaf nodes are usually of the form property relationship value where a property is some key feature of the data such as time or name a relationship is usually a numerical operator 

This may form the basis of an activity query formulation schema as in embodiments of the present invention. In case of a video surveillance application the properties may be features of the object detected in the video stream such as size speed color classification human vehicle or the properties may be scene change properties. gives examples of using such queries. In the query Show me any red vehicle is posed. This may be decomposed into two property relationship value or simply property queries testing whether the classification of an object is vehicle and whether its color is predominantly red . These two sub queries can combined with the Boolean operator and . Similarly in the query Show me when a camera starts or stops moving may be expressed as the Boolean or combination of the property sub queries has the camera started moving and has the camera stopped moving .

Embodiments of the invention may extend this type of database query schema in two exemplary ways 1 the basic leaf nodes may be augmented with activity detectors describing spatial activities within a scene and 2 the Boolean operator branch nodes may be augmented with modifiers specifying spatial temporal and object interrelationships.

Activity detectors correspond to a behavior related to an area of the video scene. They describe how an object might interact with a location in the scene. illustrates three exemplary activity detectors. represents the behavior of crossing a perimeter in a particular direction using a virtual video tripwire for further information about how such virtual video tripwires may be implemented one may consult e.g. U.S. Pat. No. 6 696 945 . represents the behavior of loitering for a period of time on a railway track. represents the behavior of taking something away from a section of wall for exemplary approaches to how this may be done one may consult U.S. patent application Ser. No. 10 331 778 entitled Video Scene Background Maintenance Change Detection Classification filed on Jan. 30 2003 . Other exemplary activity detectors may include detecting a person falling detecting a person changing direction or speed detecting a person entering an area or detecting a person going in the wrong direction.

Combining queries with modified Boolean operators combinators may add further flexibility. Exemplary modifiers include spatial temporal object and counter modifiers.

A spatial modifier may cause the Boolean operator to operate only on child. activities i.e. the arguments of the Boolean operator as shown below a Boolean operator e.g. in that are proximate non proximate within the scene. For example and within 50 pixels of may be used to mean that the and only applies if the distance between activities is less than 50 pixels.

A temporal modifier may cause the Boolean operator to operate only on child activities that occur within a specified period of time of each other outside of such a time period or within a range of times. The time ordering of events may also be specified. For example and first within 10 seconds of second may be used to mean that the and only applies if the second child activity occurs not more than 10 seconds after the first child activity.

An object modifier may cause the Boolean operator to operate only on child activities that occur involving the same or different objects. For example and involving the same object may be used to mean that the and only applies if the two child activities involve the same specific object.

A counter modifier may cause the Boolean operator to be triggered only if the condition s is are met a prescribed number of times. A counter modifier may generally include a numerical relationship such as at least n times exactly n times at most n times etc. For example or at least twice may be used to mean that at least two of the sub queries of the or operator have to be true. Another use of the counter modifier may be to implement a rule like alert if the same person takes at least five items from a shelf. 

This example also indicates the power of the combinators. Theoretically it is possible to define a separate activity detector for left turn without relying on simple activity detectors and combinators. However that detector would be inflexible making it difficult to accommodate arbitrary turning angles and directions and it would also be cumbersome to write a separate detector for all potential events. In contrast using the combinators and simple detectors provides great flexibility.

Other examples of complex activities that can be detected as a combination of simpler ones may include a car parking and a person getting out of the car or multiple people forming a group tailgating. These combinators can also combine primitives of different types and sources. Examples may include rules such as show a person inside a room before the lights are turned off show a person entering a door without a preceding card swipe or show if an area of interest has more objects than expected by an RFID tag reader i.e. an illegal object without an RFID tag is in the area.

A combinator may combine any number of sub queries and it may even combine other combinators to arbitrary depths. An example illustrated in and may be a rule to detect if a car turns left and then turns right . The left turn may be detected with the directional tripwires and while the right turn with the directional tripwires and . The left turn may be expressed as the tripwire activity detectors and corresponding to tripwires and respectively joined with the and combinator with the object modifier same and temporal modifier before . Similarly the right turn may be expressed as the tripwire activity detectors and corresponding to tripwires and respectively joined with the and combinator with the object modifier same and temporal modifier before . To detect that the same object turned first left then right the left turn detector and the right turn detector are joined with the and combinator with the object modifier same and temporal modifier before . Finally to ensure that the detected object is a vehicle a Boolean and operator is used to combine the left and right turn detector and the property query .

All these detectors may optionally be combined with temporal attributes. Examples of a temporal attribute include every 15 minutes between 9 00 pm and 6 30 am less than 5 minutes longer than 30 seconds and over the weekend.

In block of the video surveillance system is operated. The video surveillance system of the invention operates automatically detects and archives video primitives of objects in the scene and detects event occurrences in real time using event discriminators. In addition action is taken in real time as appropriate such as activating alarms generating reports and generating output. The reports and output can be displayed and or stored locally to the system or elsewhere via a network such as the Internet. illustrates a flow diagram for operating the video surveillance system.

In block the computer system obtains source video from the video sensors and or the video recorders .

In block video primitives are extracted in real time from the source video. As an option non video primitives can be obtained and or extracted from one or more other sensors and used with the invention. The extraction of video primitives is illustrated with .

In block objects are detected via change. Any change detection algorithm for detecting changes from a background model can be used for this block. An object is detected in this block if one or more pixels in a frame are deemed to be in the foreground of the frame because the pixels do not conform to a background model of the frame. As an example a stochastic background modeling technique such as dynamically adaptive background subtraction can be used which is described in 1 and U.S. patent application Ser. No. 09 694 712 filed Oct. 24 2000. The detected objects are forwarded to block .

The motion detection technique of block and the change detection technique of block are complimentary techniques where each technique advantageously addresses deficiencies in the other technique. As an option additional and or alternative detection schemes can be used for the techniques discussed for blocks and . Examples of an additional and or alternative detection scheme include the following the Pfinder detection scheme for finding people as described in 8 a skin tone detection scheme a face detection scheme and a model based detection scheme. The results of such additional and or alternative detection schemes are provided to block .

As an option if the video sensor has motion e.g. a video camera that sweeps zooms and or translates an additional block can be inserted before blocks between blocks and to provide input to blocks and for video stabilization. Video stabilization can be achieved by affine or projective global motion compensation. For example image alignment described in U.S. patent application Ser. No. 09 609 919 filed Jul. 3 2000 now U.S. Pat. No. 6 738 424 which is incorporated herein by reference can be used to obtain video stabilization.

In block blobs are generated. In general a blob is any object in a frame. Examples of a blob include a moving object such as a person or a vehicle and a consumer product such as a piece of furniture a clothing item or a retail shelf item. Blobs are generated using the detected objects from blocks and . Any technique for generating blobs can be used for this block. An exemplary technique for generating blobs from motion detection and change detection uses a connected components scheme. For example the morphology and connected components algorithm can be used which is described in 1.

In block blobs are tracked. Any technique for tracking blobs can be used for this block. For example Kalman filtering or the CONDENSATION algorithm can be used. As another example a template matching technique such as described in 1 can be used. As a further example a multi hypothesis Kalman tracker can be used which is described in 5. As yet another example the frame to frame tracking technique described in U.S. patent application Ser. No. 09 694 712 filed Oct. 24 2000 can be used. For the example of a location being a grocery store examples of objects that can be tracked include moving people inventory items and inventory moving appliances such as shopping carts or trolleys.

As an option blocks can be replaced with any detection and tracking scheme as is known to those of ordinary skill. An example of such a detection and tracking scheme is described in 11.

In block each trajectory of the tracked objects is analyzed to determine if the trajectory is salient. If the trajectory is insalient the trajectory represents an object exhibiting unstable motion or represents an object of unstable size or color and the corresponding object is rejected and is no longer analyzed by the system. If the trajectory is salient the trajectory represents an object that is potentially of interest. A trajectory is determined to be salient or insalient by applying a salience measure to the trajectory. Techniques for determining a trajectory to be salient or insalient are described in 13 and 18.

In block each object is classified. The general type of each object is determined as the classification of the object. Classification can be performed by a number of techniques and examples of such techniques include using a neural network classifier 14 and using a linear discriminatant classifier 14. Examples of classification are the same as those discussed for block .

In block video primitives are identified using the information from blocks and additional processing as necessary. Examples of video primitives identified are the same as those discussed for block . As an example for size the system can use information obtained from calibration in block as a video primitive. From calibration the system has sufficient information to determine the approximate size of an object. As another example the system can use velocity as measured from block as a video primitive.

In block the video primitives from block are archived. The video primitives can be archived in the computer readable medium or another computer readable medium. Along with the video primitives associated frames or video imagery from the source video can be archived. This archiving step is optional if the system is to be used only for real time event detection the archiving step can be skipped.

In block event occurrences are extracted from the video primitives using event discriminators. The video primitives are determined in block and the event discriminators are determined from tasking the system in block . The event discriminators are used to filter the video primitives to determine if any event occurrences occurred. For example an event discriminator can be looking for a wrong way event as defined by a person traveling the wrong way into an area between 9 00 a.m. and 5 00 p.m. The event discriminator checks all video primitives being generated according to and determines if any video primitives exist which have the following properties a timestamp between 9 00 a.m. and 5 00 p.m. a classification of person or group of people a position inside the area and a wrong direction of motion. The event discriminators may also use other types of primitives as discussed above and or combine video primitives from multiple video sources to detect event occurrences.

In block action is taken for each event occurrence extracted in block as appropriate. illustrates a flow diagram for taking action with the video surveillance system.

In block responses are undertaken as dictated by the event discriminators that detected the event occurrences. The responses if any are identified for each event discriminator in block .

In block an activity record is generated for each event occurrence that occurred. The activity record includes for example details of a trajectory of an object a time of detection of an object a position of detection of an object and a description or definition of the event discriminator that was employed. The activity record can include information such as video primitives needed by the event discriminator. The activity record can also include representative video or still imagery of the object s and or area s involved in the event occurrence. The activity record is stored on a computer readable medium.

In block output is generated. The output is based on the event occurrences extracted in block and a direct feed of the source video from block . The output is stored on a computer readable medium displayed on the computer system or another computer system or forwarded to another computer system. As the system operates information regarding event occurrences is collected and the information can be viewed by the operator at any time including real time. Examples of formats for receiving the information include a display on a monitor of a computer system a hard copy a computer readable medium and an interactive web page.

The output can include a display from the direct feed of the source video from block transmitted either via analog video transmission means or via network video streaming. For example the source video can be displayed on a window of the monitor of a computer system or on a closed circuit monitor. Further the output can include source video marked up with graphics to highlight the objects and or areas involved in the event occurrence. If the system is operating in forensic analysis mode the video may come from the video recorder.

The output can include one or more reports for an operator based on the requirements of the operator and or the event occurrences. Examples of a report include the number of event occurrences which occurred the positions in the scene in which the event occurrence occurred the times at which the event occurrences occurred representative imagery of each event occurrence representative video of each event occurrence raw statistical data statistics of event occurrences e.g. how many how often where and when and or human readable graphical displays.

In the exemplary report is an image from a video marked up to include labels graphics statistical information and an analysis of the statistical information. For example the area identified as coffee has statistical information of an average number of customers in the area of 2 hour and an average dwell time in the area as 5 seconds. The system determined this area to be a cold region which means there is not much commercial activity through this region. As another example the area identified as sodas has statistical information of an average number of customers in the area of 15 hour and an average dwell time in the area as 22 seconds. The system determined this area to be a hot region which means there is a large amount of commercial activity in this region.

In the exemplary report is an image from a video marked up to include labels graphics statistical information and an analysis of the statistical information. For example the area at the back of the aisle has average number of customers of 14 hour and is determined to have low traffic. As another example the area at the front of the aisle has average number of customers of 83 hour and is determined to have high traffic.

For either or if the operator desires more information about any particular area or any particular area a point and click interface allows the operator to navigate through representative still and video imagery of regions and or activities that the system has detected and archived.

The video image of is from a time period where the trajectories were recorded. Of the three objects two objects are each classified as one person and one object is classified as not a person. Each object is assigned a label namely Person ID Person ID and Object ID . For Person ID the system determined the person spent 52 seconds in the area and 18 seconds at the position designated by the circle. For Person ID the system determined the person spent 1 minute and 8 seconds in the area and 12 seconds at the position designated by the circle. The trajectories for Person ID and Person ID are included in the marked up image. For Object ID the system did not further analyze the object and indicated the position of the object with an X.

Referring back to block in calibration can be 1 manual 2 semi automatic using imagery from a video sensor or a video recorder or 3 automatic using imagery from a video sensor or a video recorder. If imagery is required it is assumed that the source video to be analyzed by the computer system is from a video sensor that obtained the source video used for calibration.

For manual calibration the operator provides to the computer system the orientation and internal parameters for each of the video sensors and the placement of each video sensor with respect to the location. The computer system can optionally maintain a map of the location and the placement of the video sensors can be indicated on the map. The map can be a two dimensional or a three dimensional representation of the environment. In addition the manual calibration provides the system with sufficient information to determine the approximate size and relative position of an object.

Alternatively for manual calibration the operator can mark up a video image from the sensor with a graphic representing the appearance of a known sized object such as a person. If the operator can mark up an image in at least two different locations the system can infer approximate camera calibration information.

For semi automatic and automatic calibration no knowledge of the camera parameters or scene geometry is required. From semi automatic and automatic calibration a lookup table is generated to approximate the size of an object at various areas in the scene or the internal and external camera calibration parameters of the camera are inferred.

For semi automatic calibration the video surveillance system is calibrated using a video source combined with input from the operator. A single person is placed in the field of view of the video sensor to be semi automatic calibrated. The computer system receives source video regarding the single person and automatically infers the size of person based on this data. As the number of locations in the field of view of the video sensor that the person is viewed is increased and as the period of time that the person is viewed in the field of view of the video sensor is increased the accuracy of the semi automatic calibration is increased.

In block the typical object is monitored throughout the scene. It is assumed that the only or at least the most stable object being tracked is the calibration object in the scene i.e. the typical object moving through the scene . The size of the stable object is collected for every point in the scene at which it is observed and this information is used to generate calibration information.

In block the size of the typical object is identified for different areas throughout the scene. The size of the typical object is used to determine the approximate sizes of similar objects at various areas in the scene. With this information a lookup table is generated matching typical apparent sizes of the typical object in various areas in the image or internal and external camera calibration parameters are inferred. As a sample output a display of stick sized figures in various areas of the image indicate what the system determined as an appropriate height. Such a stick sized figure is illustrated in .

For automatic calibration a learning phase is conducted where the computer system determines information regarding the location in the field of view of each video sensor. During automatic calibration the computer system receives source video of the location for a representative period of time e.g. minutes hours or days that is sufficient to obtain a statistically significant sampling of objects typical to the scene and thus infer typical apparent sizes and locations.

In block trackable regions in the field of view of the video sensor are identified. A trackable region refers to a region in the field of view of a video sensor where an object can be easily and or accurately tracked. An untrackable region refers to a region in the field of view of a video sensor where an object is not easily and or accurately tracked and or is difficult to track. An untrackable region can be referred to as being an unstable or insalient region. An object may be difficult to track because the object is too small e.g. smaller than a predetermined threshold appear for too short of time e.g. less than a predetermined threshold or exhibit motion that is not salient e.g. not purposeful . A trackable region can be identified using for example the techniques described in 13.

In block the sizes of the objects are identified for different areas throughout the scene. The sizes of the objects are used to determine the approximate sizes of similar objects at various areas in the scene. A technique such as using a histogram or a statistical median is used to determine the typical apparent height and width of objects as a function of location in the scene. In one part of the image of the scene typical objects can have a typical apparent height and width. With this information a lookup table is generated matching typical apparent sizes of objects in various areas in the image or the internal and external camera calibration parameters can be inferred.

For plot A the x axis depicts the height of the blob in pixels and the y axis depicts the number of instances of a particular height as identified on the x axis that occur. The peak of the line for plot A corresponds to the most common height of blobs in the designated region in the scene and for this example the peak corresponds to the average height of a person standing in the designated region.

Assuming people travel in loosely knit groups a similar graph to plot A is generated for width as plot B. For plot B the x axis depicts the width of the blobs in pixels and the y axis depicts the number of instances of a particular width as identified on the x axis that occur. The peaks of the line for plot B correspond to the average width of a number of blobs. Assuming most groups contain only one person the largest peak corresponds to the most common width which corresponds to the average width of a single person in the designated region. Similarly the second largest peak corresponds to the average width of two people in the designated region and the third largest peak corresponds to the average width of three people in the designated region.

As an exemplary application the invention can be used to analyze retail market space by measuring the efficacy of a retail display. Large sums of money are injected into retail displays in an effort to be as eye catching as possible to promote sales of both the items on display and subsidiary items. The video surveillance system of the invention can be configured to measure the effectiveness of these retail displays.

For this exemplary application the video surveillance system is set up by orienting the field of view of a video sensor towards the space around the desired retail display. During tasking the operator selects an area representing the space around the desired retail display. As a discriminator the operator defines that he or she wishes to monitor people sized objects that enter the area and either exhibit a measurable reduction in velocity or stop for an appreciable amount of time.

After operating for some period of time the video surveillance system can provide reports for market analysis. The reports can include the number of people who slowed down around the retail display the number of people who stopped at the retail display the breakdown of people who were interested in the retail display as a function of time such as how many were interested on weekends and how many were interested in evenings and video snapshots of the people who showed interest in the retail display. The market research information obtained from the video surveillance system can be combined with sales information from the store and customer records from the store to improve the analysts understanding of the efficacy of the retail display.

The invention is described in detail with respect to preferred embodiments and it will now be apparent from the foregoing to those skilled in the art that changes and modifications may be made without departing from the invention in its broader aspects and the invention therefore as defined in the claims is intended to cover all such changes and modifications as fall within the true spirit of the invention.

