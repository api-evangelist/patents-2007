---

title: Interactive image tagging
abstract: Techniques are described for performing automatic generation of one or more tags associated with an image file. One or more ink annotations for a displayed image are received. Handwriting recognition processing of the one or more ink annotations is performed. A string is generated and the string includes one or more recognized words used to form the one or more tags associated with the image file. The handwriting recognition processing and generating the string are performed in response to receiving the ink annotations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08347206&OS=08347206&RS=08347206
owner: Microsoft Corporation
number: 08347206
owner_city: Redmond
owner_country: US
publication_date: 20070315
---
Image files such as those containing photographs or other image data may be tagged with one or more different types of tags such as keywords. The keywords may be used in connection with performing subsequent operations using the image files such as sorting and retrieval of selected image files based on the keywords. One existing technique for tagging images with keywords provides for manually specifying the keywords such as by a user entering the keywords using a keyboard. However manually entering the keywords and associating them with each image file can be a cumbersome and time consuming process. Furthermore if a user has a device with no keyboard such as a tablet computer it may not be possible to manually enter the keywords used in connection with the image.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Techniques are described herein for performing automatic generation of one or more tags associated with an image file. One or more ink annotations for a displayed image are received. Handwriting recognition processing of the one or more ink annotations is performed and a string is generated including one or more recognized words. The words are used to form one or more tags associated with the image file. The handwriting recognition processing and generating of the string are performed in response to receiving the ink annotations to provide for automatic generation of the tags.

Referring now to illustrated is an example of a suitable computing environment in which embodiments utilizing the techniques described herein may be implemented. The computing environment illustrated in is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the techniques described herein in connection with automatically generating one or more types of tags associated with an image. One type of tag is a keyword tag. The keyword tag may be used in connection with performing operations on one or more images such as for example sorting searching and or retrieval of image files based on tags which have keywords matching specified criteria.

The techniques set forth herein may be described in the general context of computer executable instructions such as program modules executed by one or more computers or other devices. Generally program modules include routines programs objects components data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments. Those skilled in the art will appreciate that the techniques described herein may be suitable for use with other general purpose and specialized purpose computing environments and configurations. Examples of well known computing systems environments and or configurations include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

Included in are a device a network and a server . The device may be for example a computer such as a personal computer having a display output device and an input device providing for interactive I O with a user thereof. In following paragraphs additional details are provided with respect to the device . However the same details may also apply to one or more other devices that may be connected to the network in an embodiment. Although the example of includes only a single device and a single server an embodiment utilizing the techniques herein may include any number of devices and other components.

The device included in is exemplary for purposes of illustrating the techniques described herein in connection with software components. In one embodiment any device providing the functionality described herein may be included in an embodiment. The device may include a processor used to execute code included in one or more program modules. Described in more detail elsewhere herein are program modules that may be executed by the device in connection with the techniques described herein. The device may operate in a networked environment and communicate with the server and other computers or components not shown in . As described herein the device may be a personal computer. In other embodiments the functionality of device or the device itself may be included in another component in accordance with a particular environment in which the device is utilized.

The server may communicate with device when connected to the network . The server may include one or more applications and associated data for use in connection with communications to device .

It will be appreciated by those skilled in the art that although the device is shown in the example as communicating in a networked environment the device may communicate with other components utilizing different communication mediums. For example the device may communicate with one or more components utilizing a network connection and or other type of link known in the art including but not limited to the Internet an intranet or other wireless and or hardwired connection s to the server and or other components.

It should also be noted that although the device is illustrated as having network connectivity to the server the techniques described herein may be used in connection with a device directly connected to the server without a network. The device may also operate standalone without external connectivity to the network and server.

Referring now to shown is an example of components that may be included in the device as may be used in connection with performing the various embodiments of the techniques described herein. The device may include one or more processing units memory a network interface unit storage one or more other communication connections and a system bus used to facilitate communications between the components of the device .

Depending on the configuration and type of user device memory may be volatile such as RAM non volatile such as ROM flash memory etc. or some combination of the two. Additionally the device may also have additional features functionality. For example the device may also include additional storage removable and or non removable including but not limited to USB devices magnetic or optical disks or tape. Such additional storage is illustrated in by storage . The storage of may include one or more removable and non removable storage devices having associated computer readable media that may be utilized by the device . The storage in one embodiment may be a mass storage device with associated computer readable media providing non volatile storage for the device . Although the description of computer readable media as illustrated in this example may refer to a mass storage device such as a hard disk or CD ROM drive it will be appreciated by those skilled in the art that the computer readable media can be any available media that can be accessed by the device .

By way of example and not limitation computer readable media may comprise computer storage media and communication media. Memory as well as storage are examples of computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can accessed by device . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

The device may also contain communications connection s that allow the computer to communicate with other devices and components such as by way of example input devices and output devices. Input devices may include for example a keyboard mouse pen voice input device touch input device etc. Output device s may include for example a display speakers printer and the like. These and other devices are well known in the art and need not be discussed at length here. The one or more communications connection s are an example of communication media.

In one embodiment the device may operate in a networked environment as illustrated in using logical connections to remote computers through a network. The device may connect to the network of through a network interface unit connected to bus . The network interface unit may also be utilized in connection with other types of networks and or remote systems and components.

In one embodiment the device may be tablet computer. As known in the art a tablet computer may be characterized as a computer shaped in the form of a notebook or a slate with the capabilities of being written on through the use of digitizing tablet technology a touch screen or other two dimensional input device. A user can use a stylus or electronic pen and operate the computer without having to have a keyboard or mouse. An electronic representation of the stylus or pen movements pressure and other characteristics may be referred to as digital or electronic ink. Ink resulting from an elementary pen movement may be referred to as a stroke. One or more strokes in a sequence constitute a trace defined as a complete pen down movement bounded by two pen up movements. A sequence of traces may comprise other larger recognized units such as characters or words. A gesture may be defined as a collection of ink traces that indicate an action to be performed. An ink annotation may be defined as a handwritten note made for example using the electronic pen on a display of a tablet computer. The annotation may be a sequence of traces entered for example by a user interactively writing with an electronic pen or stylus on a digitized surface screen of a tablet computer or other device to perform handwriting or drawing over a document such as an image.

In connection with techniques that will be described herein handwriting recognition processing of the ink annotations may be performed. Results of the handwriting recognition processing may be in the form of a string including recognized text. The recognized text may include one or more words used to specify keywords or other types of tags associated with the annotated image. The handwriting recognition processing and designation of recognized text as keyword tags associated with the image may be automatically performed. The conversion of the digital annotations to image keywords using handwriting recognition processing is described in more detail in following paragraphs. Although the examples set forth in following paragraphs illustrate the techniques herein with automatically generating particular types of tags such as keywords it will be appreciated by those skilled in the art that techniques herein may be used in connection with automatically generating one or more different types of tags.

One or more program modules and or data files may be included in storage . During operation of the device one or more of these elements included in the storage may also reside in a portion of memory such as for example RAM for controlling the operation of the user computer . The example of illustrates various components including an operating system one or more application programs a recognition engine and other components inputs and or outputs .

The recognition engine may be used in connection with recognizing handwritten inputs made using a pen or stylus. In one embodiment the recognition engine may be included as an operating system component. The engine may receive as an input one or more lines of ink text or blocks. Ink text may be characterized as one or more lines of text represented as digital ink. The recognition engine may receive as an input ink strokes or traces forming letters and words. As an output the engine may generate a string including recognized characters in accordance with the input of one or more lines of ink text. The use of the recognition engine and other components in connection with the techniques herein is described in more detail in following paragraphs.

In one embodiment the application program may be an application used in connection with image files of one or more types. The application program may be able to process digital ink annotations for use in connection with the one or more image file types. For example the application program may be a photo editor which loads image files such as JPEG files. The application program may allow a user to enter digital ink annotations on a displayed image using a pen or stylus. The application program may allow the user to save the ink annotations as part of the image file. The application program alone or by also invoking other components such as the recognition engine may perform processing to automatically generate keywords associated with the image using handwriting recognition results of the ink annotations made on the image. The keywords may be persisted with the image file as tags. In one embodiment the tags may be included as part the image file. The image file may include the image data and other data portions such as metadata describing image file. As set forth in more detail in following paragraphs the tags may be stored within an image file as metadata. An embodiment using the techniques herein for automatically recognizing and forming tags from ink annotations may also store the tags outside of the image file such as for example as keywords in a database catalogue or other file. The operating system may be any one of a variety of commercially available or proprietary operating systems. In one embodiment the operating system may be the Microsoft Windows XP Tablet PC Edition operating system. The operating system for example may be loaded into memory in connection with controlling operation of the device . Components of the operating system may be utilized in conjunction with the application program in connection with performing the techniques herein.

In one embodiment the device may be a tablet computer as described above and may operate in a standalone mode in connection with performing the techniques herein. In other words the components used in connection with performing the techniques herein may all reside and execute on the device in one arrangement. The application program may utilize the recognition engine and possibly other components to perform processing described herein. As an alternative the application program may include its own recognition engine and other components used to automatically obtaining keywords from ink annotations using the techniques herein.

It should be noted that an embodiment of the server may include hardware components similar to those illustrated in connection with . The server may also include server side software application components for performing various tasks as may be used in an embodiment. In an embodiment in which components for performing the techniques herein reside on both the server and the device the application program may operate with a browser executing on the device . The application program may be for example a browser plugin. In one variation of this embodiment the recognition engine and possibly other components used in connection with performing the techniques herein may be located on the server .

Referring now to shown is a block diagram illustrating the data flow between various components that may be included in an embodiment utilizing the techniques herein. The example includes an image application an ink analysis component a recognition engine and an image file with tags . The image application may be for example an application program such as the photo editor described in connection with capable of processing digital ink annotations.

The image application may load an image file such as a JPEG file for use with the application . As an example the user may load an image file of a photograph taken with a digital camera. The user may wish to annotate the image file such as by making digital ink annotations thereon of particular items in the photo. The digital ink annotations may be formed from one or more ink strokes . The one or more ink strokes may be analyzed using an ink analysis component . Processing may be performed by the ink analysis component to determine one or more lines or blocks of ink text gestures and the like formed from one or more of the ink strokes. The ink text may be characterized as one or more lines or blocks of text represented as digital ink. As an example an annotation which is a 3 letter word may be represented as digital ink in accordance with the strokes forming the 3 letters. As an output the ink analysis component may generate analyzer output . In one embodiment the output may be the ink text sent to the recognition engine . The recognition engine generates recognition results based on the received analyzer output . In one embodiment the recognition engine may be a handwriting recognition engine which outputs recognized text strings as the recognition results based on the ink text received from the ink analysis component . In other words the recognition engine outputs a string representation based on the input which is a digital ink representation of the ink text. The recognition results which in this example are the string result may be returned to the ink analysis component and then to the image application . The image application may then utilize one or more text words included in the string result as one or more keywords in forming tags for the image. All the text words in the string result may be stored as keywords. Additionally an embodiment may provide a user interface by which a user may edit the string results to select a portion of the text words included therein to be stored as keywords. In one embodiment the keywords formed by performing handwriting recognition processing on the digital ink annotations may be stored as part of the image file . In one embodiment the image file may include image data and metadata. The keywords may be persisted as metadata included in the image file . The particular location of the keyword tags with each image file may vary with the file type.

In one embodiment the techniques herein may be performed using the RecognizerContext or InkAnalyzer application programming interface API included in the Microsoft Windows Xp Tablet PC Edition Platform Software Development Kit. The image application may be implemented using the .NET Framework and associated image file type APIs for one or more image file types e.g. JPEG GIF TIFF and the like . The ink analysis component may be implemented using the foregoing InkAnalyzer API that invokes the recognition engine which may be an operating system component.

The techniques herein may be used to obtain ink annotations and automatically perform handwriting recognition processing thereon to automatically obtain keywords associated with an image. In one embodiment the keywords may be included as metadata in the image file. The keywords may be included as a type of tag associated with the image and may be used in connection with performing subsequent processing operations on the image. The tagging of the image with the foregoing keywords may be characterized as implicit tagging or explicit tagging. With implicit tagging the image may be annotated and the automatic keyword generation and image keyword tagging may be performed. In the implicit tagging mode the annotations may be stored as digital ink with the image file along with the keywords. With explicit tagging the image may be tagged with the keywords but the ink annotations are not stored or persisted. In other words with the latter explicit tagging mode the purpose of the ink annotations is to facilitate the automatic creation of keywords used with tagging the image file rather than in annotating the loaded image data itself. When explicitly tagging the ink annotations may be erased when the image file is persisted.

An embodiment may provide the user with an option for selection of the implicit tagging mode or explicit tagging mode with ink annotations. In one embodiment an annotation may have an associated gesture such as a checkmark indicating explicit tagging for the associated annotation. As such with explicit tagging the annotation is not persisted as digital ink with the image file. However the keywords as generated using handwriting recognition processing on the annotations are persisted with the image file. If no gesture is specified a default implicit tagging mode may be presumed. When the implicit tagging mode is enabled such as a default mode of operation a user may derive the benefits of tagging without first having knowledge about tagging functionality as described herein. An embodiment may also utilize a gesture to enable disable the processing described herein to automatically recognize and form keywords from ink annotations. For example a gesture may be used to indicate that subsequently entered digital ink is used in automatically forming keywords using the techniques herein. Prior to entering the gesture the automated processing to form the keywords from ink annotations is not performed.

As illustrated in an embodiment may store the tags as part of the image file. The tags may be included as metadata included in the image file. In another embodiment tags associated with the image file may not be included as part of the image file. For example the tags may be stored in another file database and the like other than the image file. In the embodiment in which the tags are not stored as part of the image file the tags may be stored at location other than on the device . For example the tags may be stored in a database on the server .

In one embodiment all the components of may be included on the device . In another embodiment one or more of the components of may alternatively be located on the server . For example the image application may be included on the device and the other components of may be located on the server . The image application may be a browser plugin utilizing server side components to obtain the recognition results used as keywords which are then displayed to a user on the device . The keywords may be included in an image file stored on the server . Alternatively the keywords may be persisted in a location other than as part of the image file such as a database which is located on the server .

Referring now to shown is a flowchart of processing steps that may be performed in an embodiment using the techniques herein. The steps of summarize processing described above. In step an image file may be loaded for use with an application that performs digital ink annotation processing. At step one or more digital ink strokes are collected. Step may be performed via user interaction with a digital pen or stylus on a digitized input surface such as of a tablet computer or touchscreen. In one embodiment after each stroke of digital ink the InkAnalyzer API may be invoked which in turn invokes a parser to parse the ink stokes. The parser processing may include determining which digital ink strokes form gestures ink text and the like. Those ink strokes which are determined by the parser as forming words of one or more letters may be the ink text sent to the recognition engine. The parser forms one or more lines of the ink text and sends the one or more lines of ink text to the recognition engine for recognition processing in step . The recognition processing results are generated by the recognition engine in step in the form of a string. The recognition engine forms a string of alphanumeric characters from the ink text having a digital ink representation. In step the one or more words in the string may be added as keywords associated with the image file loaded in step . In one embodiment all the words in the string may be added as keywords. An embodiment may also populate a user interface with all the words in the string from which a user may selectively remove those words which are not to be persisted as keywords. An embodiment may also include an automated filtering mechanism in which particular words such as articles e.g. a an the are automatically removed from the string and not stored as keywords. The embodiment may allow a user to specify which words or characters are filtered from the string when forming the keywords. In one embodiment the keywords may be stored as a type of tag and included as part of the image file for example as metadata where the particular format of the image file type accommodates metadata. The particular location within the image file at which the keywords are stored may vary with the image file type organization structure and the like. In one embodiment APIs may be defined for use with the different supported image file types to store the keywords as part of the image file.

The keywords may be added as tags used to facilitate subsequent operations such as for example retrieving searching and or sorting one or more image files. The keywords may be indexed for example for use in connection with performing subsequent data operations such as data retrieval using a search engine.

In addition to the foregoing in the flowchart if implicit tagging is used the ink annotations may also be persisted to the image file. In one embodiment APIs may be included in the operating system or development environment for storing the ink annotations to the image file.

Referring now to shown is an example of an image file that may be displayed with ink annotations thereon. The original image may be loaded from an image file. Subsequently the two annotations and may be entered by a user. Using the techniques herein processing may be performed to parse the ink stokes of the ink annotations as entered by the user and generate one or more lines of ink text upon which handwriting recognition processing is performed. The result of the handwriting recognition processing may be the recognition of one or more words in the form of a string. Using the techniques herein the one or more words may be stored as a type of tag a keyword tag associated with the image file for the displayed image. The steps of performing handwriting recognition and obtaining a text string of the ink annotations used for keywords may be performed automatically as the ink annotations are entered by a user on the image display. Furthermore the persisting or storing the keywords to the image file or other storage location may be automatically performed as the ink annotations are entered by a user on the image display. An embodiment such as one with implicit tagging enabled may also automatically perform handwriting recognition and other processing steps to obtain and persist keywords in response to saving the image file rather than as they are entered by a user.

The example illustrates two different ways in which the keywords may be persisted in an embodiment. An embodiment may store the keywords as part of the metadata included in an image file . Alternatively an embodiment may store the keywords alone or in conjunction with other types of tags in a database file or other data container separate from an image file .

In connection with the image displayed in an embodiment may allow annotations to be made in any arbitrary location over the displayed image. For example an embodiment may allow a user to make annotations used in connection with techniques herein in any portion of a display area rather than in one or more designated portions of the display area.

Referring now to shown is an example of a user interface that may be included in an embodiment performing the techniques herein. The example may include field which is populated with the keywords as identified in the string generated from handwriting recognition processing. The example may include other properties associated with the image file currently being processed by the image application . In the example the keyword tags are automatically set to the keywords of as recognized using the ink annotations illustrated in . In an embodiment performing automated handwriting recognition and conversion to a text string as the ink annotation are entered the user interface may be automatically populated with keywords as corresponding ink annotations are entered interactively and processed using the techniques herein.

The example may also include other types of tags in associated with an image file. The particular types of tags may vary with each image file type and embodiment. As illustrated in an image file may have tags designating a title subject user comments and keyword tags.

Once the interface in the example is populated based on the ink annotations a user may selectively edit the information included in the user interface. Such editing functions may allow a user to correct spelling or other errors resulting from incorrect recognition processing selectively remove one or more recognized words as displayed and the like.

Also illustrated in the example is one representation of how the keywords and other tags may be persisted in an embodiment which stores the keywords and other tags in the metadata of the image file .

In connection with the techniques herein an embodiment may define one or more APIs allowing developers of applications such as image application of to utilize the functionality described herein for automatic keyword tagging using the handwriting recognition results from ink annotations. An embodiment operating in the implicit tagging mode as described above may define a boolean flag indicating a property of an image file. When the boolean is set e.g. 1 or true the keywords for the ink annotations may persisted along with the ink annotations with the image file. If the boolean flag is off e.g. 0 or false then the keywords are not persisted along with any ink annotations. It will be appreciated by those skilled in the art that any one of a variety of different APIs may be defined to facilitate use of the techniques herein by developers and the foregoing example should not be construed as a limitation.

The foregoing describes techniques that provide for automatic generation of keywords for an image from handwriting recognition results from ink annotations associated with the image. The keywords may be associated with an image and used as image tags in connection with subsequent data operations such as for example data search and retrieval operations on one or more tagged image files. For example the keywords may be indexed and used in connection with performing query operations with a search engine where the search results correspond to one or more image files having associated keywords matching specified searching criteria.

The techniques herein may be used with image files of any one or more different image file types and the image application may perform any one or more different operations. For example as described herein the image files may be digital photographs. A photo editor application may be used to load and annotate the image files containing the photos. The techniques herein may be used to automatically associate keywords with the photos. The keywords may be persisted as tags included within the image file. At a later time the keywords may be used to facilitate sorting and locating particular photos in accordance with the keywords automatically generated using the techniques herein. The generation of the keywords or other tags may be performed automatically as the user makes ink annotations for a displayed image.

Besides being used in connection with automatically generating keywords the techniques herein may be used in connection with automatically generating other types of image tags as will be described in more detail below.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

