---

title: Application-controlled network packet classification
abstract: Embodiments of the present invention provide a system, method, and computer program product that enables applications transferring data packets over a network to a multi-processing system to choose how the data packets are going to be processed by, e.g., allowing the applications to pre-assign connections to a particular network thread and migrate a connection from one network thread to another network thread without putting the connection into an inconsistent state.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08838817&OS=08838817&RS=08838817
owner: NetApp, Inc.
number: 08838817
owner_city: Sunnyvale
owner_country: US
publication_date: 20071107
---
This application is related to U.S. patent application Ser. No. 11 869 365 entitled MULTI THREADED INTERNET SMALL COMPUTER SYSTEM INTERFACE ISCSI SOCKET LAYER by Carlisle Trimble filed Oct. 9 2007 the disclosure of which is incorporated by referenced herein.

The present invention relates to transmission of data packets across a network and more particularly to parallelizing processing of data packets.

Applications on network devices such as computer systems connected over a network can create connections among each other over which they can exchange streams of data in the form of data packets. A data packet is a unit of information transmitted as a discrete entity between devices over the network. To achieve high speed and high performance of data packet processing it is common to parallelize the processing so that network devices can execute more than one thread e.g. a separate stream of packet execution that takes place simultaneously with and independently from other processing simultaneously on a multi processing platform. Multi processing is useful when a single task takes a long time to complete and processing packets serially e.g. one at a time would slow down the overall packet throughput. In a multiprocessing system packets can be queued to network contexts e.g. data structures that queue data packets that belong to the same network connection for further processing based on some kind of algorithm. As a result data packets that belong to a single connection such as for example a Transmission Control Protocol TCP connection are queued to a single network context and thus are processed by a single network thread. Data packets that belong to different network connections may be processed by different network threads.

Conventionally after connection is established between two network devices data packets for a particular connection are received by network drivers at a destination network device. The network drivers execute driver threads to queue the received data packets and call a packet classifier. The packet classifier in turn is responsible for maintaining a pool of network threads and their associated network contexts. The packet classifier receives a data packet calculates a hash based on a 3 tuple source IP address source port and destination port indicated in the packet and uses the calculated value to identify a network context to which the data packets arriving on the connection has to be queued. The following hash function can be used 

wherein x is a combination of a source IP address source port and destination port indicated in the packet y represents a hash number which then becomes an input to another function which maps the hash to a network context number y1 as follows 

A network thread picks up the packet and performs TCP processing. A TCP module of the destination network device receives the data packet and the network context and determines TCP connection to which the data packet belongs. It does so by calculating a hash value based on a 3 tuple using the same hash function that the packet classifier was using . The TCP module uses the hash to index into a TCP hash table such as TCP table shown in to obtain a protocol control block PCB corresponding to the connection each PCB stores information related to one TCP connection such as establishing a connection managing data transmission via data packets managing data receipt and termination of the connection . A TCP table represents an array with each index in the array being a linked list of PCBs. An index is also referred to herein as a hash bucket. 

Thus conventionally the packet classifier and the TCP module share the same hash function to perform its processing. The rational for doing this is as follows. Since in multiprocessing systems all network threads access the TCP hash table at the same time the TCP hash table has to be protected from access conflicts. The TCP hash table can be protected by ensuring that no two threads access the same data structure at the same time. This can be done by locking the data structure or by ensuring that no two threads can access the same PCB at the same time. Locking however is a very cumbersome mechanism to implement. Thus one feasible alternative to locking is to ensure that a particular hash index y is accessed only by a particular network thread. This can be done by segmenting a single TCP hash table into different network context queues by using a single hash function y hash x as described above as follows 

where x is a logical summation of a destination port source port and source address of a particular TCP connection y is the hash index to the TCP hash table y1 is an identifier of a network context queue for a particular network thread. Since y is always the same for a given x a particular TCP connection always gets mapped to the same network context queue y1.

Since a hash index y is uniquely mapped to a network context y1 all the connections in hash bucket y are assigned to a network context y1. As a result a network thread processing connections in a different network context will not be able to access data related to connections queued to a network context y1. This ensured that no locks are needed to access TCP hash table in a multiprocessing system.

However using the same hash function by the TCP module and by the packet classifier limits the ability of applications to decide how they want their data packets to be processed. Since in prior art implementations the load balancing of connections was achieved by using the default hash algorithm for all TCP connections in general and did not differentiate between TCP connections of one application and another application connections of a particular application were not load balanced. Furthermore an application may want data packets that belong to the same session but to different connections to be processed by the same network thread. Currently applications do not have this capability and data packets that belong to the same session but to different connections might be processed by different network threads and then reassembled after processing is completed. This in turn slows down performance of the multiprocessing device.

Accordingly what is needed is a mechanism that provides flexibility to applications to distribute connections in a multiprocessing system.

Embodiments of the present invention provide a system method and computer program product that enables applications transferring data packets over a network to a multi processing system to choose how the data packets are going to be processed by e.g. allowing the applications to pre assign processing of data packets to a particular network thread and to move the processing of the data packets to another network thread. This can advantageously increase throughput of the multi processing system. Furthermore rather than having multiple network threads accessing a single TCP data structure a hash table each network thread is associated with its own TCP table that stores information about connections assigned to the network thread for processing. Since each thread can only access its own TCP data structure the TCP module can process network threads using an algorithm different from the one used by a packet classifier to distribute connections to different network contexts. By having each network thread associated with its own TCP data structure the present invention eliminates the need to segment the TCP data structure or to lock the data structure to prevent multiple threads from accessing the same data structure.

Since the packet classifier herein referred to as a classification module of a multiprocessing system and network threads are no longer required to share the same hash function according to an embodiment of the present invention the packet classifier can use various hash algorithms rather than a default algorithm to distribute connections to different network contexts. Using custom hash functions enables applications to flexibly distribute connections over different network contexts and thus their associated network threads . As a result connections that belong to a single application are better load balanced in a multiprocessing system.

According to another embodiment of the present invention a mechanism is provided that enables applications to pre assign connections to a particular network context and thus to its associated network thread so that data packets that belong to the same session yet to different connections are processed by the same network thread.

Furthermore the present invention provides capability to migrate connections and data packets that arrive on the connections . As used herein migrating a connection means terminating assignment of a connection to a particular network context and assigning the connection to a different network context. Creating TCP tables for each network context and thus for each network thread makes migration of connections a lot easier since a PCB corresponding to a connection that is being migrated can be easily moved from a TCP table that stores information about that connection to another TCP table that stores connections for a network context where the connection is migrated. Importantly embodiments of the present invention block processing of all data packets on the connection until the migration is completed.

Those of skill in the art would understand that although the present invention is described in the context of TCP other protocols such as User Datagram Protocol UDP and Hypertext Transfer Protocol HTTP can be used for transmitting data over a network.

Other aspects of the invention will become apparent from the following detailed description taken in conjunction with the accompanying drawings which illustrate the principles of the invention by way of example.

To improve reliability and facilitate disaster recovery in the event of a failure of a storage system its associated devices or some portion of the storage infrastructure source storage system and destination storage system may execute a replication application shown in configured to replicate some or all of the underlying data and or the file system that organizes the data. Such an application that establishes and maintains minor relationship between a source storage system and a destination system and provides infinite updates to the destination storage system can be SnapMirror a product provided by Network Appliance Inc. Sunnyvale Calif. Currently when a component of a replication application executed at the source storage system establishes a connection with a component of a replication application at the destination storage system to transfer data packets over the network the replication application at the destination storage system has no control how data packets are going to be processed. Thus packets that belong to the same session but to different connections might be processed by different network threads. Instead these packets are being reassembled after being processed by different network threads. This in turn slows down the performance of the computer systems that processes the received packets.

According to an embodiment of the present invention a mechanism is provided that enables applications to choose a network thread for processing data packets received on a particular connection. More specifically as will be described in more detail herein applications can pre assign its connections to particular network contexts so that data packets that belong to the same session yet to different connections are processed by the same network thread. A network context data structure includes work items to be processed. A work item includes description of work that needs to be done by a thread. A work item generally includes data packets that have to be processed and a function pointer that needs to be executed with the packets.

Furthermore the present invention provides capability to migrate connections and data packets that arrive on the connections to another network context. Moreover the present invention enables applications to use more than one function such as a hash function rather than one default hash function to distribute data packets among various network threads. This increases throughput of a multiprocessing network device.

Still referring to she source and destination storage systems each comprise a plurality of processors a memory a network adapter and a storage adapter interconnected by a system bus . Each storage system also includes a storage operating system shown in more detail in that implements for example a file system to logically organize the information as a hierarchical structure of directories and files on devices.

It will be understood by those skilled in the art that the inventive techniques described herein may apply to any type of special purpose computer or general purpose computer including a standalone computer embodied as a storage system. Moreover the teachings of this invention can be adapted to a variety of storage system architectures including but not limited to a network attached storage environment a storage area network and disk assembly directly attached to a client host computer. The term storage system should therefore be taken broadly to include such arrangements.

In the illustrative embodiment the memory comprises storage locations that are addressable by the processors and adapters for storing software program code. The memory can be a random access memory RAM . The processor and adapters may in turn comprise processing elements and or logic circuitry configured to execute the software code and manipulate the data structures stored in memory. The operating system shown in more detail in portions of which are typically resident in memory functionally organizes the storage system by inter alia invoking storage operations in support of a file service implemented by the storage system. It will be apparent to those skilled in the art that other processing and memory means including various computer readable media may be used for storing and executing program instructions pertaining to the inventive technique described herein.

The network adapter comprises the mechanical electrical and signaling circuitry needed to connect each storage system to the network which may comprise a point to point connection or a shared medium such as a local area network.

The storage adapter cooperates with the operating system executing on the storage system to access information requested by the client such as client . The information may be stored on the devices that are attached via the storage adapter to each storage system or other node of a storage system as defined herein.

In one exemplary implementation each storage system can include a nonvolatile random access memory NVRAM that provides fault tolerant backup of data enabling the integrity of storage system transactions to survive a service interruption based upon a power failure or other fault. The size of the NVRAM depends in part upon its implementation and function in the storage system. It is typically sized sufficiently to log a certain time based chunk of transactions.

Referring now to it illustrates client in communication with storage device such as destination storage system over network . Although one client is shown in those skilled in the art would understand that any number of clients can communicate with storage system over network . The client transmits requests for data to the destination storage system and receives responses to the requests over network . Data is transferred between the client and the storage system using data packets . If the client executes the Windows operating system not shown in data packets can be transmitted using the Common Internet File System CIFS protocol over TCP IP. On the other hand if client runs the UNIX operating system it may communicate with the storage system using either the Network File System NFS protocol over TCP IP or the Direct Access File System DAFS protocol over a virtual interface VI transport in accordance with a remote DMA RDMA protocol over TCP IP. It will be apparent to those skilled in the art that client systems running other types of operating systems may also communicate with the storage system using other file access protocols.

As shown in client includes an application layer which can include software such as CIFS client software NFS client software DAFS client software or any other application resident in memory and executed by processor on a client . Client further includes a protocol stack which may include TCP IP protocol stack Internet Protocol layer and its supporting transport mechanisms the Transport Control Protocol layer and the User Datagram Protocol layer .

Similarly destination storage system includes an application layer which may include a file system protocol server software e.g. CIFS server NFS server DAFS server etc . Destination storage system further includes among other layers a protocol stack which includes an Internet Protocol layer and its supporting transport mechanisms the Transport Control Protocol layer and the User Datagram Protocol layer.

An exemplary data packet transmitted between client and storage system as well as between storage systems and is shown in . Data packet includes various fields such as IP header TCP header application header and payload .

IP header in turn includes fields for storing a source IP address also referred to herein as a foreign IP address and a destination IP address also referred to herein as a local IP address .

TCP header includes fields for storing a source port also referred to herein as a foreign port and a destination port also referred to herein as a local port .

Application header includes control data provided by an application when processing a data packet. If the client executes CIFS client software the application header stores control information related to CIFS. Similarly in the case of NFS software the header stores control information related to NFS. If the application is a replication application executed at the source storage system such as SnapMirror and destination storage system and respectively than the application header includes control information inserted by the replication application. Payload includes actual data to be stored at the destination storage system .

Still referring to the storage operating system comprises a series of layers or modules organized to form an integrated network protocol stack which was referred to in as protocol stack or more generally a multi protocol engine that provides data paths for clients or other storage systems to access information stored on the storage system or using block and file access protocols. The protocol stack includes a media access layer comprising network drivers e.g. gigabit Ethernet drivers that interfaces to network protocol layer such as the IP module and its supporting transport mechanisms e.g. the TCP module as well as a socket interface such as Berkeley Software Distribution BSD interface. The media access layer further includes a classifier module . The classifier module is responsible for maintaining a pool of network threads and their associated queues referred to herein as network context . A network thread is a process that executes network functionality.

Application layer may include the CIFS server NFS server the Hypertext Transfer Protocol HTTP server SnapMirror application as well as other applications.

As briefly described in the background section first a network storage device such as client or source storage system sends a request to establish connection with a destination network device such as destination storage device . For example a request may include a source IP address a source port and a destination port.

TCP module at destination storage device is responsible for establishing a connection with the source network device. TCP module determines whether information related to this connection already exists. To this end TCP module uses a TCP table one such table is shown in . TCP table also referred to herein as a hash table is a data structure that stores information used by TCP module to process data packets. TCP table is established upon initialization of storage system and can be maintained in memory . As shown in TCP table is an array of hash indexes or hash buckets associated with a linked list of PCBs. A PCB stores information related to one network connection. This information may include data related to 

a establishing a connection such as sending a connection request from an initiating device to a destination device receiving an acknowledgement from the destination device and sending an acknowledgement signal to the destination device 

To determine whether information related to a new connection already exists TCP module indexes into a hash bucket using for example a value calculated as a hash of a source IP address a source port and a destination port of the incoming data packet. TCP module compares a 3 tuple in the incoming packet with information in PCBs. If there is a match e.g. the PCB block for the requested connection already exists TCP module uses the information stored in the PCB to manage data transmission for the connection. Otherwise TCP module creates a new PCB and attaches it to a linked list of PCBs in the TCP table. TCP module populates a new PCB block with the information regarding the initiated connection such as information related to a establishing a connection b managing data transmission c managing data receipt and d termination of connection.

After the connection has been established data packets for the particular connection are received by the network drivers . The network drivers execute driver threads to queue the received data packets and call the classifier module .

The classifier module receives a data packet calculates a hash based on a 3 tuple source IP address source port and destination port indicated in the packet and uses the calculated value to identify a network context to which queue the data packets arriving on the connection. The following hash function can be used 

wherein x is a source IP address of the incoming data packet source port and destination port also referred to herein as a 3 tuple y represents a hash number which then becomes an input to another function which maps the hash to a network context number y1 as follows y1 map hash q y .

A network thread picks up the packet and performs TCP and IP processing. The TCP module receives the data packet and the network context and determines TCP connection to which the data packet belongs. As was described in the background section TCP module does so by calculating a hash value based on a 3 tuple using the same hash function that the classifier module was using . TCP module uses the calculated hash value to index into the TCP hash tables such as table shown in to obtain PCB corresponding to the connection. Thus as described herein conventionally the classifier module and the TCP module shared the same hash function to perform processing.

Although sharing the same hash function by the TCP module and the classifier module avoids locking data structures that stores TCP connections such a mechanism limits ability of the applications to flexibly distribute connections.

According to an embodiment of the present invention rather than having one TCP table that is accessed by all network threads each network thread is associated with its own TCP table that stores TCP connections queued to that thread. As a result no other thread can access that table. Referring now to each table is associated with its own network thread so that the network thread accesses its own TCP data structure during execution. Each table includes hash buckets corresponding to a linked list of portable control blocks PCBs . Each PCB stores information related to a network connection.

Since each network thread accesses its own TCP table rather than accessing one table shared by all network threads the present invention eliminates the need to segment the TCP table or to lock the table to prevent multiple threads from accessing the same data structure. As a result the network thread can use any algorithm i.e. a hash function that can be distinctly different from the classifier s hashing algorithm to look up a TCP connection.

Since TCP module and classifier module no longer need to share the same hash function according to one embodiment the classifier module can use different hash functions provided by the application rather than a default one to distribute connections among various network contexts. When classifier module picks up a data packet from network drivers the classifier module calculates a hash index of y using a 3 tuple and maps y to y1 to identify a network context on which to send the data packet as follows 

As indicated in this example classifier module can use different hash functions to distribute data packets that belong to an application e.g. CIFS NFS etc . Since different hash functions are used y is different for a given x . As a result TCP connections for one application are mapped to a different network thread y1 so that they can be distributed over different network contexts and thus their associated network threads . As a result according to this novel implementation TCP connections of a particular application are better load balanced in a multiprocessing system. This novel mechanism can be contrasted with prior art implementations in which load balancing was achieved by using the default hash algorithm for all TCP connections in general and did not differentiate between TCP connections of one application and another application. As a result connections of a particular application were not load balanced.

Referring now to it shows network drivers executing driver threads network contexts and each belonging to its corresponding network thread and and classifier module . A network thread works on multiple connections that are associated to each other in a network context. The network thread that is processing connections queued to a particular network context picks up the packet and initiates the processing. Packets queued to network context are processed by network thread packets queued to network context are processed by network thread and packets queued into network context are processed by network thread

According to another embodiment of the present invention applications can pre assign connections to a particular network context so that data packets arriving on those connections will be queued to a pre assigned network context. Furthermore applications can migrate connections to another network context after the connection has been queued to a network context and to send data over the connection at any point in the lifetime of the connections. An interface for preassigning connections to a network context as well as an interface for migrating of connections to another different context are provided.

Referring now to it shows communications between the source network device such as a client or a source storage system and a destination network device such as destination storage system to pre assign network connections to a network context as well as to migrate existing connections to other network contexts.

Initially at step an application such as CIFS NFS SnapMirror etc at the source network device creates a socket e.g. a combination of an IP address and a port used as an endpoint for sending and receiving data between network devices . This involves providing an identifier that the application uses to uniquely identify an endpoint of communication.

At step the application binds to a source port and listens on that port. For example in the case of a data replication application such as for example SnapMirror provided by Network Appliance Inc. of Sunnyvale Calif. the replication application executed at the source network device binds to a source port 32000. In this example the application asks TCP module to provide a port number. The TCP module will then assign a port number. The application wants to establish connection with a particular destination port. According to an embodiment of the present invention prior to establishing connection with a destination port the application may pre assign the connection step to a particular network context to which data packets arriving on that connection will be queued. To this end the network protocol layer provides an application programming interface API to classifier module at the source network device indicating to which network context the connection should be assigned. Also the PCB block that stores information about the connection is added to a TCP table corresponding to the network context to which the application chooses to pre assign its connection. As shown in each network context has a corresponding TCP table such as table storing TCP connections for that network context. Information about a TCP connection is stored in a PCB block.

Referring now to it illustrates more detailed steps performed by an application to pre assign a connection to a particular network context. At step an application may provide the following parameters foreign source address foreign source port and local destination port that it will use to create the connection. The application also provides in the API whether the packet classification at the source network device will be done on the basis of the destination port or the source port step . According to an embodiment of the present invention classification module at the source network device creates the following data structures source port map and destination port map. Those skilled in the art would understand that any data structure can be used for storing source and destination ports and the invention is not limited to using the map. An exemplary source port map is shown in . Data structure includes a plurality of hash buckets linked to a hash list of portable control blocks PCB . Each PCB stores information about a particular connection. A lookup of the source port map is performed based on the source port indicated in the packet. Destination port map not shown in also includes a plurality of hash buckets linked to a hash list of PCBs. A lookup of the destination port map is performed based on the destination port indicated in the packet.

If the classification queuing data packets arriving on the connection to a network context will be done based on the destination port the destination port map data structure is updated with the 3 tuple for the connection source port source address and destination port step . If the classification will be done based on the source port source port map data structure is updated with the 3 tuple step . These data structures are used later by classifier module at the source network device to queue data packets arriving on the connection to the pre assigned network context. Thus embodiments of the present invention enable applications to pre assign connections to a particular network context at the source network device. To this end an application uses an API to instruct the classifier module to assign the connection to a particular network context prior to sending a data packet on a connection to a destination network device. This gives applications flexibility to distribute connections in a multiprocessing system. As a result connections that belong to the same application are better distributed in the multiprocessing system.

Referring again to at step the application such as NFS client CIFS client or a replication application at the source network device connects to the application such as NFS server CIFS server replication application at the destination network device. For example in the case of a replication application 

The application sends to the destination network device control data in the form of a data packet which includes information about the connection and the session.

Prior to receiving a new connection from the source network device the application at destination network device creates a socket step binds to a port listens on the port and accepts connections on the port step .

Network drivers receive from the source network device the data packet steps which includes application control data. The classifier module chooses a network context to distribute the connection. In one implementation the classifier module may use a default hash algorithm to choose a network context. To this end in one implementation it computes a hash function based on a source address source port and destination port as follows 

According to another embodiment of the present invention classifier module may use a custom hash algorithm to calculate a network context as follows 

At some point an application may decide that it wants to move its connection to a different network context. For example the application decides that connections that belong to the same session should be queued to the same network context and thus processed by the same network thread. Conventionally when one thread is processing data packets that belong to one connection it is complex to process the data packets by another network thread. Moving the connection to another network thread may put the connection in an inconsistent state. That is data structures and the values they contain will be inconsistent or corrupted. For example each TCP connection maintains multiple timers that are used to send delayed acknowledgements and data retransmissions. In prior art implementations all TCP timers are processed by a single thread called the TCP timer thread or TCP callout thread. Migrating a connection in prior art implementations would require halting execution of the TCP timer thread. This in turn would halt execution of timer threads for all the connections. According to embodiments of the present invention a connection s state data structures and values that they contain are moved from one network thread to another network thread without putting the connection in an inconsistent state. This is accomplished by blocking all processing of data packets on the connection to be migrated until the migration is complete.

Still referring to an application calls an API to classifier module to switch to a different network context step e.g. to migrate a connection . When the application decides that it wants to move the connection to a different network context the connection s assignment to its current network context is terminated and it has to be re assigned to a different network context as described herein. illustrates steps performed by classifier module to migrate a connection from one network context to another network context.

Referring now to to migrate the connection a link to a PCB for the connection in migration is removed in a TCP table corresponding to the network context from which the connection is removed step . As described herein each network context is associated with its own TCP table . Each table is associated with one network context and is accessed by a particular network thread. Each table includes a plurality of hash buckets connected to a linked list of PCBs. Another data structure referred to herein as a floating network context queue is a temporary queue for storing data packets arriving on a connection to be migrated the floating data structure is not shown in . Since each network thread and its associated network context has its own TCP table embodiments of the present invention make migration of connections easier by simply removing a link to a PCB block for the connection in migration in a PCT table corresponding to the network context from which the connection is migrated. The floating network context queue is updated with the PCB block corresponding to the connection in migration step . At step the work item for the connection in migration is sent to the network context to which the connection is migrating thereby queuing the work item to the new network context. As previously described a work item includes description of work that needs to be done by a thread. A work item generally includes data packets that have to be processed and a function pointer that needs to be executed with the packets.

At step a data structure such as a destination port map is created at the destination network device and updated with a 3 tuple source address source port and destination port. In addition the network context is also provided by the application and is stored in the PCB. Thus a PCB that corresponds to the connection stores among other parameters a source address source port destination port and the network context to which the connection is migrated. At step a flag is set in PCB for the migrating connection to indicate that the connection is in migration.

At step the network thread wakes up picks the work item from the network context to which the connection was initially queued. The network thread calls a function such as migrate connection to migrate the connection.

The function picks up the PCB from the network context to which the connection was originally queued and adds the PCB to the TCP table corresponding to the network context to which the connection is migrated step . Then the PCB for the migrated connection is connected to the timers corresponding to the network context to which the connection is migrated step .

When a packet arrives on the connection in migration and the flag indicates that the connection is still in migration the classifier module puts the packet to the floating network context queue step . The flag is then updated to indicate that the connection is migrated step .

Thus creating TCP tables for each network context and for each network thread makes migration of connections easier as compared to prior art implementations . When one TCP table was shared by all network threads migration of connections was not feasible for the following reasons. When one TCP table was accessed by all network threads one hash bucket hash index was accessed only by one network thread. Since each TCP connection has one unique 3 tuple which always computes to a unique hash value when the hash function operates on it moving PCBs from one hash index to another hash index was not feasible.

Furthermore in prior art implementations all TCP timers are processed by a single thread called the TCP timer thread or TCP callout thread. To migrate a connection in prior art would require halting execution of the TCP timer thread. According to an embodiment of the present invention TCP timers are spread across different network threads and processed by the same thread that does other TCP processing. That is the network thread that does the packet processing of one TCP connection also does the timer processing of that connection. As a result when a network thread that owns that connection migrates the connection to another network thread it makes a lot easier to remove a PCB for that connection as well as the TCP timers place the PCB and the TCP timers in the floating network context queue and then put the PCB and the TCP timers for the connection to a TCP table of another thread where the connection is migrated. This novel mechanism provides for migration of the connections any number of times in a lifetime of a connection.

After the connection is migrated to another network context when a classifier module receives data packets that arrive on the migrated connection it queues the data packets to the network context using a look up algorithm which is described in greater details in reference to .

Referring now to at step when a data packet is received classifier module checks a destination port in the data packet. Classifier module determines whether the destination port has a hash function associated with it step . If so that hash function is used to queue the incoming data packet to a network context step as follows 

If the destination port does not have a default function associated with it classifier module looks up the destination port map to find the destination port in the map step . If the destination port is found classifier module obtains a network context from an entry corresponding to the destination port in the destination port map data structure step as was described herein at some point during the process of migrating of the connection destination port map is created at the destination network device and updated with a 3 tuple source address source port and destination port. In addition the network context is also provided by the application and is stored in the PCB. Thus a PCB that corresponds to the connection stores among other parameters a source address source port destination port and the network context to which the connection is migrated . Thus the destination port map stores the destination port and the network context to which the connection is migrated. Classifier module then queues the arrived data packet to that network context.

If the destination port is not found in a data structures such as destination port map classifier module reads a source port in the incoming data packet and performs a look up of the source port map step . If the source port is found in the data structure classifier module reads a network context corresponding to the source port in the data structure step .

If the source port is not found in a data structure such as the source port map classifier module uses its lookup functions to identify other hash functions corresponding to the source port step .

If no hash functions are found it might be indicative that the packet is not a TCP packet corresponding to an application that uses the network thread model. As a result the packet will be queued to a network thread such as for example the 0network thread that services all applications that do not support the network thread model.

TCP module then picks up the packet and the network context processes the packet and sends the packet off to the IP module . The IP module in turn validates the packet and sends it off to the TCP module . TCP module uses a function to call into application layer . Layer in turn allocates a data structure in memory for a data packet and populates the data structure with a protocol header such as NFS header CIFS header etc . If the data packet is a read request destination storage system looks up its memory for data. If the data is not in the memory the packet goes to the file system which in turn requests a storage device management module not shown in Figs. to satisfy the request. The application layer receives the data assembles a packet and inserts a protocol header.

TCP module receives the packet adds a TCP header and hands off the packet to IP module . IP module looks at the destination address in the data packet and sends the data packet to an appropriate network driver. The network driver transmits the packet over the network to the source network device such as a client or a source storage system .

Thus embodiments of the present invention advantageously enable applications to have control over assignment of network connections to a particular network context. An application may want to pre assign a connection to a network context. Furthermore an application can migrate the connection to another network context after the connection has been established and send data packets over that connection at any point during the lifetime of the connection. A particular connection can be migrated multiple times during the lifetime of the connection.

Furthermore rather than maintaining one TCP table accessed by all network threads each network thread is associated with its own TCP table that stores information about connections assigned to the network thread for processing. Since no other thread can access the TCP table associated with a particular network thread each network thread can use a hash function different from the one used by a classifier module to distribute connections to different network contexts. By having each network thread associated with its own TCP table the present invention eliminates the need to segment the TCP hash table or to lock the hash table to prevent multiple threads from accessing the same data structure. Moreover creating TCP tables for each network context and thus for each network thread makes migration of connections a lot easier since a PCB corresponding to a connection in migration can be easily moved from a TCP table that stores information about that connection to another TCP table that stores connections for a network context where the connection is migrated. Importantly embodiments of the present invention halt processing of all data packets on the connection until the migration is completed.

Although the present invention for purpose of explanation has been described with reference to specific exemplary embodiments it will be understood that the invention is not limited to the embodiments described. A person of ordinary skill in the art would understand that the present invention can be practiced with modifications and alternations to those embodiments or can be practiced in other embodiments within the spirit and scope of the appended claims. For example although various embodiments are described in the context of the TCP those skilled in the art would understand that any protocol for transmitting packets over a network can be employed such as UDP HTTP etc . Furthermore those of skill in the art would understand that although embodiments of the present invention were described in the context of using hash functions any other suitable method for turning data into another number can be used with the present invention.

Furthermore the use of the phrase one embodiment throughout does not necessarily mean the same embodiment. Although these particular embodiments of the invention have been described the invention should not be limited to these particular embodiments. Accordingly the specification and drawings are to be regarded in an illustrative sense rather than a restrictive sense.

Moreover the teachings of this invention can be adapted to a variety of storage system architectures including but not limited to a network attached storage environment a storage area network and disk assembly directly attached to a client or host computer. The term storage system should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or system.

Unless specifically stated otherwise it is to be appreciated that throughout the discussions utilizing terms such as processing or computing or calculating or determining or displaying or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical e.g. electronic quantities within the computer systems registers and memories into other data similarly represented as physical quantities within the computer system.

The present invention can be implemented by apparatuses for performing the operations herein. These apparatuses may be specially constructed for the required purposes or they may comprise a machine such as a general purpose computer selectively activated or reconfigured by a computer program such as a collection of instructions for execution by a machine or processor for example stored in the computer. Such a computer program may be stored in a computer readable storage medium such as but not limited to any type of disk including floppy disks optical disks magnetic optical disks read only memories random access memories EPROMS EEPROMS magnetic or optical cards or any type of media suitable for storing physical e.g. electronic constructions and each coupled to a computer system bus. Each of these media may be coupled to a computer system bus through use of an appropriate device for reading and or for writing the media.

