---

title: Image processing apparatus, image processing method and computer program
abstract: An image processing apparatus for extracting pictures-in-picture information contained in an image, includes an image segmentation unit segmenting an input image into regions, and a region extraction unit extracting a pictures-in-picture region containing the pictures-in-picture information on the basis of a contour of a segmented region.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07986831&OS=07986831&RS=07986831
owner: Sony Corporation
number: 07986831
owner_city: Tokyo
owner_country: JP
publication_date: 20070827
---
The present document contains subject matter related to Japanese Patent Application No. 2006 232582 filed in the Japanese Patent Office on Aug. 29 2006 the entire content of which being incorporated herein by reference.

The present invention relates to an image processing apparatus an image processing method and a computer program that process a digital image and particularly to an image processing apparatus an image processing method and a computer program that process images of objects contained in an image taken by a digital camera.

More specifically the present invention relates to an image processing apparatus an image processing method and a computer program that process pictures in picture information contained in a digital image and particularly to an image processing apparatus an image processing method and a computer program that extract from a digital image containing a plurality of pictures in picture information items each pictures in picture document by separation from a background image.

Recently digital cameras are extensively used which digitally encoded images taken by a solid state imager such as a CCD Charge Coupled Device or CMOS Complementary Metal Oxide Semiconductor sensor. When compared with cameras with a silver salt film or a photosensitized plate the digital cameras are advantageous in their capability of storing digitally encoded images into a memory so that the images be processed and managed by a computer along with their being free from an issue of film s life time.

The digital cameras are usually used to take images of scenery and persons but can also be used to digitize pictures in picture information. For example pictures in picture information such as documents including paper documents and business cards a blackboard and a whiteboard whereon information is written for a presentation or a conference or a screen image projected by a projector can be digitally inputted through a digital camera for making it available for various image processing including e.g. storage and management of information.

For example an imaging apparatus having a business card capturing function has been proposed see e.g. Japanese Patent Application Publication No. JP 2003 283909 . This imaging apparatus is configured to automatically zoom in on a business card to image the business card in almost the same size as the imaging angle of view.

Furthermore an electronic camera has been proposed which extracts textual information from an image signal obtained by imaging an object such as a business card or a signboard for conversion into a textual character string and stores the textual information by classification on the basis of a predetermined item recognized from the textual character string see e.g. Japanese Patent Application Publication No. JP 2005 275447 whereby business card data can be easily managed without initial investment or cumbersome labor.

Furthermore a digital image is split into foreground objects such as pictures in picture and a background and only a pictures in picture region is extracted for use as a single photo image. The inventor of the present application calls PicsInPic the technology for extracting or exporting another photo image contained in a photo image.

In the related art it has been typical practice to extract a contour of an image object such as a picture in picture on the basis of an edge image obtained by differential processing a source image to cut out the image object from a background image. For example an image processing apparatus has been proposed in which straight lines are detected from an edge image for imaging using Radon conversion and a quadrilateral forming a contour for an imaging object is formed from the detected straight line parameters for projective transformation to obtain an image which is formed as if the object for imaging were imaged from the front see e.g. Japanese Patent Application Publication No. JP 2005 275447 .

However for extraction of a contour using an edge image an absolute contrast must be found between a picture in picture and its background. If edge information is contained in the background and the picture in picture itself it becomes difficult to extract the contour accurately. For example it is difficult to extract a photo placed on a patterned carpet. It is also difficult to extract from a digital image containing a plurality of picture in picture each picture in picture image one by one.

Accordingly it is desirable to provide an image processing apparatus image processing method and computer program which can suitably process one or more object images contained in a digital image such as an image taken by a digital camera.

Furthermore it is also desirable to provide an image processing apparatus image processing method and computer program which can perform extraction processing on one or more picture in picture images contained in a digital image after separating them from a background image.

Furthermore it is also desirable to provide an image processing apparatus image processing method and computer program which can accurately extract various pictures in picture information such as photos business cards and or book covers contained in a digital image from a complicated background image.

The present invention has been made in view of the above circumstances. In one embodiment of the present invention there is provided an image processing apparatus for extracting pictures in picture information contained in an image which includes image segmenting means for segmenting an input image into regions and region extracting means for extracting a pictures in picture region containing the pictures in picture information on the basis of a contour of a segmented region.

The image processing apparatus may further include a quadrilateral detecting means for detecting a quadrilateral from the pictures in picture region extracted by the region extracting means and image converting means for subjecting the detected quadrilateral region to inverse projective transformation such that the region look like an image viewed from the front and adjusting an aspect ratio thereof.

By extracting a pictures in picture region from a photo image taken by a digital still camera the extracted image object and further textual information such as text contained in the image are recognized whereby various services can be provided.

However in the related art method in which the contour of a picture in picture is extracted using an edge image obtained by differential processing a source image for separation from a background image it is assumed that there is an absolute contrast between the picture in picture and the background. If edge information is contained in the background or the picture in picture itself it becomes difficult to extract the contour accurately. For example it is difficult to extract a photo placed on a patterned carpet. It is also difficult to extract from a digital image containing a plurality of pictures in picture individual pictures in picture one by one.

By contrast in the image processing apparatus according to the present embodiment the image segmenting means handles an input image in the form of an incidence graph. The incidence graph describes image information by treating an image component unit such as a pixel or a polygon formed from a cluster of pixels as a node and connecting adjacent nodes by an edge. Further a weight factor is given to the edge on the basis of a result of comparison between attribute values of each node connected by the edge and those edges in the incidence graph are sorted on the basis of their weights. Then a pair of the nodes with the edge in between is extracted in sorted order of the edges and whether or not the pair of nodes should be merged is evaluated on the basis of a statistical processing algorithm and performs a merge processing on the nodes. By repeating such merge processing the input image is segmented into a plurality of image regions.

In other words the image segmenting means judges whether or not the adjacent nodes should be merged on the basis of the statistical processing algorithm and by repeating merging of the nodes a node can be grown into a small discernible unit called a segment from raw data formed from a multitude nodes each of which is not discernible. In the statistical processing algorithm herein used it is judged whether adjacent nodes are similar i.e. adjacent nodes can be merged on the basis of a predicate derived from a phenomenon of concentration inequality in e.g. attribute information each node has.

Since the merge processing on the nodes based on the statistical processing algorithm mentioned above involves simple computation of e.g. statistically processing the attribute information of each node high speed processing can be implemented. For example some millions of polygons can be processed per second using general computing machines such as personal computers. Furthermore by adjusting a parameter value contained in the predicate a criterion for merging nodes can be set arbitrary to produce a segment having a desired coarseness and thus the system has scalability.

Therefore according to the present embodiment using the topology of a plurality of nodes forming raw data as an input value nodes are merged recursively i.e. mesh grown according to the statistical processing algorithm whereby a segment having an arbitrary coarseness can be produced. Furthermore by changing the parameter value of the predicate based on the statistical processing algorithm the input image can be segmented such that each of the segments has a coarseness optimized for extracting pictures in picture regions contained in a digital image or for separating a foreground region including pictures in picture from a background region excluding the foreground region.

It should be noted that if pictures in picture have complicated texture or if a background on which the pictures in picture are placed has texture each of the pictures in picture regions are also segmented to lose its single body or the background is also segmented to be undistinguished from the pictures in picture regions. Hence the image segmenting means may not operate satisfactorily.

In an embodiment of the present invention the image segmenting means may perform first image segmenting processing for exporting a foreground region including individual pictures in picture from a source image and second image segmenting processing for exporting a background region other than the pictures in picture from the source image in a two step manner whereby to improve image segmenting accuracy.

The image processing apparatus further includes a differential processing means for differential processing the input image. The incidence graph creating means assign only to a pixel which frequency band is less than a predetermined value in a differentiated image outputted from the differential processing means or which does not correspond to the contour of a pictures in picture region or of a texture region an edge for connection with another pixel to create a partial incidence graph. No adjacent pixels could be merged without an edge and thus the image segmentation proceeds with such adjacent pixels left separated.

Therefore the merge processing means can merge nodes on a border to merge the background into a single region. As a result the image processing apparatus can export the foreground image region including the pictures in picture and export the background image region on which the pictures in picture are placed to output each of the foreground and background images.

Furthermore after having performed the image segmentation processing by an image segmenting mean still another small region may be contained in a resultant segmented region. However a small region contained in another region is basically individual content contained in pictures in picture information and thus only a region defined by the outermost contour needs to be considered. Hence the region extracting means discards such a small region.

Furthermore in another embodiment of the present invention there is provided a computer program described in a computer readable form for execution on a computer of processing for extracting pictures in picture information contained in an image. The computer program causes the computer to execute 

a region extracting processing for extracting a pictures in picture region containing the pictures in picture information on the basis of a contour of a segmented region 

a quadrilateral detecting processing for detecting a quadrilateral from the pictures in picture region extracted in the region extracting procedure and

an image converting processing for subjecting the detected quadrilateral region to inverse projective transformation so that the region looks like an image viewed from the front and adjusting an aspect ratio thereof.

The computer program according to the present embodiment is obtained by defining a computer program described in a computer readable form such that predetermined processing is executed on a computer system. In other words when the computer program according to the present embodiment is installed in the computer system collaborative operations are performed on the computer system whereby advantages similar to those provided by the image processing apparatus according to the above described embodiment can be obtained.

According to the embodiments of the present invention an image processing apparatus image processing method and computer program can be provided which can perform extracting processing of one or more pictures in picture contained in a digital image from a background image.

Furthermore according to the embodiments of the present invention an image processing apparatus image processing method and computer program can be provided which can accurately extract various pictures in picture such as photos business cards and or book covers contained in a digital image from a complicated background image.

Further objects features and advantages of the present invention will become apparent from a more detailed description that is based on a later described embodiment of the present invention and accompanying drawings.

An embodiment of the present invention will be described below in details with reference to the accompanying drawings.

In the field of image processing it is typical practice to represent image data formed from nodes each being a pixel or a polygon mesh formed from a cluster of pixels in the form of an incidence graph or a region adjacent graph RAG that describes a connectivity relationship between adjacent nodes. The present embodiment is configured to describe a digital image in the form of an incidence graph formed from a plurality of nodes and edges for connecting nodes and image segment the original digital image through repeatedly merging the nodes connected by the corresponding edges to finally separate image regions of pictures in picture such as postcards business cards and or book covers contained in the digital image from the background image. For example if a source digital image is 8 MB image data containing four pictures in picture as shown in four image data items each having a size of about 1 MB can be extracted by separation from the background as shown in according to an embodiment of the present invention.

In an image processing method according to an embodiment of the present invention it is configured to recognize each pictures in picture contained in a digital image and then gradually define each of the pictures in picture as an image region to generate the picture using image data described in the form of an incidence graph. Furthermore quadrilaterals contained in a source digital image are subjected to projective transformation to be converted to appropriate rectangular regions. In order to extract individual pictures accurately from a patterned background image a system must be robust and capable of high speed processing.

When an embodiment of the present invention is applied to e.g. a digital camera the digital camera can image pictures in picture information such as documents including paper documents and business cards or information written on a blackboard or a whiteboard or on a screen projected by a projector in a presentation or in a meeting and then extract pictures in picture contained in the photo image taken. shows a configuration of a digital still camera according to an embodiment of the present invention.

A digital still camera shown in the figure includes an imaging device a preprocessing unit and a camera digital signal processing DSP unit .

The imaging device has pixels each having a photoelectric conversion effect such as a CCD or CMOS arranged two dimensionally and e.g. an RGB color coding single plate is disposed on the light receiving side. Signal charges equivalent to an amount of incident light passing through each of the corresponding color filters are stored in each pixel and from an amount of charges in each color signal read from the pixel the color of the incident light at the pixel position can be reproduced.

The CDS AGC ADC block performs correlated double sampling CDS to highly accurately suppress small noise in a pixel signal receives from the imaging device thereafter converts the resultant signal into digital signals and further performs AGC Automatic Gain Control for proper gain control.

The timing generator generates a timing pulse signal for driving the imaging device . The V driver outputs a drive signal for outputting charges stored in the respective pixels of the imaging device per each line at a time vertically according to this timing pulse signal.

The camera DSP unit has a camera signal processing section a resolution converting section an image codec processing section a memory control section a display control section and a media control section .

The camera signal processing section performs white balance gain control on an image signal supplied thereto from the preprocessing unit by AWB Auto White Balance to reproduce a proper color condition and further produces an RGB image signal by demosaic processing. Also the camera signal processing section performs correction on the RGB image signal and converts the image information into a tone suitable for output to a monitor printing or image recording.

The resolution converting section changes the image size. The image codec processing section performs color space conversion of the RGB image signal into a luminance signal and a color difference signal Y Cr Cb and also performs coding such as JPEG Joint Picture Experts Group compression.

The memory control section controls access operation for writing and reading data such as captured image information from a memory device such as an SDRAM Synchronous DRAM .

The display control section controls the driving of a monitor display such as an LCD Liquid Crystal Display and outputs the photo images held in e.g. the memory device for display.

The media control section has a slot for inserting a detachable recording medium such as a memory stick registered trademark and writes reads data to and from the recording medium . For example it records photo image files held in the memory device on the recording medium .

Furthermore the camera DSP unit is connected to a control unit with a bus interface unit BIU inbetween. The control unit includes an operation section through which a user instructs shutter button operation zooming and other camerawork a CPU that totally controls the operation of the entire apparatus in response to a user operation a RAM being a main storage memory for the CPU an EEPROM Electrically Erasable and Programmable ROM that holds program codes apparatus information and the like in a nonvolatile manner.

The image processing function shown in the figure may be designed as a dedicated hardware device but may also be realized as applications incorporated into the digital camera . Alternatively it may be realized in the form of starting an application program that executes processing corresponding to each of function modules on a typical computing system such as a personal computer PC that captures photo images from the digital camera. The typical computing system uses e.g. Pentium registered trademark IV 1.6 GHz by Intel Corporation of the United States as its processor and has a main memory such as a 1 GB RAM. Also the application programs can be coded in the C programming language by utilizing e.g. an API Application Programming Interface provided by an Open GL.

The image processing function shown in the figure has an image segmenting unit that performs segmenting processing on image regions using an incidence graph a region extracting unit that extracts regions from outer contours a quadrilateral finding unit that finds quadrilaterals forming pictures in picture from segmented images and an aspect ratio guessing unit that estimates the original aspect ratio of each quadrilateral and reassigns the quadrilaterals into a rectangular region in accordance with the guessed aspect ratio to output one or more pictures pictures in picture .

For example if this technology is incorporated into a digital camera in a normal imaging mode an actual image in which a plurality of business cards are scattered is displayed in a view finder as shown in . Meanwhile in a picsinpic pictures in picture display mode images obtained by reassigning the recognized individual business cards at a predetermined aspect ratio are neatly arranged.

Furthermore according to the image processing function shown in book covers can be processed as pictures in picture in addition to business cards. As shown in a region of a digital image in which books scattered across a carpet are imaged is segmented using an incidence graph to extract a region of each book through its outer contour as shown in . Furthermore as shown in the image of each extracted region is captured into networked information equipment such as a computer whereby the book cover image is character recognized to read its book title or character string information such as its ISBN International Standard Book Number for database search. Still furthermore on the basis of a result of the database search links with other service applications such as online shopping to purchase books discussion over blogS provision of other additional information and the like can be implemented.

Furthermore if from a result of a database search made on character string information contained in a quadrilateral extracted from a digital image in which various pictures in picture are scattered it is found out that the corresponding picture in picture is a jacket of a medium such as a CD or a DVD the extracted quadrilateral can be remapped into a rectangular region at the aspect ratio of the jacket as shown in .

Below the various units to forming the image processing function shown in will be described in great detail.

In the field of image processing it is typical to represent a polygon mesh as an image region in the form of an incidence graph or a regional adjacent graph RAG that describes a relationship among a plurality of polygons forming the polygon mesh. Several specific methods are available for describing an incidence graph. An incidence graph is formed from a plurality of nodes and edges each connecting between the corresponding nodes. What to use for a node and an edge depend on each case. For example if a polygon is used as a node a side or a vertex of the polygon can be an edge. If a side of a polygon is used as a node a vertex of the polygon or the polygon can be an edge. If a vertex of a polygon is used as a node a side of the polygon or the polygon can be an edge.

In the present embodiment an incidence graph is formed using a polygon as a node and a side of the polygon as an edge. Namely the image information editing section uses as its input data an incidence graph that is described by using polygons forming a polygon mesh as nodes and by connecting corresponding nodes through an edge being a side on which the adjacent polygons touches each other.

First polygons T Tbelonging to an image region for processing are associated with nodes N N. And between the nodes Nand N if there is only one side belonging to the polygons Tand Trespectively corresponding to both nodes the side is produced as an edge econnecting between both nodes.

An incidence graph can be directly built from index arrays of vertices and surfaces by sorting polygons according to their edge endpoints. Sides i.e. edges belonging to each polygon are classified into boundary edges demarcating a polygon mesh i.e. an image region and interior edges each not touching the polygon mesh but touching an adjacent polygon inside the polygon mesh. Since the boundary edge of image region belongs to only one polygon only the interior edges other than boundary are to be processed. Only the index arrays of vertices and surfaces suffice for this processing and thus complicated incidence data structure such as half edge and quad edge is not needed.

Furthermore shows an example of a somewhat complicated incidence graph. A polygon mesh shown on the left of the figure consists of seven triangles Tto T in which Ttouches T Ttouches T T and T Ttouches Tand T Ttouches Tand T Ttouches Tand T and Ttouches T T and T. An incidence graph describing this polygon mesh is formed as shown on the right of the figure by connecting between nodes respectively corresponding to the triangles through the sides i.e. edges belonging to adjacent triangles.

Note that a node is initially a pixel or a polygon being the smallest unit of a polygon mesh in a two dimensional image or that for a three dimensional image a voxel is a node. As merge processing on an image proceeds a node grows into an image region formed from a polygon mesh that includes a plurality of polygons or pixels or voxels . During the course of the image processing shown in node statistical information is held for each node N. The node statistical information includes identification information id N for uniquely identifying the node an area N of the associated image region initially a single polygon and a polygon count n N initial value set to 1 being the number of polygons forming the associated image region i.e. polygon mesh. The reason why the area and polygon count are held for each node is that they are information necessary for judging whether the node i.e. the associated image region is successfully merged or not using a predicate based on a statistical processing algorithm.

The incidence graph evaluating section evaluates each edge of the inputted incidence graph for sorting. Specifically edge evaluation involves comparing attribute values of each image region connected through an edge to give a weight to the edge on the basis of the comparison result and edges in the incidence graph are then sorted on the basis of their weight values. An image region herein used includes a polygon being the smallest unit and an image region configured as a polygon mesh obtained by merging a plurality of polygons.

Using the area an average value of the areas of all polygons merged into an image region of e.g. an image region as an attribute value a difference between the areas of image regions connected through each edge is given as a weight value for sorting in increasing order of the weights. In this case the smaller the difference between the areas of image regions is the smaller the weight value is and the higher the processing priority in the subsequent image merge processing will be.

In addition to the area of a polygon forming an image region the weight of an edge can also be given using a difference in any of various attribute values of an adjacent vertex including the direction of a normal line and pixel attribute information such as color an average color of at least one of RBG components provided that a polygon mesh has texture .

For example in an RGB color image having a width w and a height h let a node of a pixel in an i line and a j row be Vand its identification information be RegID V i w j. Each of pixels thereinside has four adjacent nodes and the total edge count m equals 2wh w h. And a weight between the node Vand a node V can be represented by e.g the following formula.

The image region mesh growing section extracts image region pairs sandwiching an edge in sorted order of the edges to perform mesh growing. Since edges are given a weight serving as an index of similarity between the image regions connected through edges performing mesh growing in increasing order of the weights amounts to executing mesh growing preferentially between similar image regions.

The image region mesh growing section judges whether each pair of image regions connected through an edge extracted in sorted order of the edges should be merged or not on the basis of the statistical processing algorithm. Specifically if the weight of an edge is calculated on the basis of the area information as shown in the above formula 1 when two image regions Rk and Rl connected through an edge satisfy a predicate based on the following statistical algorithm it is judged that the image regions Rk and Rl should be merged. In the following formula it is supposed that the image region Rk has an area Sk and is formed from nk polygons and that the image region Rl has an area Sl and is formed from nl polygons. It is also supposed that A is the largest one of polygon areas and that Q is a parameter for controlling segmenting coarseness.

The above predicate 3 represents a phenomenon occurring in the areas of polygons forming an image region. It is derived from a statistical concentration in equality. This phenomenon is common as a central limit theorem in the field of statistics even when a population exhibits an arbitrary distribution if the size of samples in the population is increased averages of the samples converge into a normal distribution. 

 Q on the right side of the above formula is a parameter for controlling segmenting coarseness. A larger Q decreases the value of the right side to make it difficult to satisfy the predicate whereby to suppress the merging of the image regions. Conversely a smaller Q increases the value on the right side to easily satisfy the predicate whereby to promote the merging of the image regions to obtain a coarser mesh segmentation result.

Alternatively if the weight of an edge is calculated on the basis of the RGB color information as shown in the above formula 2 when the adjacent nodes Vand V connected through the edge satisfy the following predicate based on the statistical algorithm it is judged that the nodes should be merged.

However in the above formula a function b x is represented as follows. In the following formula nand n are pixel counts contained in the corresponding nodes. Also Q is a parameter for controlling segmenting coarseness.

A node is initially a pixel or a polygon being the smallest unit of a polygon mesh which forms a digital image. However as the image region merge processing proceeds the node grows into an image region formed from a polygon mesh including a plurality of polygons. The node statistical information has for each node N a record for holding the identification information id N the area N of the associated image region initially a single polygon the polygon count n N initial value set to 1 being the number of polygons forming the associated image region i.e. polygon mesh and the like. And the image region mesh growing section gives when nodes are merged each other a new id for identifying the new node and then calculates the area and polygon count of an image region newly produced by the merging to update the node statistical information. To produce new identification information Union Find algorithms can be used. As to the Union Find algorithms see e.g. T. H. Cormen C. E. Leiserson R. L. Rivest Data Structures for Disjoint Sets Chapter 22 pp. 440 461 Introduction to Algorithms .

The small region merging section merges any small region remaining as a result of merge processing performed on image regions. For example a small polygon mesh left unmerged either between large image regions or inside a large image region is merged with any of its adjacent image regions independently of whether or not the predicate is satisfied such that the resultant image region looks nicer. A small region herein used means e.g. a polygon mesh whose area is less than several percent of the entire mesh surface.

First the image information editing section edits the image information of a three dimensional object for processing step S . In the present embodiment the image information is described in the form of an incidence graph in which a polygon is used as a node and a side of the polygon is used as an edge see the earlier description and .

The image information editing section scans the inputted incidence graph to give each node Nits identification information id N and also finds an area of the corresponding polygon to register initialize the identification information area and polygon count initial value set to 1 for each node in the node statistical information. Pseudo program codes for initializing the node statistical information are shown below where id is an array for storing the identification information of a node denoted by an argument area is an array for storing an area of the node having the identification information denoted by the argument and n is an array for storing a polygon count forming node of the identification information denoted by the argument.

For a node Nextracted as an i node from the incidence graph i is substituted into the identification information id N the area T of a polygon is substituted into the area i of the node N and initial value 1 is substituted into the polygon count n i .

Next the incidence graph evaluating section evaluates an each edge in the inputted incidence graph for sorting step S . Specifically a difference between the areas of image regions connected through the edge is given as a weight of the edge and the image regions are sorted in increasing order of the weights. The smaller the difference between the areas of image regions is the smaller the weight value is and the higher the processing priority in the subsequent image merge processing is.

Then the parameter setting section sets the parameter Q for controlling segmenting coarseness step S .

The image region mesh growing section extracts a pair of image regions sandwiching the edge in sorted order of the edges step S . And mesh growing is performed on the basis of whether or not these image regions satisfy the predicate based on the statistical algorithm step S . The predicate used here is one derived from statistical concentration inequality being the phenomenon occurring in the areas of the polygons forming the image region mentioned earlier . The parameter Q set in step S is used in the predicate.

The node statistical information has for each node N a record for holding the identification information id N the area N of the associated image region initially a single polygon the polygon count n N initial value set to 1 being the number of polygons forming the associated image region i.e. polygon mesh and the like mentioned earlier . The image region mesh growing section gives when the image regions are merged into a new node a new id for identifying the new node and then calculates the area and polygon count of the image region newly produced by the merging to update processing of the node statistical information step S .

The pseudo program codes for merging image regions and thereafter updating the node statistical information are shown below where Merge is a function for merging and processing each image region denoted by an argument.

First mesh growing is performed on nodes Nand Ndenoted by an argument of the Merge function. Then by giving the same new identification information id N id N to the respective nodes Nand N both image regions are merged to indicate that a new node is produced. In the present embodiment the old identification information about either Nor Nis used as the identification information about the new node. In giving the identification information to the new node the Union Find algorithms mentioned earlier devised by Robert Endre Tarjan can be used.

Then a sum area id N area id N of the areas of the respective source image regions is substituted into an area id N of the new node and also a sum n id N n id N of the polygon counts of the respective source image regions is substituted into a polygon count n id N of the new node. And by giving new identification information id N and id N to the source nodes Nand N respectively the updating of the node statistical information ends.

And when the processing is completed for all the edges in the incidence graph step S the small region merging section merges any small region remaining as a result of the merge processing performed on the image regions step S . For example a small polygon mesh left unmerged between large image regions or inside a large image region is merged with any of its adjacent image regions independently of whether or not the predicate 3 is satisfied such that the resultant image region looks nicer. A small region herein means e.g. a polygon mesh whose area is less than several percent of the entire mesh surface.

Since the mesh growing on image regions based on the statistical processing algorithm mentioned above involves simple computation of statistically processing the areas of polygons high speed processing can be implemented. For example some millions of polygons can be processed per second using the typical computation system mentioned earlier . Furthermore by adjusting the parameter Q contained in the predicate a criterion for merging image regions can be set randomly to produce a polygon mesh having a desired coarseness and thus the system has scalability.

A larger Q decreases the value on the right side of the above formula 3 to make it difficult to satisfy the predicate 3 whereby the merging of image regions is suppressed see . Conversely a smaller Q increases the value on the right side of the above formula 3 to easily satisfy the predicate whereby the merging of image regions is promoted to obtain a coarser mesh segmentation result see .

Thus according to the image segmentation method of the present embodiment by setting the proper value of Q in the predicate 3 segmentation can be performed by which pictures in picture regions and a background region contained in a photo image taken are separated from each other. For example as shown in pictures in picture objects having texture regions such as business cards book covers and or CD DVD labels contained in photo image can be extracted from a source image by image segmentation.

However if pictures in picture have complicated texture or if a background on which the pictures in picture are placed has texture pictures in picture regions are also segmented to lose its single body or the background is also segmented to be undistinguished from the pictures in picture regions. Hence it is difficult to extract only a desired pictures in picture regions by separation. For example when a photo formed from complicated semantics is image segmented a region is not extracted as a single picture in picture but is further segmented into a plurality of regions as shown in and the image segmentation ends in failure.

In the present embodiment in order to accurately process a background formed from complicated texture it is configured to perform two step segmentation in which segmentation processing for exporting a foreground region including individual pictures in picture from a source image and segmentation processing for exporting a background region other than the pictures in picture from the source image are performed in a two step manner. Furthermore a color edge image is used in the two step segmentation which can be obtained by differential filtering a source image.

As mentioned already in the initial state of an incidence graph nodes are individual pixels in a two dimensional image and any adjacent nodes are connected through an edge. And judgment is made on a weight given to each edge using the predicate based on the statistical processing algorithm and by repeating merging of the nodes the image segmentation proceeds. In step S in a differential filtered color edge image a partial incidence graph is created by giving only to a pixel whose edge color frequency band is less than a predetermined value e.g. not falling under the contour of a pictures in picture region or of a texture region an edge for connecting with another pixel. No adjacent pixels could be merged without an edge and thus the image segmentation proceeds with such adjacent pixels left separated.

When the image segmentation ends a small region having ten pixels or less is merged with any of its surrounding regions step S .

When the image segmentation processing in steps S and S ends some of the regions on the border of the image for processing are merged step S . In this processing step all regions each touching the border similar to four corner regions of an image are merged. For example even if the background is segmented into several regions as shown in as a result of image segmentation processing regions on the border are merged whereby the background is merged into a single region as shown in .

Then foreground image regions of pictures in picture are exported step S and also a background image region on which the pictures in picture are placed is exported step S .

After having performed image segmentation processing further other small regions may be contained in any resultant segmented region. In an example of in the outermost contour of a business card as a picture in picture a small region is contained which is formed from a contour surrounding a logo printed on the business card. However as is apparent from the figure a small region contained in another region is basically just an individual content contained in pictures in picture information and thus only a region defined by the outermost contour needs to be considered. Hence in extracting a region such a small region is discarded.

In extracting a region from an image segmented image first the image is scanned along both horizontal and vertical scanning lines to detect closed contours. Then the image is updated by applying a flood fill algorithm to the individual closed contours. Thereafter only a region object formed from the outermost contour is extracted.

If two step image segmentation such as mentioned above is to be performed all the regions excluding the background are extracted to create a set of desired quadrilaterals.

As shown in by scanning the image along the horizontal and vertical scanning lines a region defined by the outermost contour is detected.

Here a region defined by the outermost contour is extracted and then the flood fill algorithm is applied thereto such that a region defined by the inner contours will not be extracted by mistake as shown in .

Note that for details of the flood fill algorithm see e.g. Frank Nielsen Visual Computing Geometry Graphics and Vision Charles River Media ISBN 1 58450 427 7 2005 Chapter 2 page 26 .

When an almost quadrilateral region is detected from the outermost contour if this region is a modified rectangle as viewed perspectively see image conversion is performed such that this region becomes an image viewed from the front see . The reason why the region is converted into a front view image is that man is generally inclined to view a flat surface using two cameras active lighting a projector or hologram AF and the like.

In extracting the outermost contour it is judged whether that contour is quadrilateral. Specifically as to each pixel forming the contour for processing the inclinations of their tangents are calculated for chopping in units of 5 degrees whereby to identify two main inclinations directions see .

The pixels on the border of the contour are grouped into four sets in accordance with the inclinations of their tangents and then line regression is performed for each set. Then a quadrilateral is detected as a region where four half planes intersect see .

Alternatively as a substitute technique for finding quadrilaterals a line simplification algorithm by Douglas Peucker may be applied to extract pixels forming the outermost contour a closed C4 curve . Note that for details of this line simplification algorithm see e.g. http geometryalgorithms.com Archives algorithm0205 as of Jul. 27 2006 John Hershberger and Jack Snoeyink Speeding Up the Douglas Peucker Line Simplification Algorithm Proc 5th Symp on Data Handling 134 143 1992 or the like.

After extracting the quadrilateral in this way a Hausdorff distance from original line segment is calculated. If the distance is within a predetermined value the extracted region is accepted as a quadrilateral.

Note that the Hausdorff distance is a known technique for comparing shapes using a scale of distance.

Finally inverse projective transformation is performed such that the detected quadrilateral becomes an image viewed from the front and also its aspect ratio is adjusted.

Many techniques are available for subjecting a rectangular image to inverse projection and the scope and spirit of the embodiments of the present invention are not limited to any specific technique.

For example an average of aspect ratios is calculated on the basis of a formula a h1 h2 w1 w2 . Also the closest one is found out from a predetermined set of aspect ratios. For example an aspect ratio of 10 15 is selected for A4 size paper photos and postcards and an aspect ratio of 5.5 9.1 for business cards for a picture in picture rotated 90 its aspect ratio is the inverse of a corresponding one of the above aspect ratios .

A dimensional factor s is selected such that a s2 equals the pixel count within the quadrilateral where a is the aspect ratio . Alternatively the dimensional factor is selected such that the distance between two points subjected to inverse projection is within a predetermined value e.g. 1.0 or 1.414 .

The image conversion is called homography or collineaction and is represented by a 3 3 homogeneous matrix H determined by eight coefficients.

Let a pixel p in the quadrilateral be mapped into a pixel p whose scale is adjusted using the aspect ratio a. If p and p are homogeneous coordinates as p x y z p x y z then p Hp. If they are not homogenous coordinates then p x w y w .

As shown in a synthesized image is backward mapped into a source image. A backward mapped pixel P is represented as P Hp .

Note that for details of backward mapping or the like it is suggested to refer to e.g. Frank Nielsen Visual Computing Geometry Graphics and Vision Charles River Media ISBN 1 58450 427 7 2005 Chapter 3 p. 127 Chapter 4 p. 203 .

The present invention has been described above in great detail with reference to the specific embodiment. However it is self explanatory that those skilled in the art can make modifications to and substitutions for the embodiment without departing from the scope and spirit of the present invention.

The image processing technology of the present invention can be incorporated into information equipment such as personal computers that capture photo images from a digital camera to process these images digital still cameras themselves or various equipment incorporating therein a digital camera.

According to the image processing technology of the present invention a plurality of pictures in picture such as business cards postcards and or book covers contained in a photo image taken by a digital camera or the like can be exported as foreground regions by separation from other background region. Also the individual extracted pictures in picture image can be subjected to inverse projective transformation such that they are imaged from the front or can have their aspect ratios adjusted for reconstruction into image objects close to the original pictures in picture. These image objects are reusable as content. Additionally text contained in picture in picture is character recognized so that the obtained textual information can be used to store or arrange the image object and further used to search information and provide other services based on textual information.

That is the present invention has been disclosed by way of examples and thus should not be construed in a restrictive sense. In order to judge the scope and the spirit of the present invention the appended claims should be taken into consideration.

It should be understood by those skilled in the art that various modifications combinations sub combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.

