---

title: Method and apparatus for designing an embedded system for a programmable logic device
abstract: Method and apparatus for designing an embedded system for a programmable logic device (PLD) is described. Parameters specific to the embedded system are obtained. Source code files that use the parameters to define configurable attributes of the base platform are generated. A software definition and a hardware definition are obtained. The software and hardware definitions each use an application programming interface (API) of the base platform to define communication between software and hardware of the embedded system. An implementation of the embedded system is automatically built for the PLD using the source code files, the software definition, and the hardware definition.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07917876&OS=07917876&RS=07917876
owner: Xilinx, Inc.
number: 07917876
owner_city: San Jose
owner_country: US
publication_date: 20070327
---
One or more aspects of the invention relate to programmable logic devices PLDs and more particularly to a method and apparatus for designing an embedded system for a PLD .

Programmable logic devices PLDs exist as a well known type of integrated circuit IC that may be programmed by a user to perform specified logic functions. There are different types of programmable logic devices such as programmable logic arrays PLAs and complex programmable logic devices CPLDs . One type of programmable logic device known as a field programmable gate array FPGA is very popular because of a superior combination of capacity flexibility time to market and cost.

An FPGA typically includes an array of configurable logic blocks CLBs surrounded by a ring of programmable input output blocks IOBs . The CLBs and IOBs are interconnected by a programmable interconnect structure. The CLBs IOBs and interconnect structure are typically programmed by loading a stream of configuration data known as a bitstream into internal configuration memory cells that define how the CLBs IOBs and interconnect structure are configured. An FPGA may also include various dedicated logic circuits such as memories microprocessors digital clock managers DCMs and input output I O transceivers.

Traditional complex processing systems are typically implemented using software running on a microprocessor in conjunction with multiple dedicated hardware blocks and thus are suitable for implementation using a PLD. In such systems hardware blocks are used to perform complex functions more efficiently than performing such functions in software. Supporting mixed hardware software processing systems with an appropriate hardware software platform is desirable. Communication between the software portion of the system i.e. software running on a processor and the hardware portion of the system should be efficient. It is further desirable to encapsulate platform dependent aspects of communication between the software and hardware portions of the system in order to provide an efficient programming interface. It is further desirable to provide an automated design tool to map hardware software systems onto a hardware software platform in a PLD.

An aspect of the invention relates to an apparatus for communication between processing elements and a processor in a programmable logic device PLD . A first lookup table is configured to store first information representing which of the processing elements is capable of performing which of a plurality of instructions. In an embodiment the first lookup table is also configured to store a measure of the relative speed in which each processing element can perform each of its respective instructions. A second lookup table is configured to store second information representing which of the plurality of instructions is being serviced by which of the processing elements. Control logic is coupled to the processor the first lookup table and the second lookup table. The control logic is configured to communicate data from the processor to the processing elements based on the first information and communicate data from the processing elements to the processor based on the second information.

Another aspect of the invention relates to a method of communication between processing elements and a processor in a PLD. A first packet is received from the processor. The first packet comprising a header and a data block. The header includes an outstanding instruction of a plurality of instructions to be performed. At least one of the processing elements is selected to service the outstanding instruction to be performed based on first information. The first information represents which of the processing elements is capable of performing which of the plurality of instructions. The first packet is provided to the selected at least one processing element. Second information is updated based on the selected at least one processing element servicing the outstanding instruction to be performed. The second information represents which of the plurality of instructions is being serviced by which of the processing elements. In an embodiment a second packet is received from the processor. The second packet comprises a header including an outstanding instruction of the plurality of instructions for which data is to be read. Data is read from a selected one of the processing elements that serviced the outstanding instruction for which data is to be read based on the second information. The second information is updated based on the selected one of the processing elements.

Another aspect of the invention relates to a method apparatus and computer readable medium for designing an embedded system for a PLD. Parameters specific to the embedded system are obtained. Source code files that use the parameters to define configurable attributes of the base platform are generated. A software definition and a hardware definition are obtained. The software and hardware definitions each use an application programming interface API of the base platform to define communication between software and hardware of the embedded system. An implementation of the embedded system is automatically built for the PLD using the source code files the software definition and the hardware definition.

The system comprises a processor block a memory and a virtual socket platform . The processor block includes a processor and an auxiliary processor unit APU . The virtual socket platform includes a platform interface a processing engine . The processing engine includes sockets through N collectively referred to as sockets where N is an integer greater than zero. The sockets are processing elements that encapsulate user defined logic blocks. A port of the processor is coupled to a port of the APU . Another port of the processor is coupled to a port of the memory . Another port of the APU is coupled to a port of the platform interface . Another port of the platform interface is coupled to processing engine .

In the embodiment shown the processor is coupled to the virtual socket platform via the APU . Those skilled in the art will appreciate that communication between the processor and the virtual socket platform may be achieved using other types of interfaces know in the art. For example the system described herein may be adapted to use a processor bus interface such as a processor local bus PLB in place of the APU .

In operation the processor executes software instructions. The processor may be any type of microprocessor known in the art. The software instructions to be executed are stored in the memory software code . The software instructions comprise user defined software i.e. the software portion of a user s embedded system . The memory generally represents the various types of memories associated with the processor . For example the memory may include memory integrated within the processor e.g. cache memory memory within the PLD coupled to the processor and or memory external to the PLD coupled to the processor . The software instructions to be executed may be stored in cache memory for example.

The virtual socket platform provides hardware software blocks for use by the processor . In particular each of the sockets provides an interface to a hardware or software block configured to perform a particular function or task. That is each of the sockets provides a wrapper for its corresponding logic block. A hardware block performs its task in hardware e.g. using logic resources of the PLD . A software block performs its task by executing software instructions e.g. via a processor . The hardware blocks are in effect hardware accelerators in that they perform their functions more efficiently than software implementations of such functions. The software blocks are in effect software accelerators in that they allow the processor to delegate tasks that would otherwise consume resources of the processor e.g. computationally intensive tasks . The processor may offload particular tasks to the virtual socket platform thereby freeing processor resources to perform additional instructions and tasks.

The virtual socket platform implements a fixed protocol for communication between the processor block and the processing engine . As described below various aspects of the virtual socket platform are configurable through use of a hardware based API. The hardware based API encapsulates the platform dependent aspects of the communication protocol specifically communication between the APU and the platform interface and between the platform interface and the processing engine . An advantage of such a socket based system is the scalability provided. The complexity of the hardware based API scales with the number of sockets N. If only a single socket is employed i.e. N 1 the hardware based API exhibits minimum possible complexity.

In particular some of the software instructions configured for execution by the processor comprise auxiliary instructions that are sent by the processor to the APU . The processor determines which instructions are auxiliary instructions for the APU using an operation code op code in the instructions as is well known in the art. An auxiliary instruction designated for the virtual socket platform includes a task to be performed by the processing engine . The APU forwards auxiliary instructions and associated data designated for the virtual socket platform to the platform interface . The platform interface provides a defined communication link between the processor block and the processing engine .

In one embodiment each auxiliary instruction designated for the virtual socket platform comprises one of a load instruction a store instruction a register read instruction or a register write instruction. A load instruction is used to pass instructions and data from the processor to the processing engine for performing particular tasks. A store instruction is used to read data resulting from performance of a task from the processing engine to the processor . The register read and register write instructions are discussed in more detail below.

In one embodiment the load instructions are in a packet format. is a block diagram depicting an exemplary embodiment of a packet format for an instruction in accordance with one or more aspects of the invention. The packet format includes a priority field an instruction field and a packet length field . The instruction field includes an instruction to perform a particular task. Note that the instructions to perform tasks are distinguishable from the load and store instructions discussed above which are auxiliary instructions associated with the APU APU instructions . In this exemplary embodiment the instruction field comprises 12 bits. The processing engine is configured to perform multiple tasks and thus supports multiple instructions. For example assume instructions 0x10000A 0x10000B and 0x10000C correspond to operation operation and operation respectively. If the instruction field contains instruction 0x10000B then the virtual socket platform delegates the task to a socket in the processing engine that can handle and perform operation .

The priority field includes a priority value for the instruction. In this exemplary embodiment the priority field comprises 4 bits. The priority field provides a mechanism for the processor to communicate to the virtual socket platform the priority of the instruction. In one embodiment the priority field is used by the virtual socket platform along with the relative speed information to decide which of the sockets will perform the requested instruction. The packet length field includes the length in bytes of data that follows. Notably the priority field the instruction field and the packet length field comprise a first word of the packet and are thus the packet header 32 bit words . The packet may include one or more additional words e.g. words and are shown. The additional words include data associated with the instruction to be performed. In one embodiment the load instruction is implemented using a burst of words such as a quad word burst or dual word burst. The packet may include any number of words and thus may be divided over several consecutive load instructions. If more than one load instruction is needed to send the packet only one header word is needed in the first packet . Each following load burst will be a continuation of the packet and will contain only data until the specified packet length is met.

The APU passes the header and data block of a packet conveyed by one or more load instructions to the platform interface . The APU may also pass the load instruction itself to the platform interface . In an embodiment the load instruction includes an extended op code field that can be used by the platform interface to determine the length of the bursts e.g. single dual or quad word from the APU .

The store instruction from the APU is also in the packet format but only includes header information. The header information includes the priority the instruction and the length in bytes to store. The APU passes the header to the platform interface . The APU may also pass the store instruction itself to the platform interface . The APU then waits to receive data from the platform interface .

The communication link includes a first in first out buffer FIFO a FIFO and a bus . The FIFO is a receive FIFO for receiving data from the platform interface and providing data to the socket X. The FIFO is a send FIFO for receiving data from the socket X and providing data to the platform interface . In one embodiment the FIFOs and are asynchronous to support sockets that operate on a difference clock frequency that the platform interface . The FIFOs and ensure that no data is lost in the transfer between the platform interface and the socket X. In one embodiment the FIFOs and comprise LocalLink FIFOs as described in Application Note XAPP691 Parameterizable LocalLink FIFO by Wen Ying Wei and Dai Huang published Feb. 2 2004 by Xilinx Inc. which is incorporated by reference herein. As described in XAPP691 the LocalLink interface defines a set of protocol agnostic signals that allow transmission of packet oriented data and enables a set of features such as flow control and transfer of data of arbitrary length.

The socket X includes a hardware or software block referred to as HW SW block or generally as a logic block configured to perform one or more functions. The socket X also includes register logic and a data transfer state machine . The socket X provides a standard interface or wrapper for the HW SW block . The data transfer state machine is configured to control data flow to the HW SW block from the FIFO and from the HW SW block to the FIFO . For example the data transfer state machine may handle a LocalLink interface to the FIFOs and . The data transfer state machine also may control data flow to from the register logic . The register logic is used to write and read control information.

The registers through store four bit priorities associated with the particular instructions. In one embodiment a four bit priority comprises a metric representative of the time it takes for the HW SW block to complete the particular instruction i.e. a speed performance metric . The priority may comprise other metrics or combinations of metrics. The registers through may store user defined data. Those skilled in the art will appreciate that the register configuration in is merely exemplary. The register logic may include more or less registers which may be larger or smaller than 32 bits. The register logic may support more or less than 32 possible instructions and associated priorities.

Returning to the register logic is accessed via the bus . In one embodiment the bus includes 32 read data lines 32 write data lines five address lines a write enable line and a clock line. The register to be accessed is determined by the five address lines. The write enable line forces the register identified by the address lines to be written with the contents of the write data lines. The contents of the register specified by the address lines is always present of the read data lines. All register operations occur in accordance with a clock signal on the clock line thus allowing the socket X and the platform interface to share data while operating on difference clock frequencies.

Returning to the APU may send register read and register write instructions to the platform interface for reading and writing register logic in the processing engine . A register read instruction includes a header as described above followed by a single word of the data to be written. A register write instruction also includes a header as described above. In both the register read and register write instructions the packet length value in the header contains both an identifier of the socket that is to be accessed and an identifier of a specific register in the socket.

The socket is referred to as the master socket. The master socket may be configured similarly to the socket X described above with respect to . The master socket may also include system parameter registers . The system parameter registers may store information such as an identifier for the virtual socket platform a list of instructions serviceable by the processing engine and the like. The master socket may contain functionality used by all the sockets as well as the processor such as access to shared memory and communication devices such as audio and video players and displays.

Upon receipt of an instruction to be performed the control state machine uses the priority LUT to determine an available socket having a selected priority e.g. selected runtime for the particular operation to be performed. The instruction field determines which operation is to be performed. is a block diagram depicting an exemplary embodiment of a table representative of the data stored in the priority LUT in accordance with one or more aspects of the invention. The table stores information representing which of the sockets is capable of performing which instructions. The table includes N rows through N 1 corresponding to instruction through instruction N 1 where N is the number of instructions serviceable by the processing engine . The table includes X columns where X is the number of sockets in the processing engine configured with a hardware software block. In the present example columns through are shown by way of example. In one embodiment each entry in the table defined by a row and column comprises 5 bits which is the width used to specify the identity of a particular socket e.g. 5 bit identifier to identify up to a maximum of 32 sockets .

In one embodiment for each instruction each row sockets are listed in priority order from the leftmost column to the rightmost column. Thus the socket with the highest priority e.g. fastest runtime is in the first column the socket with the next highest priority second fastest runtime is in the second column and so on until the socket with the lowest priority slowest runtime in the last column . Note that there may not be 8 possible sockets for every instruction. Some instructions may be capable of being performed by only one socket or in general a plurality of sockets. Those skilled in the art will appreciate that the table is merely exemplary. In general the priority LUT may implement a table that contains N rows for each of the N instructions and a user selectable number of columns associated with a user specified maximum number of sockets that can perform the same instruction. The width of each column would be log number of sockets . Thus the priority LUT may be scalable to a smaller size or a larger size depending on specifications of the user. For each instruction the sockets capable of performing the instruction are sorted based on a cost function. In one embodiment the cost function is priority based where higher priority indicates faster runtime and lower priority indicates slower runtime. In this manner the table is configured to store a measure of the relative speed in which each socket can perform its respective instructions.

In one embodiment the table is dynamically updated based on the reconfiguration of one or more of the sockets and hence the modification of the capabilities of the sockets. As is well known in the art and described below with respect to an FPGA can be reconfigured multiple times including partial reconfiguration of a portion of the FPGA while the rest of the FPGA is powered and operating. A user of the system may decide to reconfigure a portion of the sockets based on criteria such as operation usage statistics knowledge of future operations the performance of the sockets and upgrades and improvements to the sockets. As the capability of performing instructions changes via reconfiguration of one or more sockets the table is dynamically updated to reflect the changes.

Returning to the control state machine may determine if the socket having the selected priority for the particular operation to be performed is available by checking the Busy flag in the register logic of the socket. The selected priority may be based on the priority in the header for the instruction i.e. the priority field shown in . If the task is high priority then the control state machine will use an available socket having the highest priority as determined from the priority LUT . If the task is a lower priority the control state machine uses an available socket having a lower or lowest priority as determined from the priority LUT . The control state machine is also configured to initialize the priority LUT . The control state machine loads the priority LUT with the priorities of each of the instructions that are supported by the processing engine . Once a socket is selected data is sent or read from a respective FIFO coupled to the selected socket.

The control state machine also stores task identifiers task IDs in the task LUT . The task LUT is used to track which socket has recently handled which instruction. is a block diagram depicting an exemplary embodiment a table representative of the data stored in the task LUT in accordance with one or more aspects of the invention. The table is configured to store information representing which of the instructions is being serviced by which of the sockets. The table includes N rows through N 1 corresponding to instruction through instruction N 1 where N is the number of instructions serviceable by the processing engine . The table includes X columns where X is the number of sockets in the processing engine configured with a hardware software block. In the present example columns through are shown by way of example. Similar to the embodiment of table described above each entry in the table defined by a row and column comprises 5 bits which is the width used to specify the identity of a particular socket e.g. 5 bit identifier for a maximum of 32 sockets .

Each of the instructions is associated with a read pointer and a write pointer. Thus the table also includes read pointers through N 1 and write pointers through N 1. Each row is in effect a FIFO. When a packet is sent to a particular socket for processing the control state machine pushes the socket identifier into the FIFO for the particular instruction. The socket identifier is written to a particular column pointed to by the write pointer of the particular instruction and the write pointer is incremented. For example for the instruction three packets were sent to the sockets and respectively. The write pointer now points to the column which is the tail of the FIFO.

When a store instruction is received by the control state machine the control state machine selects the socket to read data from by popping the FIFO for the instruction indicated in the store instruction. That is the read pointer for a given instruction points to the head of the FIFO. For example for the instruction assume the read pointer points to the column . Then if the control state machine receives a store instruction indicating instruction then data is read from the socket . The read pointer is then incremented. The table guarantees that the socket read from will be the socket that has the most outstanding call to that particular instruction. That is for each instruction the sockets are ordered in the FIFO based on time of service. Similar to the priority LUT those skilled in the art will appreciate that the table is merely exemplary. In general the task LUT may implement a table that contains N rows for each of the N instructions and a user selectable number of columns associated with a user specified maximum number of sockets that can perform the same instruction. The width of each column would be log number of sockets . Thus the task LUT may be scalable to a smaller size or a larger size depending on specifications of the user.

In one embodiment the control state machine is configured to select more than one socket to perform a particular instruction. That is the control state machine implements a redundancy scheme in the selection of sockets to perform instructions. The sockets process the instruction. The control state machine then selects the winner of the selected sockets and data from the winning socket is passed back to the processor. The winning socket may be determined based on various metrics such as a run time metric a parity check of the results and the like. The control state machine may also decide what to do with the losers of the selected sockets including not selecting the socket for future instructions forcing the socket in a self test mode and reconfiguring the socket to a new function.

At step at least one available socket in the processing engine capable of performing the instruction and having either a priority commensurate with the instruction priority or the highest priority is selected. The socket s is are selected based on socket status data and socket priority data . The socket status data includes information as to which sockets in the processing engine are available to process data e.g. not busy . As described above such information may be obtained from the register logic in each of the sockets via the Busy flag. The socket priority data includes the information represented by the priority LUT . The socket priority data may indicate that several sockets are capable of performing the identified instruction. In one embodiment an available socket s having a priority commensurate with the instruction priority is selected i.e. highest instruction priority highest priority socket lower instruction priority lower priority socket etc. . In another embodiment an available socket s having the highest priority is always selected regardless of the instruction priority.

At step the packet is sent to the selected socket s for processing. In an embodiment the packet is pushed into the receive FIFO of the selected socket s . The selected socket s pops the packet from the receive FIFO and performs the requested operation on the data block. At step the selected socket s is are noted as performing the instruction in outstanding instruction data . The outstanding instruction data includes information represented by the task LUT . As discussed above an identifier for the selected socket s is pushed into a FIFO associated with the instruction to be performed and a write pointer for the instruction is updated.

At step one or more sockets having the most outstanding call s to the instruction is are identified from the outstanding instruction data . As discussed above a socket identifier is popped from a FIFO associated with the instruction and the read pointer is updated. Moreover multiple sockets may have been selected to perform a particular instruction in a redundancy scheme. At step data is read from the identified socket s . In an embodiment the data to be read is pushed into the read FIFO of the identified socket s . The platform interface pops the data to be read from the read FIFO . At step the outstanding instruction data is updated i.e. the read pointer is updated . At optional step if data is obtained from more than one socket data is selected from one of the sockets e.g. a winning socket is chosen as described above . At optional step if data is obtained from more than one socket at least one of the sockets is reconfigured e.g. one or more of the losing sockets is are reconfigured as described above . At step the data is provided from the platform interface to the APU .

The system includes a specification capture module a compiler a linker a library generator a synthesizer a platform generator implementation tools and a bitstream initializer . The specification capture module is configured to capture specification data for the system. The specification data includes various parameters specification to the user s system design. Exemplary user defined parameters include 1 the number of processing elements in the platform 2 the tasks supported by the processing elements and the corresponding instructions and op codes to perform the tasks 3 whether writes and or reads to processing elements are supported 4 the size of the memories used by the processor 5 the target PLD platform e.g. part number communication protocol used 6 data to be stored in user defined register logic and 7 the name of the project.

In one embodiment the specification capture module comprises a graphical user interface GUI through which the user may interact to define the parameters. Other techniques may be used such as manual editing of a parameter file. In one embodiment the specification capture module includes an automated build script that will automatically build the user design in response to the defined parameters. The automated build script will control the execution of the other tools in the design system . In this manner the specification capture module provides a single entry point for the user. The specification capture module automatically creates one or more hardware description language HDL package files and one or more source code header files in response to the defined parameters.

A virtual socket API provides a wrapper for hardware HW and software SW aspects of the base platform. The source code header file s map user defined parameters onto the SW portion of the API . That is the software code header file s define the configurable attributes of the software portion of the base platform. The user source code utilizes data and functions defined in the SW portion of the API and in the header file s to delegate tasks to user defined logic blocks in the platform. The SW portion of the API encapsulates the platform dependent aspects of communication with the user defined logic blocks. The compiler receives the user source code and the header file s and accesses the SW portion of the API . The compiler compiles the user source code to produce one or more object files .

The library generator configures libraries device drivers file systems and interrupt handlers for the system to create a software platform. A description of the software platform is maintained a microprocessor software specification MSS file . Since the user defined aspects of the system are wrapped by the virtual socket API the MSS file is application independent. That is the MSS file may be defined generally for the base platform and does not require any user defined parameters. The library generator processes the MSS file to produce one or more libraries . The linker receives the object file s and the libraries and produces an executable file in a well known manner.

The synthesizer is configured to receive a behavioral hardware description of the system and produce a logical or gate level description e.g. logical network lists netlists . The platform generator produces a top level HDL design file for the system to define the hardware platform. A description of the hardware platform is maintained in a microprocessor hardware specification MHS file and in one or more microprocessor peripheral definition MPD files MPD MHS files . Since the user defined aspects of the system are wrapped by the virtual socket API the MPD MHS files are application independent. That is the MPD MHS files may be defined generally for the base platform and do not require any user defined parameters.

The HDL package file s map user defined parameters onto the HW portion of the API . That is the HDL package file s define the configurable attributes of the hardware portion of the base platform. The user HDL code defines the various user defined logic blocks used in the system. The user HDL code utilizes constructs defined in the HW portion of the API to establish a communication interface between the logic blocks and the base platform. The HW portion of the API encapsulates the platform dependent aspects of the communication interface between the platform and the user defined logic blocks.

The synthesizer receives the HDL package file s the HDL source and a top level HDL design file from the platform generator to produce the netlist s . The implementation tools process the netlist s to produce a system bitstream for configuring a PLD. For example the implementation tools may comprise well known map place and route and bitstream generation tools for implementing a design in a PLD such as an FPGA. The bitstream initializer receives the system bitstream and the executable file . The bitstream initializer initializes memory coupled to the processor with the executable file i.e. software instructions . The bitstream initializer produces a bitstream that can be loaded into a PLD to implement the designed system.

At step a software definition and a hardware definition of the user design are obtained. The software and hardware definitions utilize an API of the base platform. The software definition includes software source code written by the user for execution by the processor of the base platform. The software source code uses the API of the base platform to communicate with the defined processing elements. The hardware definition includes HDL source code that describes logic blocks to be implemented by the processing elements. The HDL source code uses the API of the base platform to establish an interface between the logic blocks and the processing elements.

At step an executable is generated from the software definition the software header file s and a software specification description of the base platform. The software specification description may comprise a MSS file. Since the configurable attributes of the base platform are included in the software header file s the software specification description of the base platform is independent of the user design. The executable is generated by compiling the software definition to form object file s generating library file s from the software specification description and linking the object file s with the library file s to produce the executable.

At step a hardware implementation is generated from the hardware definition the hardware package file s and a hardware specification description of the base platform. The hardware specification description of the base platform may comprise MPD and MHS files. Since the configurable attributes of the base platform are included in the hardware package file s the hardware specification description of the base platform is independent of the user design. The hardware implementation is generated by generating a top level HDL design file from the hardware specification description of the base platform synthesizing the hardware package file s the top level HDL design file and the hardware definition of the user design to produce logical network lists and implementing the logical network lists for a target PLD e.g. map place and route and bitstream generation . At step the executable and the hardware implementation are merged to produce an embedded system implementation for a target PLD. In an embodiment the embedded system implementation is produced by initializing a bitstream for the target PLD with the executable.

The memory stores processor executable instructions and or data that may be executed by and or used by the processor . These processor executable instructions may comprise hardware firmware software and the like or some combination thereof. Modules having processor executable instructions that are stored in the memory include system design module . The system design module is configured to implement the design system and perform the method . The computer may be programmed with an operating system which may be OS 2 Java Virtual Machine Linux Solaris Unix Windows Windows95 Windows98 Windows NT and Windows2000 WindowsME and WindowsXP among other known platforms. At least a portion of an operating system may be disposed in the memory . The memory may include one or more of the following random access memory read only memory magneto resistive read write memory optical read write memory cache memory magnetic read write memory and the like as well as signal bearing media as described below.

An aspect of the invention is implemented as a program product for use with a computer system. Program s of the program product defines functions of embodiments and can be contained on a variety of media which include but are not limited to i information permanently stored on non writable storage media e.g. read only memory devices within a computer such as CD ROM or DVD ROM disks readable by a CD ROM drive or a DVD drive or ii alterable information stored on writable storage media e.g. floppy disks within a diskette drive or hard disk drive or read writable CD or read writable DVD Such media when carrying computer readable instructions that direct functions of the invention represent computer readable media embodiments of the invention.

As noted above advanced FPGAs can include several different types of programmable logic blocks in the array. For example illustrates an FPGA architecture that includes a large number of different programmable tiles including multi gigabit transceivers MGTs configurable logic blocks CLBs random access memory blocks BRAMs input output blocks IOBs configuration and clocking logic CONFIG CLOCKS digital signal processing blocks DSPs specialized input output blocks I O e.g. configuration ports and clock ports and other programmable logic such as digital clock managers analog to digital converters system monitoring logic and so forth. Some FPGAs also include dedicated processor blocks PROC .

In some FPGAs each programmable tile includes a programmable interconnect element INT having standardized connections via routing conductor segments to and from a corresponding interconnect element in each adjacent tile. Therefore the programmable interconnect elements and routing conductor segments taken together implement the programmable interconnect structure for the illustrated FPGA. The programmable interconnect element INT also includes the connections to and from the programmable logic element within the same tile as shown by the examples included at the top of . The programmable interconnect element INT may also include connections via routing conductor segments to and from a corresponding interconnect element that span multiple columns of logic. That is routing conductor segments may span a plurality of tiles e.g. a hex line spans six tiles .

For example a CLB can include a configurable logic element CLE that can be programmed to implement user logic plus a single programmable interconnect element INT . In an embodiment the CLE includes four slices not shown of logic. A BRAM can include a BRAM logic element BRL in addition to one or more programmable interconnect elements. Typically the number of interconnect elements included in a tile depends on the height of the tile. In the pictured embodiment a BRAM tile has the same height as four CLBs but other numbers e.g. five can also be used. A DSP tile can include a DSP logic element DSPL in addition to an appropriate number of programmable interconnect elements. An IOB can include for example two instances of an input output logic element IOL in addition to one instance of the programmable interconnect element INT . As will be clear to those of skill in the art the actual I O pads connected for example to the I O logic element are manufactured using metal layered above the various illustrated logic blocks and typically are not confined to the area of the input output logic element .

In the pictured embodiment a columnar area near the center of the die shown shaded in is used for configuration clock and other control logic. Horizontal areas extending from this column are used to distribute the clocks and configuration signals across the breadth of the FPGA.

Some FPGAs utilizing the architecture illustrated in include additional logic blocks that disrupt the regular columnar structure making up a large part of the FPGA. The additional logic blocks can be programmable blocks and or dedicated logic. For example the processor block PROC shown in spans several columns of CLBs and BRAMs.

Note that is intended to illustrate only an exemplary FPGA architecture. The numbers of logic blocks in a column the relative widths of the columns the number and order of columns the types of logic blocks included in the columns the relative sizes of the logic blocks and the interconnect logic implementations included at the top of are purely exemplary. For example in an actual FPGA more than one adjacent column of CLBs is typically included wherever the CLBs appear to facilitate the efficient implementation of user logic. Examples of FPGAs that may be used with embodiments of the invention are the Virtex 4 FPGAs available from Xilinx Inc. of San Jose Calif.

While the foregoing describes exemplary embodiments in accordance with one or more aspects of the present invention other and further embodiments in accordance with the one or more aspects of the present invention may be devised without departing from the scope thereof which is determined by the claims that follow and equivalents thereof. Claims listing steps do not imply any order of the steps. Trademarks are the property of their respective owners.

