---

title: Implementing user-selectable concurrent access protection mechanism in a multi-tasking modeling environment
abstract: A system for providing model level protection for resources holding data accessed by multiple tasks in a model is discussed. The protection occurs at the model level so that the protection mechanism does not interfere with model dynamics. Resources concurrently accessed by multiple tasks are identified so that a unified protection mechanism can be applied to the resource. A user interface may be provided which enables the selection of a particular type of protection mechanism for the data in the resource. User supplied protection mechanisms may also be implemented.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08707306&OS=08707306&RS=08707306
owner: The MathWorks, Inc.
number: 08707306
owner_city: Natick
owner_country: US
publication_date: 20070724
---
This application claims the benefit under 35 U.S.C. 120 as a continuation of U.S. Non provisional application Ser. No. 11 687 576 filed Mar. 16 2007 entitled DATA TRANSFER PROTECTION IN A MULTI TASKING MODELING ENVIRONMENT the entire disclosure of which is hereby incorporated by reference for all purposes.

Technical computing environments such as the environments provided by MATLAB software STATEFLOW software and SIMULINK software all from The MathWorks Inc. of Natick Mass. as well as parallel state machines hybrid automata data flow models e.g. synchronous data flow models and other graphical modeling formalisms such as for example Petri nets provide environments for designing simulating and executing dynamic system models. The models may be models of real time and or non real time control systems real time and or non real time communication systems and other real time and or non real time applications.

Dynamic system models may model multi task systems that can include tasks components that execute independently potentially at different rates and or with different priorities. For example in a block diagram model the model may include blocks related to tasks in the system being modeled that execute at different rates e.g. a first block that executes at a first rate and a second block that executes at a second rate . Blocks and or components in a system being modeled are frequently required to write to or read from a memory location or other resource. In certain situations one block component may attempt to read from a memory location while another block component writes to the location. When multiple blocks components attempt to interact with a memory location at the same time problems may arise e.g. a block may read partially overwritten data from the memory location . For example if the first block has a sample time that causes it to execute every 0.2 seconds and the second block has a sample time of 0.1 seconds problems can arise if both the first block and second block are independently executing and attempting to access a shared memory location the sample time is the time interval at which the inputs state or outputs of the system are updated and or traced as time progresses . Similarly parallel state machine states that are active in parallel or parallel transitions may also write to the same memory location.

In one embodiment a method for protecting data in a multi tasking modeling environment includes the step of identifying at least one resource that will be accessed by at least two tasks being modeled. The method also changes the identified resource to a central designated resource. The central designated resource is protected from at least one type of concurrent access by the tasks being modeled.

In another embodiment in a multi tasking modeling environment a system for protecting resources includes a first and second task in a system being modeled. The first task executes at a first sample rate. The second task executes at a second sample rate. The system also includes an identified first resource that will be accessed by the first and second model tasks during an execution of the system being modeled. The system additionally includes a central designated resource to which the identified first resource is redirected. A protection mechanism is also included that protects the central designated resource from at least one type of concurrent access by the first and second tasks.

Some multi task models may model systems where a number of tasks are operating at substantially the same time e.g. a first block may execute a first task and a second block may execute a second task . At times multiple tasks may attempt to interact with a memory location or other resource such as a bus processor or processor core at the same time e.g. the first block may attempt to write to the memory location while the second block attempts to read or write to the memory location when the system that is being modeled operates. In case of a memory read or write data integrity and or data determinism may be compromised when the multiple tasks attempt concurrent access to the memory location. For example data being read from the memory location by the first block or task may be in the process of being written to by the second block or task . This problem of simultaneous and uncoordinated access to the memory location may occur for example in a multi rate system being modeled when the second task is operating at a rate that differs from an operating rate for the first task. Without proper protection data may be delivered to the first task the second task or to another task that is corrupted incomplete or otherwise incorrect or undesired.

Conventional techniques for modeling the protection of memory locations and other resources during the execution of multi task systems use rate transition algorithms to protect data transfer locally for each case. For example in a block diagram model which requires data transfers between two model components running at different rates such as subsystem blocks with different sample times a rate transition block may be inserted between the two model components. The rate transition block includes protection logic that is used to synchronize transfers between the two model components executing at different rates speeds and or with different priorities. Protection logic included in rate transition blocks may take a number of forms such as including code causing the generation use of double buffers or the use of semaphores to handle the reading and writing of data to the shared memory location.

These conventional techniques for protecting resources in a multi tasking system being modeled may require the insertion into the model of a local protection technique e.g. a rate transition block for every data transfer to a shared memory location e.g. a protection technique may be needed for every transfer of data to and from a memory location that is of concern to a model designer . The insertion of local protection logic into the model is inefficient and may affect model dynamics i.e. the manner in which model components interact and are executed . These local protection mechanisms may further be static non configurable and or may not be extended to account for different schedulers software environments operating systems hardware targets etc.

Conventional memory protection techniques may have a further shortcoming that affects code generated using a model. For example generated code for a specific target may include the protection code that was embedded into model code to address issues in the system being modeled such as multiple rates. Local protection techniques that are included in generated code may limit the ability of a user of a target platform to implement his her own preferred solution e.g. code generated by the user or code obtained from a third party that is adapted to operate on the target platform .

Exemplary embodiments described herein provide model level protection for memory locations holding data or other resources accessed by multiple independently executing tasks in a system being modeled. The protection of the memory locations or other resources may take place at the model level so that the protection mechanism does not interfere with model dynamics. For example in one embodiment memory locations holding data associated with multiple tasks are identified and grouped together so that a unified protection mechanism can be applied to the grouped memory location. A user interface may be provided which enables the selection of a particular type of protection mechanism for the data in the grouped memory location. For example a user may identify one or more protection mechanisms that can be applied at a model level using one or more grouped memory locations. Exemplary implementations of user interfaces may allow users to describe multi tasking multi rate environments and to choose or suggest data transfer protection mechanisms based on characteristics of multi tasking environments. In one implementation a set of Application Programming Interfaces APIs may be provided to allow users to integrate their own rate transition solutions protection mechanisms with models model components generated code etc.

The grouping of the shared resources allows protection mechanisms such as rate transition solutions data transfer protection etc. to be unified at a model level rather than requiring separate treatment e.g. via insertion of rate transition blocks for each data transfer between independently executing tasks and or between executing tasks and a local memory location. The protection may also be supplied for parts of a model rather than the entire model. Because the protection mechanism is separate from model dynamics the code of each task is independent from other tasks and is exportable. Model level protection allows the behavior of each task to be independently or collectively simulated and or evaluated. Model level protection can also be scheduler independent thereby avoiding rate transition issues associated with conventional techniques that do not employ model level protection. Grouped memory locations can provide a data interface between different tasks and can be protected by each task. The data interface may also allow tasks to communicate with each other.

Exemplary embodiments further provide a protection mechanism that can be customized for different users target hardware etc. without changing the implementation of model dynamics. For example support for multi processors time slicing multi readers multi writers etc. can be added to a model without impacting the implementation of model dynamics.

In order to better explain the differences between conventional protection mechanisms and embodiments of the present invention a modeling environment employing conventional protection mechanisms is first examined. Although many of the examples contained herein refer to the protection of shared memory locations it should be understood that the protection of other types of shared resources is also considered to be encompassed within the scope of the present invention and that many of the protection techniques discussed herein are applicable to other types of shared resources in addition to shared memory locations. depicts components of a system being modeled in a block diagram writing to and reading from shared memory locations using conventional techniques. Model includes two independently executing tasks labeled as Task One and Task Two each with their own collection of block components. Task One includes Block A1 Block B1 and Block C1 . Task Two includes Block A2 Block B2 and Block C2 . Tasks and may execute at different sample rates or with different priority levels but share the use of one or more memory locations or . A portion of the memory available to the computing device has been allocated for the use of the model . Both Block A1 from Task One and Block A2 from Task Two access shared memory location A with Block A1 writing to shared memory location A and Block A2 reading from shared memory location A. Similarly Block B1 from Task One writes to shared memory location B and Block B2 from Task Two reads from shared memory location B. Likewise Block C1 from Task One writes to shared memory location C and Block C2 from Task Two reads from shared memory location C.

In order to protect data in shared memory locations a model designer may insert a rate transition block or other type of block level protection mechanism into model . A rate transition block may include protection logic for a shared memory location such as shared memory locations or . For example the protection logic may utilize double buffers or a semaphore. The double buffers are separate buffers that may be written to and read from so as to account for the differences in sample rates between tasks. Each transfer of data to and from a shared memory location to and from a block in an independently executing task requires its own protection mechanism.

Continuing the discussion of in the code for Task One the code of Block B1 and Block C1 attempt write operations to shared memory location B and shared memory location C respectively. The execution of the code for Block B1 causes the execution of the associated protection logic and the execution of the code for Block C1 causes the execution of the associated protection logic . The depicted code for other blocks is included to illustrate the point that not all of the code executing for Task One causes a write operation to a shared memory location. In the code for Task Two the code of Block B2 and Block C2 attempt read operations from shared memory location B and shared memory location C respectively. The execution of the code for Block B2 causes the execution of the associated protection logic and the execution of the code for Block C2 causes the execution of the associated protection logic . The depicted code for other blocks is included to illustrate the point that not all of the code executing for Task Two causes a read operation from a shared memory location.

As can be seen from the conventional block level protections embed the protection logic within the task code. Protection logic may be embedded for each read or write operation to a shared memory location. As a result code generation based on the model generates code that includes the embedded protection logic thus limiting the customizability of protection mechanisms for generated code for an end user.

Exemplary embodiments identify one or more memory locations holding data or other resources that are to be accessed by more than one task thread during the execution of the system being modeled the term task as used herein should be understood to encompass independently executing tasks threads blocks or other components in a multi tasking system being modeled . Exemplary embodiments perform this identification at the time of the model compilation or during code generation. A number of mechanisms may be employed to perform the identification. For example task and or sample time information may be added to memory attributes. Exemplary embodiments may then leverage the information to determine which memory locations are being concurrently accessed. For example a task index may be set for all memory locations accessed by code with the tasks grouped by rate. Memory locations determined to be concurrently accessed by more than one task may be associated with a central designated location in memory that is protected with a protection mechanism. This central designated location forms a data interface between the different tasks. It should be appreciated that the identified memory locations may also be protected without being associated with a central designated location in memory by recording the current memory location that is determined to be currently accessed by more than one task and applying a protection mechanism to the determined location. Other types of resources determined to be concurrently accessed by more than one task may similarly be protected with a protection mechanism.

Similar to Task One any read operations in Task Two caused by the execution of the code for Block A2 code for Block B2 and code for Block C2 utilize the reference to the remotely located read protection logic e.g. Task two rd rather than including the protection logic within the code of Task Two . It should be noted that although the model depicted in has been discussed as having one task performing only write operations and another task performing only read operations to shared memory locations tasks performing a mixture of both read and write operations to shared memory locations may also be utilized in other exemplary embodiments. In another embodiment one task may share memory with multiple tasks or one shared memory may be accessed by more than two tasks. It should further be understood that the protection is not required to be by reference.

The separation of the protection mechanism protection logic from task code provides a number of benefits. For example separation of the protection mechanism from the task code allows the protection mechanism to be switched without altering the model dynamics. Additionally the separation of the protection mechanism protection logic from the task code allows code to be generated from the model that does not include the protection logic. The protection code may be generated as a separate identifiable module or code segment that may be replaced by a user. The generated protection code may be a function procedure a method a macro etc. written in at least one or a combination of C C Java Java bytecode a hardware description language or assembly code. This separate generation of the protection code allows a user of the generated code to supply their own protection mechanism for the code and or to select a protection mechanism during code generation. As a result the protection mechanism can be easily customized for different customer and or target hardware without changing the implementation of model dynamics. The separation of the protection mechanism from the algorithm code of each task also results in the tasks being independent from other tasks and exportable. Also in one embodiment different protection mechanisms can be chosen for different multitasking environments. The model level protection mechanism also provides flexibility to simulate and generate scheduler or environment independent code. Support for multi processors time slicing or a multi reader writer can be added without impacting the implementation of model dynamics. For example some solutions may require the use of more than two buffers and the use of a model level solution allows this decision to be made at the model level rather than the task level.

The use of a centralized model level protection mechanism may also prove to be more efficient than conventional techniques as instead of protection being provided for each data transfer separately data transfer is protected at the model level for each task. As a result instead of running every time data is transferred between two tasks the protection mechanism only runs once for each task. There may also be less memory usage in some embodiments as there is only one set of rate transition control flags for each task. Additionally the separation of the protection mechanism from the model dynamics allows the behavior of each task to be simulated or evaluated independently.

Model level protection mechanisms may be added by embodiments of the present invention to control the access of the independently executing tasks to the identified memory locations central designated locations in memory or identified resources. Any of a number of conventional protection mechanisms may be utilized to protect the identified central designated location in memory or identified resources. For example the protection mechanism may be a double read write buffer holding copies of the data that is to be accessed by the tasks during execution of the system being modeled. A pointer to the buffers indicates which buffer may currently be read from while the other buffer is available to be written. Alternatively the protection mechanism may be a semaphore a flag which indicates the availability of the designated location. A task takes a semaphore before starting to write to a shared memory location and then releases the semaphore after completing the write operation. Another task will only read from the shared memory location if the semaphore controlling the location has not been taken by some other task. Similarly the protection mechanism may be operating system based with the operating system controlling access to the identified memory locations central memory locations or other identified resources. Likewise the protection mechanism may be hardware based such as by selectively disabling a hardware interrupt to prevent unwanted access to the identified memory locations central designated memory locations or other identified resources.

The application of the protection mechanism to the identified memory location central designated location in memory or other identified resource may be performed programmatically without the participation of a user. Alternatively in one embodiment a user interface may be added to the multi tasking modeling environment that enables user involvement in the selection of the protection mechanism. depicts an exemplary user interface that may be utilized in conjunction with an embodiment of the present invention. The user interface may present a user with a list of different protection mechanisms for selection . In another embodiment the user interface may allow user input for fields related to multi tasking attributes of real time operating systems hardware targets or tasks. Examples of these attributes may include whether a task is preemptive whether the OS supports time slicing or not whether two tasks are concurring and the priority of task. Once the input has been entered the user interface may suggest a protection mechanism or automatically apply a data transfer protection solution. In another embodiment the user interface may enable the user to identify and apply their own protection solution to the designated location.

As noted above one of the features of the present invention is the ability to generate code for target devices from a model that does not result in the generated code including the protection logic from the model. depicts the generation of code to target devices. A computing device that includes a modeling environment with a model generates code based on the model. The generated code may be generated for a specific target device such as the first target device and the second target device . The generated code for the first target device is device specific and allows a user of the first target device to add their own preferred protection mechanism for shared memory locations. Similarly the generated code for the second target device is also device specific and allows a user of the second target device to add their own preferred protection mechanism for shared memory locations. In one embodiment code may also be generated for the protection mechanism in a separate identifiable module fragment container or code segment from the remainder of the model code so as to facilitate its examination and or replacement by a user.

It will be appreciated that the embodiments of the present invention may be practiced in a number of differently configured environments including the alternate distributed environment depicted in . A first computing device may communicate over a network with a second computing device using a number of different mediums and configurations. The network may be a Local Area Network LAN a Wide Area Network WAN an intranet the Internet a wireless network and or a telephone line or some other type of network allowing the first computing device to communicate with the second computing device . The first computing device supports a multi tasking modeling environment and is accessible to a user . The multi tasking modeling environment may retrieve a model from the second computing device . Upon its receipt at the multi tasking modeling environment the model may be examined and any shared resources memory locations holding data that are to be concurrently accessed by more than one task being modeled may be identified and moved to a central designated resource location in memory. The distributed environment may also include a remote database holding model related information .

The present invention may be provided as one or more computer readable programs embodied on or in one or more mediums. The mediums may be a floppy disk a hard disk a compact disc a digital versatile disc a flash memory card a PROM an MRAM a RAM a ROM or a magnetic tape. In general the computer readable programs may be implemented in any programming language. Some examples of languages that can be used include MATLAB FORTRAN C C C Python or Java. The software programs may be stored on or in one or more mediums as object code. Hardware acceleration may be used and all or a portion of the code may run on a FPGA an ASIP or an ASIC. The code may run in a virtualized environment such as in a virtual machine. Multiple virtual machines running the code may be resident on a single processor.

Since certain changes may be made without departing from the scope of the present invention it is intended that all matter contained in the above description or shown in the accompanying drawings be interpreted as illustrative and not in a literal sense. Practitioners of the art will realize that the sequence of steps and architectures depicted in the figures may be altered without departing from the scope of the present invention and that the illustrations contained herein are singular examples of a multitude of possible depictions of the present invention.

