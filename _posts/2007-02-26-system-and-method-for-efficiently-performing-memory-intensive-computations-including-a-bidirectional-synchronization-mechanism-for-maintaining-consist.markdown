---

title: System and method for efficiently performing memory intensive computations including a bidirectional synchronization mechanism for maintaining consistency of data
abstract: A system and method for efficiently performing memory intensive computations including a bidirectional synchronization mechanism for maintaining consistency of data on which computations will be performed. This can be used to solve various problems such as those in a business context. Synchronization occurs in a near-real-time fashion between data in a database and data stored in memory. The synchronization is accomplished by periodically scanning the database to see if any data has changed. If any data has changed, the changes are copied over to memory so that the data in memory is current. This update is accomplished without copying the entire database into memory each time data in the database changes.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07444477&OS=07444477&RS=07444477
owner: Oracle International Corporation
number: 07444477
owner_city: Redwood Shores
owner_country: US
publication_date: 20070226
---
This application is a continuation of and claims priority to U.S. Patent application Ser. No. 10 041 033 filed Dec. 28 2001 and entitled SYSTEM AND METHOD FOR EFFICIENTLY PERFORMING MEMORY INTENSIVE COMPUTATIONS INCLUDING A BIDIRECTIONAL SYNCHRONIZATION MECHANISM FOR MAINTAINING CONSISTENCY OF DATA which is hereby incorporated herein by reference.

The present invention relates generally to the field of computer software and more particularly to a system and method for efficiently performing memory intensive computations including a bidirectional synchronization mechanism for maintaining consistency of data.

The intensive computations required in certain application software necessitate access to and manipulation of a substantial amount of data simultaneously. If all of the data is not resident in memory computation speed will be significantly slowed down. In addition the required data is typically closely tied to transactional data stored in a database. The data in the database might be changing frequently due to for example real world transactions. The disparity between the two data sets causes inaccuracies in the results of the computations.

These problems are encountered in many business applications. For example supply chain planning exhibits such problems. Supply chain planning requires a large amount of information to build an enterprise plan. This information typically includes data related to production capacity inventory balance distribution network bill of material BOM sourcing of components etc. In order to build a good enterprise plan a computation intensive mathematical algorithm should have instant access to this data in order to be able to run efficiently.

This information such as inventory balance etc. is typically stored in a database. As mentioned herein problems arise when live business transactions are performed against the database thus causing data in the database to change at the same time as a mathematical algorithm is being run on the data. At least two prior art attempts were made with respect to trying to overcome the problem of the continuous change of data in the database.

Referring to a first approach was to extract the required transactional data from a database and store the data in a flat file . Computation software would then read file and process the data through the appropriate mathematical algorithm. The output from this computation would be written to another file and exported to or merged with database .

Referring to a second approach was to extract and transfer a snapshot of the required transactional data from a database to a dedicated database . Computation software would read the data directly from dedicated database and process the data through the appropriate mathematical algorithm. The output from this computation would be written to dedicated database and transferred to or merged with database . In this scenario all business transactions are processed through database but not through dedicated database . Dedicated database acts as a medium to mitigate the constant changing nature of the data in database while providing a stable view of the data to the computation algorithm.

There are various drawbacks to these prior art approaches. These approaches cannot handle incremental changes to the data in database and database efficiently. Both approaches require a full reload of the entire data set to accommodate situations where even only a small portion of the data in database or database has been changed. It has heretofore not been possible to build a computationally intensive application that simultaneously supports high frequency interactions from a user or otherwise and access to the most current changes to information.

The present invention provides in various embodiments a system and method for efficiently performing memory intensive computations including a bidirectional synchronization mechanism for maintaining consistency of data.

In a system according to one embodiment of the present invention the system facilitates efficiently performing memory intensive applications. The system comprises a data cache coupled to a first set of data and a second set of data and configured to perform a scan operation on at least a portion of the first set of data and an update operation on the second set of data with changes that have occurred in the first set of data an engine manager coupled to the data cache and configured to instruct the data cache to perform the scan and update operations and a solver coupled to the data cache and configured to perform computations on the second set of data.

In a method according to another embodiment of the present invention the method facilitates efficiently performing memory intensive computations. The method comprises performing using a data cache a scan operation on at least a portion of a first set of data performing using the data cache an update operation on a second set of data with changes that have occurred in the first set of data and performing computations using a solver on the second set of data.

A further understanding of the nature and advantages of the inventions herein may be realized by reference to the remaining portions of the specification and the attached drawings.

As shown in the exemplary drawings wherein like reference numerals indicate like or corresponding elements among the figures an embodiment of a system according to the present invention will now be described in detail. The following description sets forth an example of a system and method for efficiently performing memory intensive computations including a bidirectional synchronization mechanism for maintaining consistency of data.

As mentioned previously the computationally intensive processing necessitated by some modern application software requires immediate access to a substantial amount of data simultaneously. Having this data available only in a database would slow run time down enormously. Therefore the present system allows this data to be resident in memory to facilitate efficient processing thereof. In particular a user may have a particular overall problem overall problem instance in mind that he or she wants to solve. This overall problem can be modeled mathematically. Taking the business problem of supply chain planning for example the user may want to know the answers to various questions related to when where why how how much and the like in the context of questions related to materials vendors manufacturing supply etc. For example one of the many questions a user typically wants answered relates to what vendors should be used for various materials and parts. The user might also want to know what facilities to use to manufacture various parts of a product.

The answers to these and other questions depend on a multitude of variables. One example is the costs charged by the various vendors and the corresponding expected supply times. Another example is whether cost or service quality is of higher priority to the user. In one example sales growth in a given year may increase from 10 percent to 15 percent. The user may want to know how this change in sales growth affects production capacity and manufacturing specifics.

Furthermore the data within the database may be frequently changing. Consequently the present system synchronizes in a near real time fashion the data in the database with the data stored in memory. Prior attempts in the art described herein involved copying over the entire database into memory if even only a small amount of data in the database had changed. Obviously this could be extremely time consuming. Therefore the present system implements in memory storage and processing of the data. This implementation is referred to herein as an in memory computation system. A mechanism is provided to bring changes to the data in the database by say business transactions into the in memory computation system. This is much more efficient than copying over the entire set of data in the database into memory every time there is a small change in the data in the database. It should be noted that the present system is not limited to use as a business application.

Referring now to a system according to embodiments of the present invention is depicted. System comprises a data storage means such as database an in memory engine and a client computer system . In memory engine is capable of receiving a plug in as will be discussed further herein. In memory engine and the plug in co reside on the same computer system such as computer system in one embodiment. Database comprises a first set of data. The first set of data may be related to transactional and other data related to running a business and needed for running a related business application e.g. orders inventory costs of parts etc. Database and in memory engine may reside on different computer systems in one embodiment.

In memory engine is coupled to database in a bidirectional fashion. It is contemplated that in memory engine can reside in computer system or some other system or medium. In memory engine comprises a second set of data which is updated as needed with changes that have been made to the first set of data. The second set of data is the data on which the desired memory intensive computations will be run.

Referring to is shown in greater detail. Database comprises both metadata and application data . Together metadata and application data comprise the first set of data. In another embodiment application data alone comprises the first set of data.

Metadata is definitional data that provides information about application data and how the application data will be managed within system . Metadata describes the structure of application data in database and how the application data is to be synchronized with the second set of data i.e. the in memory data. Metadata is typically embodied in the form of tables. Metadata can contain information related to what information was updated and when. For example a flag may be used within a table of metadata that indicates that row seven was last updated on Mar. 3 2001 at 2 38 04 P.M.

Conversely application data comprises conventional database tables that store the data of database . An example of application data is the number of a certain item currently available in inventory.

In keeping with some embodiments according to the present invention in memory engine interfaces with plug in . Together in memory engine and plug in comprise an in memory computation system. Plug in comprises application specific software. Plug in can be changed to suit various specific applications without modifying the rest of system . Plug in contains the application specific knowledge and business logic to interpret the physical meaning of the in memory data.

Plug in plus the related content in metadata in one embodiment is the application specific part of the application software. The application specific part of the application software plug in plus the related metadata is conveniently separate from the rest of the application software. Therefore whenever the particular application changes only plug in plus the related metadata need be modified or replaced. It should be noted that plug in in one embodiment is excluded. In this embodiment the application specific modules are integrated into in memory engine or elsewhere.

Plug in puts the particular overall problem e.g. business problem which the user or an application programmer defines into a mathematical formulation or model which a generic algorithms module solver then solves. As used herein solver refers to one or any combination of generic algorithms module solver manager and other solvers. Plug in maps the raw application data from data cache into the mathematical model e.g. business model . As an example one variable in the mathematical model represents the time at which manufacturing should start.

Moreover plug in interacts with a data cache and an in memory engine manager . In one embodiment data cache generic algorithms module or generic solver and in memory engine manager comprise in memory engine . Data cache is a component that stores the in memory data i.e. the second set of data. Data cache provides an update means such as a bidirectional synchronization mechanism indicated by the dashed lines having arrowheads at both ends coupling database to data cache . Data cache is more than just a traditional data cache in one embodiment. Data cache has the capability to scan read metadata and application data . Data cache also has the capability to update write to metadata and application data . Thus data can flow from database to data cache and vice versa. In one embodiment data cache comprises logic and memory. In another embodiment data cache comprises only logic and is coupled to memory.

In further keeping with some embodiments according to the present invention the bidirectional synchronization mechanism manages changes in the content of the first set of data present in database as explained further herein. Changes in the first set of data within database flow from database to data cache and are used to update the second set of data within the data cache. In one embodiment this update happens in a near real time fashion. Moreover solutions flow from data cache to database as discussed further herein. A user through computer system then accesses solutions from database via an applications server discussed further herein.

In prior art attempts discussed herein the data being processed the second set of data was stored in a dedicated database and was not readily available in memory. Moreover if there was a change to even only a small portion of the first set of data the second set of data would not reflect these changes unless the entire first set of data was transferred and used to replace the second set of data. This would lead to inaccuracies in the results of the computations being run on the second set of data since the data was not current. Moreover it was a very time consuming process to make the second set of data current due to the fact that it would take a long time to copy over the entire first set of data which was usually voluminous.

A solution to this problem is keeping the second set of data current and readily available in memory. This is accomplished by mirroring the first set of data resident in database into data cache . When there is a change in data in database this change is almost immediately reflected in data cache by transferring to the data cache only in one embodiment the changes that have occurred in the data in database since a previous update. This methodology ensures that the data in data cache is always current. Furthermore the fact that only the change in the data rather than the entire data set is transferred saves a great deal of time and bandwidth.

These changes in data are transferred to data cache periodically in one embodiment. In another embodiment the changes in application data are transferred to data cache after a user initiates a transaction request discussed further herein .

Generic algorithms module is a generic solver that comprises the common utilities and interface to general purpose problem independent algorithms used in in memory engine . Examples of such algorithms involve linear programming mixed integer programming etc.

In memory engine manager manages various components and communications within in memory engine . Additionally in memory engine manager interfaces with database and as already mentioned plug in . In one embodiment plug in is the only application specific software and all other software is reusable. In one embodiment in memory engine plus plug in is one executable.

In further keeping with some embodiments according to the present invention illustrates one embodiment of in greater detail. An application server is provided that interfaces with computer system . In one embodiment application server interfaces with a web server not shown which in turn interfaces with computer system . The user typically interacts with computer system using a browser. Application server includes a dispatcher . Dispatcher is an application programming interface API that handles the invocation of other modules in system . The application server is coupled to database and middleware .

Middleware is in turn coupled to in memory engine manager . Middleware manages communication traffic between different server processes such as between application server and in memory engine manager .

Optional code interface is a part of in memory engine in one embodiment. Code interface is a language that gives the user the capability to customize the behavior of plug in without having to rebuild the plug in. In particular code interface allows the user to customize a graphical user interface GUI of plug in to suit the particular application.

Another part of in memory engine a data access module is coupled to database and facilitates communication of the in memory engine therewith. Specifically data access module handles communication between database and data cache . In one embodiment a SQL Access Manager SAM is the mechanism used by data access module to communicate with database .

In one embodiment also included within in memory engine are various optimization utilities . These optimization utilities include third party packages an optimization wrapper other solvers and other utilities . Third party packages are other generic algorithms modules generic solvers that can be written or purchased from various vendors and used in place of or in conjunction with generic algorithms module . Optimization wrapper is a generic layer wrapper interface. Optimization wrapper provides a generic interface so that various generic algorithms modules from various vendors or that were self written can be used. This module is an interface with plug in . Other solvers are generic algorithms modules that are self written. Other solvers can be used as alternatives to or in conjunction with third party packages . Each third party package and other solver has an optimization wrapper associated therewith. Other utilities comprise utilities that are used frequently enough to include in order to avoid having to build them from scratch. An example is a program to compute a histogram.

It is noteworthy that plug in can contain various modules as well. Some typical examples are a model representation module a solver manager and a solution strategy module .

Model representation module is an application specific module that contains information related to the specific application. In other words the model representation module contains a mathematical model of the specific real world scenario being analyzed.

Solver manager orchestrates the flow of certain information. For example solver manager passes output from generic algorithms module to plug in . Solver manager also routes various requests. Solver manager takes results from generic algorithms module and interprets them placing the result into data cache . For example if Xequals 5 the solver manager might interpret this to mean that Project 1 should be staffed with five consultants.

Solution strategy module orchestrates at a higher level how to solve the overall problem. Solution strategy module invokes generic solvers e.g. Solver X and subsequently Solver Y in order to refine the solution. Solution strategy module is basically a control mechanism for how to combine the capability of the generic solvers.

In operation according to one embodiment a user desires to use system to solve a particular overall business problem as discussed herein. Initially the user would store the pertinent data in database . As discussed this data includes information related to inventory suppliers BOMs etc. At the outset using computer system or some other means of data entry and a GUI the user also defines the overall problem to be solved which is stored in database in one embodiment. The user decides what criteria e.g. cost service quality etc. are of most and least importance at this time. The user also decides what parameters should be solved for.

The user enters business criteria stating that profit is of number one concern customer service is of number two concern and utilizing resources as desired is of number three concern in one example. Database and now data cache is already populated or is manually populated with pertinent data needed to solve the overall problem. As discussed herein this data typically changes over time as new sales orders come in inventory is depleted etc.

Referring to at step the user instructs that the overall problem overall problem instance which was previously defined and stored as data in database be initialized from database into data cache using computer system and dispatcher . The overall problem instance comprises the relevant information that is necessary to solve a particular business problem. One example of an overall problem instance in the supply chain planning context includes that customer XYZ requires of item P on Jan. 20 2002 and 3000 of item P on Feb. 15 2002 etc. Furthermore building one P item requires five P items two P items etc. With this and other information the user may want a production plan that minimizes the total cost.

Consequently the data representing the overall problem is loaded from database into data cache . Importantly all of the pertinent data is now readily available in data cache . This availability of all of the pertinent data in data cache facilitates rapid computations. In one embodiment all of the data from database is loaded into data cache . In another embodiment substantially all of the data from database is loaded into data cache . Substantially all of the data as used herein refers to a significant portion of the data but not necessarily incidental data such as data related to overhead data dependent upon the hardware that the application is running on etc.

At step solution strategy module creates a mathematical representation of the overall problem. The creation may include one or more mathematical representations that may be used in conjunction with one or more generic solvers. Plug in creates a model representation module where the mathematical representation of the overall problem is located. Model representation module is created using the data representing the overall problem that was defined by the user and other data already now resident in data cache . Mathematical models now represent much of the overall problem and data.

At step solver manager passes control to solution strategy module . Solution strategy module contains information about how to solve the overall problem using various generic solvers such as generic algorithms module .

At step solution strategy module thus invokes the appropriate generic solver s and reads from and writes to model representation module accordingly in order to produce data representing a solution to the overall problem the user is trying to solve. Then solver manager interprets this data to determine a solution that is meaningful to the user. At step solution strategy module updates data cache with the solution to the overall problem the user is trying to solve. Subsequently control passes back to solver manager and then to in memory engine manager .

Referring again to at step if application data has not changed during the solving of the overall problem then at step the data representing the solution is loaded from data cache into database via the bidirectional mechanism through data access module and is accessed by the user. The user accesses the solution via application server and computer system . At step the process returns to either step or step depending on the instructions of the user.

If at step application data has changed during the solving of the overall problem then at step the solution is discarded the user is informed and the process proceeds to step . However the user can decide to override the discarding of the problem.

With reference to step it should be noted that some of the data in database could change in various ways. For example the user can change data in database . Other examples of the changes that typically occur in the data in database include new sales orders coming in depletion of raw materials etc.

As previously mentioned as data within database changes the changes are reflected in data cache . If the user instructs at step to make a transaction request the process proceeds to step . The user may change or modify the overall problem to be solved or other data may have been modified in database . For example the user may now wish to generate a production plan that maximizes customer satisfaction e.g. shipping on time is the top priority .

This user request will automatically cause a synchronization to occur. Thus the user transaction enters engine manager and the process proceeds to step . At step engine manager instructs data cache to synchronize with database . Performing synchronization at this point is desirable because even though data from database may have recently been copied to data cache the data in database can be in a continual state of flux and may have changed since the last synchronization. Performing a synchronization means that data cache will be updated if necessary to mirror metadata and application data in database . This synchronization is performed with the assistance of the bidirectional mechanism shown by the dashed lines with arrowheads at both ends. Data cache scans through the rows of data in the metadata arrays via data access module and determines if any rows indicate a change since the last synchronization or in this case since the data from database was loaded into data cache . In order to make this check flags within metadata are examined. These flags indicate the last occurrence of updates for various parts e.g. rows of metadata tables. The update flags are compared against flags from the last update of data cache . This check will be made at the initiation of a user request.

Still referring to step the data that has changed if any is then loaded from database into data cache via the bidirectional mechanism through data access module . In one embodiment only the data in database that has changed is loaded from database into data cache . In another embodiment substantially no more than the data in database that has changed is loaded from database into data cache . For example database holds 1 gigabyte of data and only 1 kilobyte of data has changed. Only or substantially only the 1 kilobyte of changed data is loaded from database into data cache . Consequently the current data in database is resident in in memory engine and can be accessed quickly to rapidly perform memory intensive computations.

This process is much more efficient than copying over an entire database periodically or each time a data update is desired. Control is then passed back to engine manager .

At step in memory engine and plug in refine the solution as discussed with reference to step after the update of step . Refining the solution as used herein refers to solving the overall problem as before albeit using an updated set of data. Accordingly new results if different than the previous results are immediately transferred from data cache to computer system via database and application server . The process then proceeds to step and beyond as described herein.

As can be seen from this process of the first set of data within database changing the second set of data in data cache changing and the solution to the overall problem being updated if different than the previous solution when the user makes a transaction request is an ongoing process. As mentioned herein the data in data cache is updated in a near real time fashion due to the synchronization made at the onset of user requests to see if the data in database has changed since the last update. As described herein it is noteworthy that consistency of data is maintained in two ways. First changes in the first set of data are used to update the second set of data. Second when the data representing the solution to the overall problem changes data cache sends this changed data to database .

In one embodiment a module is included in in memory engine and referred to herein as model representation base classes. This module contains a set of base classes used to create the business model inside model representation module of plug in . A primary goal of these base classes is to provide structure to the plug in implementation without sacrificing flexibility. A secondary goal is to provide the plug in with an interface to data cache . The model representation base classes allow plug in to register for data cache changes look up data in data cache and make changes to the data in data cache . Additionally the model representation base classes provide a mechanism to pass messages between objects in model representation module in order to maintain overall model integrity. For example if a customer order object is deleted other objects related to the supply chain plan for that customer order need to deleted or adjusted. This change notification occurs by sending a delete message from the customer order object to the plan objects that depend on it. This mechanism is built into the base classes so that the plug in specific tangible classes can take advantage of it in model representation module .

Thus a system has been shown and described that exhibits an efficient mechanism to handle near real time bidirectional synchronization between a database and an application. System continuously and efficiently updates data resident in memory a near real time fashion. System computes a solution that changes when the data resident in memory is updated. It should be noted that unlike in the prior art a separate GUI does not need to be created for each specific application. There is one GUI that is a part of system that is independent of the various plug ins that can be used.

Subsystems within computer system are directly interfaced to an internal bus . The subsystems include an input output I O controller a system random access memory RAM a central processing unit CPU a display adapter a serial port a fixed disk and a network interface adapter . The use of the bus allows each of the subsystems to transfer data among the subsystems and most importantly with CPU subsystem. External devices can communicate with CPU or other subsystems via bus by interfacing with a subsystem on the bus.

One embodiment according to the present invention is related to the use of an apparatus such as computer system for implementing a system according to embodiments of the present invention. CPU can execute one or more sequences of one or more instructions contained in system RAM . Such instructions may be read into system RAM from a computer readable medium such as fixed disk . Execution of the sequences of instructions contained in system RAM causes the processor to perform process steps such as the process steps described herein. One or more processors in a multi processing arrangement may also be employed to execute the sequences of instructions contained in the memory. In alternative embodiments hard wired circuitry may be used in place of or in combination with software instructions to implement the invention. Thus embodiments of the invention are not limited to any specific combination of hardware circuitry and software.

The terms computer readable medium and computer readable media as used herein refer to any medium or media that participate in providing instructions to CPU for execution. Such media can take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media include for example optical or magnetic disks such as fixed disk . Volatile media include dynamic memory such as system RAM . Transmission media include coaxial cables copper wire and fiber optics among others including the wires that comprise one embodiment of bus . Transmission media can also take the form of acoustic or light waves such as those generated during radio frequency RF and infrared IR data communications. Common forms of computer readable media include for example a floppy disk a flexible disk a hard disk magnetic tape any other magnetic medium a CD ROM disk digital video disk DVD any other optical medium punch cards paper tape any other physical medium with patterns of marks or holes a RAM a PROM an EPROM a FLASHEPROM any other memory chip or cartridge a carrier wave or any other medium from which a computer can read.

Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to CPU for execution. Bus carries the data to system RAM from which CPU retrieves and executes the instructions. The instructions received by system RAM can optionally be stored on fixed disk either before or after execution by CPU .

Many subsystem configurations are possible. is illustrative of but one suitable configuration. Subsystems components or devices other than those shown in can be added. A suitable computer system can be achieved without using all of the subsystems shown in .

The above description is illustrative and not restrictive. Many variations of the invention will become apparent to those of skill in the art upon review of this disclosure. The scope of the invention should therefore be determined not with reference to the above description but instead should be determined with reference to the appended claims along with their full scope of equivalents.

