---

title: Acoustic pattern identification using spectral characteristics to synchronize audio and/or video
abstract: Embodiments of the invention relate generally to computing devices and systems, software, computer programs, applications, and user interfaces for identifying acoustic patterns, and more particularly, to determining equivalent portions of audio using spectral characteristics to, for example, synchronize audio and/or video captured at multiple cameras or different intervals of time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08849432&OS=08849432&RS=08849432
owner: Adobe Systems Incorporated
number: 08849432
owner_city: San Jose
owner_country: US
publication_date: 20070531
---
Embodiments of the invention relate generally to computing devices and systems software computer programs applications and user interfaces for identifying acoustic patterns and more particularly to determining equivalent portions of audio using spectral characteristics to for example synchronize audio and or video captured at multiple cameras or different intervals of time.

When editing audio and video captured either by multiple cameras or in multiple takes of the same scene e.g. with a single audio video capture device traditional media editing applications typically operate on the premise that audio portions captured at different cameras angles are coextensive with the captured video and thus align at a common point in time. But this is often not the case. In practice audio in multiple takes vary due slight variances in delivery volume word usage utterances etc. For example the actors can ostensibly deliver the same lines in each take but they might inevitably differ somewhat in timing. Sometimes they will actually say slightly different things as well which varies the audio from take to take. Whereas in multiple camera applications the spatial arrangement of the cameras as well as the environment can also contribute to deviations in audio relative to some point in time. These deviations which can be as small as a fraction of a second can lead to two or more captured audio portions being out of synchronization as perceived for example by a human listener. Further the efforts to edit audio and video captured in digitized form are usually exacerbated by the amounts of raw audio and video requiring editing. Specifically editors typically expend much effort usually manually to search through significant amounts of content to find audio that can be synchronized for use in a final product.

One common technique for identifying similar video captured at capture devices and is to implement time codes associated with each video or otherwise use some sort of global synchronization signal to synchronize both the video and audio portions. In particular a user is usually required to manually adjust the different videos to bring their time codes into agreement. A time code normally describes the relative progression of a video images in terms of an hour minute second and frame e.g. HH MM SS FR . But a drawback to using time codes to identify similar audio e.g. to synchronize audio requires the user to identify different video portions to a particular frame before synchronizing the audio portions. The effort to identify similar audio portions is further hindered due to the number of samples of audio sound that is captured relative to the number of video frames. Typically for each frame of video e.g. 30 frames per second there are 1 600 samples of audio e.g. 48 000 samples per second . As such audio portions for capture devices and are typically synchronized based on the video portions and their time codes which can contribute to undesired sound delays and echoing effects. Another common technique for synchronizing the audio and the video captured at capture devices and is to use a clapper to generate a distinctive sound during the capture of the audio and video. A clapper creates an audible sound as a reference sound to synchronize audio during the capture of the audio. The clapper sound is used for editing purposes and would otherwise be discarded during editing. The time codes and clapper sounds thus require effort to ensure their removal as they are intended for editing purposes and are distracting to an audience if time codes remain visible or clapper sounds remain audible in the final product. A drawback to using a clapper as noise to synchronize audio is that the distance from noise and capture devices and can cause delays that hinder synchronization of the audio relating to scene .

It would be desirable to provide improved computing devices and systems software computer programs applications and user interfaces that minimize one or more of the drawbacks associated with conventional techniques for identifying acoustic patterns to for example synchronize either audio or video or both.

Like reference numerals refer to corresponding parts throughout the several views of the drawings. Note that most of the reference numerals include one or two left most digits that generally identify the figure that first introduces that reference number.

In view of the foregoing acoustic pattern identifiers and of respectively can implement spectral characteristics to identify matching audio portions for a variety of applications including but not limited to synchronizing audio and video for producing media such as movies or videos. In various embodiments a spectral characteristic can be resistant to additive noise and amplitude variations for audio waveforms that include speech. As such an acoustic pattern identifier in accordance with at least one embodiment can match audio having different amplitudes due to for example different audio being captured at different angles of multiple cameras. The different audio can be affected by differences in tone background noise volume and the like. A spectral characteristic can also facilitate matching audio that can include speech that is spoken at different rates for example over multiple takes of the same scene or with some variants in speech. For example actors might deliver their lines at different speeds over multiple takes and they might say different things as well. An actor might say hi dude in one take but might say yeah hi dude in another take with the latter including a variant in speech i.e. the word yeah . As such an acoustic pattern identifier of at least one embodiment can match audio that includes speech spoken with either different cadences used by an actor over multiple takes of the same scene or with additions or omissions of utterances and or words such as uh spoken in one scene and ah uh in another. Further the use of spectral characteristics reduces the necessity to find similar parts of audio by using either strings of words e.g. by matching text or phonemes which are basic distinctive units of speech sounds that constitute intelligible speech including words. The computational overhead to implement word based matching in a speech recognition processes as well as deviations from the spoken script e.g. actors deviating from the script and in delivery for each of multiple takes of a scene can affect the matching of words. Matching phonemes usually require matching phonetic labels or other values representing similar sounds such as uh oh and the like. Phonetic labeling may not provide a sufficient number of possible phonemes especially when multiple persons speak either serially or concurrently. In addition the implementation of acoustic pattern identifiers and can conserve resources and computational overhead by reducing the need to implement speech recognition hardware and or software processes to match words and or phonemes for the purposes of finding matching audio portions. Also the implementation of acoustic pattern identifiers and can synchronize at least two portions of the after the two portions of audio are captured.

As used herein the term spectral characteristic refers generally at least in one embodiment to an attribute characteristic property quality or state of audio or a portion thereof that can be used to determine whether two or more portions of audio are either equivalent or are not equivalent. A spectral characteristic can be numeric or otherwise and can describe in whole or in part a portion of audio in terms of or based on frequency and or power distribution e.g. over frequencies . In one embodiment the determination of a spectral characteristic can be either a sufficient step or an intermediary step for generating a spectral signature. In some examples spectral characteristics can relate to a shape or pattern of frequency spectra e.g. in terms of amplitude and frequency or can be spectral coefficients. As used herein the term spectral signature refers generally at least in one embodiment to a sample of a portion of audio that can be expressed in terms of a spectral characteristic such as a spectral coefficient. In various embodiments a degree of correlation for spectral signatures among different audio portions can be calculated to determine the similarity between samples of audio portions. As used herein the term spectral coefficient refers generally at least in one embodiment to a representation of amplitude e.g. a value indicating acoustic energy at a specific frequency. Examples of spectral coefficients include Fourier series coefficients layered or low energy coefficients auto correlation coefficients linear prediction coefficients and the like as well as cepstral coefficients such as linear prediction based cepstral coefficients LPCC Fast Fourier Transform FFT based cepstral coefficients MEL cepstrum coefficients and the like.

As used herein the term matched audio portions refers generally at least in one embodiment to portions of audio having equivalent or substantially equivalent spectral signatures or spectral coefficient based measures such as distances with which to correlate different spectral signatures. Note that matched audio portions can include variant audio such as is the case with audio portions captured during multiple takes of the same scene where actors might speak at different rates of speech interject or omit different words and the like. Regardless acoustic pattern identifiers of various embodiments can be configured to correlate audio portions with variant audio to form matched audio portions based on the equivalency of for example spectral signatures. As used herein the term acoustic pattern refers generally at least in one embodiment to the groupings e.g. sequences of either spectral signatures or spectral coefficient based measures such as distances or both. Such groupings can indicate matched audio portions. In one embodiment the magnitude of the spectral coefficient based measures such as distances can be used to determine trough distances which signify matching audio portions. In a specific embodiment a relationship e.g. a linear relationship between spectral signatures and their distances provide for an acoustic pattern that is indicative of matching audio portions.

As used herein the term audio refers generally at least in one embodiment to one or more sounds that are audible e.g. perceived by humans and can be of or relate to the transmission storage reproduction or reception of sound. For example audio can be in the form of an audio waveform an audio file an audio signal an audio clip an audio track and the like. As used herein the term video refers generally at least in one embodiment to one or more images that are visible e.g. perceived by humans and can be of or relate to the transmission storage reproduction or reception of images. For example video can be in the form of a video waveform a video file a video signal a video clip a video track and the like. As used herein the term content refers generally at least in one embodiment to information and or material presented within a display an interface or the like in relation to for example an audio and or visual presentation of sounds and or imagery. Examples of content include text such as an electronic document e.g. a document in Portable Document Format PDF as well as audio images audio video media such as Flash presentations text and the like. As such a content file or media file can include a digital data file which is composed of images sound and words for one camera angle. As used herein the term panel at least in one embodiment can refer to displays palettes tabs windows screens portions of an interface and the like.

To illustrate the operation of spectral signature generator and a spectral signature correlator consider the following example. As is shown spectral signature generator can be configured to analyze audio Audio and audio audio to generate arrangements e.g. vectors not shown of spectral signatures and respectively. In particular spectral signature generator can generate a spectral signature at each unit of time such as spectral signatures SS at i 1 SS at i SS at i 1 for audio and can generate a spectral signature at each unit of time such as spectral signatures SS at j 1 SS at j SS at j 1 for audio . In one embodiment one spectral signature and one spectral signature can be generated at each 1 100of a second. Spectral signature correlator can be configured to calculate a correlation or a degree of correlation among spectral signatures and . In one embodiment spectral signature correlator can determine a calculated correlation between a specific spectral signature and a specific spectral signature whereby groupings of calculated correlations can be indicative of matching audio portions between audio and audio . In one embodiment the calculated correlations between spectral signature and spectral signature can be distances.

In a specific embodiment spectral coefficient calculator can be configured to operate as a linear prediction based cepstral coefficient LPCC calculator to characterize portions of audio based on cepstral coefficients such as linear prediction based cepstral coefficients. In one example spectral coefficient calculator implementing linear prediction based cepstral coefficient calculator can generate linear prediction based cepstral coefficients as follows. One or more of spectral audio matcher spectral signature generator and spectral coefficient calculator either alone or in combination can digitize audio from either audio file or audio file and in some cases subdivide the audio into frames over which linear prediction coefficients LPCs can be generated.

Linear prediction based cepstral coefficient calculator can convert the linear prediction coefficients into linear prediction based cepstral coefficients. In some instances spectral coefficient calculator can implement the Levinson Durbin algorithm as is known to generate the linear prediction based cepstral coefficients. In at least one embodiment linear prediction based cepstral coefficient calculator can calculate linear prediction based cepstral coefficients in accordance with an inverse z transform of the logarithm of the spectrum. In some cases spectral signature generator can generate a portion of the linear prediction based cepstral coefficients using at least a frequency domain with the linear prediction based cepstral coefficients being in the time domain. In a specific embodiment linear prediction based cepstral coefficient calculator can implement about 14 linear prediction based cepstral coefficients which can represent a spectral shape in a level independent manner. In some instances the linear prediction based cepstral coefficients are quantized or include a degree of quantization in accordance with a k means Vector Quantization algorithm which is known to form for example an 8 bit number to represent a spectral signature.

In one embodiment spectral coefficient calculator is configured to generate linear prediction based cepstral coefficients as spectral signatures at a rate that can be in the fractions of a second such as one generated linear prediction based cepstral coefficient per 1 100of a second. As such spectral coefficient calculator can generate 100 spectral signatures as samples for one second of audio in audio file and audio file . Spectral coefficient calculator provides these spectral signatures to spectral signature correlator which in some embodiments can be configured to calculate correlations among the spectral signatures for audio file and audio file to form calculated correlations.

In this example spectral signature correlator includes a spectral signature distance engine a pattern detector and a pattern parametric manager . In a specific embodiment spectral signature distance engine is configured to determine a distance representing a correlation or a degree of correlation between multiple spectral signatures from for example audio files and . As such spectral signature correlator can determine a distance that is indicative of whether spectral signatures associated with audio file are equivalent or substantially equivalent to spectral signatures associated with audio file . As used herein the term distance at least in one embodiment can refer to any measure that can be used to determine the degree of similarity between two or more spectral signatures.

In one embodiment spectral signature distance engine computes a distance from one spectral signature SS to another spectral signature SS as follows Distance Distance log 1 sqrt SS SS 2 for summation over N coefficients. Further SS Ceps means std i and SS Ceps means std j where Ceps is the icoefficient for audio file means is the imean for audio file std i is the istandard deviation Ceps is the jcoefficient for audio file means is the jmean for audio file std j is the jstandard deviation.

Pattern parametric manager among other things is configured to manage the determination of whether a specific distance is sufficient to deem two spectral signatures as being associated with the same portion of audio or substantially so . For example pattern parametric manager can set a threshold below which a distance is sufficiently short enough for corresponding spectral signatures to be considered as being part of the same portion of audio. In some cases this threshold is referred to as a trough distance.

Pattern detector can be configured to detect whether a pattern of spectral signatures or any other spectral characteristic an be determined whereby a pattern i.e. an acoustic pattern can be indicative of whether matching portions of audio can be identified. In one embodiment pattern detector can operate to detect patterns in which the distances for the portions of the audio are substantially coextensive to for example a linear relationship. That is the distances indicating a match for the portions of the audio track each other as time linearly progresses e.g. for each 1 100of a second for both audio files and . Detected patterns can be output as matched audio portion s .

Optionally spectral audio matcher can provide the matched audio portion or identifiers thereof to audio video synchronizer to synchronize audio and or video at a synchronization point. In one embodiment audio video synchronizer includes a cross correlator that is configured to perform a cross correlation operation for synchronization purposes. The cross correlation operation can implement known statistics to use cross correlation to measure the similarity of two signals. Further if the audio files in audio files and are offset from each other in relation to time then the cross correlation operation can figure out the offset for aligning or synchronizing audio files and . In one embodiment cross correlator correlates audio in a 1 second interval for each of audio files and .

An acoustic pattern identifier implementing spectral signature distance engine and pattern detector can determine matching audio portions for audio captured during multiple takes of the same scene according to at least one embodiment of the invention. To illustrate consider the following in which two different people are interacting with each other. In this case first grouping can relate to audio i.e. speech generated by a first person whereby second grouping can relate to audio generated by a second person.

Note that second grouping begins approximately after first grouping finishes at S of the X axis . As such the two persons speak in substantially a consecutive non overlapping fashion. Further the timing between the two audio files is fairly synchronized as evidenced by for example the equivalent duration for first grouping which spans 5 units of time in both audio e.g. S to S of the X axis and audio e.g. S to S of the Y axis. Audio files and can have a higher degree of synchronization should audio begin at S of the Y axis not shown which would be in synchronicity with audio beginning at S of the X axis.

Note too that the speech delivered in both audio and audio relating to first grouping is shown to be spoken at approximately the same speed. For purposes of discussion consider that the slope of a linear relationship coextensive with a diagonal line not shown defined by first grouping is 45 degrees. In cases where audio is delivered more slowly than audio then one would expect the slope of the linear relationship to increase over 45 degrees because audio which otherwise covers 5 units of time would be extended to for example 6 8 units of time not shown . The opposite can be true for cases in which audio is delivered more quickly than audio .

Moreover consider an instance in which the first person adds or omits utterances or speech in audio relative to audio . While spectral signature distance engine might generate some distances that are not within a trough distance i.e. indicating mismatches in audio for some samples or spectral signatures due to for example an omitted uh sound pattern detector can nevertheless operate to determine a pattern such as first grouping based on a tolerance for such variances in speech.

Note further that in some instances in which multiple people speak at the same time such as in a situation in which two people in a coffee shop each give an exact same order for coffee at the same time. Since their speech overlaps each other spectral signature distance engine might generate distances that may or may not be associated with higher values of distances e.g. signifying less of a match . But pattern detector can nevertheless operate to determine a pattern based on a tolerance for such variances in speech and or spectral signatures. In view of the foregoing example an acoustic pattern identifier can match audio portions for first grouping regardless of the differences in the rate of speech or audio between audio and audio as well as the differences in utterances or speech i.e. different portions of speech in audio relative to audio .

According to some examples computer system performs specific operations in which processor executes one or more sequences of one or more instructions stored in system memory . Such instructions can be read into system memory from another computer readable medium such as static storage device or disk drive . In some examples hard wired circuitry can be used in place of or in combination with software instructions for implementation. In the example shown system memory includes modules of executable instructions for implementing an operation system O S an application e.g. a host client web services based distributed i.e. enterprise application programming interface API program procedure or others and an audio synchronization point generation module .

The term computer readable medium refers at least in one embodiment to any medium that participates in providing instructions to processor for execution. Such a medium can take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media includes for example optical or magnetic disks such as disk drive . Volatile media includes dynamic memory such as system memory . Transmission media includes coaxial cables copper wire and fiber optics including wires that comprise bus . Transmission media can also take the form of acoustic or light waves such as those generated during radio wave and infrared data communications.

Common forms of computer readable media includes for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge carrier wave or any other medium from which a computer can read.

In some examples execution of the sequences of instructions can be performed by a single computer system . According to some examples two or more computer systems coupled by communication link e.g. LAN PSTN or wireless network can perform the sequence of instructions in coordination with one another. Computer system can transmit and receive messages data and instructions including program code i.e. application code through communication link and communication interface . Received program code can be executed by processor as it is received and or stored in disk drive or other non volatile storage for later execution. In one embodiment system is implemented as a hand held device But in other embodiments system can be implemented as a personal computer i.e. a desk top computer or any other computing device.

In at least some of the embodiments of the invention the structures and or functions of any of the above described elements can be implemented in software hardware firmware circuitry or a combination thereof. Note that the structures and constituent elements described above as well as their functionality can be aggregated with one or more other structures or elements. Alternatively the elements and their functionality can be subdivided into constituent sub elements if any. As software the above described described techniques can be implemented using various types of programming or formatting languages frameworks syntax applications protocols objects or techniques including C Objective C C C Flex Fireworks Java Javascript AJAX COBOL Fortran ADA XML HTML DHTML XHTML HTTP XMPP and others. These can be varied and are not limited to the examples or descriptions provided.

The foregoing description for purposes of explanation used specific nomenclature to provide a thorough understanding of the invention. However it will be apparent to one skilled in the art that specific details are not required in order to practice the invention. In fact this description should not be read to limit any feature or aspect of the present invention to any embodiment rather features and aspects of one embodiment can readily be interchanged with other embodiments.

Thus the foregoing descriptions of specific embodiments of the invention are presented for purposes of illustration and description. They are not intended to be exhaustive or to limit the invention to the precise forms disclosed many alternatives modifications equivalents and variations are possible in view of the above teachings. For the purpose of clarity technical material that is known in the technical fields related to the embodiments has not been described in detail to avoid unnecessarily obscuring the description. Thus the various embodiments can be modified within the scope and equivalents of the appended claims. Further the embodiments were chosen and described in order to best explain the principles of the invention and its practical applications they thereby enable others skilled in the art to best utilize the invention and various embodiments with various modifications as are suited to the particular use contemplated. Notably not every benefit described herein need be realized by each embodiment of the present invention rather any specific embodiment can provide one or more of the advantages discussed above. In the claims elements and or operations do not imply any particular order of operation unless explicitly stated in the claims. It is intended that the following claims and their equivalents define the scope of the invention.

