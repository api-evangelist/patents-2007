---

title: Differential file compression of software image versions
abstract: Embodiments include systems and methods for pre-processing and post-processing original and new versions of files as part of difference file generation between the original and new file versions. The systems and methods of an embodiment include a set of algorithms that reduce the difference file size by preprocessing a variety of regions in software images for embedded computing devices, an example of which is the compressed read-only memory (ROM) file system (CRAMFS) image. The algorithms treat a variety of types of data regions that are created by the compiler. Embodiments operate on the server side and the client side. On the server side, the preprocessing generates Compact Functional Differences (CFD) hint data directly from a pair of CRAMFS images, without the use of symbol files or log files generated by compiler/linker utilities.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07676506&OS=07676506&RS=07676506
owner: Innopath Software, Inc.
number: 07676506
owner_city: Sunnyvale
owner_country: US
publication_date: 20070509
---
This application claims priority from U.S. Provisional Patent Application No. 60 799 578 filed May 10 2006.

This application is a continuation in part application of U.S. patent application Ser. No. 11 432 984 filed May 12 2006 which claims priority to U.S. Provisional Patent Application No. 60 720 264 filed Sep. 23 2005. U.S. patent application Ser. No. 11 432 984 is a continuation in part application of U.S. patent application Ser. No. 10 600 978 filed Jun. 20 2003 now U.S. Pat. No. 7 089 270.

Software running on a processor microprocessor and or processing unit to provide certain functionality often changes over time. The changes can result from the need to correct bugs or errors in the software files adapt to evolving technologies or add new features to name a few. In particular embedded software components hosted on mobile processing devices for example mobile wireless devices often include numerous software bugs that require correction. Software includes one or more files in the form of human readable American Standard Code for Information Interchange ASCII plain text files or binary code. Software files can be divided into smaller units that are often referred to as modules or components.

Portable processor based devices like mobile processing devices typically include a real time operating system RTOS in which all software components of the device are linked as a single large file. Further no file system support is typically provided in these mobile wireless devices. In addition the single large file needs to be preloaded or embedded into the device using a slow communication link like a radio infrared or serial link.

Obstacles to updating the large files of mobile processing devices via slow communication links include the time bandwidth and cost associated with delivering the updated file to the device. One existing solution to the problem of delivering large files to mobile processing devices includes the use of compression. While a number of existing compression algorithms are commonly used often however even the compressed file is too large for download to a device via a slow costly narrowband communication link.

Another typical solution for updating files uses difference programs to generate a description of how a revised file differs from an original file. There are available difference programs that produce such difference data. However as with compression the difference files produced using these difference programs can sometimes be too large for transfer via the associated communication protocols.

Each publication patent and or patent application mentioned in this specification is herein incorporated by reference in its entirety to the same extent as if each individual publication and or patent application was specifically and individually indicated to be incorporated by reference.

Systems and methods are provided for pre processing original and new versions of files as part of difference file generation between the original and new file versions. This pre processing supports a further reduction in the size of the difference file. Software executable changes between file versions include primary changes logical changes which are defined to be the source code changes and secondary changes. The secondary changes generally result from the primary changes and are generated by the software compiler linker utilities. The secondary changes include address changes pointer target address changes and changes in address offsets resulting from the primary changes and generated by the software compiler linker utilities. The pre processing systems and methods provided use approximation rules between file versions to remove reduce the secondary changes and encode information relating to the removal of these changes in information of the corresponding difference file.

The systems and methods of an embodiment include a set of algorithms that reduce the difference package size by preprocessing a variety of regions in software images for embedded computing devices an example of which is the compressed read only memory ROM file system CRAMFS image. These regions are collectively referred to herein as Compact Functional Differences CFD preprocessing regions. One of the main types of CFD preprocessing regions includes the various large tables of pointers that are common in execute in place XIP files pre linked execute in place files . However the algorithms are not limited to these tables and they also treat a variety of other types of regions that are created by the compiler.

Preprocessing systems and methods described below and referred to herein as XIP preprocessing perform tasks on both the client side as well as the server side. On the server side the XIP preprocessing generates CFD hint data directly from a pair of CRAMFS images without the use of symbol files or log files generated by compiler linker utilities. One example of how to apply the XIP preprocessing is to look at the XIP files in the old and new CRAMFS file systems and look for files with matching paths. Approximate matching techniques are used to find regions in these files that are in correspondence and have the necessary alignment properties. Then the differences between these regions are analyzed in order to describe them using a transformation that depends only on the values of groups of N bytes not their addresses. The value of N can for example be four 4 but it is not limited to this value. It is possible to describe these transformations using quite general functions G x where x is an N byte value. A class of functions that is very successful is the form where f is a piece wise constant function. The algorithms take into account the trade off between increasing the preprocessing success rate and keeping the overall amount of preprocessing data small. On the client side the XIP post processing strives to apply the changes in a way that is fast and uses minimal memory.

In some cases the improvements due to the preprocessing described herein are dramatic because a large number of changes can be encoded using just a few bytes of data to store a simple f function. The best cases are the regions of pure data pointers which were the original motivation for the CFD preprocessing techniques.

In the following description numerous specific details are introduced to provide a thorough understanding of and enabling description for embodiments of the XIP processing. One skilled in the relevant art however will recognize that the XIP processing can be practiced without one or more of the specific details or with other components systems etc. In other instances well known structures or operations are not shown or are not described in detail to avoid obscuring aspects of the XIP processing.

The XIP preprocessing of an embodiment includes client side referred to herein as DUC side topics and server side referred to herein as NSCD side topics. The DUC side topics include but are not limited to the following definitions of the f function XIP hint file format how to apply faster implementations and ways to reduce DUC memory requirements. The NSCD side topics include but are not limited to the following how to create XIP hint data work on making the package smaller speed of applying the hints is less important and speed of creating the hints is less important.

On the NSCD side there are two steps Step 1 and Step 2 which are described below. There are two steps because of use of the idea of preprocessing the new image rather than the old and there is a need to know the list of postprocessor calls to calculate the fix up data. For the case of XIP preprocessing a mandatory scenario in which this is relevant is when the start address or end address of a postprocessor call is not 4 byte aligned. Then the 4 byte value that is split cannot be treated as one of the 4 byte values that are transformed by the post processing algorithms. Therefore any changes that need to be encoded here would have to be encoded as fix up data. Another scenario this one is optional is that the CRAMFS block dependency algorithms might decide not to use a preprocessed portion. Then this portion would not be present in the list of postprocessor calls and therefore it would not require any fix up data so it would be wasteful to store fix up data for this portion.

It is easier to understand why fix up data is needed for XIP post processing than ARM post processing. XIP post processing is based on the transformation x f x where f is a piece wise constant function that can be stored with a small amount of data which is part of the XIP hint data the other main part of the XIP hint data is the specification of the regions where the post processing is to be applied . If the region being post processed includes two identical 4 byte values at different locations and the result after post processing is supposed to have two different values then this cannot be accomplished by the transformation x f x the region would be split which might use more hint data than storing the fix up data.

Systems and methods for generating difference files between two versions of an electronic file herein referred to as file differencing including XIP processing are described in detail herein. is a block diagram showing file differencing and updating provided under an embodiment. The file differencing and updating includes a differencing component and an updating component. The differencing component referred to herein as the file difference generator generates a difference file in a first processor based or computer system from an original version and a new version of an electronic file. The updating component referred to herein as the update generator generates a copy of the new file on a second processor based or computer system using the difference file and the hosted copy of the original file.

In the following description numerous specific details are introduced to provide a thorough understanding of and enabling description for embodiments of the invention. One skilled in the relevant art however will recognize that the invention can be practiced without one or more of the specific details or with other components systems etc. In other instances well known structures or operations are not shown or are not described in detail to avoid obscuring aspects of the invention.

With reference to a first computer system and a second computer system communicate via a communication path . These computer systems and include any collection of computing components and devices operating together as is known in the art. The computer systems and can also be components or subsystems within a larger computer system or network.

The communication path includes any medium by which files are communicated or transferred between the computer systems and . Therefore this path includes wireless connections wired connections and hybrid wireless wired connections. The communication path also includes couplings or connections to networks including local area networks LANs metropolitan area networks MANs wide area networks WANs proprietary networks interoffice or backend networks and the Internet. Furthermore the communication path includes removable fixed mediums like floppy disks hard disk drives and CD ROM disks as well as telephone lines buses and electronic mail messages.

The first communication system receives an original or old version and a new version of an electronic file. The new file is generally an updated or revised version of the original file but is not so limited. The electronic files and include software files including dynamic link library files shared object files embedded software components EBSCs firmware files executable files data files including hex data files system configuration files and files including personal use data but are not so limited. Since any type of file can be regarded as a byte stream hereinafter a file can be described as a byte stream depending on the context.

Components of the file difference generator receive the new file compare it to the original file and calculate the differences between the compared files as described below. These differences include byte level differences between the compared files but are not so limited. The file difference generator generates a difference file referred to herein as a delta file during the comparison.

The file difference generator of an embodiment couples among components of the host computer system where the components include at least one of a processor at least one controller at least one memory device and at least one bus but is not so limited. The components of the file difference generator of an embodiment include at least one pre processing subsystem and at least one differencing subsystem . The pre processing subsystem also referred to as the pre processor includes at least one processor running under control of at least one pre processing algorithm program or routine. Likewise the differencing subsystem includes at least one processor running under control of at least one differencing algorithm program or routine.

Contents of the delta file provide an efficient representation of the differences between the new files and the original files . The delta file includes meta data along with actual data of replacement and or insertion operations that represent the differences between the new or current version of the associated file and previous versions of the file as described in the United States patent application entitled Byte Level File Differencing and Updating Algorithms application Ser. No. 10 146 545 filed on May 13 2002. The file difference generator provides any differences between the original and the new files in the delta file using a minimum number of bytes and a pre defined format or protocol thereby providing a delta file optimized in space.

The delta file is transferred or transmitted to another processing system via the communication path . Prior to transfer the delta file may be compressed using compression techniques known in the art but is not so limited. The update generator hosted on the receiving system uses the delta file along with the hosted original file H to generate or create a copy of the new file C. This copy of the new file C is then used to update the original file H hosted on the client device that is targeted for revision or updating. Upon completion of this update process the new file now stored on the second computer system is identical to the new file received in the first computer system .

The differences between an original file and a new file are typically smaller than the new file leading to significant storage and transmission savings if the differences are transmitted and stored instead of the entire new file. This is particularly important for mobile electronic devices client devices hosting programs that are updated via connections that typically can be slow and expensive for example wireless or cellular connections. The reduced size of the delta file provides numerous improvements one of which includes a reduction in bandwidth required for transmission of the delta file to the client device the smaller file means less bandwidth is required for the transfer. Also smaller files require less time for transmission and therefore decrease the probability that the file transfer will be interrupted and simultaneously reduce transmission errors in the received file. In addition it is safer to transmit the delta files than the new software images via a non secure connection. All of these improvements increase customer satisfaction.

Pre processing operations are performed between contents of the new file and the original file in order to identify common segments and simple patterns among contents of the two files at block . Generally the pre processing uses identified common segments and patterns to reduce remove the secondary changes between the new and original files. The pre processing of an embodiment includes reducing and or removing changes between the original and new files resulting from address shifts associated with logical changes as described below but is not so limited. Thus this pre processing reduces the differences among common segments of the files including secondary changes thereby increasing the efficiency of the difference calculation.

Following pre processing the byte level differences are calculated between the new file and the modified original file at block . The calculated differences are coded and merged and the delta file is generated by following the pre defined encoding format at block . The delta file is then optimized as is known in the art to further reduce the file size when possible at block and the optimized delta file is provided as an output at block .

As described above pre processing operations are performed between the contents of the new file and the original file in order to identify common segments and simple patterns among contents of the two files. The knowledge of common segments and simple patterns is used to reduce remove the secondary changes thereby resulting in an overall performance gain.

As described above the transmission of electronic file or software upgrades between a system and a client device can take a significant amount of time especially when done via low bandwidth channels. An example is a cellular telephone software upgrade. It has become typical practice to send the byte level file differences or changes between the new and original software versions over the cellular wireless couplings. The significant transfer time arises because the differences between the new and original versions of the executable files are more complex than the differences between their corresponding source files.

These complex differences between the new and original file versions arise in part because a small change in the source files often introduces major changes throughout the executable files. As an example the changes introduced in the executable files include two main types of changes primary changes and secondary changes. The primary changes also referred to as logical changes are source code changes arising from source code line deletion from the original file source code line addition to the new file and source code line modifications. The secondary changes are defined to include but not limited to address changes pointer target address changes and changes in address offsets resulting from the primary changes and generated by the software compiler linker utilities. The pre processing routines described below remove reduce the secondary changes and encode information relating to the removal of these changes in information of the corresponding delta file.

An analysis of the secondary changes introduced in the executable files begins with an assumption that the executable files include code text sections and data sections. is a block diagram showing an original V and a new V version of an executable file. The original V and new V versions both include a code text section and and a data section and . The new version V differs from the original V in that the new version V includes an additional block of new code of size 0x500. The presence of the block of new code introduces two types of secondary changes.

A first type of secondary change occurs in the code text section of the new version V and results in the branch instruction BRANCH having a different branch displacement also referred to as the relative address or branch offset resulting from the addition of the block of new code between the address of the branch instruction BRANCH and the target instruction address TARGET. In this example the target instruction address is 0x1000 and the branch instruction address is 0x3000 resulting in a branch displacement of 0x2000 0x3000 0x1000 in the original version. The addition of the block of new code size 0x500 between the branch instruction address and the target instruction address changes the branch instruction address to 0x3500 0x3000 0x500 . Therefore the branch displacement in the new version V changes to 0x2500 0x3500 0x1000 .

A second type of secondary change occurs in the data section of the new version V and results in a change of the value stored in the data pointer POINTER or the data pointer value which stores the absolute address of a corresponding data area. The change of the data pointer value results from the addition of the new code in the code text section. The new code is inserted at a point in the original version that precedes the data section . Thus the data pointer value which is 0x8000 in the original version changes to 0x8500 0x8000 0x500 in the new version.

As the software development becomes increasingly complicated the secondary changes spread throughout the executable files to the point that the secondary changes can outnumber the primary changes when considered in the context of byte level file differencing. The pre processing routines described below use relationships between the original and new versions of files to reduce the amount of information encoded in the delta file as to differences relating to the secondary changes. With the minimum information the effect of cascading computations can be achieved when doing byte level differencing and reconstructing thereby reducing the size of the delta file.

Generally the pre processing routine of an embodiment includes at least one approximation routine and at least one merging routine for use in minimizing the delta file size. The approximation routines function to reduce remove secondary changes according to text code and data model assumptions. The merging routines also referred to as a hint merging routines encode the model information at a least cost level for transfer to devices receiving the new versions. The model information is used in the recovery of the new version in the device as described above but is not so limited.

The pre processor next assigns a unique index or index value to each unique function unit at block . This assignment of index values to unique function units supports identification of function units that are common to both the original and new file versions. Consequently when the same function unit is found in both the original and the new versions of the file that function is assigned a common index value but the embodiment is not so limited.

As an example consider an original file version that includes original function units F F F and F and a new file version that includes new function units F F F and F. If the pre processor indexes function units F F F F and F using index values 1 2 3 4 and 5 respectively the following table is assembled for the original file version 

In both of these tables startAddress is generally defined as the starting address of the corresponding function unit therefore startAddressV is the startAddress of a function unit of the original file and startAddressV is the startAddress of a function unit of the new file. Further the endAddress is generated by adding the function unit size to the starting address of the function unit so that endAddress startAddress function unit size but the embodiment is not so limited. Consequently endAddressV is defined as an endAddress for a function unit of the original file while endAddressV is defined as an endAddress for a function unit of the new file. This definition of ending address is also applied to data units herein but is not so limited.

Continuing the pre processor generates a HintTable of common function units using information of the index value starting address and ending address from the tables above at block . The HintTable includes information of the common function units assembled in one table including index value the starting and ending addresses of the original function units of the original file version V and the starting and ending addresses of the new function units of the new file version V . The information of the HintTable is arranged using any number of techniques known in the art. Using the information above the HintTable of an embodiment is generated as follows 

The pre processor continues with the generation of new target address values for instructions of the original function units that include target addresses at block . is a flow diagram for generating new target address values for the code text sections of an original version of an electronic file under the embodiment of .

In describing generation of new target address values the various addresses associated with the function units are described using particular notation as follows. The instruction address is generally referred to herein using the notation addr therefore addrV refers to an instruction address in the original function unit while addrV refers to an instruction address in the new function unit. The target address is generally referred to herein using the notation targetAddr therefore targetAddrV refers to a target address in the original function unit while targetAddrV refers to the corresponding target address in the new function unit. Further the start address of the original function unit that includes targetAddrV is referenced herein using the notation targetStartAddrV is the start address of the original function unit that includes targetAddrV and the start address of the new function unit that includes targetAddrV is referenced herein using the notation targetStartAddrV. 

Likewise common function unit CFU B of new version V has a starting address startAddrV and includes a calculable instruction cal insB located at instruction address addrV. Common function unit CFU A of new version V has a starting address targetStartAddrV and includes the target address targetAddrV of the calculable instruction cal insB.

Returning to generation of new target address values begins by reading an un preprocessed calculable instruction from original function unit j of the original file version at block where j is a counter value initialized to a value of one 1 and subsequently incremented by one each time until j n where n represents the total number of common function units between the original version and the new version.

The current target address of the calculable instruction is then generated or calculated at block as follows. For any instruction that includes a target address such as program counter related jump instructions and load store instructions for example the target address is computed using the current instruction address and the corresponding instruction decoding. Using the above referenced notation the current target address computation becomes targetAddr1 addr1 decode instruction or alternatively decode instruction targetAddr1 addr1. If the value targetAddrV addrV is known the instruction can also be calculated based on the corresponding encoding scheme as instruction encode targetAddr1 addr1 . This type of instruction is referred to as a calculable instruction referred to herein as cal ins and the value targetAddrV addrV is referred to as the calculable instruction s value or the instruction value. 

For calculable instructions in common function units the pre processor of an embodiment generates the instruction value in the new version of a common function unit using the instruction value in the original version along with the original function unit starting addresses and the new function unit starting addresses. Using the above referenced notation therefore the instruction value in the new version targetAddrV addrV is generated or computed using the instruction value in the original version targetAddrV addrV startAddrV targetStartAddrV startAddrV and targetStartAddrV.

Consequently upon generation of the target address of the original file targetAddrV the pre processor accesses the HintTable to identify k the function unit of the original file version that includes the target address targetAddrV at block . With original function unit j and the identity of its targeted function unit k the pre processor reads startAddrV startAddrV targetStartAddrV and targetStartAddrV from the HintTable at block .

Continuing the pre processor now generates the instruction value targetAddrV addrV for cal insB to replace the instruction value of cal insA at block as follows. The pre processor of an embodiment operates under at least two assumptions but is not so limited. The first assumption assumes that a common function unit having the same size in both the original version and the new version has the same instruction structure across both the original and new versions where the instruction structure includes the instruction type and instruction order. The second assumption assumes that for any calculable instruction in a common function unit satisfying the first assumption when the calculable instruction is a function call or the target address of the calculable instruction falls in a common function unit that also satisfies the first assumption two invariants generally hold across both the original and new versions as follows addr1 startAddr1 addr2 startAddr2 and targetAddr1 targetStartAddr1 targetAddr2 targetStartAddr2. Thus in accordance with the two assumptions the pre processor generates the new instruction value targetAddrV addrV for cal insA at block as

Using the new instruction value of cal insA at block the pre processor modifies cal insA as instruction encode targetAddr2 addr2 . The original instruction at address addrV of the original version cal insA is then replaced with the new instruction.

The pre processor subsequently determines if any calculable instructions of the original function unit j remain un preprocessed at block . When calculable instructions remain un preprocessed the pre processor returns to read another or alternatively the next un preprocessed calculable instruction from the original function unit j at block and pre processing continues as described above.

When all calculable instructions of original function unit j have been pre processed as determined at block the preprocessor determines if the value in counter j is greater than a value n at block . A determination that j is not greater than n indicates that there are common function units that have not been pre processed so the value in counter j is incremented by one at block and pre processing continues as described above.

A determination that j is greater than n indicates that all function units of the original file version have been pre processed. Consequently the pre processor outputs a modified version of the original file that includes an approximated version of the new file at block .

As described above with reference to the pre processor and the approximation routines also function to remove secondary changes according to data model assumptions at block in addition to removing the secondary changes according to text code model assumptions. is a flow diagram for pre processing data sections of original and new versions of an electronic file under the embodiment of . Generally the data sections of the files are made up of one or more global variable units or blocks referred to herein as data units. 

The pre processing of data sections of an embodiment begins with the identification of start and end addresses of each data unit of the original and new files at block where the data units of the original files are referred to herein as original data units and the data units of the new files are referred to herein as new data units. The start and end addresses of the data units are identified using map files but are not so limited.

The pre processing next assigns a unique index or index value to each unique data unit at block . This assignment of index values to unique data units supports identification of data units that are common to both the original and new file versions. Consequently when the same data unit is found in both the original and the new versions of the file that data unit is assigned a common index value but the embodiment is not so limited. The assignment of index values to unique data units is the same as the assignment of index values to unique function units described above but is not so limited. Likewise the generation of tables organized according to index value and including the starting address and ending address for each data unit is the same as the generation of tables described above for the function units of the original and new file versions. Alternative embodiments however can assign index values and generate tables using any number of techniques known in the art.

Continuing the pre processor generates a HintTable of common data units using information of the index value starting address and ending address from the tables above at block . The HintTable includes information of the common data units assembled in one table including index value the starting and ending addresses of the original data units of the original file version V and the starting and ending addresses of the new data units of the new file version V . Generation of the HintTable is as described above with reference to the HintTable of common function units but the HintTable can be generated in alternative embodiments using any number of techniques known in the art.

The pre processor continues by generating new data pointer values for data pointers of the original version at block . is a flow diagram for generating new data pointer values for the data pointers in the original version of an electronic file under the embodiment of .

A data pointer is an instruction that points to some data in a data unit. The notation used herein in describing generation of new data pointer values follows. The address of an instruction that includes a data pointer is generally referred to herein using the notation dataPointer therefore dataPointerV refers to a dataPointer in the original version while dataPointerV refers to a dataPointer in the new version. The start address of a data unit including data pointed to by a data pointer is referred to herein using the notation dataStartAddr therefore dataStartAddrV refers to a dataStartAddr in the original version while dataStartAddrV refers to a dataStartAddr in the new version.

Returning to generation of new data pointer values begins by identifying an un preprocessed data pointer in the original version at block . The pre processor of an embodiment generates the data pointer value dataPointerV of the new version using the pointer value in the original version dataPointerV along with the start addresses of the data unit including data pointed to by dataPointerV dataStartAddrV and the start address of its corresponding data unit in the new version dataStartAddrV as described below. This is done by accessing the HintTable to identify the k the data unit in the original version which includes data pointed to by dataPointerV at block . With the identity of the data unit k the pre processor reads dataStartAddrV and dataStartAddrV from the HintTable at block .

The pre processor subsequently generates the data pointer value dataPointerV to replace dataPointerV at block as follows. The pre processor of an embodiment operates under at least two additional assumptions with regard to data units referred to herein as the third and fourth assumptions but is not so limited. The third assumption assumes that a common data unit having the same size in both the original version and the new version has the same data structure across both the original and new versions where the data structure includes the type size and order of the data variables. The fourth assumption assumes that for any data pointer in a common data unit satisfying the third assumption an invariant generally holds across both the original and new versions as follows dataPointer1 dataStartAddr1 dataPointer2 dataStartAddr2. Thus in accordance with the third and fourth assumptions the pre processor generates the new data pointer value dataPointerV for the new data unit at block as dataPointer2 dataPointer1 dataStartAddr2 dataStartAddr1 referred to herein as Formula 2.

Using the data pointer value dataPointerV at block the pre processor replaces dataPointerV with dataPointerV at the corresponding address in the original version. The pre processor subsequently determines if any data pointers of the original data unit remain un preprocessed at block .

When data pointers of the original data unit remain un preprocessed the pre processor returns to read another or alternatively the next un preprocessed data pointer from the original data unit at block and pre processing continues as described above. When all data pointers of the original data unit have been pre processed as determined at block the preprocessor outputs a modified version of the original file including an approximated version of the new file at block .

The starting and ending addresses of the common function units and the common data units as used above in the HintTables are collectively referred to as algorithm hints or hints because of their use in determining relative positioning of common units between different file versions. As such the hints are transferred to client devices receiving the difference or delta file for use in recovering the new file version from the delta file and the original file as described above. Because transfer of the hints is performed via the same low bandwidth channel used for transfer of the delta file and other information to the client device the pre processor of an embodiment performs hint merging to merge common function units and common data units of the HintTable without affecting the performance of the pre processing algorithms or routines. This merging reduces the size of the file that includes the hints and consequently the amount of information transferred to the client devices.

Using the common function units resulting from the pre processing of code text sections described above and returning to the pre processor under the control of hint merging routines or algorithms merges the common function units to form common function blocks at block . is a flow diagram of hint merging of common function units under the embodiment of .

Likewise the pre processor uses the common data units resulting from the pre processing of data sections described above to merge the common data units to form common data blocks at block . is a flow diagram of hint merging of common data units under the embodiment of . Hint merging of the common function units and common data units is described in turn below.

While hint merging of common function units and common data units is described separately herein for clarity the embodiment can perform the operations associated with the merging in any order and any combination. Regarding notation the starting address of a function or data unit is generally referred to herein using the notation startAddress as described above therefore startAddress V refers to a start address of an original function or data unit while startAddress V refers to the corresponding start address in the new function or data unit. Likewise the ending address of a function or data unit is generally referred to herein using the notation endAddress therefore endAddress V refers to an ending address of an original function or data unit while endAddress V refers to the corresponding ending address in the new function or data unit.

As described above with reference to a HintTable of common function units was generated that includes information of the common function units assembled in one table including index value the starting and ending addresses of the original function units of the original file version V and the starting and ending addresses of the new function units of the new file version V. The HintTable provided above is used as an example in describing the hint merging of common function units but the embodiment is not so limited 

With reference to and as well as the HintTable operation of hint merging of common function units begins with the pre processor marking all n entries of the HintTable as usable setting counter j 1 and reading the original and new versions of function unit j and unit j 1 from the associated HintTable at block . In this example the values of unit j and unit j 1 correspond to the index values of the hint table where j 1 2 . . . n 1 but are not so limited. Further the value of j is initially set equal to 1 and is subsequently incremented using methods known in the art as the hint merging progresses and common units are processed. Therefore the information of common function units associated with index values 1 and 2 j 1 1 1 2 is read at block .

The pre processor determines at block whether the original version V and new version V of common function unit j are equal in size. This determination is made by taking a difference between the starting and ending addresses of the original V and new V versions as endAddr1 startAddr1 endAddr2 startAddr2 but is not so limited. When the original V and new V versions have different size files operation proceeds to determine whether the value of j is less than the quantity n 1 at block .

When the original version V and the new version V are equal in size the pre processor determines whether the ending address of the original version V of common function unit j is the same as the starting address of the original version V of common function unit j 1 as endAddr1 startAddr1 1 at block but is not so limited. When the ending address of the original version V of common function unit j is different from the starting address of the original version V of common function unit j 1 operation proceeds to determine whether the value of j is less than the quantity n 1 at block .

When the ending address of the original version V of common function unit j is the same as the starting address of the original version V of common function unit j 1 the pre processor determines whether the ending address of the new version V of common function unit j is the same as the starting address of the new version V of common function unit j 1 as endAddr2 startAddr2 1 at block but is not so limited. When the ending address of the new version V of common function unit j is different from the starting address of the new version V of common function unit j 1 operation proceeds to determine whether the value of j is less than the quantity n 1 at block .

When the ending address of the new version V of common function unit j is the same as the starting address of the new version V of common function unit j 1 the pre processor merges the information of common function unit j and common function unit j 1 to form a common function block to replace the entry for unit j 1 then marks the entry for unit j as not usable at block . Operation then proceeds to determine whether the value of j is less than the quantity n 1 at block .

The pre processor determines at block whether the value of j is less than the quantity n 1 . When the value of j equals the quantity n 1 indicating that all function units have been preprocessed operation proceeds to output all usable entries as common function blocks at block and operation returns. When the value of j is less than the quantity n 1 indicating that function units remain un preprocessed the value of j is incremented at block and operation proceeds to read information of common function units corresponding to the new value of j at block . Pre processing then continues as described above.

An example involving hint merging of common function units is described below with reference to and the HintTable. Operation begins with the pre processor marking all three entries usable and reading the original and new versions of function units and from the HintTable. The pre processor then determines whether the original version V and new version V of common function unit are equal in size. This determination is made by taking a difference between the starting and ending addresses of the original V and new V versions as endAddr1 1 startAddr1 1 endAddr2 1 startAddr2 1 . Substituting the actual values from the HintTable results in 08062 08040 08082 08060 .

As the original version V and the new version V are equal in size the pre processor next determines whether the ending address of the original version V of common function unit is the same as the starting address of the original version V of common function unit as endAddr1 1 startAddr1 2 . Substituting the actual values from the HintTable results in a determination that the ending address of the original version V of common function unit is the same as the starting address of the original version V of common function unit as 0x8062 0x8062 .

Because the ending address of the original version V of common function unit is the same as the starting address of the original version V of common function unit a determination is next made as to whether the ending address of the new version V of common function unit is the same as the starting address of the new version V of common function unit as endAddr2 1 startAddr2 2 . Substituting the actual values from the HintTable results in a determination that the ending address of the new version V of common function unit is the same as the starting address of the new version V of common function unit as 08082 08082 .

In response to the determination that the ending address of the new version V of common function unit is the same as the starting address of the new version V of common function unit the pre processor merges the information of common function unit and common function unit to form a common function block as follows 

Continuing the example the pre processor next reads the original and new versions of function units and from the HintTable. The pre processor determines whether the original version V and new version V of common function unit are equal in size. This determination is made by taking a difference between the starting and ending addresses of the original V and new V versions as endAddr1 2 startAddr1 2 endAddr2 2 startAddr2 2 . Substituting the actual values from the HintTable results in 08080 08040 0800 08060 which shows the original version V and the new version V are equal in size.

The pre processor next determines whether the ending address of the original version V of common function unit is the same as the starting address of the original version V of common function unit as endAddr1 2 startAddr1 3 . Substituting the actual values from the HintTable results in a determination that the ending address of the original version V of common function unit is different from the starting address of the original version V of common function unit as 0x8080 not equal 0x8086 .

Because the ending address of the original version V of common function unit is not the same as the starting address of the original version V of common function unit operation returns and common function units and are not merged to form a common function block.

After merging common function units the usable entries of the HintTable of the above example are as follows for the output 

The pre processor of an embodiment performs hint merging of common data units in a manner similar to that described above with regard to the common function units. With reference to and operation of hint merging of common data units begins with the pre processor marking all n entries of the HintTable setting the counter j 1 and reading the original and new versions of data unit j and j 1 from the associated HintTable at block . The values of unit j and unit j 1 correspond to the index values of the hint table where j 1 2 . . . n 1 but are not so limited.

The pre processor determines at block whether the original version V and new version V of common data unit j are equal in size. This determination is made by taking a difference between the starting and ending addresses of the original V and new V versions as endAddr1 startAddr1 endAddr2 startAddr2 but is not so limited. When the original V and new V versions have different size files operation proceeds to determine whether the value of j is less than the quantity n 1 at block .

When the original version V and the new version V are equal in size the pre processor determines whether the ending address of the original version V of common data unit j is the same as the starting address of the original version V of common data unit j 1 as endAddr1 startAddr1 1 at block but is not so limited. When the ending address of the original version V of common data unit j is different from the starting address of the original version V of common data unit j 1 operation proceeds to determine whether the value of j is less than the quantity n 1 at block .

When the ending address of the original version V of common data unit j is the same as the starting address of the original version V of common data unit j 1 the pre processor determines whether the ending address of the new version V of common data unit j is the same as the starting address of the new version V of common data unit j 1 as endAddr2 startAddr2 1 at block but is not so limited. When the ending address of the new version V of common data unit j is different from the starting address of the new version V of common data unit J 1 operation proceeds to determine whether the value of j is less than the quantity n 1 at block .

When the ending address of the new version V of common data unit j is the same as the starting address of the new version V of common data unit j 1 the pre processor merges the information of common data unit j and common data unit j 1 to form a common data block to replace the entry for unit j 1 then marks the entry for unit j is not usable at block . Operation then proceeds to determine whether the value of j is less than the quantity n 1 at block .

The pre processor determines at block whether the value of j is less than the quantity n 1 . When the value of j equals the quantity n 1 indicating that all function units have been preprocessed operation proceeds to output usable entries in the HintTable as common data blocks at block and operation returns. When the value of j is less than the quantity n 1 indicating that function units remain un preprocessed the value of j is incremented at block and operation proceeds to read information of common data units corresponding to the new value of j at block . Pre processing then continues as described above.

The systems and methods described for pre processing different versions of an electronic file can be applied to software and executable files of any number of processing and or processor based systems using any number of instruction architectures. For example the systems and methods herein can be used in the ARM architecture as described in the ARM Architecture Reference Manual 2Edition by D. Jagger and D. Seal. The ARM architecture is a microprocessor architecture based on a 16 32 bit embedded Reduced Instruction Set Computer RISC core and incorporating the Thumb 16 bit instruction set. When used in the ARM architecture for example the calculable instructions referred to above would include branch with link BL and branch with link and change mode to ARM Thumb BLX instructions of the ARM Thumb instruction set. Further the data pointer referred to above includes the DCD instruction of the ARM Thumb instruction set.

The processing of an embodiment described herein includes post processing in addition to the pre processing that generates common code data tables directly from a pair of software executables without the use of symbol information from map files symbol files or log files generated by compiler linker utilities. The post processing of pre processed data includes post processing of an array of common code blocks as described above.

Referring to the vertical line to the left designated old image V represents an original version of an electronic file. The vertical line to the right designated new image V represents a new version of the electronic file. Each vertical line represents units of code such as a byte sequence. The old image V and new image V will be used in describing embodiments of systems and methods for post processing that improve the performance of preprocessed instructions but is not so limited.

In an embodiment the post processing examines instruction characteristics to determine pairs of instructions having a specified relationship described below. For example the post processing processing examines instruction characteristics to determine pairs of aligned instructions. For each pair of aligned instructions the post processing generates a pair of target addresses. After the pairs of target addresses have been collected post processing algorithms may be used to extend some of the existing known common code blocks and or create new common code blocks. The post processing algorithms account for any trade off between increasing the preprocessing success rate and keeping the overall amount of preprocessing data small. This is an important consideration because one may readily improve the preprocessing success rate by introducing large amounts of new preprocessing data which is undesirable. After one or more of the post processing algorithms have improved the common code blocks any data blocks may then be re calculated which improves the preprocessing performance of instructions that have data pointers. Such instructions include but are not limited to the familiar ARM LDR instruction.

Post processing of preprocessed data described herein receives preprocessed data as an array of common code blocks. Calculable instructions such as Thumb BL instructions for example may be analyzed in the one or more common code blocks to identify instruction characteristics which may be used to determine whether to extend and or add common code blocks. For example calculable instructions may be analyzed to identify instructions that have target addresses in the image but not in the known common code blocks. Since both the old and the new images are available at this time a determination may be made as to whether there are instructions having a specified relationship such as aligned instructions in the code blocks. An evaluation as to whether to add and or extend may then be made based in part on the relationship and or the starting addresses and or target addresses of the instructions. Based on the collection of this type of data including the starting and target addresses the existing or known common code blocks may be extended and or new common code blocks may be generated.

The post processing of an embodiment collects data by creating or generating two 2 arrays of integers with size equal to the number of bytes in the old image. All of the integers are initialized to zero and

If address i is in the old image and it is not in a known code block backward i counts how many instructions such as BL instructions would be preprocessed correctly if the previous code block were extended forward to include address i . Forward i counts how many instructions would be preprocessed correctly if the following code block were extended backward to include address i . The post processing also creates a list of addr pair structures wherein the structures have an allocated size equal to about half the number of bytes in the old image which should be sufficient to account for the instructions. For example since the relevant bits are different for the first and second parts of a Thumb BL instruction there should not be more BL instructions in an image than about one quarter the number of bytes in the image. A variable keeps track of the number of addr pair s stored in the list which is initially set to zero.

These values represent a target address in the old image and a target address in the new image but the embodiment is not so limited. A pair of target addresses are added to this list when the pair includes characteristics that result in the instruction not being preprocessed correctly using either the preceding or following code block. Generally the backward and forward arrays may be used when attempting to extend known code blocks and the addr pair list may be used when attempting to create new code blocks.

As shown in the old image V and the new image V include a number of known common code blocks and a new common code block . For example known common code block may represent a JPEG or MPEG file. Known common code block may represent a WAV file. Known common code block may represent an address book. Common code block is a new common code block which is generated by the post processing of an embodiment the dashed boundary of common code block represents it as a new common code block . While a certain number of common code blocks are depicted that there may be greater or fewer numbers of common code blocks.

The post processing of an embodiment improves the performance of the preprocessing of instructions that use the concept of relative addressing. Such instructions may be referred to as beacons or generalized beacons. They include but are not limited to calculable instructions such as the familiar ARM BL instruction. Since both the old and the new images are available when the preprocessing data is created it is possible to test if there are instructions at aligned locations in the common code blocks. It is also possible to examine the associated starting and or target addresses. Based on the collection of this type of data about the instructions including the starting and or target addresses it is possible to extend the existing common code blocks and or create new common code blocks.

According to an embodiment a function algorithm uses the addr pair list to try to create a new code block.

As described above the post processing has identified instructions and to have characteristics which are conducive to creating a new common code block . For example the post processing has identified that the target addresses and of instructions and do not exist in a known code block and are spaced apart according to a defined minimal spacing. Additionally the starting addresses and of instructions and exist within one or more known common code blocks such as known common code block .

The spacing between the target addresses and is but one factor which may be used in the determination as to whether to create a new common code block. The number of instructions that include target addresses that point to a common area is yet another factor which may be used in the determination as to whether to create a new common code block. Additionally the frequency of instructions that include target addresses that point to a common area is another factor which may be used in the determination as to whether to create a new common code block. According to an embodiment one or more new code blocks are created based on at least one of a number of instructions a frequency of instructions and a spacing between instructions that may point to one or more common code areas in the old and new images.

Referring now to post processing is used to increase the size or expand one or more previously identified common code blocks while also generating a new common code block under an embodiment. Regarding the algorithms that post process the code blocks the backward and forward arrays may be used by this function algorithm to extend a code blocks as 

As shown in the old image V and the new image V include a number of known common code blocks and a new common code block . As discussed above the post processing may increase the size or expand one or more previously identified common code blocks such as one or more of the known common code blocks . When determining whether to extend or expand a known common code block such as common code block the post processing identifies instructions that have target addresses in the image but not in the known code blocks. The post processing also identifies instructions having starting addresses which have a calculable relationship with respect to the instructions and or the known common code blocks.

For example the post processing has identified instructions and as instructions which include characteristics that may lead to the expansion of one or more known common code blocks such as known common code block . That is the identified instructions and have corresponding target addresses and that are not in a known common code block. Since the target addresses and are not in a known common code block the post processing may then evaluate one or more characteristics of the instructions and to determine whether to expand the known common code block .

After determining that the target addresses and are not in a known common code block the post processing may examine each starting address and of instructions and to determine whether to expand known common code block to include the target addresses and . According to an embodiment since starting address is within the known common code block the post processing examines the offset or difference between the starting address of instruction and the starting address of the known common code block . This difference is represented as delta a in . Likewise the post processing examines the offset or difference between the starting address of instruction and the starting address of the known common code block . This difference is represented as delta b .

If delta a is equal to delta b then starting addresses and are aligned and the post processing expands the known common code block to include the target addresses and . Stated a different way based on one or more characteristics of the instructions and the post processing may increase the size of common code block so that the target addresses and are now encompassed by the expanded common code block . Consequently the extended common code block includes a new boundary which corresponds to the increase in the size of the common code block . The post processing may extend the size of a common code block by using the backward and or forward arrays to thereby change two 2 numbers in the hint table. Moving the boundary by modifying StartADDRV and StartADDV may also change the SIZE variable described above.

As a further example the post processing has identified instructions and as instructions which include characteristics that may lead to the expansion of one or more known common code blocks such as known common code block . That is the identified instructions and have corresponding target addresses and that are not in a known common code block. Since the target addresses and are not in a known common code block the post processing may then evaluate one or more characteristics of the one or more instructions and to determine whether to expand known common code block .

Since the target addresses and are not in a known common code block the post processing may examine each starting address and of instructions and to determine whether to expand known common code block to include the target addresses and . As described above in accordance with an embodiment the post processing examines the offset or difference between the starting address of instruction and the starting address of the known common code block . This difference is represented as delta c in . Likewise the post processing examines the offset or difference between the starting address of instruction and the starting address of the known common code block . This difference is represented as delta d .

If delta c is equal to delta d then starting addresses and are aligned and the post processing expands the known common code block to include the target addresses and . Stated a different way based on one or more characteristics of the instructions and the post processing may increase the size of common code block so that the target addresses and are now encompassed by the expanded common code block . Consequently the extended common code block includes a new boundary which corresponds to the increase in the size of the common code block . In this example the common code block has been extended backward whereas in the first example the common code block was extended forward. The determination as to whether to extend backwards or forwards is based at least in part on how many instructions would be preprocessed correctly as described above.

In addition to extending the known common code blocks and the post processing has added a new common code block . Common code block is a new common code block which is generated by the post processing of an embodiment the dashed boundary of the common code block represents it as a new common code block . When determining whether to add a new common code block such as common code block the post processing identifies instructions that have target addresses in the image but not in the known code blocks. For example the post processing has identified instructions and as instructions which include characteristics that may lead to the generation of one or more new common code blocks. The post processing of the instructions and resulted in the addition of the new common code block .

As described above the post processing has identified instructions and to have characteristics which are conducive to creating a new common code block . For example the post processing has identified that the target addresses and do not exist in a known code block and are spaced apart according to a defined minimal spacing. Additionally the starting addresses and exist within known common code blocks and . The spacing between the target addresses and is but one factor which may be used in the determination as to whether to create a new common code block such as the new common code block .

The number of instructions that include target addresses that point to a common area is yet another factor which may be used in the determination as to whether to create a new common code block. Additionally the frequency of instructions that include target addresses that point to a common area is another factor which may be used in the determination as to whether to create a new common code block. According to an embodiment one or more new code blocks are created based on at least one of a number of instructions a frequency of instructions and a spacing between instructions that may point to one or more common areas in the old and new versions.

In some instances the overall improvements realized using the post processing techniques are dramatic. This is due in part because the embodiments are able to find common code blocks that are small in size but very important in terms of the overall graph of instructions within the images. One such example would be the veneers that are common in ARM code. The veneers are often just a few bytes and are consequently difficult to detect using conventional techniques.

According to an embodiment for a given input of code block arrays two different post processing procedures may be executed and a procedure is selected based on the number of instructions that are correctly preprocessed. The two different procedures include a first procedure and a second procedure described below. The first procedure includes but is not limited to clearing the data arrays based on the input code blocks calculating the data arrays modify tryToAddArray clearing the data arrays based on the modified code blocks calculating the data arrays modify tryToExtend and based on the modified code blocks calculating a number of instructions correctly preprocessed.

The second procedure includes but is not limited to clearing the data arrays based on the input code blocks calculating the data arrays modify tryToExtend clearing the data arrays based on the modified code blocks calculating the data arrays modify tryToAddArray based on the modified code blocks calculating a number of instructions correctly preprocessed. The first procedure and the second procedure differ in that they use the algorithms modify tryToAddArray and modify tryToExtend in the opposite sequence. The selection of the first or second procedure is made based at least in part on a number of instructions correctly preprocessed.

As described above each vertical strip represents one common code block a first part identifies a region in the old image this is the extent of the strip that is in contact with the lower axis in the diagram and a second part identifies a region in the new image this is the extent of the strip that is in contact with the middle axis in the diagram . Most of the strips in the diagram appear to be nearly vertical because the horizontal scale of the diagram is more than nine 9 megabytes and small shifts in the code blocks are not easily seen on such a large scale.

There are 258 822 BL instructions in v1.bin that are in the common code blocks. Of these 187 162 have target addresses that are also in the common code blocks. Of these target addresses 186 058 are predicted correctly by the common code blocks. A correct prediction generally means that the spacing between the target addresses differs between the old and new images in a manner that agrees with the relevant common code block shifts. As explained above the post processing methodologies analyze instructions such as BL instructions that do not have target addresses in the common code blocks. If the instructions do not have target addresses in the common code blocks then the post processing attempts to improve the common code blocks by extension of known common code blocks and or the addition of new common code blocks but is not so limited.

As described above in accordance with an embodiment the post processing attempts the following procedures 

This post processing results in a count of 257 217 BL instructions having correct predictions. Since the second procedure results in a higher number of instructions having correct predictions for this example the second procedure is used. Note that the count from the second procedure is fairly close to the total number of BL instructions in v1.bin 258 822. Also recall that the count of BL instructions with correct predictions was 186 058 before post processing. Thus the delta file is significantly smaller as a result of the post processing methodology. The size of the delta file without post processing is 274 259 bytes. The size of the delta file with post processing is 131 799 bytes. Thus for this example the post processing results in a delta file that is less than half the size of the delta file without using post processing.

The following table below provides more detailed information. The table highlights the effects of the post processing for a few of the common code blocks in the examined region discussed above.

In the table above each common code block is described by three numbers a b and c. The prefix a represents the start address of the block in v1.bin. The prefix b represents the start address of the block in v2.bin. The prefix c represents the length of a block in both v1.bin and v2.bin .

The numbers of the table show that the first block has been extended at its end because the a and b values are the same but the c value has increased. This extension was accomplished by using the modify tryToExtend algorithm. The second block has been extended on both the left and right also using the modify tryToExtend algorithm. A new block has been added by using the modify tryToAddArray algorithm this is the third narrow block of . Note that the last block in the table was unchanged. The changes are evident in . is a magnification of a region of which shows the effects of the block that was added by the post processing. The dots that are contained in the added block represent BL instructions that are now preprocessed.

Embodiments of the electronic file updating system and method generally referred to herein as XIP processing will now be described with reference to .

Execute in place XIP files are only one type of file appropriate to the system and method and there are many other examples of files that would benefit from the preprocessing described.

An f function is a piece wise constant function that takes an integer as an input and returns an integer making use of a table of pairs of integers which must also be specified. Alternative embodiments may use unsigned integers instead. Under one embodiment one f function is defined for each XIP preprocessing region.

Because the work here is with integers not real numbers each interval of constancy has a well defined right hand endpoint and function value there. An f array holds the data for the piece wise constant function. The function is defined by this information for the right hand endpoint of each interval input output . In the code such a pair is called a b . is a sample plot of the function under an embodiment with x indicating a point stored in the array. As is standard the input axis is horizontal and the output axis is vertical.

The integers are stored using variable length integers. Originally this encoding was available only for unsigned integers. Now the XIP code includes an option recommended value yes that allows a special encoding to be used for signed integers. The result is that small negative numbers e.g. 4 12 etc. are encoded more efficiently. Without this option such numbers would require five bytes each.

For historical reasons in the code the XIP hint data is also called intHint data preprocessing data for the integer table hinting .

The arrays are encoded as an initial value followed by subsequent differences. The reason why the .b values with even and odd indices are stored separately is that the .b values often alternate between two values such as 0 and a nonzero value for a part of the array so this is better after compression.

Currently the endian is an input quantity. The ARM heuristics for determining the endian should not be used here because there is no guarantee that enough ARM code can be found for the statistics. The endian could be stored in the device.xml file. Alternatively since this is a value that probably will not be changed too much it can be stored in the NSCDCLI CONFIG.txt file so no changes are required to the device.xml files.

The step1 XIP function carries out these steps after creating an EBSC list that is the same as the input list except that the types of some components can be changed from CRAMFS TYPE to BINARY TYPE if they are really not CRAMFS TYPE in at least one of the images 

Diagnostic information is produced during the calculation. This is useful to check the assumptions that are part of the foundation of the algorithms. This information can also be used to predict how successful the preprocessing is expected to be for an individual case.

only multiples of4 is a boolean implemented as an integer currently set to 0. A nonzero value would mean that only values that are multiples of 4 are processed.

This function may be thought of as a generalized parameter. An ordinary parameter is just one number. The function useful is a boolean valued function of several integers.

In an embodiment this is an extension of the Step 2 without the XIP preprocessing. The new functions are in the DUC side post processing functions.

In an embodiment heuristics are used to determine whether the XIP preprocessing is profitable for any given region without knowing exactly what is in it.

For all of these examples Number different after preprocessing 0. For each example the data includes an Image 1 and Image 2 and Differences of 4 byte values.

As an example of a device and or system using the pre processing and or post processing described above the computing devices receiving and using the delta file may be client devices that host corresponding software applications in need of updating for example cellular telephones mobile electronic devices mobile communication devices personal digital assistants and other processor based devices. This support is provided for all mobile device software ranging from firmware to embedded applications by enabling carriers and device manufacturers to efficiently distribute electronic file content and applications via their wireless infrastructure.

Another example of systems that benefit from the pre processing and or post processing described above includes systems using wired serial connections to transfer the delta file from a device hosting the file difference generator to a device hosting the file update generator. These systems typically have slow transfer rates and because the transfer rates are slow a reduction in the size of the delta file is a way to realize faster transfer times.

Yet another example of systems that benefit from use of the pre processing and or post processing includes wireless systems using radio communications to transfer the delta file from a device hosting the file difference generator to a device hosting the file update generator. While suffering from low reliability associated with the wireless connections these systems also have slow transfer rates. The use of a smaller delta file in these systems provides several advantages. For example the smaller file size results in a faster delta file transfer time. The faster transfer time while saving time for the device user reduces the opportunity for the introduction of errors into the delta file thereby increasing system reliability. Also with cellular communications the reduced transfer time results in a cost savings for the consumer who is typically charged by the minute for service.

As another advantage the smaller delta file reduces the bandwidth required to transfer the delta files to client devices. The reduced bandwidth allows for the support of more client devices via the allocated channels. As with the reduced transfer time this too results in a reduction in operating costs for the wireless service provider.

Aspects of the invention may be implemented as functionality programmed into any of a variety of circuitry including programmable logic devices PLDs such as field programmable gate arrays FPGAs programmable array logic PAL devices electrically programmable logic and memory devices and standard cell based devices as well as application specific integrated circuits ASICs . Some other possibilities for implementing aspects of the invention include microcontrollers with memory such as electronically erasable programmable read only memory EEPROM embedded microprocessors firmware software etc. Furthermore aspects of the invention may be embodied in microprocessors having software based circuit emulation discrete logic sequential and combinatorial custom devices fuzzy neural logic quantum devices and hybrids of any of the above device types. Of course the underlying device technologies may be provided in a variety of component types e.g. metal oxide semiconductor field effect transistor MOSFET technologies like complementary metal oxide semiconductor CMOS bipolar technologies like emitter coupled logic ECL polymer technologies e.g. silicon conjugated polymer and metal conjugated polymer metal structures mixed analog and digital etc.

The functions described herein as the invention can be performed by programs or sets of program codes including software firmware executable code or instructions running on or otherwise being executed by one or more general purpose computers or processor based systems. The computers or other processor based systems may include one or more central processing units for executing program code volatile memory such as RAM for temporarily storing data and data structures during program execution non volatile memory such as a hard disc drive or optical drive for storing programs and data including databases and other data stores and a network interface for accessing an intranet and or the Internet. However the functions described herein may also be implemented using special purpose computers wireless computers state machines and or hardwired electronic circuits.

It should be noted that components of the various systems and methods disclosed herein may be described using computer aided design tools and expressed or represented as data and or instructions embodied in various computer readable media in terms of their behavioral register transfer logic component transistor layout geometries and or other characteristics. Formats of files and other objects in which such circuit expressions may be implemented include but are not limited to formats supporting behavioral languages such as C Verilog and HLDL formats supporting register level description languages like RTL and formats supporting geometry description languages such as GDSII GDSIII GDSIV CIF MEBES and any other suitable formats and languages.

Computer readable media in which such formatted data and or instructions may be embodied include but are not limited to non volatile storage media in various forms e.g. optical magnetic or semiconductor storage media and carrier waves that may be used to transfer such formatted data and or instructions through wireless optical and or wired signaling media. Examples of transfers of such formatted data and or instructions by carrier waves include but are not limited to transfers uploads downloads e mail etc. over the Internet and or other computer networks via one or more data transfer protocols e.g. HTTP FTP SMTP etc. . When received within a computer system via one or more computer readable media such data and or instruction based expressions of the above described systems and methods may be processed by a processing entity e.g. one or more processors within the computer system in conjunction with execution of one or more other computer programs.

Unless the context clearly requires otherwise throughout the description and the claims the words comprise comprising and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense that is to say in a sense of including but not limited to. Words using the singular or plural number also include the plural or singular number respectively. Additionally the words herein hereunder above below and words of similar import refer to this application as a whole and not to any particular portions of this application. When the word or is used in reference to a list of two or more items that word covers all of the following interpretations of the word any of the items in the list all of the items in the list and any combination of the items in the list.

The above description of illustrated embodiments of the invention is not intended to be exhaustive or to limit the invention to the precise form disclosed. While specific embodiments of and examples for the invention are described herein for illustrative purposes various equivalent modifications are possible within the scope of the invention as those skilled in the relevant art will recognize. The teachings of the invention provided herein can be applied to other processing systems and communication systems not only for the file differencing systems described above.

The elements and acts of the various embodiments described above can be combined to provide further embodiments. These and other changes can be made to the invention in light of the above detailed description. Aspects of the invention can be modified if necessary to employ the systems functions and concepts of the various patents and applications described above to provide yet further embodiments of the invention.

In general in the following claims the terms used should not be construed to limit the invention to the specific embodiments disclosed in the specification and the claims but should be construed to include all processing systems that operate under the claims to provide file differencing. Accordingly the invention is not limited by the disclosure but instead the scope of the invention is to be determined entirely by the claims.

While certain aspects of the invention are presented below in certain claim forms the inventor contemplates the various aspects of the invention in any number of claim forms. For example while only one aspect of the invention is recited as embodied in computer readable medium other aspects may likewise be embodied in computer readable medium. Accordingly the inventor reserves the right to add additional claims after filing the application to pursue such additional claim forms for other aspects of the invention.

