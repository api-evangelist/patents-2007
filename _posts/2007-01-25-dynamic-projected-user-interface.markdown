---

title: Dynamic projected user interface
abstract: A dynamic projected user interface device is disclosed, that includes a projector, a projection controller, and an imaging sensor. The projection controller is configured to receive instructions from a computing device, and to provide display images via the projector onto display surfaces. The display images are indicative of a first set of input controls when the computing device is in a first operating context, and a second set of input controls when the computing device is in a second operating context. The imaging sensor is configured to optically detect physical contacts with the one or more display surfaces.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08022942&OS=08022942&RS=08022942
owner: Microsoft Corporation
number: 08022942
owner_city: Redmond
owner_country: US
publication_date: 20070125
---
The functional usefulness of a computing system is determined in large part by the modes in which the computing system outputs information to a user and enables the user to make inputs to the computing system. A user interface generally becomes more useful and more powerful when it is specially tailored for a particular task application program or other context of the operating system. Perhaps the most widely spread computing system input device is the keyboard which provides alphabetic numeric and other orthographic keys along with a set of function keys that are generally of broad utility among a variety of computing system contexts. However the functions assigned to the function keys are typically dependent on the computing context and are assigned often very different functions by different contexts. Additionally the orthographic keys are often assigned non orthographic functions or need to be used to make orthographic inputs that do not necessarily correspond with the particular orthographic characters that are represented on any keys of a standard keyboard often only by simultaneously pressing combinations of keys such as by holding down either or any combination of a control key an alt key a shift key and so forth. Factors such as these limit the functionality and usefulness of a keyboard as a user input device for a computing system.

Some keyboards have been introduced to address these issues by putting small liquid crystal display LCD screens on the tops of the individual keys. However this presents many new problems of its own. It typically involves providing each of the keys with its own Single Twisted Neumatic STN LCD screen LCD driver LCD controller and electronics board to integrate these three components. One of these electronics boards must be placed at the top of each of the mechanically actuated keys and connect to a system data bus via a flexible cable to accommodate the electrical connection during key travel. All the keys must be individually addressed by a master processor controller which must provide the electrical signals controlling the LCD images for each of the keys to the tops of the keys where the image is formed. Such an arrangement tends to be very complicated fragile and expensive. It places each of many LCD screens where they must be repeatedly struck by the user s fingers posing the likelihood of being cracked. The LCD screens are flat thereby preventing the design of concave or otherwise shaped keypads to help a user s sense of tactile feedback. And the flexible data cable attached to each of the keypads is subject to mechanical wear and tear with each keystroke.

The discussion above is merely provided for general background information and is not intended to be used as an aid in determining the scope of the claimed subject matter.

A dynamic projected user interface is hereby disclosed in a variety of different embodiments. According to one illustrative embodiment a dynamic projected user interface device includes a projector a projection controller and an imaging sensor. The projection controller is configured to receive instructions from a computing device and to provide display images via the projector onto display surfaces. The display images are indicative of a first set of input controls when the computing device is in a first operating context and a second set of input controls when the computing device is in a second operating context. The imaging sensor is configured to optically detect physical contacts with the one or more display surfaces.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. The claimed subject matter is not limited to implementations that solve any or all disadvantages noted in the background.

As depicted in dynamic projected user interface device A is depicted in a simplified block diagram that includes projector projection controller and imaging sensor . Projector illustratively includes a laser source in this embodiment. Projector also includes collimator in the beam path of laser emitter so that a laser emitted from laser emitter passes through and is collimated by collimator in this illustrative embodiment. is not meant to represent the actual optics of dynamic projected user interface device A or the actual path of laser which are readily within design choices that may be made within the understanding of those skilled in the art. Rather demonstrates a simplified block diagram to make clear the concepts involved. Projector may also emit any other kind of electromagnetic radiation such as from a laser an LED array a cathode ray or other type of source and in any frequency range including but not limited to visible light ultraviolet rays infrared rays other frequencies or a combination of any of these.

Laser subsequently follows a beam path into waveguide nexus of waveguide which directs it to the surfaces of the keys of keyboard such that the surfaces of the keys constitute display surfaces for display images provided via projector . Coordinate set A is depicted in the corner for purposes of correlating the depiction of dynamic projected user interface device A in with additional depictions in later figures. Coordinate set A shows an X direction going from left to right of the keyboard a Y direction going from bottom to top of keyboard and a Z direction going from down to up out of the page and perpendicular to the plane of keyboard . In this embodiment keyboard does not have any static characters or symbols pre printed onto any of the surfaces of the keys rather the surfaces of the keys are configured to be semi transparent and to serve as the display surfaces for images that are uniquely provided to each of the keys via projector images that may also be changed at will according to the current operating context of an associated computing system.

Lens is disposed adjacent to imaging sensor and is configured to receive optical signals returned from the surfaces of the keys and to focus them onto imaging sensor . Imaging sensor may illustratively be composed mainly of a complementary metal oxide semiconductor CMOS array for example. It may also be a different type of imager such as a charge coupled device CCD a single pixel photodetector with a scanned beam system or any other type of imaging sensor.

Projection controller is configured to receive and operate according to instructions from a computing device not depicted in see below . Projection controller communicates with an associated computing device through communication interface which may include a wired interface such as according to one of the Universal Serial Bus USB protocols for example or may take the form of any of a number of wireless protocols. Projection controller is also configured to return inputs detected through imaging sensor to the associated computing system. The associated computing system may be running any of a variety of different applications or other operating contexts which may determine the output and input modes in effect at a particular time for dynamic projected user interface device A.

Projection controller is configured to provide one or more display images via projector onto surfaces of the keys . The display images that are projected are indicative of a first set of input controls when the computing device is in a first operating context and a second set of input controls when the computing device is in a second operating context. That is one set of input controls may include a typical layout of keys for orthographic characters such as letters of the alphabet additional punctuation marks and numbers along with basic function keys such as return backspace and delete along with a suite of function keys along the top row of the keyboard .

While function keys are typically labeled simply F1 F2 F3 etc. the projector provides images onto the corresponding keys that explicitly label their function at any given time as dictated by the current operating context of the associated computing system. For example the top row of function keys that are normally labeled F1 F2 F3 etc. may instead according to the dictates of one application currently running on an associated computing system be labeled Help Save Copy Cut Paste Undo Redo Find and Replace Spelling and Grammar Check Full Screen View Save As Close etc. Instead of a user having to refer to an external reference or have to remember the assigned functions for each of the function keys as assigned by a particular application the actual words indicating the particular functions appear on the keys themselves for the application or other operating context that currently applies.

Imaging sensor is configured such as by being disposed in connection with the waveguide to receive optical signals coming in the reverse direction in which the display images are being provided by projector from the surfaces of the keys . Imaging sensor may therefore optically detect when one of the keys is pressed. For example imaging sensor may be enabled to detect when the edges of one of keys approaches or contacts the surface of waveguide in one illustrative embodiment. Because the surfaces of the keys are semi transparent in this embodiment imaging sensor may also be enabled to optically detect physical contacts with the surfaces of the keys by imaging the physical contacts through the waveguide in another detection mode. Even before a user touches a particular key the imaging sensor may already detect and provide tracking for the user s finger. Imaging sensor may therefore optically detect when the user s finger touches the surface of one of the keys . This may provide the capability to treat a particular key as being pressed as soon as the user touches it. Different detection modes and different embodiments may therefore provide any combination of a variety of detection modes that configure imaging sensor to optically detect physical contacts with the one or more display surfaces.

Imaging sensor may further be configured to distinguish a variety of different modes of physical contact with the display surfaces. For example imaging sensor may be configured to distinguish between the physical contact of a user s finger with a particular key and the key being pressed. It may also include for example distinguishing if the user s finger makes sliding motions in one direction or another across the surface of one of the keys or distinguishing how slowly or how forcefully one of the keys is pressed. Dynamic projected user interface device A may therefore be enabled to read a variety of different inputs for a single one of the keys as a function of the characteristics of the physical contact with that display surface. These different input modes per a particular key may be used in different ways by different applications running on an associated computing system.

For example a game application may be running on the associated computing system a particular key on the keyboard may control a particular kind of motion of a player controlled element in the game and the speed with which the user runs her finger over that particular key may be used to determine the speed with which that particular kind of motion is engaged in the game. As another illustrative example a music performance application may be running with different keys on keyboard or on a different keyboard with a piano style musical keyboard layout for example corresponding to particular notes or other controls for performing music and the slowness or forcefulness with which the user strikes one of the keys may be detected and translated into that particular note sounding softly or loudly for example. Many other possible usages are possible and may be freely used by developers of applications making use of the different input modes enabled by dynamic projected user interface device A.

In another illustrative embodiment the imaging sensor may be less sensitive to the imaging details of each of the particular keys or the keys may be insufficiently transparent to detect details of physical contact by the user or plural input modes per key may simply not be a priority and the imaging sensor may be configured merely to optically detect physical displacement of the keys . This in itself provides the considerable advantage of implementing an optical switching mode for the keys so that keyboard requires no internal mechanical or electrical switching elements and requires no moving parts other than the keys themselves. In this and a variety of other embodiments the keys may include a typical concave form in addition to enabling typical up and down motion and other tactile cues that users typically rely on in using a keyboard rapidly and efficiently. This provides advantages over virtual keys projected onto a flat surface and to keys in which the top surface is occupied by an LCD screen which thereby is flat rather than having a concave form and thereby may provide less of the tactile cues that efficient typers rely on in using a keyboard. Since the up and down motion of the keys is detected optically and has no electrical switch for each key as in a typical keyboard or electronics package devoted to each key as in some newer keyboards the keys of keyboard may remain mechanically durable long after mechanical wear and tear would degrade or disable the electrical switches or electronic components of other keyboards.

In yet another embodiment the keys may be mechanically static and integral with keyboard and the imaging sensor may be configured to optically detect a user striking or pressing the keys so that keyboard becomes fully functional with no moving parts at all while the user still has the advantage of the tactile feel of the familiar keys of a keyboard.

A wide variety of kinds of keypads may be used in place of keyboard as depicted in together with components such as projector projection controller imaging sensor and waveguide . For example other kinds of keypads that may be used with a device otherwise similar to dynamic projected user interface device A of include a larger keyboard with additional devoted sections of function keys and numeric keys an ergonomic keyboard divided into right and left hand sections angled to each other for natural wrist alignment a devoted numeric keypad a devoted game controller a musical keyboard that is with a piano style layout of 88 keys or an abbreviated version thereof and so forth.

Dynamic projected user interface device A thereby takes a different tack from the effort to provide images to key surfaces by means of a local LCD screen or other electronically controlled screen on every key each key with the associated electronics. Rather than sending electrical signals from a central source to an electronics and screen package at each of the keys photons are generated from a central source and optically guided to the surfaces of the keys in this illustrative embodiment. This may use light waveguide technology that can convey photons from entrance to exit via one or more waveguides which may be implemented as simply as a shaped clear plastic part as an illustrative example. This provides advantages such as greater mechanical durability water resistance and lower cost among others.

Waveguide includes an expansion portion and an image portion . Expansion portion has horizontal boundaries and shown in that diverge along a projection path away from the projector and vertical boundaries and that are substantially parallel. Image portion has vertical boundaries and that are angled relative to each other. Projector B is positioned in interface with the first waveguide section by means of waveguide nexus . Waveguide nexus is a part of waveguide that magnifies the images from projector B and reflects them onto their paths into expansion portion as particularly seen in . The image portion is positioned in interface with the display surface of the keyboard such that rays emitted by the projector B are internally reflected throughout the expansion portion to propagate to image portion and are transmitted from the image portion to the keys as further elaborated below.

As demonstrates waveguide is substantially flat and tapered along its image portion . Waveguide is disposed between the keypad at one end and the projector and imaging sensor B at the other end. Waveguide and its boundaries are configured to convey rays of light or another electromagnetic signal such as representative projection ray paths A and B with total internal reflection through expansion portion and to convey the images by total internal reflection through a portion of image portion as needed before directing each ray in an image at upper boundary at an angle past the critical angle and which may be orthogonal or relatively close to orthogonal to the surfaces of keys to cause the rays to transmit through upper boundary to render visible images. The critical angle for distinguishing between internal reflection and transmission is determined by the index of refraction of both the substance of waveguide and that of its boundaries . Waveguide may be composed of acrylic polycarbonate glass or other appropriate materials for transmitting optical rays for example. The boundaries and may be composed of any appropriate optical cladding suited for reflection while boundary includes a number of discontinuities for inclusion of the keys as display surfaces which may be semi transparent and diffuse in this illustrative embodiment so that they are well suited to forming display images that are easily visible from above due to optical projections from below as well as being suited to admitting optical images of physical contacts with the keys in this illustrative embodiment. The surfaces of keys may also be coated with a turning film which may ensure that the image projection rays emerge orthogonally to the key surfaces. The turning film may in turn be topped by a scattering screen on each of the key surfaces to encourage visibility of the display images from a wide range of viewing angles. In another embodiment optical fibers may be used to transmit optical signals along at least part of waveguide for example.

As a further advantage of these embodiments the entire keyboard may be detached at waveguide nexus and easily washed. Keyboards in generally notoriously tend to get dirty over time but are inconvenient to wash and in traditional keyboards have electrical switches associated with each of the keys. This becomes more of an issue with efforts to make keyboards with a screen and associated electronics package associated with individual keys. On the contrary keyboard has no electrical components and once detached at waveguide nexus can easily have cleaning solution applied to it or even be submerged in cleaning solution without any electrical components to be concerned about. Keyboard may thereby easily be washed dried and reattached at waveguide nexus thereby enabling a user to conveniently keep a cleaner keyboard. Alternately projector B projection controller B imaging sensor B and communication interface B may all be enclosed within a watertight chamber. The lack of electrical components in the body of keyboard also means that any accidental spill of a liquid onto keyboard will not pose a threat to it as it would to a traditional keyboard or a keyboard with a local screen and associated electronics at individual keys.

As another advantage the keys may be associated with a tray that may be removed from the top of keyboard so that the surface of keyboard may then become a single display. The entire single display may also track lateral stroke direction to enable multiple input modes depending on different directions or characteristics of the user s finger strokes.

Projector B may project a monochromatic laser or may use a collection of different colored lasers in combination to create full color display images on keys or keyboard in an illustrative embodiment. Full color may also be achieved by using a violet laser for projector B and using photoluminescent materials to alternately scale down the energy of the violet laser to provide a full color spectrum in the images projected onto keys or keyboard in another illustrative embodiment.

Projector B may also include a position sensing emitter that emits parallel to the image projection emitter. The position sensing emitter may be a non visible form of light such as an infrared laser for example and the imaging sensor may be configured to image reflections of the infrared light as they are visible through the surfaces of the keys . This provides another illustrative example of how a user s fingers may be imaged and tracked in interfacing with the keys so that multiple input modes may be implemented for each of the keys for example by tracking an optional lateral direction in which the surfaces of the keys are stroked in addition to the basic input of striking the keys vertically.

Because the boundaries of expansion portion are parallel and the boundaries of second waveguide section are angled relative to each other at a small angle waveguide is able to propagate projections provided by projector B from a small source through a substantially flat package to form images on a broad array of imaging surfaces such as the keys of keyboard and to convey images from that broad array back to imaging sensor B. Waveguide is therefore configured according to this illustrative embodiment to enable imaging sensor B to convey images provided by projector B onto the surfaces of keys only a sampling of which are explicitly indicated in as well as to detect physical displacement of the keys . The specific details of the embodiment of are exemplary and do not connote limitations. For example a few other illustrative embodiments are provided in the subsequent figures.

One projector projection controller imaging sensor and communication interface are operatively connected to waveguide nexus and thereby to lower waveguide while another projector projection controller imaging sensor and communication interface are operatively connected to waveguide nexus and thereby to upper waveguide . Expansion portion of lower waveguide lies underneath image portion of upper waveguide while expansion portion of upper waveguide lies on top of image portion of lower waveguide . Keyboard is laid on top of upper waveguide . Keyboard has keys a representative sample of which are indicated with reference number on the left side thereof and keys on the right side thereof again a representative sample of which are indicated with reference number .

Upper waveguide is thereby enabled to convey images projected by projector through expansion portion to image portion and on to the surfaces of keys on the left side of keyboard illustratively indicated by the representative projection ray paths A and B. Lower waveguide is similarly enabled to convey images projected by projector through expansion portion to image portion as these images are projected out the top of image portion they then pass entirely through expansion portion of upper waveguide and on to the surfaces of keys on the right side of keyboard illustratively indicated by the representative projection ray paths C and D. Although the horizontal boundaries of expansion portion of upper waveguide are strongly diverging the vertical boundaries thereof are planar and parallel and the projection ray paths of the images projected through lower waveguide may be directed substantially orthogonally to the lower vertical boundary of expansion portion of upper waveguide or otherwise configured such that these projection ray paths pass through expansion portion of upper waveguide to form the intended images on the surfaces of keys on the right side of keyboard . The timing for the projection of the images out projector connected with lower waveguide may be delayed a small amount roughly on the order of tenths of nanoseconds in one illustrative embodiment relative to the projection of the images out projector connected with upper waveguide to compensate for the additional distance traveled before intersecting the surfaces of keys analogously to a delay curve of the projection of the individual image portions from each of projectors or other projectors in other embodiments as a function of the distance each image portion must travel before intersecting the key surfaces roughly on the order of nanoseconds in one illustrative embodiment . In other embodiments these delays may not be implemented without any significant impact on the desired precision of performance.

Projector B of B projectors of B and projector of provide projection ray paths that form images on the keys by passing underneath them through the waveguides and striking the keys from below. In other embodiments the images can be provided to the image surfaces from above. An example of this is provided in .

Dynamic projected user interface device is also configured to use additional ambient surfaces off of keyboard as additional display surfaces as can be seen in the case of virtual numberpad . While projector projects some rays A onto keyboard to provide display images there it also projects other rays B onto an ambient space from a portion of desktop adjacent to keyboard to provide additional input interface space. Virtual numberpad is just one illustrative example of additional user interface images that can be projected onto any available ambient display surfaces while imaging sensor is equally capable of monitoring this additional user interface space such as virtual numberpad and detecting physical contacts with the user interface images projected there that correspond to a user physically contacting or pressing on the surface at a location corresponding to a projected key or whatever other form the ambient user interface space may take.

Among the advantages of such a projected virtual user interface space is that it avoids taking up space on a user s workspace or adding bulk to a user s hardware particularly for mobile devices while adding additional user interface space on an as needed basis. It may include any number of projected virtual user interface spaces of any variety for example which may be projected on either or both sides of keyboard .

While a numberpad is depicted in other virtual user interface spaces may include a media player a game control console another alphabetic keyboard a musical keyboard or a cursor control panel for example or any combination of these and other possible user interfaces. All of these projected user interfaces may be dynamically generated in accordance with an application currently being executed by an associated computing system or any other type of computing context currently engaged on an associated computing system.

In order to provide display images to each of a large number of keys and other display surfaces projector may for example use a spatial light modulator in one illustrative embodiment or two dimensional holographic projections in another embodiment or one or more laser emitters configured to project the display images in a rasterized scanning beam format in another illustrative embodiment.

In one illustrative embodiment projector may be configured to emit a non visible form of light such as ultraviolet light and at least some of the display surfaces comprise a composition adapted to re emit visible light responsively to absorption of the non visible light. This may be particularly useful to prevent the potential distraction of the light projected from projector shining on the user s fingers when the user is striking keys on keyboard . For example projector may emit ultraviolet rays onto the keys of keyboard while the keys include a composition that is adapted to re emit light at visible frequencies responsively to absorption of the non visible light. Such compositions may include phosphors optical brighteners quantum dots composed for example with cadmium sulfide or any of a wide variety of other substances that fulfill this function.

In order to prevent display images on keyboard from being shadowed by a user s fingers the keys of keyboard may also include a composition that is further adapted to re emit the visible light with a prolonged emission time so that momentary occlusion of the light being projected onto one of the display surfaces will not prevent the display image from continuing to appear. The latency period for the prolonged emission may be selected so that display images will persist for longer than the typical time a user might have her fingers in a given position over part of the keyboard during normal usage but not so long as to interfere substantially with a subsequent dynamically generated image when the image configuration for that key is reassigned. This may be in part addressed by a means for selectively dispersing a persistently latent image such as by digital light processing for example.

Projector may also include ultraviolet emitters for projecting onto keyboard in addition to visible light emitters for projecting onto an ambient display surface which may not be ideally configured for reflecting easily visible light in response to emission of ultraviolet or other non visible light. In another embodiment a user may be enabled to test and select from a variety of types of emitted light for the display images so that the user is free to select ultraviolet projections for ambient surfaces that interact well with ultraviolet projections or to select a visible frequency of her preference.

Some components of dynamic projected user interface device may be located separately from keyboard such as imaging sensor for example. Keyboard may also include one or more positioning reference transmitters for example on the corners thereof and in a non visible optical frequency such as infrared that may be tracked by imaging sensor and used to reference the position and orientation of keyboard . Imaging sensor may use this positioning reference to continue directing its imaging at the relevant positions of the keys on keyboard as keyboard moves relative to imaging sensor .

In the state in which it is depicted in dynamic projected user interface device includes display images for a fairly conventional layout for a numeric keypad such as might be the initial default in which it starts out beginning when the operating context of the associated computing system includes the operating system and background processes and system tray functions running but no active applications being executed. This layout may persist as the default when some other applications are opened by a user. Other applications may be configured so that when they are opened they quickly reconfigure the layout of the of keypad dynamic projected user interface device as a matter of course to provide input interface functionalities special to that application. Some applications or the operating system itself or other operating context of the associated computing system may also enable user configurability for dynamic projected user interface device .

The user has thereby reconfigured the keypad B of the dynamic projected user interface device B for her convenience including by reconfiguring keys for orthographic characters as function keys and vice versa and the reassignment inputs entered by the user were interpreted by the particular application at hand to provide instructions through communication interface to dynamic projected user interface device which thereby dynamically generated the new key display images accordingly. At the same time the application reorders the interpretation of the inputs sensed by imaging sensor to correspond to inputs in accordance with the display images in current display on the keys B.

The user or another application or computing context may later reconfigure the state of keypad B yet again by dynamically generating additional new display images and reconfiguring the interpretation of inputs on those keys accordingly. The examples in are only a small sampling of possible reconfigured keys of a dynamic projected user interface device. Other operating contexts may include for example a math or physics modeling application which provides options for assigning mathematical functions to the keys on keypad a presentation application that provides options for clipart icons to be assigned to the keys on keypad or a word processing program which alters the fonts of the letters and other orthographic characters as they are displayed on a keyboard in accordance with a font selected within the word processing application while many other possible examples are readily apparent from the configurations that naturally suggest themselves for any type of application or computing context.

The applications and their operating environments that may be used in such a way are further described with reference to . Software that includes computer executable instructions for implementing such a system may be stored on a medium such as a hard drive an optical disc a flash drive etc. and may be available to a computing system on a local bus a network connection and so forth. The software may configure a computing system to project user interface display images onto display surfaces. The user interface display images may be selectable from several user interface display images dependent on a context of the computing system such as an application an operating system a network connection status etc. The computing system may then detect physical contacts with the one or more display surfaces while the one or more user interface display images are projected thereon and interpret the physical contacts with the user interface display images as user inputs associated with the context of the computing system.

According to one illustrative embodiment computing system environment may be configured to perform collocation error proofing tasks in response to receiving an indication of a word collocation in a text. Computing system environment may then perform a Web search for each of one or more query templates associated with the indicated word collocation. Various query templates used may include a sentence a reduced sentence a chunk pair and or an individual word pair any of which may include the word collocation. Computing system environment may then evaluate whether results of the Web search for each of the query templates indicates that the word collocation corresponds to normal usage or whether it is disfavored or indicative of likely error. Normal usage may be indicated by either an exact match of the query template comprising the sentence or a matching score that is larger than a preselected threshold. The system may then indicate as part of the output of computing system environment via a user perceptible output device as a result of an embodiment of a collocation error proofing method whether the word collocation corresponds to normal usage or is disfavored and is indicated to be erroneous usage.

Computing system environment as depicted in is only one example of a suitable computing environment for executing and providing output from various embodiments and is not intended to suggest any limitation as to the scope of use or functionality of the claimed subject matter. Neither should the computing environment be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the exemplary operating environment .

Embodiments are operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with various embodiments include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers telephony systems distributed computing environments that include any of the above systems or devices and the like.

Embodiments may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Some embodiments are designed to be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules are located in both local and remote computer storage media including memory storage devices. As described herein such executable instructions may be stored on a medium such that they are capable of being read and executed by one or more components of a computing system thereby configuring the computing system with new capabilities.

With reference to an exemplary system for implementing some embodiments includes a general purpose computing device in the form of a computer . Components of computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies.

A user may enter commands and information into the computer through input devices such as a keyboard a microphone and a pointing device such as a mouse trackball or touch pad. Other input devices not shown may include a joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface .

The computer is operated in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a hand held device a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on remote computer . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

Memory is implemented as non volatile electronic memory such as random access memory RAM with a battery back up module not shown such that information stored in memory is not lost when the general power to mobile device is shut down. A portion of memory is illustratively allocated as addressable memory for program execution while another portion of memory is illustratively used for storage such as to simulate storage on a disk drive.

Memory includes an operating system application programs as well as an object store . During operation operating system is illustratively executed by processor from memory . Operating system in one illustrative embodiment is a WINDOWS CE brand operating system commercially available from Microsoft Corporation. Operating system is illustratively designed for mobile devices and implements database features that can be utilized by applications through a set of exposed application programming interfaces and methods. The objects in object store are maintained by applications and operating system at least partially in response to calls to the exposed application programming interfaces and methods.

Communication interface represents numerous devices and technologies that allow mobile device to send and receive information. The devices include wired and wireless modems satellite receivers and broadcast tuners to name a few. Mobile device can also be directly connected to a computer to exchange data therewith. In such cases communication interface can be an infrared transceiver or a serial or parallel communication connection all of which are capable of transmitting streaming information.

Input output components include a variety of input devices such as a touch sensitive screen buttons rollers and a microphone as well as a variety of output devices including an audio generator a vibrating device and a display. The devices listed above are by way of example and need not all be present on mobile device . In addition other input output devices may be attached to or found with mobile device such as dynamic projected user interface .

Mobile computing system also includes network . Mobile computing device is illustratively in wireless communication with network which may be the Internet a wide area network or a local area network for example by sending and receiving electromagnetic signals of a suitable protocol between communication interface and wireless interface . Wireless interface may be a wireless hub or cellular antenna for example or any other signal interface. Wireless interface in turn provides access via network to a wide array of additional computing resources illustratively represented by computing resources and . Naturally any number of computing devices in any locations may be in communicative connection with network . Computing device is enabled to make use of executable instructions stored on the media of memory component such as executable instructions that enable computing device to implement various functions of dynamic projected user interface in an illustrative embodiment.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims. As a particular example while the terms computer computing device or computing system may herein sometimes be used alone for convenience it is well understood that each of these could refer to any computing device computing system computing environment mobile device or other information processing component or context and is not limited to any individual interpretation. As another example while some embodiments are depicted and described with one or two projectors and associated components any number of projectors can be used in other embodiments with their associated components and configured to provide display images each to their own portion of one or more display surfaces or to overlapping portions of one or more display surfaces. This may include top down or bottom up projections or a combination of the two and may include waveguides disposed between any or all of the individual projectors and their respective display surfaces and with any combination of purpose built display surfaces such as a keyboard or keypad or ambient display surfaces. As yet another particular example while many embodiments are presented with illustrative elements that are widely familiar at the time of filing the patent application it is envisioned that many new innovations in computing technology will affect elements of different embodiments in such aspects as user interfaces user input methods computing environments and computing methods and that the elements defined by the claims may be embodied according to these and other innovative advances while still remaining consistent with and encompassed by the elements defined by the claims herein.

