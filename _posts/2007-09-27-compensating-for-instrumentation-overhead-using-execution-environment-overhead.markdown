---

title: Compensating for instrumentation overhead using execution environment overhead
abstract: A computer implemented method, apparatus, and computer program code for profiling an application. Execution of an application is monitored. A set of metrics relating to execution of the application occurring during monitoring execution of the application are collected to form a set of observed metrics. An execution environment overhead occurring with respect to the set of observed events is identified to form an identified execution environment overhead. The set of observed metrics is adjusted using the identified execution environment overhead to form a set of calibrated metrics.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08271999&OS=08271999&RS=08271999
owner: International Business Machines Corporation
number: 08271999
owner_city: Armonk
owner_country: US
publication_date: 20070927
---
The present invention is related to the following patent application entitled Method and Apparatus for Compensating for Instrumentation Overhead Using Sequences of Events Ser. No. 11 863 092 filed even date hereof assigned to the same assignee and incorporated herein by reference.

The present invention relates generally to an improved data processing system and in particular to a method and apparatus for optimizing performance in a data processing system. Still more particularly the present invention provides a computer implemented method apparatus and computer usable program code for identifying and adjusting for overhead caused by instrumentation code.

In analyzing and enhancing performance of a data processing system and the applications executing within the data processing system it is helpful to know which software modules routines and or methods executing on a data processing system are using system resources. Effective management and enhancement of data processing systems requires knowing how and when various system resources are being used. Performance tools are used to monitor and examine a data processing system to determine resource consumption as various software applications are executing within the data processing system. For example a performance tool may identify the most frequently executed modules and instructions in a data processing system or may identify those modules which allocate the largest amount of memory or perform the most input output requests. Hardware performance tools may be built into the system or added at a later point in time. Software performance tools also are useful in data processing systems such as personal computer systems which typically do not contain many if any built in hardware performance tools.

One known software performance tool is a profiler. A profiler is a program that monitors the execution of an application or program using one or more metrics. These metrics may take various forms. For example the metrics tracked by a profiler may include for example without limitation the cycles and number of instructions executed. With instructions the number of instructions executed while a routine is active also may be tracked. These and other metrics are examples of information that may be collected by a profiler for analysis and for use to improve performance of an application.

One example of a profiler is a trace tool which may use more than one technique to provide trace data that indicates execution flows for an executing program. One technique keeps track of particular sequences of instructions by logging certain events as they occur. This technique is referred to as an event based profiling technique. For example a trace tool may log every entry into and every exit from a module subroutine method function or system component. Alternately a trace tool may log the requester and the amounts of memory allocated for each memory allocation request. Corresponding pairs of records similar to entry exit records also are used to trace the execution of arbitrary code segments starting and completing input output or data transmission and for many other events of interest.

Measuring execution of code in a data processing system perturbs the data processing system. In other words monitoring the execution causes changes in the execution that would not be present if the monitoring did not occur. This effect is well understood in the study of elementary particle physics and is known as the Heisenberg uncertainty principle. With software profiling the cost associated with the tracing can severely affect the system being profiled. The effect may include disruption of the cache or the instruction pipeline or simply the overhead associated with the tracing.

One effect that may be measured is the overhead associated with the execution of instrumentation code within the execution flows of the application program. As the application program executes the instrumentation may incur significant overhead in the form of calls to obtain system information such as a call to obtain a current timestamp for a trace record. This cost also is referred to as instrumentation overhead.

Therefore it would be advantageous to provide a method and system to compensate for the disruptions described above during the profiling of code.

The different embodiments provide a computer implemented method apparatus and computer program code for profiling an application. Execution of an application is monitored. A set of metrics relating to execution of the application occurring during monitoring execution of the application are collected to form a set of observed metrics. An execution environment overhead occurring with respect to the set of observed events is identified to form an identified execution environment overhead. The set of observed metrics is adjusted using the identified execution environment overhead to form a set of calibrated metrics.

Turning now to a diagram of a data processing system is depicted in accordance with an illustrative embodiment of the present invention. In this illustrative example data processing system includes communications fabric which provides communications between processor unit memory persistent storage communications unit input output I O unit and display .

Processor unit serves to execute instructions for software that may be loaded into memory . Processor unit may be a set of one or more processors or may be a multi processor core depending on the particular implementation. Further processor unit may be implemented using one or more heterogeneous processor systems in which a main processor is present with secondary processors on a single chip. As another illustrative example processor unit may be a symmetric multi processor system containing multiple processors of the same type.

Memory in these examples may be for example a random access memory. Persistent storage may take various forms depending on the particular implementation. For example persistent storage may contain one or more components or devices. For example persistent storage may be a hard drive a flash memory a rewritable optical disk a rewritable magnetic tape or some combination of the above. The media used by persistent storage also may be removable. For example a removable hard drive may be used for persistent storage .

Communications unit in these examples provides for communications with other data processing systems or devices. In these examples communications unit is a network interface card. Communications unit may provide communications through the use of either or both physical and wireless communications links.

Input output unit allows for input and output of data with other devices that may be connected to data processing system . For example input output unit may provide a connection for user input through a keyboard and mouse. Further input output unit may send output to a printer. Display provides a mechanism to display information to a user.

Instructions for the operating system and applications or programs are located on persistent storage . These instructions may be loaded into memory for execution by processor unit . The processes of the different embodiments may be performed by processor unit using computer implemented instructions which may be located in a memory such as memory . These instructions are referred to as program code computer usable program code or computer readable program code that may be read and executed by a processor in processor unit . The program code in the different embodiments may be embodied on different physical or tangible computer readable media such as memory or persistent storage .

Program code is located in a functional form on computer readable media and may be loaded onto or transferred to data processing system for execution by processor unit . Program code and computer readable media form computer program product in these examples. In one example computer readable media may be in a tangible form such as for example an optical or magnetic disc that is inserted or placed into a drive or other device that is part of persistent storage for transfer onto a storage device such as a hard drive that is part of persistent storage . In a tangible form computer readable media also may take the form of a persistent storage such as a hard drive or a flash memory that is connected to data processing system . The tangible form of computer readable media is also referred to as computer recordable storage media.

Alternatively program code may be transferred to data processing system from computer readable media through a communications link to communications unit and or through a connection to input output unit . The communications link and or the connection may be physical or wireless in the illustrative examples. The computer readable media also may take the form of non tangible media such as communications links or wireless transmissions containing the program code.

The different components illustrated for data processing system are not meant to provide architectural limitations to the manner in which different embodiments may be implemented. The different illustrative embodiments may be implemented in a data processing system including components in addition to or in place of those illustrated for data processing system . Other components shown in can be varied from the illustrative examples shown.

For example a bus system may be used to implement communications fabric and may be comprised of one or more buses such as a system bus or an input output bus. Of course the bus system may be implemented using any suitable type of architecture that provides for a transfer of data between different components or devices attached to the bus system. Additionally a communications unit may include one or more devices used to transmit and receive data such as a modem or a network adapter. Further a memory may be for example memory or a cache such as found in an interface and memory controller hub that may be present in communications fabric .

With reference now to a block diagram illustrates the relationship of software components operating within a computer system that may implement the present invention. Java based system contains platform specific operating system that provides hardware and system support to software executing on a specific hardware platform. Java virtual machine JVM is one software application that may execute in conjunction with the operating system. Java virtual machine provides a Java run time environment with the ability to execute Java application applet which is a program servlet or software component written in the Java programming language. The computer system in which Java virtual machine operates may be similar to data processing system computer in . However Java virtual machine may be implemented in dedicated hardware on a so called Java chip Java on silicon or Java processor with an embedded picoJava core.

Java virtual machine supports all aspects of Java s environment including its architecture security features mobility across networks and platform independence.

The Java virtual machine is the name of a virtual computer component that actually executes Java programs. This flexibility allows different Java virtual machines to be designed for mainframe computers and PDAs. Java programs are not run directly by the central processor but instead by the Java virtual machine which is itself a piece of software running on the processor. The Java virtual machine allows Java programs to be executed on a different platform as opposed to only the one platform for which the code was compiled. Java programs are compiled for the Java virtual machine. In this manner a Java environment is able to support applications for many types of data processing systems which may contain a variety of central processing units and operating systems architectures. To enable a Java application to execute on different types of data processing systems a compiler typically generates an architecture neutral file format. The compiled code is executable on many processors given the presence of the Java run time system. The Java compiler generates bytecode instructions that are nonspecific to a particular computer architecture. A bytecode is a machine independent code generated by the Java compiler and executed by a Java interpreter. A Java interpreter is part of the Java virtual machine that alternately decodes and interprets a bytecode or bytecodes. These bytecode instructions are designed to be easy to interpret on any computer and easily translated on the fly into native machine code. Bytecodes are may be translated into native code by a just in time compiler or JIT.

A Java virtual machine loads class files and executes the bytecodes within them. The Java virtual machine contains a class loader which loads class files from an application and the class files from the Java application programming interfaces APIs which are needed by the application. The execution engine that executes the bytecodes may vary across platforms and implementations.

One type of software based execution engine is a just in time compiler. With this type of execution the bytecodes of a method are compiled to native machine code upon successful fulfillment of some type of criteria for jitting a method. The native machine code for the method is then cached and reused upon the next invocation of the method. The execution engine may also be implemented in hardware and embedded on a chip so that the Java bytecodes are executed natively. Java virtual machines usually interpret bytecodes but Java virtual machines may also use other techniques such as just in time compiling to execute bytecodes.

Interpreting code provides an additional benefit. Rather than instrumenting the Java source code the interpreter may be instrumented. Trace data may be generated via selected events and timers through the instrumented interpreter without modifying the source code. Profile instrumentation is discussed in more detail further below. Further many times the Java virtual machine itself may provide interfaces for obtaining information about processes and threads executing in the Java environment.

When an application is executed on a Java virtual machine that is implemented in software on a platform specific operating system a Java application may interact with the host operating system by invoking native methods. A Java method is written in the Java language compiled to bytecodes and stored in class files. A native method is written in some other language and compiled to the native machine code of a particular processor. Native methods are stored in a dynamically linked library whose exact form is platform specific.

With reference now to a block diagram of a Java virtual machine is depicted in accordance with an illustrative embodiment. Java virtual machine includes class loader subsystem which is a mechanism for loading types such as classes and interfaces given fully qualified names. Java virtual machine also contains runtime data areas execution engine native method interface and memory management . Execution engine is a mechanism for executing instructions contained in the methods of classes loaded by class loader subsystem . Execution engine may be for example Java interpreter or just in time compiler . Native method interface allows access to resources in the underlying operating system. Native method interface may be for example a Java native interface.

Runtime data areas contain native method stacks Java stacks PC registers method area and heap . These different data areas represent the organization of memory needed by Java virtual machine to execute a program.

Java stacks are used to store the state of Java method invocations. When a new thread is launched the Java virtual machine creates a new Java stack for the thread. The Java virtual machine performs only two operations directly on Java stacks it pushes and pops frames. A thread s Java stack stores the state of Java method invocations for the thread. The state of a Java method invocation includes local variables the parameters with which the thread was invoked return value if any and intermediate calculations for the method. Java stacks are composed of stack frames. A stack frame contains the state of a single Java method invocation. When a thread invokes a method the Java virtual machine pushes a new frame onto the Java stack of the thread. When the method completes the Java virtual machine pops and discards the frame for that method. The Java virtual machine does not have any registers for holding intermediate value. Any intermediate values are stored in a call stack.

PC registers indicate the next instruction to be executed. Each instantiated thread has its own program counter register and Java stack. If the thread is executing a Java virtual machine method the value of the program counter register indicates the next instruction to execute. If the thread is executing a native method then the contents of the program counter register are undefined.

Native method stacks store the state of invocations of native methods. The state of native method invocations is stored in an implementation dependent way in native method stacks registers or other implementation dependent memory areas. In some Java virtual machine implementations native method stacks and Java stacks are combined.

Method area contains class data while heap contains all instantiated objects. The Java virtual machine specification strictly defines data types and operations. Most Java virtual machines choose to have one method area and one heap each of which are shared by all threads running inside the Java virtual machine. When the Java virtual machine loads a class file the Java virtual machine parses information about a type from the binary data contained in the class file.

The Java virtual machine places this type information into the method area. Each time a class instance or array is created the memory for the new object is allocated from heap . Java virtual machine includes an instruction that allocates memory space within the memory for heap but includes no instruction for freeing that space within the memory. Memory management in the depicted example manages memory space within the memory allocated to heap . Memory management may include a garbage collector which automatically reclaims memory used by objects that are no longer referenced. Additionally a garbage collector also may move objects to reduce heap fragmentation.

The illustrative embodiments provide a computer implemented method apparatus and computer usable program code for processing events. Events occurring during the execution of an application are monitored to form monitored events. A plurality of sequences of method types and transition types are identified from the monitored events.

The different illustrative embodiments provide a computer implemented method apparatus and computer usable program code for monitoring execution of an application. Events occurring during execution of the application while during monitoring execution of the application are identified to form a set of observed events. An execution environment overhead occurring with respect to the set of observed events is identified to form an identified execution environment overhead. The set of observed metrics for the observed events is adjusted using the identified execution environment overhead to form a set of calibrated metrics. As used herein a set refers to one or more items. For examples a set of events may be one or more events. As another example a set of values contains one or more values.

In some embodiments monitoring of events occurring during execution of an application to form monitored events occurs. Event types are identified from the monitored events. Environmental overhead values are identified for the identified event types to form identified environmental overhead values. Overhead compensation values are identified for the identified event types to form identified overhead compensation values. Overhead compensation values are adjusted for the identified event types using the identified environmental overhead values to form identified environment overhead compensation values. Observed metrics for the monitored events are adjusted using the identified environmental overhead compensation values.

The different embodiments provide at least two mechanisms for calibrating overhead observed during execution of an application. In one embodiment the sequences of transition types and method types are considered. In another embodiment the execution environment overhead without instrumentation of an application is used. These two techniques may be used independently or in conjunction with each other to calibrate data collected or observed during execution of an application.

With reference now to a block diagram of components used to identify method types and transition types is depicted in accordance with an illustrative embodiment. In this example these components are used to identify method types and transition types. This information is then used to identify the amount of overhead that occurs from instrumentation code being included to profile or identify performance of programs or other codes executing on a data processing system. This type of overhead is also referred to as instrumentation overhead.

In these examples profiler profiles processes . In particular profiler may identify information about threads executing within processes .

Processes are executed by Java virtual machine in these examples. As threads execute Java virtual machine generates events . Events may be for example entry and exit events into and out of methods which are transitions between methods. The generation of events may be initiated using various mechanisms. In these examples events are self instrumented by Java virtual machine . In other embodiments other mechanisms may be used. For example without limitation hooks may be used in some cases.

Events are sent to profiler through interface in Java virtual machine . These interfaces may take various forms. For example interface may be a Java virtual machine tool interface JVMTI or a Java virtual machine profiling interface JVMPI . With these types of interfaces events are generated as part of callouts to profiler . The Java virtual machine tool interface is a native interface within Java virtual machine that is available in Java 5 Software Development Kit SDK . The Java virtual machine profiling interface is available in both the Java 2 Platform Standard Edition J2SE SDK and Java 5. These kits are available from Sun Microsystems Inc.

In response to receiving events from interface profiler may send queries to Java virtual machine through interface . Queries may be used to identify information such as method types. In Java environments these method types may include for example at least one of jitted static methods jitted non static methods interpreted static methods interpreted non static methods native static methods and native non static methods. In these examples at least one of means one of more of the items in the list. As an example at least one of may include just jitted static methods or jitted static methods and interpreted static methods. In other examples one method may be present for each of the method types.

Responses from interface may include this information. In some cases the information may be derived from method identifiers. This method identifier may be used to determine the type of method executing in threads . In some embodiments the type of method or method type may be identified from events . In these embodiments the event may identify the method as jitted interpreted or native. Also profiler may make a call to device driver or some other utility or code to obtain metric information. For example profiler may call device driver to identify a number of instructions completed on threads and the differences between the number of instructions completed when transitioning from one method to another method. These differences are also referred to as deltas.

The information collected by profiler forms trace information. Profiler stores this trace information as trace data within buffer . Trace data may be structured as records. These records may correspond to events received in callouts from interface . In these examples trace data includes method types transition types and other trace data .

Trace data may be organized in the form of records in which each record contains information for a particular event that is received. Other trace data may include for example accumulations of metric changes as well as adjustments to metrics. In these examples other trace data may include the number of instructions completed.

With this information profiler may identify instrumentation overhead generated by Java virtual machine self instrumenting itself to create events to profile the execution of threads within processes .

Further the different advantageous embodiments may include processes to compensate or calibrate for the identified instrumentation overhead. These processes may be found in a software component such as profiler . The information about instrumentation may be used to adjust other trace record information to increase the accuracy of the observed execution of a program process and or thread of interest.

Calibration is a process compensating for overhead caused by the execution of instrumentation when performance testing or profiling the execution of an application. In these examples instrumentation or instrumentation code refers to the code that is executed to generate information about program execution or to record performance information about a running application.

In the illustrative examples calibration is typically performed by identifying a smallest number of instructions executed between two consecutive events. That number is decremented by one and subtracted from all observed instruction counts. The decrement by one instruction is to take into account the call or return instruction itself. This result is intended to represent the number of instructions that would have been observed if no instrumentation had been inserted into the application.

The adjustment of the trace information may be performed dynamically during execution of the application or may be performed after the application has completed execution during post processing.

In some illustrative embodiments these adjustments are made dynamically or on the fly to trace data in buffer while an application executes. In other illustrative embodiments trace data may be post processed after execution of the application is completed and then adjusted to take into account the instrumentation overhead. When the calibration is performed dynamically profiler may adjust trace data while trace data is still stored in buffer . Profiler may then write trace data into file after execution of the application has completed. Profiler may then generate reports using the information in file .

In other illustrative embodiments the calibration or adjustment for instrumentation overhead may be performed after execution of the application has completed and trace data is stored in file . In this type of embodiment profiler adjusts the trace data within file before generating reports .

As a result the different illustrative embodiments provide a computer implemented method apparatus and computer usable program code for more accurately identifying instrumentation overhead. The different illustrative embodiments are especially useful when instrumentation occurs at entry and exit points of methods. The different illustrative embodiments also recognize that adjusting metrics involving instruction execution for these types of transitions by only one instruction does not take into account actual execution environment overhead.

With reference next to a state diagram illustrating different phases in profiling active processes is depicted in accordance with an illustrative embodiment. The different states illustrated in may be implemented using components described above with respect to . In particular these components may include profiler Java virtual machine and interface with respect to the execution of threads and processes in .

Initialization phase captures the state of the data processing system at the time tracing is initiated. This phase may include the collection of profiling data which is used later.

Next during profiling phase trace data in the form of trace records are written to a trace buffer or file such as buffer or file in . The trace records originate from event based profiling. Event based records may originate from events generated by an interface in the Java virtual machine in response to a particular type of event such as a method entry or method exit. In some embodiments calibration processes are performed to adjust the trace data to take into account instrumentation overhead during this phase.

In post processing phase the calibration or adjustment for instrumentation overhead may be performed.

Of course depending on available resources the post processing also may be performed on the client data processing system.

Alternatively trace information may also be processed on the fly so that trace data structures are maintained during profiling phase .

In the event based traces a fundamental assumption is made that entry exit pairs are nested in the traces because routines call other routines. Time spent or memory consumed between entry into a routine and exit from the same routine is attributed to that routine. However a user of a profiling tool may want to distinguish between time spent directly in a routine and time spent in other routines that it calls.

With reference now to a time chart is depicted in accordance with an illustrative embodiment. In this example time chart illustrates an example of the manner in which time may be spent in two routines an application s main calls routine A at time t equal to zero routine A computes for 1 ms and then calls routine B routine B computes for 8 ms and then returns to routine A routine A computes for 1 ms and then returns to main .

From the point of view of main routine A took 10 ms to execute but most of that time was spent executing instructions in routine B and was not spent executing instructions within routine A. This information is useful for a person attempting to optimize the example program. In addition if routine B is called from many places in the program it might be useful to know how much of the time spent in routine B was on behalf of or when called by routine A and how much of the time was on behalf of other routines.

The post processing of a trace file may result in a report consisting of three kinds of time spent in a routine such as routine A 1 base time the time spent executing code in routine A itself 2 cumulative time the time spent executing in routine A plus all the time spent executing every routine that routine A calls and all the routines they call etc. and 3 wall clock time or elapsed time. This type of timing information may be obtained from event based trace records as these records have timestamp information for each record.

A routine s cumulative time is the sum of all the time spent executing the routine plus the time spent executing any other routine while that routine is below it on the call stack. In the example above in routine A s base time is 2 ms and its cumulative time is 10 ms. Routine B s base time is 8 ms and its cumulative time is also 8 ms because it does not call any other routines. It should be noted that cumulative time may not be generated if a call stack tree is being generated on the fly.

If metrics are virtualized by synchronous events on thread base and cumulative time are unaffected by interrupts dispatching or blocking. Base time only increases while a routine is running and cumulative time only increases while the routine or a routine below it on the call stack is running.

In the example in routine A s elapsed time is the same as its cumulative time 10 ms. Changing the example slightly suppose there was a 1 ms interrupt in the middle of B as shown below in .

With reference next to a time chart illustrating an interrupt is depicted in accordance with an illustrative embodiment. In time chart routine A s base and cumulative time are unchanged at 2 ms and 10 ms but its elapsed time is now 11 ms.

More general definitions for the accounting concepts during profiling include the following base the amount of the tracked system resource consumed directly by this routine cumulative the amount of the tracked system resource consumed by this routine and all routines below it on the call stack elapsed the total amount of the tracked system resource consumed by any routine between entry to this routine and exit from the routine.

With reference now to a diagram illustrating sources of instrumentation overhead is depicted in accordance with an illustrative embodiment. Event flow diagram illustrates events with respect to four subroutines in an application. Main results in subroutine A subroutine B subroutine C and subroutine D being called. In this example subroutine A is called by main . In turn subroutine A calls subroutine B . Additionally subroutine A also calls subroutine C . Subroutine C calls subroutine D .

In this example an event occurs at each of transitions and . Each of these transitions is either an entry to or an exit from a method. Instrumentation is used to generate an entry or exit event to obtain information about the execution of the application when these transitions occur. The different illustrative embodiments recognize that these transitions may include more instrumentation overhead than merely the instruction required to enter or exit a subroutine.

In this example e represents a delta metric associated with an entry event while x represents a delta metric associated with a method exit event. These delta metrics include the instrumentation overheads associated with each event. It is this instrumentation overhead that is removed in the various illustrative embodiments.

Previously algorithms or processes used to remove instrumentation overhead operated by observing all entry and exit events and saving minimum observed values. These processes assumed that the minimum value is the result of a single call or return instruction between invocations of the instrumentation. This technique does not take into account the actual overhead associated with instrumentation of code during profiling.

The different illustrative embodiments recognize that the context in which the methods are invoked should be considered. In other words the different illustrative embodiments recognize that other types of methods are being executed and also need to be identified. As a result a series of method executions may have a number of variations of overhead depending on the types of methods being invoked.

Further the different illustrative embodiments also recognize that the execution of methods includes overhead that is present because of the environment in which the execution of the application occurs. This overhead is also referred to as execution environment overhead. Other overhead that occurs in addition to the execution environment overhead is considered instrumentation overhead. The instrumentation overhead is overhead that the different embodiments may adjust for in calibrating a set of metrics collected during monitoring the execution of the application. In addition and or alternatively adjustment for overhead may be performed based on sequences of method types and transition types. As a result the overhead observed during execution may be calibrated using the sequence of transition types and method types and or identifications of execution environment overhead.

In this example information about method entry and method exit events may be captured and stored within a buffer. A device driver such as device driver in may be used. With this type of implementation the device driver may capture the current total number of instructions completed for a particular thread. Further the device driver also may compute or identify the deltas or differences between the numbers of instructions.

Of course other metrics may be used other than instructions. For example time or cache misses may be used. In these examples accuracy is improved by guaranteeing a constant overhead in the code that reads the metrics.

With reference now to an event flow diagram is depicted in accordance with an illustrative embodiment. In this example event flow diagram illustrates identifying different types of overhead to take into account entry and exit for different types of methods.

In this example a Java program such as main calls methods such as method A method B method C and method D . All of these methods are executed as subroutines prior to returning to main . In this example main calls method A which in turn calls method B . Method B exits back to method A which then calls method C . Method C calls method D . After executing method D exits back to method C which exits to method A . Method A then returns to main .

Transitions and are events that occur during the execution of the application at which instrumentation is executed. The different illustrative embodiments adjust the observed delta metrics to remove overhead caused by the instrumentation. The different illustrative embodiments recognize that in addition to the type of transition the context in which a transition occurs may affect the amount of instrumentation overhead. The adjustment also depends on the execution environment.

In this example e1 identifies pre instrumentation entry overhead e2 identifies post instrumentation entry overhead. Also x1 identifies pre instrumentation exit overhead and x2 identifies post instrumentation exit overhead. Rather than identify the unique combinations of e1 e2 x1 and x2 for all method types the illustrative embodiments identify sequences of method types and transition types.

This type of information may be used to identify the minimum overhead values for all combinations of entry and exit events followed by entry and exit events for all combinations of identifiable method types.

In these examples the different minimum overhead values are identified for all combinations of entry and exit events followed by entry and exit events for all combinations of identifiable method events. These entry and exit events are transitions. In the Java Virtual Machine JVM the identifiable method types include but are not limited to jitted static methods jitted non static methods interpreted static methods interpreted non static methods native static methods and native non static methods. In considering all sequences of methods and transitions the transition types include but are not limited to method entry and method exit. If only these method types and transition types are considered a total of 6 2 6 2 6 864 possible sequences of two transitions from a first method to a second method to a third method are present. Some of these sequences will never occur since a return from a method must be to the same type of method that called it. These are some of method types that may be found in a Java programming environment. Others may exist in other programming environments. Other transition types such as return due to exception process might also be considered.

With reference now to an event flow diagram is depicted in accordance with an illustrative embodiment. In this example event flow diagram illustrates a metric that changes between two events. These metrics may take various forms as described above. The metric may be for example without limitation the number of instructions or the amount of time that has passed.

Previous event is the point at which a previous event has occurred such as an entry event or an exit event. Current event is the point at which the subsequent event has been recorded as occurring such as the next entry event or exit event. The difference between previous event and current event is delta event .

The different embodiments are directed towards determining whether delta event contains identifiable instrumentation overhead. The different illustrative embodiments include processes to identify the amount of instrumentation overhead. In these examples the instrumentation overhead may be quantified using different types of metrics. The particular metric may be for example time or a number of instructions.

The metric measured between these two events may include a portion that is attributed to the execution of the routine as well as another portion that is attributed to the execution of code relating to instrumentation that facilitates recording or tracing of previous event and current event . The portion of the recorded metric within delta event that is associated with the execution of the routine is referred to as adjusted delta event . The portion of the delta event associated with the instrumentation overhead is referred to as event instrumentation overhead .

The different illustrative embodiments may identify current event instrumentation overhead and subtract that value from delta event to obtain adjusted delta event . Adjusted delta event more accurately identifies the value of the metric that is actually associated with executing a particular routine.

In the different examples this metric may take the form of time or instructions. When time is used adjusted delta event may be considered the base time of the routine.

With reference now to a high level flowchart of a process for calibrating metrics observed during the execution of an application is depicted in accordance with an illustrative embodiment. The process in this example may be applied to an observed metric on a per thread basis.

The process begins by monitoring events occurring during execution of an application step . In particular the events may be selected once for a particular process or set of threads that execute for the application. This monitoring may be performed using an interface such as interface in Java virtual machine in .

Next a sequence of method types and transition types are identified from the monitored events step . In this example the method type identifies the type of method from the events. The process then calibrates metrics for the events using the sequence of method types and transition types step . The calibrating of the metrics for the events may be performed a number of different ways. In particular overhead compensation values may be identified for each sequence of method types and transition types. These values represent the minimum metric value for a particular sequence of method types and transition types. This minimum value may be subtracted from the actual value for the observed or recorded sequence of method types and transition types to adjust that value to exclude the instrumentation overhead.

The overhead compensation value is a minimum overhead compensation value in these examples. A set of overhead compensation values which is used to adjust the observed metrics may be adjusted to account for the execution environment overhead.

The calibrating of the metrics may be performed dynamically while the application is executing and while events are occurring. In other illustrative embodiments the calibration of the metrics may occur in a post processing phase after execution of the application has completed.

In this manner the overhead associated with instrumentation may be removed from observed metrics to provide a more accurate identification of the overhead used by a particular application and execution. The different illustrative embodiments improve the calibration processes by separating the overhead for the language from the instrumentation overhead.

The execution environment overhead in these examples is the overhead imposed by the execution environment when no instrumentation exists. These values may be identified by running another application especially designed to generate data for the different sequences of method types and transition types that are desired. This application is examined without instrumentation to obtain the execution environment overhead associated with each sequence. This execution environment overhead replaces the adjustment of one instruction that was previously used. Any technique that allows for identifying the execution environment overhead may be used. In one embodiment this identification is performed by manually examining portions of the generated code. In another embodiment this is done by automatically examining the code generated for routines that have been carefully designed to demonstrate the overhead.

With reference next to a high level flowchart of a process for identifying method times and transitions is depicted in accordance with an illustrative embodiment. The process illustrated in may be implemented in a profiling process such as profiler in .

The process begins by waiting for an event step . Step involves waiting for a callout to be generated by an interface such as interface in Java virtual machine in . When a callout for an event occurs the process identifies the type of event step . In these examples the type of event may be identified from information in the callout itself. The event may be for example an entry or exit event.

Thereafter the process identifies the method type and the caller step . The identification of these method types may be made from the event received by the process. Further the caller of the method also is identified in these examples in step .

Next a utility or device driver is called to obtain new values of the metrics on the thread and deltas step . These values are instructions in step . This may be for example the current time or instruction being executed. The process then stores the method type the transition type and the metric changes step . The metric changes in step include for example changes caused by the execution of the instrumentation. As one example one of the metrics may be the instructions completed for the thread. With this type of example the instructions also include instrumentation instructions that are executed or have occurred since the last event.

Next the control is returned to the Java virtual machine step with the process then returning to step as described above. At this point execution of the application continues.

With reference now to a flowchart of a process for building a call stack tree is depicted in accordance with an illustrative embodiment. In this example the process illustrated in is an example of a process that may be implemented in a process such as profiler in to generate a call stack tree using trace data. In these examples this process is used to build a call stack tree for illustrating entry and exit points for the different methods.

The process begins by determining whether more trace records are present in the trace text file step . If more trace records are present several pieces of data are obtained from the trace record including metrics and whether the event is an entry or an exit step .

Next the last metric increment is attributed to the current node in the tree step . A check is made to determine if the trace record is an entry or an exit record step . If an exit record is present the tree is traversed to the parent using the parent pointer and the current tree node is set equal to the parent node step . If the trace record in step is an entry record a determination is made to determine if the module is already a child node of the current tree node step . If the module is not already a child node a new node is created for the module and it is attached to the tree below the current tree node step .

The tree is then traversed to the module s node and the current tree node is set equal to the module node step . In step if the module is already a child node the process proceeds to step as described above. The number of calls to the current tree node is then incremented step . This process is repeated for each trace record in the trace output file until there are no more trace records to parse. If there are no more trace records to parse in step the process terminates.

With reference now to a flowchart depicts a method for dynamically building a call stack tree as tracing is taking place during system execution. The process illustrated in may be performed using a profiler such as profiler in . In as an event is logged it is added to the tree in real time. Preferably a call stack tree is maintained for each thread. The call stack tree reflects the call stacks recorded to date and a current tree node field indicates the current location in a particular tree.

The process begins by waiting for an event step . When an event occurs the thread identification is obtained step . The time type of event location of the thread s call stack and location of the thread s current tree node are then obtained step . The type of event may be for example whether the event is an entry or exit. The last metric increment is attributed to the current tree node step . A determination is made to determine if the event is an entry or an exit event step .

If the event is an exit event the tree is traversed to the parent using the parent pointer and the current tree node is set equal to the parent node step . At this point the tree may be dynamically pruned in order to reduce the amount of memory dedicated to its maintenance step . The process then returns to step to wait for another event. Pruning is discussed in more detail below.

If the event is an entry event a determination is made as to whether the method is already a child node of the current tree node step . If the method is not already a child node of the current tree node a new node is created for the method and it is attached to the tree below the current tree node step . The tree is then traversed to the method s node and the current tree node is set equal to the method node step . In step if the method is already a child node of the current tree node the process proceeds to step as described above. The number of calls to the current tree node is then incremented step . The process then passes control back to the executing module returns to step to wait for the next event to occur.

One of the advantages of using the dynamic tracing reduction technique described in is its enablement of long term system trace collection with a finite memory buffer. Very detailed performance profiles may be obtained without the expense of an infinite trace buffer. Coupled with dynamic pruning the method depicted in can support a fixed buffer size trace mechanism.

The use of dynamic tracing and reduction with dynamic pruning in some cases is especially useful in profiling the performance characteristics of long running programs. In the case of long running programs a finite trace buffer can severely impact the amount of useful trace information that may be collected and analyzed. By using dynamic tracing and reduction and perhaps dynamic pruning an accurate and informative performance profile may be obtained for a long running program.

Many long running applications reach a type of steady state where every possible routine and call stack is present in the tree and updating statistics. Thus trace data can be recorded and stored for such applications indefinitely within the constraints of a bounded memory requirement using dynamic pruning. Pruning has value in reducing the memory requirement for those situations in which the call stacks are actually unbounded. For example unbounded call stacks are produced by applications that load and run other applications.

Pruning can be performed in many ways and a variety of pruning criteria is possible. For example pruning decisions may be based on the amount of cumulative time attributed to a subtree. Note that pruning may be disabled unless the amount of memory dedicated to maintaining the call stack exceeds some limit. As an exit event is encountered such as in step the cumulative metric associated with the current node is compared with the cumulative metric associated with the parent node. If the ratio of these two cumulative metrics does not exceed a pruning threshold then the current node and all of its descendants are removed from the tree. The algorithm to build the tree proceeds as before by traversing to the parent and changing the current node to the parent.

Many variations of the above pruning mechanism are possible. For example the pruning threshold can be raised or lowered to regulate the level of pruning from very aggressive to none. More global techniques are also possible including a periodic sweep of the entire call stack tree removing all subtrees whose individual cumulative times are not a significant fraction of their parent node s cumulative times.

Data reduction allows analysis programs to more easily and quickly answer many questions regarding metrics such as for example how computing time was spent within the traced program. This information may be gathered from processes such walking the tree and accumulating the data stored at various nodes within the call stack tree. This information may be processed to determine different metrics such as for example the amount of time spent strictly within a routine the total amount of time spent in the routine and in other routines called by the routine either directly or indirectly.

With reference now to a flowchart of a process for identifying the difference between one event and another event is depicted in accordance with an illustrative embodiment. The process illustrated in may be implemented in a software component such as profiler in . In this example the process in may be used to attribute or associate the difference in a metric between one event and another event to a routine. This process may be applied to interpret how data is written to a trace file and to attribute changes in metrics recorded in a trace file among routines within execution flows. This process may be performed in a post processing phase or may be performed during profiling depending on the particular implementation. In these examples this process does not include taking into account instrumentation overhead.

Still referring to the process begins by retrieving or obtaining the previous event metric that was saved from the previous trace record step . The next trace record in the trace data is then retrieved and parsed step . The current event metric is obtained from the information in the current trace record step . The process then obtains the last event metric and increase increments this value as a difference between the current event metric and the previous event metric Step . This difference represents the delta event metric in these examples. The process then associates the delta event metric to the current routine step with the process terminating thereafter. This delta event metric also may be referred to as a last metric.

With reference now to a flowchart of a process for obtaining or computing overhead compensation values to compensate for instrumentation overhead associated with entry events and exit events by methods is depicted in accordance with an illustrative embodiment. The process illustrated in may be implemented in a software component such as profiler in . This process may be used to adjust the value of a metric to take into account instrumentation overhead for a particular metric between events. This adjustment takes into account overhead that occurs from the instrumentation used to monitor the execution of an application. Overhead compensation values associated with each metric of interest may change over time.

For example the delta metric may start at a large value and be replaced with a smaller value every time a smaller delta metric is observed. In some examples time may be used as the metric while in other examples the number of instructions executed is the metric. Of course these different processes may be applied to any type of metric of interest such as cache misses.

The process begins by initializing various metric values such as the overhead compensation values to the same large number step . An event in a trace record is retrieved from the trace file step and parsed to obtain the current event metric and event type from the trace record step .

The current event metric is the current value of the metric of interest. The event type is the sequence of methods and method transitions. Each method type may have a different number of methods and transitions and method types and types of transitions. In the depicted examples a sequence of two transitions and the methods in those transitions may be identified. In other embodiments additional numbers of transitions and methods may be identified. In yet other embodiments only a single method and transition may be used in identifying method types. As the sequence becomes larger the number of event types increase.

The delta event metric is computed as the difference between the current event metric and the previous event metric step . The overhead compensation value associated with the event is identified step . The overhead compensation value is updated with the delta event metric if the delta event metric is smaller than the current value of the overhead compensation value Step . This step is used to identify the smallest value for the particular metric in identifying an overhead compensation value for the instrumentation overhead. If not then the delta event metric is ignored and the process branches to handle other trace records.

A determination is then made as to whether more events are present in the trace data to be processed step . If additional events are present then the process branches back to step to process another trace record. If additional events are not present the process terminates. In this manner the overhead compensation values may be used to identify overhead for various sequences of method types and transition types.

With reference now to a flowchart of a process for adjusting trace records to take into account instrumentation overhead is depicted in accordance with an illustrative embodiment. The process illustrated in may be implemented in a software component such as profiler in .

The process begins with the retrieval of a previous event metric that was saved from the immediately preceding trace record step . The process retrieves the next trace record from the trace file step and parses it to obtain the current event metric and event type from the trace record step .

The event is identified step . Next the overhead compensation value for the event is identified step . The process then subtracts the previous event metric from the current event metric to get the delta event metric step . The process then subtracts the event overhead compensation value from the delta event metric to get the adjusted delta event metric step . The process then attributes the adjusted delta event metric to current routine step .

The current event metric is saved as the previous event metric step with the process terminating thereafter.

Thus the different illustrative embodiments provide a computer implemented method apparatus and computer usable program code for identifying instrumentation overhead. The instrumentation overhead is identified for each type of event as described above. In the different illustrative embodiments events in the form of a sequence of method and transition types are used to better identify the context in which instrumentation is applied to the metrics associated with an application. These identifications allow for more accurate calibrations. The different illustrative embodiments also provide a computer implemented method apparatus and computer usable program code for removing only the overhead associated with the instrumentation. The adjusted metrics represent an accurate estimate of the metrics associated with the uninstrumented application.

The invention can take the form of an entirely hardware embodiment an entirely software embodiment or an embodiment containing both hardware and software elements. In a preferred embodiment the invention is implemented in software which includes but is not limited to firmware resident software microcode etc.

Furthermore the invention can take the form of a computer program product accessible from a computer usable or computer readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description a computer usable or computer readable medium can be any tangible apparatus that can contain store communicate propagate or transport the program for use by or in connection with the instruction execution system apparatus or device.

The medium can be an electronic magnetic optical electromagnetic infrared or semiconductor system or apparatus or device or a propagation medium. Examples of a computer readable medium include a semiconductor or solid state memory magnetic tape a removable computer diskette a random access memory RAM a read only memory ROM a rigid magnetic disk and an optical disk. Current examples of optical disks include compact disk read only memory CD ROM compact disk read write CD R W and DVD.

A data processing system suitable for storing and or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code bulk storage and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.

Input output or input output devices including but not limited to keyboards displays pointing devices etc. can be coupled to the system either directly or through intervening input output controllers.

Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems cable modem and Ethernet cards are just a few of the currently available types of network adapters.

The description of the present invention has been presented for purposes of illustration and description and is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain the principles of the invention the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

