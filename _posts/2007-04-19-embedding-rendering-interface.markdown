---

title: Embedding rendering interface
abstract: Methods, computer program products and systems for accessing an electronic document, the electronic document including embedded content, where the file type of the electronic document differs from the file type of the embedded content. The embedded content is provided to a first rendering engine in accordance with the embedded content file type. Rendered embedded content is received from the first rendering engine. The rendered embedded content is blended with a rendering of a page of the electronic document.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08612847&OS=08612847&RS=08612847
owner: Adobe Systems Incorporated
number: 08612847
owner_city: San Jose
owner_country: US
publication_date: 20070419
---
This application claims priority to U.S. Patent Application No. 60 828 063 entitled ELECTRONIC PUBLISHING to inventors William H. McCoy et al. which was filed on Oct. 3 2006. This application also claims priority to U.S. Patent Application No. 60 862 583 entitled RENDERING EMBEDDED CONTENT to inventors Richard Wright et al. which was filed on Oct. 23 2006. The disclosures of the above applications are incorporated herein by reference in their entirety.

The present disclosure relates to software and in particular to software for rendering electronic documents.

Electronic documents or documents can include various kinds of content. For example a word processing document can contain text a embedded video presentation and an embedded electronic spreadsheet all of which have a visual representation on one or more pages of the document. Documents can be represented as tree data structures where leaf nodes represent content e.g. text video presentations spreadsheets and non leaf nodes represent groupings or arrangement of content. Trees can be used to display and modify documents by software applications. Software applications for specific types of documents e.g. a word processors spreadsheets typically have a predetermined set of content types that they can natively render. Applications conventionally deal with non native content by ignoring the content translating the content into a native format and rendering the native format. Alternatively applications can invoke auxiliary software e.g. Object Linking and Embedding ActiveX to render the content into a fixed rectangular region on a rendering of a document page. But the above approaches do not allow embedded content to be composited since the embedded content is rendered without reference to other embedded content.

In general one aspect of the subject matter described in this specification can be embodied in a method that includes accessing an electronic document the electronic document including embedded content where the file type of the electronic document differs from the file type of the embedded content. The embedded content is provided to a first rendering engine in accordance with the embedded content file type. Rendered embedded content is received from the first rendering engine. The rendered embedded content is blended with a rendering of a page of the electronic document. Other implementations of this aspect include corresponding systems apparatus and computer program products.

These and other implementations can optionally include one or more of the following features. The embedded content further includes nested content and the file type of the embedded content differs from a file type of the nested content. The first rendering engine is further configured to 1 provide the nested content to a second rendering engine and 2 receive rendered nested content from the second rendering engine. The rendered nested content can be composited with the rendered embedded content. A transparency model transformation matrix can be applied to the rendered embedded content. The embedded content file type is PDF Flash HTML ShockWave or SVG. The embedded content further includes nested content and the file type of the embedded content differs from a file type of the nested content the method further comprising 1 providing the nested content to a second rendering engine in accordance with the nested content file type 2 receiving rendered nested content from the second rendering engine and 3 blending the rendered nested content with the rendered embedded content. It is determined if a user can access the document. The plurality of rendering engines comprise reentrant rendering engines.

Particular implementations of the subject matter described in this specification can be implemented to realize one or more of the following advantages. Documents can contain an unlimited amount of embedded content of varying content file types. Any number of rendering engines can be incorporated into the document rendering system as long as each rendering engine implements a common API. Rendering engines can be obtained dynamically on an as needed basis in order to render a document. Rendering engines are reentrant that is they can be invoked more than once before they have completed a rendering task. Moreover rendering engines are aware of and can take advantage of a transparency model for compositing rendered content on a document page. Rendering engines can be written independently of each other and use different rendering primitives. A common rendering software library is not required.

The details of one or more implementations of the invention are set forth in the accompanying drawings and the description below. Other features aspects and advantages of the invention will become apparent from the description the drawings and the claims.

Generally speaking documents contain content or flows e.g. paragraphs of text images tables which are called elements of the flow that are structured in some fashion. In various implementations documents conform to the Open eBook Publication Structure OEBPS standard promulgated by the International Digital Publishing Forum IDPS . Documents can include content having different content file types such as Adobe Portable Document Format PDF Adobe Flash HyperText Markup Language HTML Adobe ShockWave or Scalable Vector Graphics SVG . Other content file types are possible. Adobe products are available from Adobe Systems Incorporated of San Jose Calif. Additionally content of a particular content file type can further contain nested or embedded content having a different content file type. For example a PDF document could contain an embedded Flash content which in turn could contain an HTML content.

In some implementations the user interface includes a visual region configured to present a document. In further implementations the user interface includes a separate second visual region for presenting advertisement content or ads . The subject of the ads can correspond to the content of the document. For example if a document presented in the first visual region pertains to crafts the second visual region can present one or more ads for craft related products or services. Inclusion of such ads can facilitate monetization for content providers. In certain implementations ads can be turned on or off for example based flags or attributes in a document. For instance a document corresponding to premium content can turn off the ads.

The user interface can be used to render or display one or more documents which can be of any content file type such as OEBPS PDF Flash HTML ShockWave and or SVG for example. By way of illustration a document can be in Flash format and the user interface can utilize a Flash rendering engine capable of rendering Flash content. Similarly a document can have a different content file type and the user interface can utilize a rendering engine that is capable of rendering content of that content file type. In general a rendering engine is capable of rendering content of one or more content file types.

The document presented in region can also serve as a container document for embedded content. By way of illustration the document has a content file type of OEBPS and contains the following embedded content text having a content file type of Unicode a maple leaf image having a content file type of PDF a pumpkin image having a content file type of Flash a scissors graphic embedded within the image and having a content file type of SVG and a text caption embedded within a Flash document and having a content file type of HTML.

Various rendering engines e.g. OEBPS PDF Flash HTML ShockWave SVG can be utilized to render embedded content in the document . Rendering engines have access to a document s transparency model which allows the rendering engines to composite embedded content with other content on a page of the document. This allows for effects such as transparency and blending. This is illustrated in where the maple leaf image has a region surrounding the leaf that is blended the underlying scissors graphic . Also the Halloween Newsletter caption shows through a transparent region of the pumpkin image .

As shown in content in a document e.g. is logically represented for rendering purposes in a transparency model as a transparency stack . The color of a pixel or point in a rendered portion of a document page is determined by combining the colors of content in the transparency stack according to compositing rules defined by the transparency model or elsewhere. In various implementations the transparency model conforms to the model defined in the PDF R FE A PDFV1.6 Adobe Systems Incorporated which is incorporated herein by reference in its entirety. Other transparency models are possible however.

In the transparency model newly rendered content can be composited with the previously existing contents of the page producing results that combine the colors of the new content and its backdrop according to their respective opacity characteristics. Moreover transparent content can blend composite in interesting ways with other overlapping contents. Ordinarily the backdrop consists of portions of layers of the transparency stack that have previously rendered. The result of compositing is then treated as the backdrop for the next content. However within certain kinds of transparency groups see below a different backdrop can be used.

When content is composited with its backdrop the color at each point can be computed using a specified blend mode which is a function of both the content s color and the backdrop color. The blend mode determines how colors interact different blend modes can be used to achieve a variety of useful effects. In various implementations a single blend mode is in effect for compositing all of a given content but different blend modes can be applied to different contents. A given content s opacity in combination with the backdrop s opacity determines the relative contributions of the backdrop color the content s color and the blended color to the resulting composite color. In addition the content s shape can determine the degree to which the composite color replaces the backdrop color. For example shape values of 0.0 and 1.0 identify points that lie outside and inside a conventional sharp edged content intermediate values are useful in defining soft edged content.

Content in a transparency stack can be collected together into a transparency group referred to hereafter simply as a group . The group as a whole can have various properties that modify the compositing behavior of content within the group and their interactions with its backdrop. An additional blend mode shape and opacity can also be associated with the group as a whole and used when compositing it with its backdrop. Groups can be nested within other groups forming a tree structured hierarchy.

With reference to the transparency stack includes two or more layers that represent logical planes on which content is represented. Dashed lines are used to indicate overlapping layers and content. When rendered content on a given layer can incorporate content from one or more lower layers. For example the maple leaf image content on layer can composited with the scissors graphic content from layer . In various implementations embedded content can be represented on a lower plane in the transparency stack than the content that contains the embedded content. This allows the rendering of embedded content to be composited with the rendering of containing content.

A document e.g. has a hierarchical structure which can be expressed as a tree . The tree is composed of a hierarchy of nodes and . Each node corresponds to content depicted in one of the layers of the transparency stack . While the transparence stack illustrates compositing layers for rendering purposes the structure of the tree represents the hierarchy of nested content in the document . For example the top level document node represents top level content the text and embedded content represented by child node the maple leaf image and child node the pumpkin image . The node has embedded content represented by child node the scissors graphic . Likewise the node has embedded content represented by child node the caption .

The eBook reader application includes a transparency model as described above. The transparency model is a set of information regarding the rendering state of a document page. In various implementations each piece of content including embedded content on a page is associated with the following information in order to integrate with the transparency model 

In various implementations a document such as document can be rendered by traversing a tree representation of the document in a depth first fashion and rendering each visited node using the appropriate rendering engine. For example a first rendering engine can be invoked to render content for top level document node . The first invoked rendering engine renders the text and then invokes a second rendering engine to rendered the embedded content for node . Before the second rendering engine can render the content for node the maple leaf image the second rendering engine invokes a third rendering engine to render the content the scissors graphic for node which appears at a lower layer in the transparency stack. Once the third rendering engine has rendered the scissors graphic the second rendering engine can render the maple leaf image composited with the scissors graphic . In various implementations rendering engines are reentrant so that they can be invoked successively. For example a PDF document containing embedded PDF content can require that a PDF rendering engine be invoked twice first for the containing document and again before completing the rendering of the first content for the embedded content.

In various implementations when a rendering engine encounters embedded content which the rendering engine does not know how to render e.g. corresponding to a child node in the tree the rendering engine invokes another rendering engine which can render the content and provides directly or indirectly the invoked rendering engine with the transparency model information listed in TABLE 1.

Referring again to each rendering engine exposes a respective application programming interface API common to all rendering engines which allows the rendering engine to be invoked by the application by another rendering engine or by itself. In various implementations an API can be implemented as an instance of one or more classes in an object oriented programming language as a set of procedures or functions as one or more data structures as a communication protocol or combinations of these. Each API includes a common set of functionality which is offered by each rendering engine. An unlimited number of rendering engines can be incorporated into the system as long as each rendering engine implements the common API. Moreover rendering engines can be incorporated into the system dynamically on an as needed basis from a variety of sources including sources specifying local or remote storage a uniform resource locator URL or a server.

By way of illustration if an API is implemented as a set of functions a render function could be invoked when another rendering engine or the application desires to render embedded content. In particular the calling rendering engine or application determines a drawing page bounding box a drawing surface and a background bitmap for embedded content and provides these along with other transparency model parameters when invoking a rendering engine. The invoked rendering engine then renders the embedded content on the drawing surface within the bounding box potentially blending the embedded content with the background.

The invoked rendering engine can itself have similarly invoked one or more rendering engines to create the rendered drawing surface. The invoked rendering engine renders either directly to the drawing surface provided by the calling rendering engine or to temporary drawing surfaces aligned with the pixel grid of the calling engine s drawing surface. The invoked rendering engine uses a transformation matrix passed to it by the calling engine. Temporary drawing surfaces do not need to be scaled rotated or otherwise transformed. A calling rendering engine can use the rendered drawing surface of an invoked rendering engine as the calling rendering engine s background. In this way rendered content in lower transparency stack layers can be blended with content in high levels.

When a blending mode is assigned to embedded content a calling rendering engine can invoke a rendering engine twice once to draw upon a fully transparent temporary background surface and a second time to draw on the actual background. Then transparency model backdrop subtraction is used to combine the drawings as described in section 7.3.3 Group Compositing Computation of the PDF REFERENCE FIFTH EDITION ADOBE PORTABLE DOCUMENT FORMAT VERSION 1.6 .

However in many cases only a single drawing is necessary. For example if the embedded content is marked as an isolated transparency group the embedded content can be drawn on a transparent temporary drawing surface and then composited on top of a background. If the embedded content has an opacity smaller than one i.e. the embedded content is not opaque or clipping is assigned with a blending mode the embedded content should be drawn on top of the temporary drawing surface initialized with the copy of the background and then the result of drawing C is a weighted average of the painted pixels colors C from the temporary surface and unpainted pixels from the background surface C C C a C 1 a j where a is embedded content s assigned opacity and is clipping function which is 1 inside the clip path and 0 outside. If the embedded content has opacity 1 i.e. opaque and no clipping is assigned then the calling rendering engine should call the invoked rendering engine to draw directly on the calling rendering engine s drawing surface.

The eBook reader application can also include a digital rights management DRM module for use in controlling access to documents and content within documents. For example the DRM module can include information regarding how content in a document including embedded content can be accessed displayed or used. The DRM module can provide authorization functionality for authorizing users and determining their access rights to content. DRM information can be associated with a document as metadata associated with each piece of content in the document or with the document as a whole. Alternatively DRM information for content in a document can be provided externally by a DRM server or other system. The APIs can also include functionality for utilizing DRM data. In some implementations each rendering engine is responsible for determining whether a user associated with the document being rendered has rights to render a piece of content.

The application invokes the selected rendering engine to render the document content step . The application can invoke a rendering engine through the rendering engine s API. The application can also provide the transparency model to the rendering engine. The rendering engine then begins rendering the document . If the document does not contain embedded content step the rendered document is displayed on a display device e.g. step . Otherwise a rendering engine is selected to render the embedded content step . For example the enclosing document which can be a Flash document can also contain one or more instances of embedded content having a different content file type e.g. PDF . Using the selected rendering engine the embedded content in the document is rendered step . If the document contains additional embedded content step a rendering engine is selected to render the additional embedded content step . Otherwise all of the rendered content is assembled on a document page step and displayed on a display device step .

By way of illustration rendering of document tree will be explained. Initially the eBook reader application invokes the OEBPS rendering engine since the overall document type is OEBPS. The OEBPS rendering engine renders the text and upon encountering the maple leaf image on the document page the OEBPS rendering engine invokes the PDF rendering engine to render the image . When the PDF rendering engine detects the embedded scissor graphic the PDF rendering engine invokes the SVG rendering engine to render the scissor graphic . Once the SVG rendering engine has finished rendering the scissor graphic the PDF rendering engine can finish rendering the leaf image which is composited with the rendered scissor graphic . Then the OEBPS rendering engine invokes the Flash rendering engine to render the pumpkin graphic . The Flash rendering engine likewise invokes the HTML rendering engine to render the embedded HTML content . As each rendering engine completes its job calling rendering engines can composite their contents with the results.

Implementations of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. Implementations of the subject matter described in this specification can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter effecting a machine readable propagated signal or a combination of one or more of them.

The term data processing apparatus encompasses all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as a program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Moreover a computer can be embedded in another device e.g. a mobile telephone a personal digital assistant PDA a mobile audio player a Global Positioning System GPS receiver to name just a few. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user implementations of the subject matter described in this specification can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input.

Implementations of the subject matter described in this specification can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described is this specification or any combination of one or more such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN e.g. the Internet.

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

While this specification contains many specifics these should not be construed as limitations on the scope of the invention or of what can be claimed but rather as descriptions of features specific to particular implementations of the invention. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable subcombination. Moreover although features can be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination can be directed to a subcombination or variation of a subcombination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multitasking and parallel processing can be advantageous. Moreover the separation of various system components in the implementations described above should not be understood as requiring such separation in all implementations and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

Thus particular implementations of the invention have been described. Other implementations are within the scope of the following claims. For example the actions recited in the claims can be performed in a different order and still achieve desirable results.

