---

title: Integrating a voice browser into a Web 2.0 environment
abstract: The present invention discloses a system and method for integrating a voice browser into a Web 2.0 environment. For example, a system is disclosed which includes at least a Web 2.0 server, a voice browser, and a server-side speech processing system. The Web 2.0 server can serve Web 2.0 content comprising at least one speech-enabled application. The served Web 2.0 content can include voice markup. The voice browser can render the Web 2.0 content received from the Web 2.0 server which includes rendering the voice markup. The server-side speech processing system can handle speech processing operations for the speech-enabled application. Communications with the server-side speech processing system occur via a set of RESTful commands, such as an HTTP GET command, an HTTP POST command, an HTTP PUT command, and an HTTP DELETE command.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08041573&OS=08041573&RS=08041573
owner: International Business Machines Corporation
number: 08041573
owner_city: Armonk
owner_country: US
publication_date: 20070621
---
This continuation in part application claims the benefit of U.S. patent application Ser. No. 11 765 900 filed Jun. 20 2007 the benefit of U.S. patent application Ser. No. 11 765 928 filed Jun. 20 2007 and the benefit of U.S. patent application Ser. No. 11 765 962 filed Jun. 20 2007 which are incorporated by reference herein.

The present invention relates to the field of speech processing and Web 2.0 technologies and more particularly to integrating a voice browser in a Web 2.0 environment.

Voice response systems utilize a voice user interface to interact with users such as interacting via a telephone. Many of these voice response systems include a voice browser or voice interpreter which processes voice markup such as VoiceXML. The voice markup specifies speech processing actions which are to be performed by speech processing engines. The engines are often turn based engines integrated into a networked speech processing system. For example middleware solutions such as IBM s WEBSPHERE often include speech processing resources and a linked voice browser which provide speech processing capabilities to one or more voice response systems. Use of speech processing capabilities has traditionally required creation of specialized software routines that use a voice toolkit to interact with a networked speech processing system. Coding this specialized software requires programming skills beyond the expertise level of many software developers and most end users.

The complexity of creating interfaces to networked speech processing systems has prevented speech capabilities from entering many important software market segments. One of the more important segments that currently is devoid of speech processing capabilities is the Web 2.0 market. Web 2.0 refers to a set of Web applications sites that promote collaboration and information sharing among large groups of users. A fundamental Web 2.0 principle is to grant end users an ability to read write and update existing Web 2.0 content actions traditionally restricted to software developers. Additionally Web 2.0 applications often depend upon the collaborative effort of end users to provide new content and revise existing content. Different types of Web 2.0 applications include WIKIs BLOGs FOLKSONIMIES social networking sites and the like.

What is needed is a solution through which voice browsers can be integrated into a Web 2.0 environment such that Web 2.0 content providers e.g. end users will be able to create and modify speech enabled content. This would permit Web 2.0 content to be accessible from non traditional clients such as a telephone. An ideal solution would also permit Web 2.0 content providers and or users to customize speech processing behavior of speech enabled Web 2.0 applications. For example a Web 2.0 user or content provider would preferably be able to customize characteristics of a speech synthesis voice and or a speech recognition system integrated with the Web 2.0 environment. Conventional voice browser implementations typically reside in proprietary systems that are not accessible or modifiable by end users.

The present invention discloses a solution for integrating a voice browser into a Web 2.0 environment. The voice browser can receive voice markup and other Web 2.0 content from the Web 2.0 server which it utilizes to interact with clients having voice interfaces. The served Web 2.0 content can include speech enabled applications formatted in a REST ATOM Representational State Transfer Atom Publishing Protocol or APP format. Each of these applications can be introspected and modified. Introspection and modification applies to live or running speech enabled applications such as VoiceXML and to resources used by the speech enabled applications.

Additionally JAVA SCRIPT code such as AJAX can be specified within the Web 2.0 content and used to interface with speech engines for visual and voice browsers. The JAVA SCRIPT interface can provide consistency between visual and voice browsers. Use of JAVA SCRIPT interfaces for voice can also greatly reduce a complexity of the voice browser which conventionally requires the creation of a voice client interface layer to integrate the browser with speech processing resources. In one embodiment JAVA SCRIPT code can also be used to access non speech data such as data of a back end system or database using asynchronous HTTP requests. Appreciably conventional voice browsers typically use the VoiceXML or tags for requests which are synchronous in nature.

The present invention can be implemented in accordance with numerous aspects consistent with the material presented herein. For example one aspect of the present invention can include a system for using Web 2.0 as an interface to speech engines. The system can include at least a Web 2.0 server a voice browser and a server side speech processing system. The Web 2.0 server can serve Web 2.0 content comprising at least one speech enabled application. The served Web 2.0 content can include voice markup. The voice browser can render the Web 2.0 content received from the Web 2.0 server which includes rendering the voice markup. The server side speech processing system can handle speech processing operations for the speech enabled application. Communications with the server side speech processing system occur via a set of RESTful commands such as a Hyper Text Transport Protocol HTTP GET command an HTTP POST command an HTTP PUT command and an HTTP DELETE command.

Another aspect of the present invention can include a voice browser configured to render speech enabled applications served by a Web 2.0 server. Each speech enabled application rendered by the voice browser can include an introspection document a collection of entries and a collection of resources. At least one of the resources can be a speech resource associated with a speech engine which adds a speech processing capability to the speech enabled application.

Still another aspect of the present invention can include a method for speech enabling Web 2.0 content. In the method Web 2.0 content can be received from a Web 2.0 server. The Web 2.0 content can contain voice markup and JAVA SCRIPT code such as AJAX. Further the Web 2.0 content can be part of a speech enabled application which conforms to an APP based protocol. The JAVA SCRIPT code can be executed by the voice browser to establish an interface between a voice browser and at least one remotely located speech processing engine. The executing JAVA SCRIPT can establish at least one audio linkage over which speech input output can be conveyed. Digitally encoded messages related to speech audio can also be exchanged between the speech processing engine and the voice browser. These messages can include speech processing result data which the voice browser consumes to perform operations based upon the results.

In one embodiment the audio linkage established by the JAVA SCRIPT can be established by hooking a speech processing engine s audio universal resource identifier URI with an audio URI of a Voice Over Internet Protocol VoIP endpoint or the voice browser which is connected to a caller so that audio can be exchanged directly between those endpoints. In another embodiment the audio linkage can be an actual audio channel through which audio data itself can be conveyed.

It should be noted that various aspects of the invention can be implemented as a program for controlling computing equipment to implement the functions described herein or a program for enabling computing equipment to perform processes corresponding to the steps disclosed herein. This program may be provided by storing the program in a magnetic disk an optical disk a semiconductor memory or any other recording medium. The program can also be provided as a digitally encoded signal conveyed via a carrier wave. The described program can be a single program or can be implemented as multiple subprograms each of which interact within a single computing device or interact in a distributed fashion across a network space.

It should also be noted that the methods detailed herein can also be methods performed at least in part by a service agent and or a machine manipulated by a service agent in response to a service request.

For example either browser can communicate using a set of RESTful commands . The RESTful commands can include GET PUT POST and or DELETE commands which can be Hyper Text Transport Protocol HTTP based commands. There are no assumptions regarding the client upon which the interface or browser executes other than an ability to communicate with a Web 2.0 server via network .

In another example AJAX or other JAVA SCRIPT code contained in Web 2.0 content can be used to interface with a set of remotely located speech resources e.g. engines . In one configuration the voice browser can use AJAX initialization routes which execute when the speech enabled application starts. The initialization routine can establish an audio linkage between the browser and the speech system in a scenario involving a legacy e.g. non VoIP voice response system or with a Voice Over Internet Protocol VoIP endpoint in a scenario involving a voice response system in a VoIP environment not shown . The linkage can be established by an exchange audio URI s between the speech processing system and the browser of VoIP gateway device not shown . That is one audio URI can correspond to an audio endpoint of the speech processing system and another audio URI can be an audio endpoint of the browser or VoIP gateway device not shown which sends receives audio to from the user . The audio linkage can also represent an audio channel through which audio data itself can be conveyed. In one embodiment real time audio can be conveyed across the audio linkage if desired using any of a variety of communication protocols such as Real Time Protocol RTP which can be specified by the introspection associated with speech enabled application .

The browsers can include a set of AJAX libraries to interface with server resources over HTTP. Use of AJAX permits consistency between the visual and voice browsers reduces code complexity needed for speech processing tasks and permits asynchronous requests.

Each application can be associated with an introspection document and a collection of entries and resources. The resources can link a Web 2.0 server to speech processing engines of speech system . End users of environment can be permitted to introspect customize add re order and remove entries and resources of the collections via the browsers . In one embodiment applications and resources can also be created modified by a graphical editor not shown of the Web 2.0 server . In one embodiment the application can be written in accordance with Representational State Transfer architecture REST principles. For example the application can conform to the ATOM PUBLISHING PROTOCOL APP .

The voice response system can be an automated system that permits users to interact with applications through a voice communication channel. The voice response system can incorporate telephone technologies to permit callers to receive speech output and to present speech and or Dual Tone Multi Frequency DTMF dial pad input. The voice response system can provide dialog prompts each associated with a constrained grammar or a set of acceptable responses. These responses can in turn be mapped to programmatic actions which are selectively triggered based upon user responses to the prompts. In one embodiment the applications can be written in VoiceXML or other voice markup language which is interpreted or rendered by a VoiceXML browser included within or accessed by the voice response system .

The Web 2.0 server can be a WIKI server a BLOG server MASHUP server a FOLKSONOMY server a social networking server and the like. A speech system can include speech processing engines which can be accessed by the server or browser through use of a set of RESTful commands . Further the speech system can be part of a turn based network system such as the WEBSPHERE VOICE SERVER.

The method of which includes steps can be performed in the context of environment . The method can begin in step where a user accesses a voice response system via a telephone user interface TUI or other voice user interface. In step call control operations can execute which establishes a telephony link between the user and the voice response system . In step the user can interact with the TUI. In step the browser can request Web 2.0 content from a Web 2.0 server .

The voice browser can receive the Web 2.0 content in step . In step AJAX code can be executed to establish an audio linkage or channel with the speech system . In one embodiment this audio channel can refer to an audio file referenced by an HTTP URI. In step the voice browser can render markup of the Web 2.0 content . In step the method can determine whether a speech operation has been initiated. If not the method can skip from step to step .

If a speech operation is indicated the method can proceed from step to step where a speech processing request can be conveyed to the speech system . In step when speech is to be provided to the speech system i.e. the speech processing request is for a speech to text STT operation or a speaker identity verification SIV operation user provided audio can be captured and conveyed over the established audio linkage. In step when audio is to be received e.g. the speech processing request is for a text to speech TTS operation system generated audio can be conveyed over the established audio linkage. In step results from the speech system can be received such as through a digitally encoded message conveyed via a HTTP communication. In step the voice browser can process speech system results as necessary.

In step a determination can be made as to whether the voice browser is to communicate with the Web 2.0 server. If so the information can be exchanged in step which can cause new Web 2.0 content to be sent to the browser as shown by looping from step to step . When the potential speech processing operation does not result in a communication with the Web 2.0 server the method can loop from step to step where the user can continue to interact via the TUI.

The voice browser can be a browser capable of rendering voice markup such as VoiceXML X V and the like. The voice browser can include a REST ATOM command engine a REST ATOM introspection engine a state engine and a JAVA Script engine .

The REST ATOM command engine permits the voice browser to accept and issue RESTful commands which include a HTTP GET command a HTTP POST command a HTTP PUT command and a HTTP DELETE command. These commands have different meanings depending upon their context of use. One context of use applies to a live application where the RESTful commands acquire add remove and update application content. In another context the RESTful commands acquire add remove and update resources used by an application. Resources can include speech processing resources.

The HTTP GET command can return capabilities and elements that are modifiable in the browser . For live applications the HTTP GET command can be used to return all state information such as fields in a form which can be changed by a user.

The HTTP POST command can be used to trigger an interpretation of a voice browser application. The HTTP POST command is not a valid browser command for live application purposes.

The HTTP PUT command can be used to update configuration items resources in a voice browser . For a live application the HTTP PUT command can change a state of a field in the application.

The HTTP DELETE command can remove a resource from a voice browser . The HTTP DELETE command can also remove a state entry such as content contained in a field of an application.

The introspection engine provides introspection support for speech enabled applications formatted in accordance with the APP protocol or other RESTful protocol which supports introspection. The introspection engine can provide introspection with dynamic discovery and asynchronous configuration of speech resources which are resources of the speech system . Additionally the introspection engine can introspect an APP application to allow state changes for a speech enabled application. That is the introspection engine can introspect a collection of entries and resources which form a speech enabled application configured for a Web 2.0 for speech environment.

The state engine can utilize engines and to manage state for a speech enabled application. State of a live application can be queried and modified. In one embodiment the state engine can synchronize multiple concurrent modalities for a single application instance. For example the state engine can detect when a field update occurs via a GUI modality and automatically apply the state change information to a voice only modality of the same application. Further the sate engine can save a current state either automatically or through explicit user selection so that field values from a previous user session are available in future sessions with that user. This state information can be stored by engine regardless of which interactive modality is currently being used and regardless of whether a previous modality is the same as a current modality.

It should be appreciated that the engines applied to a live application such as a VoiceXML application permit a user to affect core operations for processing the application such as a Form Interpretation Algorithm FIA . This permits synchronization with visual updates on a visual channel jumping speech dialog entries for previously filled fields and the like.

As shown the voice browser can introspect modify a live application by sending suitable RESTful commands to a Web 2.0 server . The voice browser can also introspect modify resources by sending suitable RESTful commands to the Web 2.0 server .

The JAVA SCRIPT engine can define a speech interface with a remotely located speech system . The speech interface can be defined for a particular protocol in accordance with resources defined by the Web 2.0 server for a speech enabled application. The JAVA SCRIPT engine can establish audio linkages or channels between the browser and the speech system which can include real time audio channels. For example AJAX code conveyed from the Web 2.0 server can be executed by engine .

To illustrate a speech recognition request can be represented by a JAVA SCRIPT e.g. AJAX function called recognize in a Web 2.0 widget called VoiceASR . The job of this function can be to provide audio input and to get text output from a speech engine which is part of the speech system . The JAVA SCRIPT function can also indicate in VoiceXML terms the results of the ASR task. The linkage of audio input can be performed by AJAX initialization routines that are executed when the speech enabled application starts. If an audio URL is pre existing it can be sent to the speech system and a new audio channel need not be established.

An initial entry collection can refer to various pages of a Web 2.0 site such as pages of a WIKI site. Each page can have an associated entry. Additionally each page can link to other collections. When the collection is a collection of entries further decomposition of the corresponding Web 2.0 page can be specified. For example the collection can specify one or more sections of a Web 2.0 page. Additionally each entry of collection or any other collection can specify entity specific resources. These resources can be activated when the corresponding entity is active. When lower level entries are active all parent entries and their resources can also be active.

The resource collection can include an entries link used to configure the associated resource and can include links to other resources. Resources can include any of a variety of computing resources including but not limited to speech processing resources media delivery resources and the like. Speech processing resources can include automatic speech recognition resources ASR text to speech resources speaker identification and verification SIV resources voice interpreter resources and the like. Media delivery resources can include Real Time Protocol RTP Real Time Streaming Protocol RTSP Media Resource Control Protocol MRCP resources and the like.

Markup represents sample markup which can be conveyed from a Web 2.0 server to a voice browser. The markup can be VoiceXML markup which prompts for a city field having acceptable values of Boca Raton Miami and West Palm Beach. The markup can also include a people field designating a number of people who are to travel in accordance with the VoiceXML form associated with markup .

Application depicts a state of an APP formatted application for the markup . Application can be linked to an entry collection which is further linked to child entries . Specifically a travel entry can be linked to a field for city and a field for people . In the state shown for application a value of Boca Ration can be placed in the city field and a value of 2 can be placed in the people field . It should be appreciated that a voice browser can utilize RESTful commands e.g. HTTP GET HTTP POST HTTP PUT and or HTTP DELETE to determine and change a state of a live application. For example values for the fields can be obtained changed and deleted using the RESTful commands.

In system a browser can communicate with Web 2.0 server via Representational State Transfer REST architecture ATOM based protocol. The Web 2.0 server can communicate with a speech for Web 2.0 system via a REST ATOM based protocol. Protocols can include HTTP and similar protocols that are RESTful by nature as well as an Atom Publishing Protocol APP or other protocol that is specifically designed to conform to REST principles.

The Web 2.0 server can include a data store in which applications which can be speech enabled are stored. In one embodiment the applications can be written in a WIKI or other Web 2.0 syntax and can be stored in an APP format.

The contents of the application can be accessed and modified using editor . The editor can be a standard WIKI or other Web 2.0 editor having a voice plug in or extensions . In one implementation user specific modifications made to the speech enabled application via the editor can be stored in customization data store as a customization profile and or a state definition. The customization profile and state definition can contain customization settings that can override entries contained within the original application . Customizations can be related to a particular user or set of users.

The transformer can convert WIKI or other Web 2.0 syntax into standard markup for browsers. In one embodiment the transformer can be an extension of a conventional transformer that supports HTML and XML. The extended transformer can be enhanced to handle JAVA SCRIPT such as AJAX. For example resource links of application can be converted into AJAX functions by the transformer having an AJAX plug in . The transformer can also include a VoiceXML plug in which generates VoiceXML markup for voice only clients.

In system Web 2.0 clients can communicate with Web 2.0 servers utilizing a REST ATOM protocol. The Web 2.0 servers can serve one or more speech enabled applications where speech resources are provided by a Web 2.0 for Voice system . One or more of the applications can include AJAX or other JavaScript code. In one embodiment the AJAX code can be automatically converted from WIKI or other syntax by a transformer of a server .

Communications between the Web 2.0 servers and system can be in accordance with REST ATOM protocols. Each speech enabled application can be associated with an ATOM container which specifies Web 2.0 items resources and media . One or more resource can correspond to a speech engine .

The Web 2.0 clients can be any client capable of interfacing with a Web 2.0 server . For example the clients can include a Web or voice browser as well as any other type of interface which executes upon a computing device. The computing device can include a mobile telephone a mobile computer a laptop a media player a desktop computer a two way radio a line based phone and the like. Unlike conventional speech clients the clients need not have a speech specific interface and instead only require a standard Web 2.0 interface. That is there are no assumptions regarding the client other than an ability to communicate with a Web 2.0 server using Web 2.0 conventions.

The Web 2.0 servers can be any server that provides Web 2.0 content to clients and that provides speech processing capabilities through the Web 2.0 for voice system . The Web 2.0 servers can include a WIKI server a BLOG server a MASHUP server a FOLKSONOMY server a social networking server and any other Web 2.0 server .

The Web 2.0 for voice system can utilize Web 2.0 concepts to provide speech capabilities. A server side interface is established between the voice system and a set of Web 2.0 servers . Available speech resources can be introspected and discovered via introspection documents which are one of the Web 2.0 items . Introspection can be in accordance with the APP specification or a similar protocol. The ability for dynamic configuration and installation is exposed to the servers via the introspection document.

That is access to Web 2.0 for voice system can be through a Web 2.0 server that lets users e.g. clients provide their own customizations personalizations. Appreciably use of the APP opens up the application interface to speech resources using Web 2.0 JAVA 2 ENTERPRISE EDITION J2EE WEBSPHERE APPLICATION SERVER WAS and other conventions rather than being restricted to protocols such as media resource control protocol MRCP real time streaming protocol RTSP or real time protocol RTP .

The Web 2.0 for Voice system is an extremely flexible solution that permits users of clients to customize numerous speech processing elements. Customizable speech processing elements can include speech resource availability request characteristics result characteristics media characteristics and the like. Speech resource availability can indicate whether a specific type of resource e.g. ASR TTS SIV Voice XML interpreter is available. Request characteristics can refer to characteristics such as language grammar voice attributes gender rate of speech and the like. The result characteristics can specify whether results are to be delivered synchronously or asynchronously. Result characteristics can alternatively indicate whether a listener for callback is to be supplied with results. Media characteristics can include input and output characteristics which can vary from a URI reference to an RTP stream. The media characteristics can specify a codec e.g. G711 a sample rate e.g. 8 KHz to 22 KHz and the like. In one configuration the speech engines can be provided from a J2EE environment such as a WAS environment. This environment can conform to a J2EE Connector Architecture JCA .

In one embodiment a set of additional facades can be utilized on top of Web 2.0 protocols to provide additional interface and protocol options e.g. MRCP RTSP RTP Session Initiation Protocol SIP etc. to the Web 2.0 for voice system . Use of facades can enable legacy access use of the Web 2.0 for voice system . The facades can be designed to segment the protocol from underlying details so that characteristics of the facade do not bleed through to speech implementation details. Functions such as the WAS 6.1 channel framework or a JCA container can be used to plug in a protocol which is not native to the J2EE environment . The media component of the container can be used to handle media storage delivery and format conversions as necessary. Facades can be used for asynchronous or synchronous protocols .

The present invention may be realized in hardware software or a combination of hardware and software. The present invention may be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software may be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention also may be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program in the present context means any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation b reproduction in a different material form.

This invention may be embodied in other forms without departing from the spirit or essential attributes thereof. Accordingly reference should be made to the following claims rather than to the foregoing specification as indicating the scope of the invention.

