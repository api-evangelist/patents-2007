---

title: Controlling the listening horizon of an automatic speech recognition system for use in handsfree conversational dialogue
abstract: Conversational dialog with a computer or other processor-based device without requiring push-to-talk functionality. In one embodiment, a computer-implemented method first determines that a user desires to engage in a dialog. Based thereon the method turns on a speech recognition functionality for a period of time referred to as a listening horizon. Upon the listening horizon expiring, the method turns off the speech recognition functionality.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07716057&OS=07716057&RS=07716057
owner: Microsoft Corporation
number: 07716057
owner_city: Redmond
owner_country: US
publication_date: 20070615
---
This application is a continuation of U.S. patent application Ser. No. 11 257 249 filed Oct. 24 2005 and entitled CONTROLLING THE LISTENING HORIZON OF AN AUTOMATIC SPEECH RECOGNITION SYSTEM FOR USE IN HANDSFREE CONVERSATIONAL DIALOGUE which is a continuation of U.S. patent application Ser. No. 10 885 946 filed Jul. 7 2004 and entitled CONTROLLING THE LISTENING HORIZON OF AN AUTOMATIC SPEECH RECOGNITION SYSTEM FOR USE IN HANDSFREE CONVERSATIONAL DIALOGUE now issued U.S. Pat. No. 6 988 072 which is a continuation of U.S. patent application Ser. No. 10 190 978 filed Jul. 8 2002 and entitled SIGNALING AND CONTROLLING THE STATUS OF AN AUTOMATIC SPEECH RECOGNITION SYSTEM FOR USE IN HANDSFREE CONVERSATIONAL DIALOGUE now issued U.S. Pat. No. 6 782 364 which is a continuation of U.S. patent application Ser. No. 09 312 679 filed May 17 1999 and entitled SIGNALING AND CONTROLLING THE STATUS OF AN AUTOMATIC SPEECH RECOGNITION SYSTEM FOR USE IN HANDSFREE CONVERSATIONAL DIALOGUE now issued U.S. Pat. No. 6 434 527 . The aforementioned applications are incorporated herein by reference.

This invention relates generally to conversational dialog between a computer or other processor based device and a user and more particularly to such dialog without requiring push to talk functionality.

Speech recognition applications have become increasingly popular with computer users. Speech recognition allows a user to talk into a microphone connected to the computer and the computer translating the speech into recognizable text or commands understandable to the computer. There are several different types of uses for such speech recognition. In one type speech recognition is used as an input mechanism for the user to input text into a program such as a word processing program in lieu of or in conjunction with a keyboard. In another type speech recognition is used as a mechanism to convey commands to a program for example to save a file in a program instead of selecting a save command from a menu using a mouse.

In yet another type of use for speech recognition speech recognition is used in conjunction with an on screen agent or automated assistant. For example the agent may ask the user whether he or she wishes to schedule an appointment in a calendar based on an electronic mail the user is reading e.g. using a text to speech application to render audible the question through a speaker or by displaying text near the agent such that it appears that the agent is talking to the user. Speech recognition can then be used to indicate the user s acceptance or declination of the agent s offer.

In these and other types of uses for speech recognition an issue lies as to when to turn on the speech recognition engine that is as to when the computer should listen to the microphone for user speech. This is because in part speech recognition is a processor intensive application keeping speech recognition turned on all the time may slow down other applications being run on the computer. In addition keeping speech recognition turned on all the time may not be desirable in that the user may accidentally say something into the microphone that was not meant for the computer.

One solution to this problem is generally referred to as push to talk. In push to talk systems a user presses a button on an input device such as a mouse or presses a key or a key combination on the keyboard to indicate to the user that it is ready to speak into the microphone such that the computer should listen to the speech. The user may optionally then be required to push another button to stop the computer from listening or the computer may determine when to stop listening based on no more speech being spoken by the user.

Push to talk systems are disadvantageous however. A goal in speech recognition systems is to provide for a more natural manner by which a user communicates with a computer. However requiring a user to push a button prior to speaking to the computer cuts against this goal so it is unnatural for the user to do so. Furthermore in applications where a dialog is to be maintained with the computer for example where an agent asks a question the user answers and the agent asks another question etc. requiring the user to push a button is inconvenient and unintuitive in addition to being unnatural.

Other prior art systems include those that give the user an explicit unnatural message to indicate that the system is listening. For example in the context of automated phone applications a user may be hear a recorded voice Press 1 now for choice A. While this may improve on push to talk systems it nevertheless is unnatural. That is in everyday conversation between people such explicit messages to indicate that one party is ready to listen to the other is rarely heard.

The invention relates to conversational dialog with a computer or other processor based device without requiring push to talk functionality. In one embodiment a computer implemented method first determines that a user desires to engage in a dialog. Next based thereon the method turns on a speech recognition functionality for a period of time referred to as a listening horizon. Upon the listening horizon expiring the method turns off the speech recognition functionality.

In specific embodiments determining that a user desires to engage in a dialog includes performing a probabilistic cost benefit analysis to determine whether engaging in a dialog is the highest expected utility action of the user. This may include for example initially inferring a probability that the user desires an automated service with agent assistance. Thus in one embodiment the length of the listening horizon can be determined as a function of at least the inferred probability that the user desires automated service as well as a function of the acute listening history of previous dialogs.

Embodiments of the invention provide for advantages not found within the prior art. Primarily the invention does not require push to talk functionality for the user to engage in a dialog with the computer including engaging in a natural dialog about a failure to understand. This means that the dialog is more natural to the user and also more convenient and intuitive to the user. Thus in one embodiment an agent may be displayed on the screen ask the user a question using a text to speech mechanism and then wait for the listening horizon for an appropriate response from the user. The user only has to talk after the agent asks the question and does not have to undertake an unnatural action such as pushing a button on an input device or a key on the keyboard prior to answering the query.

The invention includes computer implemented methods machine readable media computerized systems and computers of varying scopes. Other aspects embodiments and advantages of the invention beyond those described here will become apparent by reading the detailed description and with reference to the drawings.

In the following detailed description of exemplary embodiments of the invention reference is made to the accompanying drawings which form a part hereof and in which is shown by way of illustration specific exemplary embodiments in which the invention may be practiced. These embodiments are described in sufficient detail to enable those skilled in the art to practice the invention and it is to be understood that other embodiments may be utilized and that logical mechanical electrical and other changes may be made without departing from the spirit or scope of the present invention. The following detailed description is therefore not to be taken in a limiting sense and the scope of the present invention is defined only by the appended claims.

Some portions of the detailed descriptions which follow are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated.

It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like. It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussions it is appreciated that throughout the present invention discussions utilizing terms such as processing or computing or calculating or determining or displaying or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

Referring to a diagram of the hardware and operating environment in conjunction with which embodiments of the invention may be practiced is shown. The description of is intended to provide a brief general description of suitable computer hardware and a suitable computing environment in conjunction with which the invention may be implemented. Although not required the invention is described in the general context of computer executable instructions such as program modules being executed by a computer such as a personal computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types.

Moreover those skilled in the art will appreciate that the invention may be practiced with other computer system configurations including hand held devices multiprocessor systems microprocessor based or programmable consumer electronics network PC s minicomputers mainframe computers and the like. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

The exemplary hardware and operating environment of for implementing the invention includes a general purpose computing device in the form of a computer including a processing unit a system memory and a system bus that operatively couples various system components include the system memory to the processing unit . There may be only one or there may be more than one processing unit such that the processor of computer comprises a single central processing unit CPU or a plurality of processing units commonly referred to as a parallel processing environment. The computer may be a conventional computer a distributed computer or any other type of computer the invention is not so limited.

The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. The system memory may also be referred to as simply the memory and includes read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within the computer such as during start up is stored in ROM . The computer further includes a hard disk drive for reading from and writing to a bard disk not shown a magnetic disk drive for reading from or writing to a removable magnetic disk and an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM or other optical media.

The hard disk drive magnetic disk drive and optical disk drive are connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical disk drive interface respectively. The drives and their associated computer readable media provide nonvolatile storage of computer readable instructions data structures program modules and other data for the computer . It should be appreciated by those skilled in the art that any type of computer readable media which can store data that is accessible by a computer such as magnetic cassettes flash memory cards digital video disks Bernoulli cartridges random access memories RAMs read only memories ROMs and the like may be used in the exemplary operating environment.

A number of program modules may be stored on the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . A user may enter commands and information into the personal computer through input devices such as a keyboard and pointing device . Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a serial port interface that is coupled to the system bus but may be connected by other interfaces such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor computers typically include other peripheral output devices not shown such as speakers and printers.

The computer may operate in a networked environment using logical connections to one or more remote computers such as remote computer . These logical connections are achieved by a communication device coupled to or a part of the computer the invention is not limited to a particular type of communications device. The remote computer may be another computer a server a router a network PC a client a peer device or other common network node and typically includes many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in office networks enterprise wide computer networks intranets and the Internal which are all types of networks.

When used in a LAN networking environment the computer is connected to the local network through a network interface or adapter which is one type of communications device. When used in a WAN networking environment the computer typically includes a modem a type of communications device or any other type of communications device for establishing communications over the wide area network such as the Internal. The modem which may be internal or external is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the personal computer or portions thereof may be stored in the remote memory storage device. It is appreciated that the network connections shown are exemplary and other means of and communications devices for establishing a communications link between the computers may be used.

Prior to describing embodiments of the invention an illustrative example as to what is meant by a listening horizon is first described. Referring to on the time line a query from the computer is first made. The query can be visibly displayed as text on the screen can be uttered by the computer through a speaker of or connected to the computer etc. the invention is not so limited. Once a query has been made then the computer listens for an utterance from the user through a microphone for example for a listening horizon . The listening horizon can be a predefined length of time or can be a function of the subject matter of the query the prior listening history regarding the user etc. again the invention is not so limited.

Utilizing a listening horizon provides embodiments of the invention with advantages not found in the prior art. Primarily the user does not have to utilize a push to talk functionality in order to converse with the computer. The computer automatically turns on speech recognition functionality for the duration of the listening horizon instead. This provides for more natural convenient and intuitive conversation between the user and the computer.

In this section of the detailed description computer implemented methods according to varying embodiments of the invention are described. The computer implemented methods are desirably realized at least in part as one or more programs running on a computer such as the computer of FIG. that is as a program executed from a computer readable medium such as a memory by a processor of a computer. The programs are desirably storable on a machine readable medium such as a floppy disk or a CD ROM for distribution and installation and execution on another computer.

Referring now to a flowchart of a method according to one or more embodiments of the invention is shown. In the method determines whether a user desires to engage in a dialog. As used herein dialog can be generally defined as any utterance from a user directed to the computer for understanding by the computer or other processor based device . For example dialog can be used to answer a query from the computer in the case of the example of it can be used to issue a command to the computer as described in the background section it can be used to dictate text to the computer as also described in the background section etc. the invention is not so particularly limited.

In one particular embodiment the method determines whether a user desires to engage in a dialog by inferring a probability that the user desires an automated service to be performed and then performing a cost benefit analysis to determine whether engaging in a dialog is the highest expected utility action of possible actions that can be taken. For example the inferred probability can be referred to as an action probability and in one particular instance as a scheduling probability the probability that the user has a goal of an automated service i.e. an action such as scheduling a calendaring appointment. The probability can in one embodiment be based on a text such as an electronic mail message as well as on contextual information such as recent user activity.

In one embodiment inference of a probability is performed as described in the copending and coassigned application entitled Systems and Methods for Directing Automated Services for Messaging and Scheduling Ser. No. 09 295 146 filed on Apr. 20 1999 which is hereby incorporated by reference.

Performing a cost benefit analysis to determine whether engaging in a dialog is the highest expected utility action is based on the inferred probability. That is based on the inferred probability for example the method may determine to 1 do nothing inaction 2 perform an action automatically or 3 suggest an action to the user dialog . In the latter instance then the method would determine that the highest expected utility action is to engage in a dialog. For example the computer may display an automated assistant or agent on the screen such that the agent asks the user whether it should perform an action e.g. the query of as has been described . That is the method engages the user with a question for example regarding a desire for an automated service. If the agent is to render audible its question such as through a speaker connected to or a part of the computer then a text to speech functionality or mechanism such as those known in and available within the art is utilized. In one embodiment the text to speech functionality used is the Speech Application Programming Interface SAPI available from Microsoft Corp. For example version 4.0a of the SAPI may be used. The SAPI is described on the Internet at http microsoft.com iit projects sapisdk.htm. 

In one embodiment determining whether engaging in a dialog is the highest expected utility action is also performed as described in the copending and coassigned application entitled Systems and Methods for Directing Automated Services for Messaging and Scheduling Ser. No. 09 295 146 filed on Apr. 20 1999 previously incorporated by reference.

In the method turns on a speech recognition functionality. The speech recognition functionality is the mechanism by which utterances spoken by the user into a microphone or other audio detection device connected to or a part of the computer or other processor based device are converted into a form understandable by the computer. Speech recognition functionality is known and available within the art. In one embodiment the speech recognition functionality used is the Speech Application Programming Interface SAPI available from Microsoft Corp. For example version 4.0a of the SAPI may be used. The SAPI is described on the Internet at http microsoft.com iit projects sapisdk.htm. .

The speech recognition functionality is specifically turned on for a duration or length of time referred to as the listening horizon such as the listening horizon of . The listening horizon may be predefined by the user or the computer or can be determined as a function. For example the function may be a function of the inferred probability that the user desires automated service a complex service that has been queried may result in the listening horizon being longer for instance than if the query relates to a relatively simple query. As another example the listening horizon may be longer as the probability that the desires a service increases. Furthermore the function may also be a function of an acute listening history that is the prior listening history between the computer and the user. Thus if the computer has had difficulty in the past understanding user utterances a longer listening horizon may be specified.

As part of turning on the speech recognition functionality in one embodiment an automated assistant or agent is displayed on the screen having listening for user utterances indications. For example the agent may be displayed such that it is shown as being attentive to the user.

In and a user utterance is first detected during the listening horizon. That is the user speaks into a microphone such that the speech is detected by the computer and translated into a form understandable by the computer by the speech recognition functionality in . Desirably the speech recognition functionality determines a confidence level of the utterance in that is a confidence level that what the functionality interpreted as the user saying is in fact what the user said. Such determination of confidence levels is a part of speech recognition functionality known and available within the art. In one embodiment the confidence level is indicated as a percentage from 0 to 1 where 1 corresponds to 100 confidence of the utterance .

Thus in one embodiment the confidence level of the utterance is determined as described in the copending and coassigned patent application entitled Confidence Measure Using A Near Miss Pattern filed on Nov. 13 1998 Ser. No. 09 192 001. In addition in one embodiment the confidence level is determined as this capability as provided by the Microsoft Speech Application Programming Interface SAPI as has been described.

Next in it is determined if the confidence level is greater than a predetermined threshold. If the confidence level is greater than this threshold this indicates that the method believes it has understood what the user has said and the method proceeds to . In it is determined if the utterance spoken by the user relates to a deliberation on the part of the user such as typical patterns of user dysfluency and reflection. For example the method detects the user saying ummm uhhh and hmmmm as signs of thought and deliberation on the part of the user.

In such an instance in one embodiment an agent or automated assistant that is displayed on the screen is shown as indicating increased attentiveness to the user that is as if the agent understands that the user is thinking and about to say his or her real response. For example the agent of is shown an agent in the form of a bird having one wing lifted to its ear to indicate that it is listening to what the user is saying. The invention is not so limited however.

Also in one embodiment in conjunction with the user conveying deliberation the listening horizon can be extended so that the user has additional time to make an utterance. In any case upon determining that the utterance is a deliberation in the method proceeds back to to detect a further utterance from the user.

If however the utterance is not a deliberation then instead the utterance is a response from the user that should be acted upon. For example in the case of the agent initially asking the user a question the response may be an affirmative or negative utterance yes no yep nope not now etc. . In such an instance in one embodiment the agent or automated assistant that is displayed on the screen is shown as indicating understanding as to what the user has said. For example the agent of is shown an agent in the form of a bird stating OK that it understands what the user has uttered. The invention is not so limited however.

In any case upon determining that the utterance is a response from the user that should be acted upon then the method proceeds to where the speech recognition functionality is turned off. The functionality is turned off because a responsive utterance with a confidence level greater than the predetermined threshold has been received from the user and thus speech recognition is no longer necessary.

If however in the confidence level of the utterance is not greater than the predetermined threshold then the method proceeds instead to . In it is determined whether the hearing difficulty encountered by the speech recognition system viz. that it has not been able to determine over a predetermined threshold level what the user is saying as measured by the confidence level of the utterance is a continued hearing difficulty. In one embodiment continued hearing difficulty is measured as a predetermined number of times that the user makes an utterance that the speech recognition functionality rates lower than the predetermined threshold. If the predetermined number of times is exceeded then the method proceeds to to turning off speech recognition and ending the method. This is because there may be a problem with the equipment the user is using to convey utterances to the computer etc. such that the speech recognition process should just be ended instead of subjecting the user to potentially frustrating continued difficulty on the part of the computer to understand what the user is saying.

In such an instance in one embodiment an agent or automated assistant that is displayed on the screen is shown as indicating failure to hear and understand utterances to the user. For example the agent of is shown an agent in the form of a bird stating to the user sorry I am having repeated difficulty understanding you. The invention is not so limited however.

If however continued hearing difficulty has not been encountered for example the predetermined number of times that a user utterance is lower than the predetermined threshold has not been exceed the method instead proceeds back from to to continue to detect another user utterance. The listening horizon may also be extended in one embodiment to allow for the fact that the speech recognition system did not understand what the user had previously said with a confidence level greater than the predetermined threshold. In such an instance in one embodiment the agent or automated assistant that is displayed on the screen is shown as indicating hearing difficulty as to what the user has said. For example the agent of is shown an agent in the form of a bird with a puzzled look on its face and potentially also stating can you repeat that please to indicate that it did not understand what the user has uttered. The invention is not so limited however.

Finally not specifically shown in is that if the listening horizon has expired before speech recognition is turned off in as a result of an utterance with a level of confidence greater than the predetermined threshold that is not a deliberation i.e. the method proceeding from to or as a result of continued hearing difficulty i.e. the method proceeding from to then the method will automatically turn off the speech recognition functionality anyway i.e. proceeding to automatically . This corresponds to a situation where it is assumed that for example the user is busy and thus for this or another reason does not wish to respond with an utterance. In such a situation an agent or automated assistant may be displayed on the screen indicating sensitivity to the fact that the user is busy.

Once the speech recognition is turned off in then in one embodiment any displayed automated assistant or agent is removed that is not displayed In one embodiment the removal is accomplished after waiting a predetermined time so that the user is able to see the gestures and behavior of the agent or automated assistant. The invention is not so limited however.

Thus the embodiment of provides for advantages not found in the prior art. The embodiment allows for a dialog between a user and a computer or other processor based device without requiring the user to press a push to talk button or key before making an utterance meant for understanding by the computer. This is accomplished by setting a listening horizon which can be extended in certain situations as has been described. Furthermore the embodiment of provides for different handling of user utterances depending on whether the confidence level of the utterance is greater than a predetermined threshold whether the utterance is a deliberation whether the utterance is a response whether the confidence level of the utterance is less than a predetermined threshold or whether continued hearing difficulty is encountered.

Although specific embodiments have been illustrated and described herein it will be appreciated by those of ordinary skill in the art that any arrangement which is calculated to achieve the same purpose may be substituted for the specific embodiments shown. This application is intended to cover any adaptations or variations of the present invention. Therefore it is manifestly intended that this invention be limited only by the following claims and equivalents thereof.

