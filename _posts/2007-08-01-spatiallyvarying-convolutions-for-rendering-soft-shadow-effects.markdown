---

title: Spatially-varying convolutions for rendering soft shadow effects
abstract: Soft shadows may include areas that are less clear (more blurry) than other regions. For instance, an area of shadow that is closer to the shadow caster may be clearer than a region that is farther from the shadow caster. When generating a soft shadow, the total amount of light reaching each point on the shadow receiving surface is calculated according to a spatially-varying convolution kernel of the occluder's transparency information. Ray-tracing, traditionally used to determine a spatially varying convolution, can be very CPU intensive. Instead of using ray-tracing, data structures, such as MIP-maps and summed-area tables, or separable linear filters may be used to compute the spatially-varying convolution. For example, a two-dimensional convolution may be computed as two spatially-varying, separable, linear convolution filtersâ€”one computing a horizontal component and the other a vertical component of the final 2D convolution.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07982734&OS=07982734&RS=07982734
owner: Adobe Systems Incorporated
number: 07982734
owner_city: San Jose
owner_country: US
publication_date: 20070801
---
The present invention is directed to computer systems. More particularly it is directed to graphical image processing including the generation of shadows and reflections.

Graphics applications may render simple shadow effects in an attempt to lend realism to an image. For example a drop shadow is a visual effect that appears to be a shadow of an object often giving the impression that the object is raised above the objects behind it. Rendering shadows using point light sources generally results in hard shadows. Hard shadows generally have a distinct edge between deep shade e.g. the umbra and no shade. A soft shadow such as one rendered using an area light source generally has a soft edge or penumbra rather than a hard edge. Soft shadow generation in graphic applications generally involves determining the amount of light and conversely the amount of shadow that strikes particular points to be shaded. Rendering realistic shadows may improve the overall realism of an image such as by providing additional spatial indicators about the geometry in the rendered image.

Additionally soft shadows cast by area light sources and glossy reflections are not uniformly clear. Traditionally however shadows in computer generated scenes are generated using techniques such as using drop shadows and or point light sources that do not result in realistic appearing shadows. Additionally blurry shadows are generally generated using a uniform blur or filter algorithm over the rendered shadow. Similarly reflections are traditionally generated using uniform image filters and convolutions function that may not result realistic looking reflections. Techniques to create more realistic drop shadow and or reflection effects are traditionally very compute intensive. For instance ray tracing or ray casting has traditionally been used to explicitly determine a spatially varying integral. However ray tracing can be very CPU intensive and therefore expensive especially when implemented in software.

This disclosure describes efficient techniques to compute soft shadows and glossy reflections of planar texture and transparency mapped polygons. These techniques generalize to spatially varying blur as would occur from an area light source as well as effects involving glossy reflections.

For graphic design and other purposes it can be appealing to cast shadows from single transparency mapped surfaces onto other surfaces especially ground planes or floors. In general rendering a graphic scene may include rendering a shadow acceptor e.g. floor plane taking into account a shadowing of the shadow acceptor by a foreground occluder and then rendering foreground graphics including the occluder over the top of the rendered shadow acceptor e.g. floor .

Soft shadows may include areas or regions in which the light is only partially hidden from the shadow acceptor and that are therefore less clear more blurry than other regions. For instance one region of a shadow may be closer to the occluder and therefore clearer than a region farther from the occluder. A region of the shadow farther from the occluder may be used to represent a region of shadow from which the light source is only partially hidden by the occluder.

In general soft shadows may be generated according to various embodiments as described herein for use in virtually any sort of graphics or image processing application or system. For instance in some embodiments a graphics application such as an image generation tool may be configured to generate soft shadows according to any of various embodiments as described herein. While in some embodiments soft shadows may be generated as part of a large image processing or other graphics application in some embodiments soft shadows may be generated as part of application not directly related to graphics processing. For example user interfaces are frequently graphical in nature and the use of soft shadows according to some embodiments may be used to enhance the visual appeal interest or usability of a graphical user interface. In general soft shadows may be generated as described herein as part of virtually any image or graphics rendering process involving planar transparency mapped surfaces according to various embodiments.

In generating a soft shadow a light and or color value may be associated with the total amount of light and or color reaching each particular point on the shadow receiving surface. According to some embodiments generating soft shadows may include the computation of a spatially varying integral of the occluder s transparency and or color information for each point or pixel on the shadow receiving surface.

Thus according to one embodiment the size and shape of a spatially varying convolution area may be determined for each of a plurality of pixels within a shadowed region of a shadow receiving plane. The shadowed region may correspond to an area of a receiving plane e.g. floor from which light from a light source is at least partially attenuated by an occluding plane.

In some embodiments the size of the convolution area may vary from pixel to pixel. For instance the size of the convolution area may vary according to the size and shape of the light source as well as according to the distance from the light source to the occluding plane. A pixel closer to the light source may have a smaller convolution area than another pixel farther from the light source. Thus differently sized convolution areas may be used for different pixels according to some embodiments.

In addition to determining the size and shape of the convolution area for each pixel a graphics application may also compute a shadow value for each pixel based on light attenuation values for the occluding plane within the convolution area in one embodiment. Each light attenuation value may specify a level of attenuation for light from the light source intersecting a corresponding pixel of the occluding plane.

Thus when rendering a soft shadow a value representing the total amount of light and or color reaching each particular point or pixel on the receiving surface may be determined and used when determining the final color for the particular pixel. The values computed according to various embodiments for the soft shadow may only represent one factor or input into additional lighting color or graphical image processing calculations. Additionally in some embodiments a scene may include more than one light source and each light source may cast a separate shadow of an occluder. In such a situation separate respective soft shadow values may be generated for each light source and may be combined into a single soft shadow value for each pixel on the receiving surface.

While the invention is described herein by way of example for several embodiments and illustrative drawings those skilled in the art will recognize that the invention is not limited to the embodiments or drawings described. It should be understood that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims. Any headings used herein are for organizational purposes only and are not meant to limit the scope of the description or the claims. As used herein the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to.

As noted above efficient techniques to compute soft shadows and glossy reflections of planar texture and transparency mapped polygons such as the use of image pyramids and spatially varying separable filters can be used for advanced 2.5D or 3D graphical effects. According to one embodiment these techniques generalize to spatially varying blur as would occur from an area light source as well as glossy reflections.

For graphic design and other purposes it may be required or appealing to cast shadows from single transparency mapped surfaces onto other surfaces especially ground planes or floors. In general three objects are required for a shadow to be cast a light source a shadow caster and a shadow acceptor. A shadow caster or occluder may represent a plane or in some embodiments an object that occludes light from reaching a surface or another plane and therefore casts a shadow. A shadow acceptor or receiver may represent a plane that is shadowed by one or more shadow casters. While the techniques described herein may be used with image information representing objects of generally any shape the embodiments and examples described herein utilize image information representing planar image data. Thus while in some embodiments an occluder may represent a 3D object of varying shape in other embodiments described herein an occluder may represent a two dimensional plane of graphics information. As described herein shadows may be generated from planar images. The planar images may have transparency or alpha information associated with them. Such transparency information may allow a particular opaque region of the planar image to cast a shadow while other transparent regions of the planar image may not. Thus only part of the planar image may cast a shadow. Such shadows are of images within the planar image not just a rectangular image of the planar image.

Rather than performing CPU expensive ray tracing or ray casting to explicitly determine a spatially varying integral of the transparency and or color information for the occluder when computing soft shadows and or glossy reflections in some embodiments data structures such as MIP maps or summed area tables may be used to determine or in some embodiments approximate the computation of a spatially varying integral of the transparency and or color information for the occluder. Similarly such data structures MIP maps summed area tables etc may be used to determine or in some embodiments approximate the computation of a spatially varying integral of the transparency and or color information for an image being reflected.

While explicitly determining the integral may produce higher quality results it can be extremely CPU intensive. Thus in some embodiments a convolution representing a spatially varying integral of the transparency and or color information for the occluder may be computed using any of various acceleration or approximation techniques as described herein. For instance in one embodiment such a convolution may be computed as two spatially varying separable convolutions. For example a two dimensional convolution may be computed as two spatially varying separable linear convolution filters one computing a horizontal component and the other a vertical component of the final 2D convolution.

Thus in some embodiments a 2D convolution may be split into two parts a horizontal pass and a vertical pass. For example a horizontal linear convolution may be applied to image or color information to obtain intermediate values to which a vertical linear convolution may be applied to obtain the result of the 2D convolution according to one embodiment. In general the order in which the separate passes of the 2D convolution are applied may vary from embodiment to embodiment. For instance in another example a vertical convolution may be applied first and a horizontal convolution may be applied to intermediate values resulting from the vertical pass. In yet other embodiments other actions convolutions functions or equations may be performed after the first pass of a separable convolution but before the second pass. For example other horizontal linear functions or convolutions may be applied to the intermediate results before applying the vertical linear convolution.

Computing a 2D convolution using two separable linear convolutions may allow for more efficient convolution computations than when using more CPU expensive explicit methods as mentioned above. Additionally when using two separable linear convolutions linear sum tables may be used in the computations according to some embodiments. Such a technique may maintain the quality or be of similar quality of explicit convolutions but may reduce the cost especially for large convolution kernels. In some embodiments generating soft shadows may involve a constant time solution that may be comparable in cost to an efficient approximation of a spatially invariant Gaussian convolution.

Algorithms for computing soft shadows and glossy reflections may in some embodiments include the computation of a spatially varying integral of the occluder s transparency map or of the image object being reflected for each pixel on the receiving surface. This may be done explicitly or by using acceleration data structures such as MIP maps or summed area tables. The explicit method gives the highest quality results but may be expensive such as in terms of execution time. In one embodiment the convolution may be computed as two spatially varying separable convolutions. Such a technique may keep the quality of explicit convolutions but may also reduce the cost especially for large kernels. In another embodiment generating soft shadows may involve a constant time solution that may be comparable in cost to an efficient approximate spatially invariant Gaussian convolution.

For graphic design and other purposes it can be appealing to cast shadows from single transparency mapped surfaces onto other surfaces especially ground planes or floors. For example illustrates a soft shadow cast by an area light onto a floor surface from a texture mapped planar surface according to one embodiment. includes an occluder namely the planar graphic image of a dog drawn to be viewed in the plane of the display screen. The rendering algorithm for the scenes illustrated in may be expressed in front to back order as first rendering the floor plane taking into account the shadowing of or reflecting in the floor by the foreground occluder i.e. the image of the dog and then rendering the foreground graphic including occluder over the top of the rendered floor.

Soft shadows may include areas or regions in which the light is only partially hidden from the shadow acceptor and that are therefore less clear more blurry than other regions. For instance as illustrated in the region of shadow indicated by pointer may be closer to the occluder and therefore clearer than the region indicated by . The region of shadow is further from occluder than region and therefore is less clear. In some embodiments region may be used to represent a region of shadow from which the light source is only partially hidden by occluder .

As noted above the generation of soft shadows may in some embodiments include the computation of a value representing the total amount of light and or color reaching a particular point on the receiving surface. In some embodiments a spatially varying integral may be computed to represent the total amount of light and or color reaching each pixel on the receiving surface.

Computing the shadow from the occluder onto the floor plane may include the use of a 3D model of the scene to guide the shadow generation. The occluder in discussed below may be considered to be texture mapped onto a vertical plane. That is the foreground image of the dog is represented by a single planar data structure of image information.

While displayed in as parallel to the front of the screen in some embodiments a foreground image such as occluder may be oriented in other manners not parallel to the screen. A rotated foreground plane may pass through a line between the two lower paws of the dog to make the shadow cast by the occluder appear like a closer approximation to the correct shadow of a corresponding 3D object. In general the shadow cast by an image of one view of a 3D shape will only approximate the shadow cast by the 3D shape itself. If the 3D shape is truly planar the shadow can be computed exactly .

To compute the amount of light reaching a point on the floor requires integrating over a cone of rays towards an area light source. The resulting shadow will have a degree of blur that depends on the distance the rays travel from the floor to the occluder s plane.

The light source is considered to have a spatial distribution which may be used to weight the amount of light arriving along each ray direction. Each ray may be modulated by the occluder s transparency value at each ray plane intersection point. The computation may be performed explicitly using ray tracing in which a large number of rays are fired for each cone and the light summed over each ray.

While illustrates an image with a soft shadow and illustrates an image with a glossy reflection in some embodiments both shadows and glossy reflections may be generated in a single image. For example illustrates an image that includes both a soft shadow and a glossy reflection of the same occluder e.g. the image of the dog . While some embodiments may be configured to generate either soft shadows or glossy reflections other embodiments may be configured to generate both soft shadows and glossy reflections either separately or in a single image.

As noted above the convolution used to computer the amount of modulated light and or color reaching a particular receiving point may be computed using an explicit convolution. However the cost of explicit convolution computation generally increases quadradically with the cone angle e.g. angle which is generally related to the size of the light source . More efficient schemes may be used for special cases of the light distribution function the intensity over the light source . While described in terms of a cone in general solid angle may not represent a spherical cone. Instead in some embodiments light source may be rectangular and therefore the light reaching receiving point may be computed using a corresponding rectangular convolution. In general the shape of the ray projection may describe a convolution may be any of various shapes depending upon the size and position of the light source in relation to both occluder and receiving point according to various embodiments. For example while illustrated as being completely within the vertical space of occluder in in some embodiments convolution area may extend beyond the bounds of occluder as illustrated in .

As noted above the size and or shape of convolution area may vary spatially from receiving point to receiving point. For example as illustrated in the size of convolution area may depend on the size shape and location of light source . In other words convolution area may be represented as a rectangle because light source is a rectangle. If light source were represented as a circle convolution area may be represented as a circle or as an ellipse in some embodiments. If the light source is represented as a circle the shape of convolution area may vary according to the distance receiving point is from a line perpendicular to the plane of light source . The further a pixel is from such a perpendicular line the angle between the receiving point and the plane of the light source may become more oblique and therefore convolution area may be more elliptical.

Similarly the size of convolution area may also depend on the size of light source and the location of the occluder between receiving point and light source . For instance if the distance between occluder and light source were smaller the size of convolution area would increase according to some embodiments since the angle between the upper and lower edges of convolution area may increase as seen from receiving point . If the light source were farther away from occluder the size of convolution area would decrease. If light source were higher or lower than illustrated in the size and shape of convolution area may increase or decrease accordingly.

Additionally as described above generating a soft shadow may in some embodiments involve computing or approximating a spatially varying convolution filter to the light attenuation or transparency e.g. alpha values for the occluder to determine the shadow value for the pixels of the shadow receiving plane. Thus as indicated by block a graphical application may determine a size and shape of a spatially varying convolution kernel or area corresponding to a cone of rays projected from a respective pixel through the occluding plane onto a light source. The size and shape of the convolution kernel or area may vary from pixel to pixel. For example as noted above regarding B and C the size and shape of a convolution area for one pixel may differ from the size and shape of the convolution area for a different pixel. For example if the light source is rectangular the convolution area may be rectangular. Similarly if the light source is circular the convolution area may be circular or elliptical such as depending upon the angle between the pixel and the plane of the light source.

Additionally as explained above using a spatially varying convolution e.g. the size may vary according to the location of the particular pixel within the shadow may generate soft shadows in which portions are clearer the nearer they are to the occluder and less clear the further they are from the occluder.

After determining the size and shape of the convolution for the respective pixel the graphical application may compute a shadow value for the respective pixel based on a plurality of light attenuation values for the occluding plane within the convolution kernel as illustrated by block . For example as noted above a graphical application may in one embodiment compute an integral of the light attenuation e.g. transparency or alpha values within the convolution on the occluding plane. In some embodiments the application may utilize ray tracing or ray casting to explicitly compute the convolution integral. In other embodiments however the application may utilize any of various types of acceleration data structures such as summed area tables MIP maps and linear sum tables to approximate the convolution integral. In yet other embodiments the graphical application may perform a two dimensional convolution filter such as a two dimensional box filter either once or repeatedly to approximate the convolution integral.

The graphical application may compute a shadow value for each of a plurality of pixels with a shadowed region of the shadow receiving plane as indicated by the negative output of decision block . In some embodiments the application may compute shadow values for the entire receiving e.g. floor plane. In other embodiments however the application may first determine which regions of the receiving plane are in shadow and then only compute shadow values for those regions. Once the application has computed the shadow values for all the pixels with a shadowed region of the shadow receiving plane as indicated by the positive output of block the application may then render the shadowed region of the receiving plane according to the respective shadow values as illustrated by block .

In some embodiments occluder may include one or more transparent at least partially areas and thus may take into account that different amounts of light and therefore color may pass through the occluder onto the receiving plane. The original light color e.g. from the light source may be attenuated according to the transparency of the occluder. For example the original light color may be multiplied by the occluder s transparency e.g. alpha value in some embodiments. Additionally in some embodiments an occluder may be more like a stained glass window where a different amount of light passes through depending on the color of the occluder at that location. Thus the light may be attenuated separately for each of the three color values red green and blue of the light and possibly using alpha values corresponding to the three color values. In other words in some embodiments an occluder may include alpha R alpha G and alpha B values that may be used to attenuate the light passing through.

Thus a soft shadow may be generated to also include color information resulting from the attenuation of light passing through a colored at least partially transparent occluder.

In embodiments where the light source is planar and parallel to the occluder as illustrated in the convolution may directly map to the distribution of the light intensity over its surface. In one embodiment the light source may be rectangular of constant intensity and vertically aligned parallel to the occluder and the convolution may be computed using a rectangular filter on the transparency information of the occluder . In some embodiments such transparency information may be stored in a transparency map for occluder . Convolutions computing using a rectangular filter may in some embodiments be achieved in constant time such as when the transparency values are stored in a summed area table thus accelerating the filter computations. Using interpolation in the summed area table may also allow for sub pixel accurate integrals to be computed independently of size of angle such as with four texture interpolations according to one embodiment.

In some embodiments the light source may be described using a non constant illumination functions or may not be parallel to the plane of occluder . In such cases it may be less accurate to approximate the convolution integral with a rectilinear shape. Additionally if light source is greatly distant from occluder and receiving point the projection of the light source distribution onto the plane of occluding plane of occluder may result in a convolution kernel that changes in scale such as according to the distance between receiving point and occluder but not in shape.

Additionally in some embodiments the convolution integral may be approximated using an image pyramid or MIP map. MIP stands for multum in parvo which means much in a small space . A MIP map may be a data structure configured to store multiple versions of an image each at a different level of detail. In some embodiments a graphics application may utilize a MIP map to store attenuation values for the occluder at different levels of detail. For example each value at one level of such a MIP map may represent a summing or other combination of a plurality of values from a lower level of the MIP map. For example a tri linear interpolation may be used between levels of a MIP map and such computations may be accelerated by modern rendering hardware such as a graphic processing unit or GPU . Thus a convolution integral may be approximated using a MIP map on a GPU or other graphics hardware in some embodiments. MIP maps may be used to approximate kernels where interpolating between two scales of a kernel typically a factor of 2 is a reasonable approximation to the real kernel at an intermediate scale. For instance a factor of the square root of two or other number may be used to improve the accuracy of MIP map based convolution computation perhaps with an additional cost of generating the MIP maps.

Box and Gaussian convolutions generally have the property that one level of the MIP map may be filtered to generate the next. Thus in some embodiments the base resolution image may not be required to generate every level of a MIP map such as for an arbitrarily light source . In general this is not true with the base resolution image being required to be filtered to generate each level of the MIP map.

For light sources that project onto the occluder with a non square aspect ratio summed area tables may be used in some embodiments to compute or approximate the convolution integral. Additionally if a light source is more Gaussian like in intensity distribution the transparency map may be non proportionally scaled such as to make the convolution kernel approximately square in the scaled transparency map and then a MIP map may be used to compute or approximate the spatially varying integral.

In some embodiments the aspect ratio of the convolution kernel may vary with the height of the light source. For instance when light source is near or at least not greatly distant from occluder the aspect ratio height to width of the mapped convolution kernel such as from the light source onto the transparency map of occluder may vary with the height of light source . Thus in some embodiments summed area tables may be used to compute or approximate the convolution kernel integral for rectilinear light sources.

In other embodiments however summed area tables may not be appropriate. For instance in one embodiment an elliptically weighted averaging filter may be used for light source with light distributions that are Gaussian like. Elliptically weighted averaging may in some embodiments be approximated using a MIP map. For example the minor axis of the ellipse may be used to compute a MIP map level and the ratio of the major to minor axis may determine the number of samples to take along the major axis of the ellipse. Such a sampling scheme may work according to some embodiments for light sources with light distributions approximated by arbitrarily scaled Gaussians.

As described above computing soft shadows may involve the computation of a convolution corresponding at least approximately to the intersection of a ray projection such as a cone of rays from a receiving point on a receiving surface through an occluder to a light source as described above. Similarly generating glossy reflections may also involve the intersection of a ray projection with a planar surface.

In general reflecting surface or plane such as a glossy floor may reflect images e.g. color information of another plane or image. A foreground image that is reflected in a reflecting plane may represent a plane that occludes color information e.g. light from a background plane from reaching the reflecting surface. For instance and image of lake may reflect the image of the sky in the surface of the water. However a foreground image such as a boat on the water will prevent a portion of the water e.g. the portion reflecting the image of the boat from reflecting the sky. Thus a foreground image may be considered an occluder e.g. occluding part of the background image from the reflecting surface .

While the techniques described herein may be used with image information representing objects of generally any shape the embodiments and examples described herein utilize image information representing planar image data. Thus while in some embodiments an occluder may represent a 3D object of varying shape in other embodiments described herein an occluder may represent a two dimensional plane of graphics information. As described herein reflections may be generated from planar images.

Additionally the planar images may have transparency or alpha information associated with them. Such transparency information may also allow a particular region of the planar image to allow some of the background image to be visible through the occluder and therefore to be reflected at least some .

For example illustrates an image including a glossy reflection cast onto a reflecting surface from a texture mapped planar surface e.g. occluder according to one embodiment. includes occluder e.g. the graphic image of a dog rendered in the plane of the display screen and a glossy reflection . In the foreground image of the dog is referred to as an occluder because it occludes part of the background that may otherwise be reflected in the reflecting surface e.g. the floor in . In general when rendering a reflecting surface such as the floor or ground plane of the background image is reflected in the floor except where a foreground object such as occluder blocks a portion of the background image from being reflected. Thus while reflection appears to be the only a reflection of occluder in some embodiments reflection may only represent that portion of a larger reflection. For example the general or background color illustrated in may itself represent a reflected image such as of the sky and thus reflection may be considered that portion of the larger reflection that corresponds to occluder . Thus while described herein main in reference to generated a reflection of an foreground object or image in general the techniques for rendering glossy reflections described herein may be applied to generating a reflection of an entire scene e.g. including a reflection of the background and any foreground images.

In general when rendering a graphic scene such as the one illustrated in may be expressed in front to back order as first rendering the floor plane taking into account the reflection on the floor of occluder and then rendering the foreground graphics including occluder over the top of the rendered floor.

Glossy reflections may include areas or regions that are less clear more blurry than other regions. In general portions of a reflection that are closer to the object being reflected will be less blurry and thus clearer than portions further away from the object being reflected. For instance as illustrated in the region of shadow indicated by pointer may be closer to the foreground image and therefore may be clearer than the region indicated by which is further away from foreground image . The region of reflection is further from foreground image than region and therefore may be less clear. In general a portion or region of a reflection is referred to as being closer to or further from an object being reflected with regards to the logical geometry of the scene construction as will be discussed in more detail below and does not necessarily reflect the positions of the various regions in a final rendered 2D image.

In general glossy reflections may be generated according to various embodiments as described herein for use in virtually any sort of graphics or image processing application or system. For instance in some embodiments a graphics application such as an image generation tool may be configured to generate glossy reflections according to any of various embodiments as described herein. While in some embodiments glossy reflections may be generated as part of a larger image processing or other graphics application in some embodiments glossy reflections may be generated as part of application not directly related to graphics processing. For example user interfaces are frequently graphical in nature and the use of glossy reflections according to some embodiments may be used to enhance the visual appeal interest or usability of a graphical user interface. In general glossy reflections may be generated as described herein as part of virtually any image or graphics rendering process involving planar transparency mapped surfaces according to various embodiments.

In order to generate a glossy reflection a light and or color value associated with the total amount of light and or color reaching each particular point on a glossy surface including light and or color values to be reflected in the surface. According to some embodiments generating glossy reflections may involve the computation of a spatially varying integral of the transparency and or color information for the foreground image being reflected for each point or pixel on the reflecting surface.

Thus when rendering a glossy reflection a value representing the total amount of light and or color reaching each particular point or pixel on the receiving surface is determined and used when determining the final color for the particular pixel. Thus the values computed according to any of various embodiments for the glossy reflection may only represent one factor or input into additional lighting color or graphical image processing calculations.

As noted above the generation of glossy reflections may in some embodiments include the computation of a value representing the total amount of light and or color reaching a particular point on the reflecting surface. In some embodiments a spatially varying integral may be computed to represent the total amount of light and or color reaching each pixel on the receiving surface. Traditionally ray tracing or ray casting has been used to explicitly determine a spatially varying integral. However ray tracing can be very CPU intensive and therefore expensive especially when implemented in software. Instead of using ray tracing the problems are recast as convolutions that are then solved efficiently for different special cases.

When rendering glossy reflections the reflecting surface may be considered less than perfectly smooth. Reflections on a less than perfectly smooth surface may be considered blurry and the relative amount of blur may increase linearly in some embodiments with the distance between the reflection point and the corresponding intersection point on foreground image i.e. the plane of foreground image .

As illustrated in B and C and described above regarding shadow generation the size and shape of convolution area may vary from reflection point to reflection point when generation glossy reflections. The size and shape of convolution area may vary depending upon the specific geometry of the scene being rendered. For example the size and shape of convolution area may depend on the location of reflection point relative to both background and occluder . While not directly involving a light source a glossy reflection may be rendered as described herein using some of same techniques described above regarding shadow generation. For example in some embodiments the size and shape of convolution area for reflection point may be determined according to an imaginary light source corresponding to occluded region located within the place of background . Thus the size and shape of this imaginary light source may be used to determine the size and shape of convolution area in the same or a similar manner as that described above regarding soft shadow generation.

In some embodiments occluder may be opaque and therefore no light or color information from background within occluded region may reach reflection point . Thus in some embodiments only the color and or transparency values of occluder within convolution area may be used when determining a reflected color value for reflection point . In other embodiments however occluder may be at least partially transparent and therefore may allow some color from within occluded region of background to reach reflection point . Thus in some embodiments the reflection color computed for reflection point may be the foreground image color from the convolution are of occluder composited or otherwise combined with the background color such as by using a corresponding transparency value for the occluder. The color value may be computed in some embodiments for each of a set of rays reaching reflection point .

Additionally in some embodiments each of the rays may be deflected differently by the reflecting surface at reflection point . For example depending on the specific geometry of reflecting surface at reflection point a ray from one location of convolution area may be deflected different by reflection point than a ray from another location in convolution area . In some embodiments the total reflected color value may also be a weighted sum of each individual ray color.

In some embodiments the background color may be constant and therefore a convolution kernel of the foreground color of occluder may be composited over the background color using a single transparency e.g. alpha value. The single transparency value may be computed using the same convolution kernel such as convolution area of the occluder . The convolution integral may then be computed or approximated using the same techniques described above regarding soft shadows. For example in some embodiments the convolution integral may be computed explicitly using ray tracing. However in other embodiments summed area tables MIP maps and multiple two separable linear convolutions may be used when computing or approximating a reflection value for a particular reflection point .

As described above regarding B and C convolution area may not be fully contained within the edges of occluder . For example as illustrated in described above regarding the generation of soft shadows convolution area may extend beyond one or more of the edges of occluder . Similarly when generating glossy reflection convolution area may extend beyond the edge s of occluder and therefore within convolution area some portion s may be affected by color or transparency values of occluder while other portions may not. Thus for those portions of convolution area that extend beyond occluder the background color may be used without using color or transparency values for occluder .

For glossy reflections the ray distribution function is frequently Gaussian like and thus in some embodiments MIP map based approximations may result in more convincing results in terms of efficient generation of and realistic look of glossy reflections than summed area tables. However other embodiments may utilize MIP map based approximations and still other embodiments may utilize summed area tables when computing or approximating a reflection value for a convolution kernel. In yet other embodiments any of various convolution computation or approximation techniques such as MIP maps or summed area tables may be used depending on the specific geometry and or other aspects of the image or scene being rendered.

As noted above glossy reflections may be clearer close to the object being reflected such as occluder and may be more blurry farther away from the object being reflected. Thus generating both soft shadows and glossy reflections may in some embodiments involve spatially varying convolutions. Additionally as described above in some embodiments a 2D convolution may be computed using two separable linear convolution filters.

Thus when rendering a glossy reflection a value representing the total amount of light and or color reaching each particular point or pixel on the receiving surface is determined and used when determining the final color for the particular pixel. Thus the values computed according to any of various embodiments for the glossy reflection may only represent one factor or input into additional lighting color or graphical image processing calculations.

For instance when rendering either a soft shadow or a glossy reflection the resultant image information may be warped in order to have the shadow or reflection better appear to be connected to the occluder. Thus warping of shadows and reflections to visually match occluder image may be performed in various embodiments. This may be desired due to the occluder being a 2D image of a 3D object rather than an actual 3D object. Referring again to since the image of the dog on occluder is planar image data and may not include any actual 3D information a shadow cast by occluder may not actually meet up with the feet of the dog in the image. In other word since the dog is represented by varying colors in the occluder there may not by any 3D geometric model that can specify where the dogs feet actually are. Additionally as illustrated in an occluder image may illustrate a 3D perspective that doesn t actually exist in the rendered image. For example in the lower paws e.g. the feet of the dog are illustrated with perspective. The dog s left foot is drawn lower on the image that its right foot thereby making it appear as if the dog s left foot is in front of the other.

Thus in some embodiments soft shadows and glossy reflections may be warped to ensure that the correct edge of the shadow or reflection appears to be correctly positioned in relation to the occluder. For instance reflection has been warped so that the reflection of the dog s right foot touches the occluding right foot. In some embodiments various types of image warping functions may be applied either during or after generating soft shadows and or glossy reflections.

Additionally as described above generating a glossy reflection may in some embodiments involve computing or approximating a spatially varying convolution filter to the color information values for the occluder to determine reflective values for the pixels of the reflecting surface. Thus as indicated by block a graphical application may determine a size and shape of a spatially varying convolution kernel or area corresponding to a cone of rays projected from a respective pixel of a reflecting surface through the occluding plane onto a background plane. As explained above by using a spatially varying convolution e.g. the size may vary according to the location of the particular pixel within the shadow may generate glossy reflections which are clearer the nearer they are to the occluder.

After determining the size and shape of the convolution for the respective pixel the graphical application may compute a reflective value for the respective pixel based on a plurality of color values for the occluding plane within the convolution kernel as illustrated by block . For example as noted above a graphical application may in one embodiment compute an integral of the color values within the convolution on the occluding plane. In some embodiments the application may utilize ray tracing or ray casting to explicitly compute the convolution integral. In other embodiments however the application may utilize any of various types of acceleration data structures such as summed area tables MIP maps and linear sum tables to approximate the convolution integral. In yet other embodiments the graphical application may perform a two dimensional convolution filter such as a two dimensional box filter either once or repeatedly to approximate the convolution integral.

The graphical application may compute a reflection value for each of a plurality of pixels with a reflected region of the reflecting surface as indicated by the negative output of decision block . In some embodiments the application may compute reflection values for the entire reflecting surface. In other embodiments however the application may first determine which regions of the reflecting plane are reflecting images other than perhaps a uniform background reflection color and then only compute reflection values for those regions. Once the application has computed the reflection values for all the pixels with a reflected region of the reflecting plane as indicated by the positive output of block the application may then render the reflected region of the receiving plane which in some embodiments may represent the entire reflecting plane according to the respective reflection values as illustrated by block .

Separable filters may be considered those filters that can be expressed as two convolutions in orthogonal directions. Examples include box filters and Gaussian convolutions. While the MIP map based techniques may give reasonable results for glossy reflections in some embodiments there may still be some approximations based on the scale steps between MIP levels. In some embodiments an explicit convolution may be preformed but as noted above this may lead to quadratic computational cost. Thus in some embodiments a convolution may be expressed as two separable passes one horizontal and one vertical.

In the case of glossy reflection generation as described herein and illustrated in the convolution size may be constant horizontally and may vary linearly with height up plane of occluder . In other words since in some embodiments the plane of occluder may be parallel to the plane of the rendered image the convolution size may be constant across the horizontal plane of the displayed image and may vary across the vertical plane of the displayed image.

Thus in some embodiments the horizontal convolution filter may be computed with a constant kernel being applied with a different kernel size at each horizontal line of the convolution kernel. In general a horizontal line of the convolution kernel may correspond to one row of color and or transparency information for occluder . The convolution kernel may be computed as either a directly Gaussian convolution or as a Gaussian approximation based on successive box filters which may have constant cost independent of the kernel size according to some embodiments. The vertical convolution filter may also be expressed or computed as an explicit Gaussian convolution filter which may have a linear cost or as a series of spatially varying box filters which may have a constant cost . Spatially varying box filters may in some embodiments be computed at constant cost by first computing a vertically summed linear table and then indexing into that table for each convolution kernel computation. Thus in some embodiments accurate approximations to spatially varying Gaussian convolution filters may be computed using multiple horizontal linear box filters and vertical summed linear tables.

Soft shadows and glossy reflections as described herein may be generated or rendered on graphics hardware such as on a graphics processing unit or GPU. A GPU is a dedicated graphics rendering device for a personal computer workstation or game console. Modern GPUs may be very efficient at manipulating and displaying computer graphics and their highly parallel structure may make them more effective than typical CPUs for a range of complex graphical algorithms. For example a GPU may implement a number of graphics primitive operations in a way that makes executing them much faster than drawing directly to the screen with the host CPU. Many GPUs have programmable shading as part of their capabilities. For example each pixel can be processed by a short program that could include additional image textures as inputs and each geometric vertex could likewise be processed by a short program before it was projected onto the screen. These pixel and vertex programs may be called shaders and may implement looping and lengthy floating point math and in general are quickly becoming as flexible as CPUs and orders of magnitude faster for image array operations. GPUs may include support for programmable shaders that can manipulate and vertices pixels and textures with many of the same operations supported by CPUs oversampling and interpolation techniques to reduce aliasing and very high precision color spaces.

GPUs may be implemented in a number of different physical forms. For example GPU may take the form of a dedicated graphics card an integrated graphics solution and or a hybrid solution. GPU may interface with the motherboard by means of an expansion slot such as PCI Express Graphics or Accelerated Graphics Port AGP and thus may be replaced or upgraded with relative ease assuming the motherboard is capable of supporting the upgrade. However a dedicated GPU is not necessarily removable nor does it necessarily interface the motherboard in a standard fashion. The term dedicated refers to the fact that hardware graphics solution may have RAM that is dedicated for graphics use not to whether the graphics solution is removable or replaceable. Dedicated GPUs for portable computers are most commonly interfaced through a non standard and often proprietary slot due to size and weight constraints. Such ports may still be considered AGP or PCI express even if they are not physically interchangeable with their counterparts.

Integrated graphics solutions or shared graphics solutions are graphics processors that utilize a portion of a computer s system RAM rather than dedicated graphics memory. For instance modern desktop motherboards normally include an integrated graphics solution and have expansion slots available to add a dedicated graphics card later. As a GPU is extremely memory intensive an integrated solution finds itself competing for the already slow system RAM with the CPU as it has no dedicated video memory. For instance system RAM may experience a bandwidth between 2 GB s and 8 GB s while most dedicated GPUs enjoy from 15 GB s to 30 GB s of bandwidth. Hybrid solutions also share memory with the system memory but have a smaller amount of memory on board than discrete or dedicated graphics cards to make up for the high latency of system RAM.

A GPU may include programmable vertex and pixel and texture units. For example is a block diagram illustrating the logic flow of rendering an image via a GPU. As shown in the model of the graphics objects to be rendered is supplied from a graphics application executing on the CPU of a system and passes data to the vertex unit and the texture unit . For example graphics application may call various functions of a graphics API such as OpenGL or DirectX that in turn instruct the various elements of the GPU to render the images. Vertex unit may describe the geometry of an object while texture unit may specify the skin covering on an object and pixel unit may deal with the view of an object. As noted above vertex unit and pixel unit may be configured to execute specific vertex and pixel programs called shaders. For instance vertex unit may accept vertex information such as position from the model through a vertex buffer. As the same time texture unit may receive surface information from the model. Both units may complete processing and generate output pixel unit . Pixel unit may then complete the lighting and view processing and output the rendered image to frame buffer for display. A frame buffer may be a video output device that drives a video display from a memory buffer containing a complete frame of data. The information in the buffer typically consists of color values for every pixel point that can be displayed on the screen.

Three D graphics rendering involves numerous steps that are performed one after another. These steps can be thought of like an assembly line or pipeline. is a block diagram illustrating one embodiment of the logical view of such a pipeline. A pipeline is a term used to describe the graphics card s architecture and it provides a generally accurate idea of the computing power of a graphics processor. There may be different pipelines within a graphics processor as there may be separate functions being performed at any given time. The pipeline may be broken down into two main stages the geometry processing stage and the rendering stage. Geometry processing may involve calculations that modify or in some cases create new data for vertices. In the rendering stage of the pipeline a pixel shader may be used to replace previously fixed function texturing filtering and blending. A programmable shader such as a pixel or vertex shader may be considered a piece of code configured to perform different kinds of operations on GPU including T L texturing etc.

An important advantage of the modern GPU is the ability to be programmed through languages like OpenGL DirectX or C for Graphics CG . DirectX and OpenGL are graphics APIs or Application Programming Interfaces. Before 3D graphics APIs each graphics card company had its own proprietary method of making their graphics card work. Developers were forced to program with vendor specific paths for each and every type of graphics card they wished to support. This was naturally a very costly and inefficient approach. To solve this problem 3D graphics APIs were created so that developers could program their software to be compliant with the API and not with each independent piece of hardware. The responsibility of compatibility was then shifted to the graphics card manufacturers who had to ensure that their drivers where compatible with the API.

There emerged two different APIs DirectX and OpenGL both of which are used today. Initially the APIs were relatively simple. Developers had to mix and match visual effects from an unchanging list of pre programmed effects. Custom shader programming allows developers to create truly custom visual effects for the first time. Thus graphics application may call various functions supplied by graphics API such as DirectX or OpenGL in order to utilize the GPU to render a graphic image.

As noted above vertex processor and pixel processor may be user programmable. A program executed by vertex processor and or pixel processor may be called a shader . Vertex shaders may deform or transform 3D elements.

A pixel processor such as pixel processor may be a component on the graphics chip devoted exclusively to pixel shader programs. These processing units may only perform calculations regarding pixels. Because pixels represent color values pixel shaders may be used for all sorts of graphical effects. Pixel shaders may change pixel colors based on various types of input. For example when the object is lit by a light source in a 3D scene in which some colors appear brighter while other colors create shadows both the brighten objects and the shadows may be generated by changing various pixels color information in a pixel shader. As noted above a GPU may also include vertex processors such as vertex processor configured to execute vertex shaders that affect vertices.

A vertex shader may receive streams of vertex data from the graphics pipeline perform operations on the data and output the transformed vertex data to the graphics pipeline for further processing. For example vertex processor may receive pretransformed vertex data from GPU front end and output transformed vertices to primitive assembly unit . Subsequently the assembled polygons lines and points may be sent to a rasterization unit . Pixel processor may receive rasterized pretransformed pixel information also called fragments execute the applicable pixel shaders and output transformed fragments pixel information to a raster operations unit that may then output the final pixel information to frame buffer Raster operation processors ROPs such as raster operations unit may be responsible for writing pixel data to memory.

A GPU may also include texture mapping units TMUs . Textures need to be addressed and filtered. This job is frequently performed by TMUs that work in conjunction with pixel and vertex shader units. The TMU s job is to apply texture operations to pixels. Data communicated between the graphics processing unit and the rest of the computer may travel through the graphics card slot or other interface.

A technique called texture mapping may be used to map a digital image onto a surface of a graphic object. The image data mapped onto the object may be called a texture and its individual elements may be called texels. The rectangular texture resides in its own texture coordinate space or the texture may be defined by a procedure. At each rendered pixel selected texels may be used to substitute for or to scale one or more surface properties such as diffuse color components. One pixel may often be mapped by a number of texels. For example when a texture is mapped to a polygon it is common to assign texture map coordinates directly onto the polygon s vertices. A number of different textures may be stored in a single texture atlas.

In the same manner that color can be assigned to a pixel transparency or opacity can be assigned to it as well. Opacity and transparency are complements of each other in the sense that high opacity implies low transparency. The opacity may be considered a normalized quantity in the range 0 1 or alternatively in a discrete form in the range 0 255 for use with 8 bit hardware. Opacity a may be related to transparency t by the expression a 1 t. If an object has high opacity a 1 the objects and light behind it are shielded and not visible. If at the same time the object has a non zero color value it is emitting light so it is visible. On the other hand if a

While the techniques described herein may be used with area lights of any arbitrary shape generally for ease of discussion the examples and exemplary embodiments described and illustrated include rectangular light sources.

The generation of soft shadows and or glossy reflections as described herein may be implemented on various types of computer systems. Referring to computer system may be any of various types of devices including but not limited to a personal computer system desktop computer laptop or notebook computer mainframe computer system handheld computer workstation network computer a consumer device video game console handheld video game device application server storage device a peripheral device such as a switch modem router or in general any type of computing device.

A graphics application configured to generate soft shadows and or glossy reflections as described herein such as graphics application may represent various types of graphics applications such as painting publishing photography games animation and other applications. Additionally such a graphics application may utilize a graphics processor when rendering or displaying images that include soft shadows and or glossy reflections according to various embodiments. A graphics processing unit or GPU may be considered a dedicated graphics rendering device for a personal computer workstation game console or other computer system. Modern GPUs may be very efficient at manipulating and displaying computer graphics and their highly parallel structure may make them more effective than typical CPUs for a range of complex graphical algorithms. For example graphics processor may implement a number of graphics primitive operations in a way that makes executing them must faster than drawing directly to the screen with a host central processing unit CPU such as CPU . Please note that functionality and or features described herein as being part of or performed by graphics application may in some embodiments be part of or performed by one or more graphics processors such as graphics processor .

A graphics application capable of generating soft shadows and or glossy reflections as described herein may be provided as a computer program product or software that may include a computer readable storage medium having stored thereon instructions which may be used to program a computer system or other electronic devices to generate soft shadows and or glossy reflections as described herein. A computer readable storage medium includes any mechanism for storing information in a form e.g. software processing application readable by a machine e.g. a computer . The machine readable storage medium may include but is not limited to magnetic storage medium e.g. floppy diskette optical storage medium e.g. CD ROM magneto optical storage medium read only memory ROM random access memory RAM erasable programmable memory e.g. EPROM and EEPROM flash memory electrical or other types of medium suitable for storing program instructions. In addition program instructions may be communicated using optical acoustical or other form of propagated signal e.g. carrier waves infrared signals digital signals or other types of signals or mediums .

A computer system may include a processor unit CPU possibly including multiple processors a single threaded processor a multi threaded processor a multi core processor or other type of processor . The computer system may also include one or more system memories e.g. one or more of cache SRAM DRAM RDRAM EDO RAM DDR RAM SDRAM Rambus RAM EEPROM or other memory type an interconnect e.g. a system bus LDT PCI ISA or other bus type and a network interface e.g. an ATM interface an Ethernet interface a Frame Relay interface or other interface . The memory medium may include other types of memory as well or combinations thereof. The CPU the network interface and the memory may be coupled to the interconnect . It should also be noted that one or more components of system might be located remotely and accessed via a network. One or more of the memories may embody a graphics application .

In some embodiments memory may include program instructions configured to generate soft shadows and or glossy reflections as described herein. A graphics application capable of generating soft shadows and or glossy reflections as described herein may be implemented in any of various programming languages or methods. For example in one embodiment graphics application may be JAVA based while in another embodiments it may be implemented using the C or C programming languages. In other embodiments such a graphics application may be implemented using specific graphic languages specifically for developing programs executed by specialized graphics hardware such as GPU . In addition such a graphics application may be embodied on memory specifically allocated for use by graphics processor s such as memory on a graphics board including graphics processor s . Thus memory may represent dedicated graphics memory as well as general purpose system RAM.

Network interface may be configured to enable computer system to communicate with other computers systems or machines such as across network described above. Network interface may use standard communications technologies and or protocols. Network may include and network interface may utilize links using technologies such as Ethernet 802.11 integrated services digital network ISDN digital subscriber line DSL and asynchronous transfer mode ATM as well as other communications technologies. Similarly the networking protocols used on network may include multiprotocol label switching MPLS the transmission control protocol Internet protocol TCP IP the User Datagram Protocol UDP the hypertext transport protocol HTTP the simple mail transfer protocol SMTP and the file transfer protocol FTP among other network protocols. The data exchanged over network by network interface may be represented using technologies languages and or formats such as the hypertext markup language HTML the extensible markup language XML and the simple object access protocol SOAP among other data representation technologies. Additionally all or some of the links or data may be encrypted using any suitable encryption technologies such as the secure sockets layer SSL Secure HTTP and or virtual private networks VPNs the international data encryption standard DES or IDEA triple DES Blowfish RC2 RC4 RC5 RC6 as well as other data encryption standards and protocols. In other embodiments custom and or dedicated data communications representation and encryption technologies and or protocols may be used instead of or in addition to the particular ones described above.

GPUs such as GPU may be implemented in a number of different physical forms. For example GPU may take the form of a dedicated graphics card an integrated graphics solution and or a hybrid solution. GPU may interface with the motherboard by means of an expansion slot such as PCI Express Graphics or Accelerated Graphics Port AGP and thus may be replaced or upgraded with relative ease assuming the motherboard is capable of supporting the upgrade. However a dedicated GPU is not necessarily removable nor does it necessarily interface the motherboard in a standard fashion. The term dedicated refers to the fact that hardware graphics solution may have RAM that is dedicated for graphics use not to whether the graphics solution is removable or replaceable. Dedicated GPUs for portable computers may be interfaced through a non standard and often proprietary slot due to size and weight constraints. Such ports may still be considered AGP or PCI express even if they are not physically interchangeable with their counterparts. As illustrated in memory may represent any of various types and arrangements of memory including general purpose system RAM and or dedication graphics or video memory.

Integrated graphics solutions or shared graphics solutions are graphics processors that utilize a portion of a computer s system RAM rather than dedicated graphics memory. For instance modern desktop motherboards normally include an integrated graphics solution and have expansion slots available to add a dedicated graphics card later. As a GPU may be extremely memory intensive an integrated solution finds itself competing for the already slow system RAM with the CPU as the integrated solution has no dedicated video memory. For instance system RAM may experience a bandwidth between 2 GB s and 8 GB s while most dedicated GPUs enjoy from 15 GB s to 30 GB s of bandwidth.

Hybrid solutions also share memory with the system memory but have a smaller amount of memory on board than discrete or dedicated graphics cards to make up for the high latency of system RAM. Data communicated between the graphics processing unit and the rest of the computer may travel through the graphics card slot or other interface such as interconnect .

While graphics application has been described herein with reference to various embodiments it will be understood that these embodiments are illustrative and that the scope of the present invention is not limited to them. Many variations modifications additions and improvements are possible. More generally the present invention is described in the context of particular embodiments. For example the blocks and logic units identified in the description are for ease of understanding and not meant to limit the invention to any particular embodiment. Functionality may be separated or combined in blocks differently in various realizations or described with different terminology.

The embodiments described herein are meant to be illustrative and not limiting. Accordingly plural instances may be provided for components described herein as a single instance. Boundaries between various components operations and data stores are somewhat arbitrary and particular operations are illustrated in the context of specific illustrative configurations. Other allocations of functionality are envisioned and may fall within the scope of claims that follow. Finally structures and functionality presented as discrete components in the exemplary configurations may be implemented as a combined structure or component. These and other variations modifications additions and improvements may fall within the scope of the invention as defined in the claims that follow.

Although the embodiments above have been described in detail numerous variations and modifications will become apparent once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.

