---

title: System and method for applying ranking SVM in query relaxation
abstract: An enterprise-wide query relaxative support vector machine ranking algorithm approach provides enhanced functionality for query execution in a heterogeneous enterprise environment. Improved query results are obtained by adjusting ranking functions using machine learning methods to automatically train ranking functions. The improved query results are obtained using a list of document-query pairs that are modeled as a binary classification training problem, combination function which requires ranking and learning functions to be implemented representing document attributes and metadata utilizing query relaxation techniques and adjusted ranking functions. Machine learning methods implement user feedback to automatically train ranking functions.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08458165&OS=08458165&RS=08458165
owner: Oracle International Corporation
number: 08458165
owner_city: Redwood Shores
owner_country: US
publication_date: 20070628
---
This application is related to U.S. patent application Ser. No. 10 434 845 filed Mar. 8 2003 which is hereby incorporated herein by reference.

A portion of the disclosure of this patent document contains material that is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever.

The present invention relates generally to generating query results as well as to information management systems that can be used with a heterogeneous enterprise environment which can include structured data in a relational database as well as unstructured data stored in document images and document management applications. Embodiments also relate to applying ranking query results such as support vector machine SVM methods and query relaxation methods to search secure data repositories that contain documents or other data items belonging to numerous heterogeneous enterprise environments. Still further embodiments relate to adjusting rank functions using machine learning methods to automatically train ranking functions to obtain improved results in a query such as in an enterprise search system able to crawl and search heterogeneous enterprise content.

Typically in an enterprise relational database query generators are used to construct database queries which are then sent to a database for execution. A user constructs a query by selecting items from a drop down list of items displayed on the screen. The items may represent data or documents which are to be obtained from a database or a URL or alternatively the items may represent operations that are to be performed on these data Once the items have been selected the query generator then generates a query usually in Structured Query Language SQL for execution by the database. Often the query consists of keyword searches for documents or simply from the drop down list for structured data. However when an enterprise corpora consists of heterogeneous applications or where the same document has differing attributes emphasized in heterogeneous applications keyword searches and drop down list searches of structured data will not meet the needs of a sophisticated enterprise search end user.

An end user in an enterprise environment will also frequently search huge databases sometimes external to the heterogeneous enterprise corpora environment. For example Internet search engines are frequently used to search the entire World Wide Web. Information retrieval systems are traditionally judged by their precision and recall. Large databases of documents especially the World Wide Web contain many low quality documents where the relevance to the desired search term is extremely low or non existent. As a result searches typically return hundreds of irrelevant or unwanted documents that camouflage the few relevant documents that meet the personalized needs of an end user. In order to improve the selectivity of the results common techniques allow an end user to modify the search or to provide additional search terms. These techniques are most effective in cases where the database is homogeneous and already classified into subsets or in cases where the user is searching for well known and specific information. In other cases however these techniques are often not effective.

A typical enterprise has a large number of sources of data and a large number of different types of data. In addition some data may be connected to proprietary data networks while other data sources may be connected to and accessible from public data networks such as the Internet. More particularly information within a single enterprise can be spread across Web pages databases mail servers or other collaboration software document repositories file servers and desktops. In enterprise search different system deployments or different corpora may require different ranking algorithms to return a customized listing of hits to an end user. Providing a simple and intuitive way to allow customers ranking search results in heterogeneous enterprise environments is critical to improve user flexibility and personalization.

One approach to search heterogeneous enterprise corpora utilizes a secure enterprise search SES system such as may be found in the Oracle Secure Enterprise Search product from Oracle Corporation of Redwood Shores Calif. a standalone product or integrated component that provides a simple yet powerful way to search data across an enterprise. An SES system can crawl and index any content and return relevant results in a way that is familiar to users such as is returned for typical Internet based search results. SES also can provide a query service API for example that can easily be plugged into various components in order to obtain a search service for those components.

A SES enterprise search system can utilize the text index of a database. In one embodiment a database application accepts documents and generates the lists and other elements useful for text searching. An application programming interface API allows a user to submit queries such as text queries to search documents based on for example keywords.

A query layer can be configured to receive queries from users applications entities etc. These can be any appropriate queries such as simple text queries entered through a search box or advanced queries. The query layer can convert a user query into the appropriate text queries making sure security authorization authentication and other aspects are addressed such that the results are returned to the user based on what the user is allowed to access across the enterprise.

In other applications search engines typically provide a source of indexed documents from the Internet or an intranet that can be rapidly scanned in response to a search query submitted by a user. As the number of documents accessible via an enterprise intranet or the Internet grows the number of documents that match a particular query becomes unmanageable. Previous approaches for prioritizing searches have involved keyword priorities and pairs of keywords leading to some limited search results improvement. However not every document matching the query is likely to be equally important from the user s perspective. As a result a user may still be overwhelmed by an enormous number of documents returned by a search engine unless the documents are ordered based on their relevance to the user s specific query and not merely limited to keywords or pairing of keywords.

Another problem is that differing deployments in a heterogeneous enterprise environment may want to emphasize different document attributes creating a difficult task for a user attempting to return results from such a document. Often the results of such a search will be that the desired document hit is at the end of several pages of results.

One way to order documents is to create a page rank algorithm. Many search engines also provide a relevance ranking which is a relative numerical estimate of the statistical likelihood that the material at a given URL will be of interest in comparison to other documents. Relevance rankings are often based on the number of times a keyword or search phrase appears in a document its placement in the document and the size of the document. However in the context of differing attributes for the same document in a heterogeneous enterprise environment such relevance ranking tools do not offer an end user the desired level of configurability and customization currently desired.

Ranking functions that rank documents according to their relevance to a given search query are known and while useful in some settings these functions do not allow a consistent user in a heterogeneous enterprise environment to personalize ranking results based on an end user set of preferences either globally or for a single instance. Therefore efforts continue in the art to develop ranking functions that provide better search results for a given search query compared to search results generated by search engines using known ranking functions. The ability to allow an enterprise end user to change ranking functions to customize the ranking of query results returned in heterogeneous enterprise environment to return personalized rankings of content for a single instance within the enterprise has remained unsolved.

Another way to improve query results is to utilize an applied ranking support vector machine SVM to change ranking functions. In applications related to Internet Web search for example ranking functions need to be changed frequently to handle search requirements. In enterprise search different deployments of search systems or different type of search corpora may require different ranking functions. A query relaxation process can improve query efficiency and generate a hit list with higher relevancy if a feature vector formation for an early ranking function is cheaper and an early feature vector and ranking function in combination actually generates more relevant hits. Where both of these conditions are met providing a query relaxation technique coupled with a machine learning ranking SVM method yields improved query results to an end user in a heterogeneous enterprise environment.

Therefore a simple intuitive and heuristic method to allow an end user to apply ranking SVM in query relaxation to meet global or single instance search requirements in a heterogeneous enterprise environment query is needed.

Systems and methods in accordance with various embodiments of the present invention provide for query relaxative ranking for support vector machines in order to provide more accurate and useful search results for a user client or application. Such an approach can comprise an enterprise wide system query execution based on a customer setting globally or in a single instance of a heterogeneous enterprise environment.

In one embodiment a set of ranked query item pairs is obtained each query item pair corresponding to a query and a hit document. Each query item further corresponds to a set of feature vectors including a set of features and corresponding feature weights. These feature weights can be set and or adjusted by a user client or application for example. A series of query relaxation operations or steps can be executed typically in sequence wherein each query relaxation operation extracts one of the set of feature vectors for an item pair and calculates a relevancy score using the extracted feature vector and a learned ranking function that is unique for that query relaxation operation or step. A hit list for a user query then is generated that contains hits from the executed query relaxation operations. In one embodiment the hit list includes any hits obtained from the sequence of query relaxation operations. In another embodiment the hit list only contains the most relevant hits from the operations.

The hit list is displayed to the user. The user can have the option of providing feedback on the hit list such as the actual perceived relevancy of items of the list to the user in regard to the submitted user query. This feedback then can be used to adjust the appropriate weighting functions and update the corresponding learned ranking function. The user can continue to provide feedback in order to further update the learned ranking function until a desired hit is displayed that is consistent with user search result preferences.

The ranked query item pairs can be obtained from across a heterogeneous enterprise network. The set of features can include an occurrence of a query term in metadata for a hit document occurrence of a query term in a document body and a document static rank. A query term can include for example a title keyword description or reference text. A static rank can include for example a page rank or a human generated document static rank. Execution of the series of query relaxation operations can be terminated when a result page is filled by the hit list or when every operation or step has been executed.

Reference to the remaining portions of the specification including the drawings and claims will realize other features and advantages of the present invention. Further features and advantages of the present invention as well as the structure and operation of various embodiments of the present invention are described in detail below with respect to the accompanying drawings. In the drawings like reference numbers indicate identical or functionally similar elements.

Systems and methods in accordance with various embodiments of the present invention overcome the aforementioned and other deficiencies in existing query and search system by providing for query relaxative ranking such as for support vector machines. Such an approach can comprise an enterprise wide system query execution based on a customer setting globally or in a single instance of a heterogeneous enterprise environment. As discussed above ranking functions in an enterprise search engine often need to be adjusted in order to handle various needs for different types of information and in Internet web searching ranking functions need to be changed frequently in order to handle search spam and other issues. In enterprise search different deployments of search systems or different types of search corpora may require different ranking functions. One way to adjust ranking functions is using machine learning methods to automatically train ranking functions so that existing ranking functions become more accurate over time and can still address various needs and security issues.

In one embodiment a Query Relaxative Ranking SVM QRRS system is provided for query execution based on a customer setting. Here a system is utilized to display query results to a user on a graphical client interface wherein a database repository is coupled to a server computer and configured in network communication with a client computer. The displayed query results are obtained by creating a list of document query pairs that are modeled as a combination function which utilizes ranking and learning functions.

The importance of various ranking factors may be defined by collecting user feedback to create a learning heuristic to decrease time between training and ranking learning. The ranking factors can specify document attributes such as document title document body document page rank etc. as in previous pure ranking algorithm and modified ranking algorithm approaches.

Ranking SVM treats the ranking function learning problem as a binary classification training problem. The input to the learning process is ranked item pairs. In a ranked pair if the first item is ranked higher than the second item this pair belongs to a first class. If the first item is ranked lower that the second item this pair belongs to a second class. The output then is a classification function that minimizes classification errors with a large margin. The classification function can be treated as a ranking function which evaluates the relevancy of a single item.

In a search engine QRRS system in accordance with one embodiment a ranked item can be modeled as a pair consisting of a query and a hit document. Only items that have the same query are ranked relative to one another. Each item in this approach is represented by a feature vector which lists features and corresponding feature weights. A feature can be any evidence that is used to determine the relevance of a document related to a given query. A feature can be an occurrence of query terms in document metadata such as title keyword description reference text etc. Also a feature can be an occurrence of query terms in the document body or in the document static ranks such as page rank human generated document static ranks etc. A ranking function accepts an item feature vector and produces relevancy scores for the item. The higher the score the higher this item will be ranked.

In one embodiment the evaluation of a ranking function consists of two steps. The first step involves extracting a feature vector of the item. The second step involves computing a relevancy score based on the corresponding input feature vector. The second step can finish after one or several operations in memory and feature vector formation can be accomplished by searching an inverted index. If the inverted index is too large to be stored in memory costly disk access is necessary. However query relaxation can solve this problem. Instead of forming a whole feature vector and using a single ranking function query relaxation methods can be used to form several feature vectors each of which corresponds to a ranking function.

Each relaxation step has one type of feature vector and a ranking function. In each step of query relaxation the feature vector is extracted and formed before the ranking function is evaluated. To produce the first of page of a search result which normally contains 10 hits in one embodiment query relaxation steps are executed one by one until the relaxation steps finish or the first result page is filled up. The union of hit lists from all relaxation steps should consist of all documents hit by the query for completeness. The query relaxation can improve query efficiency and generate hit lists with high relevancy if the following two features are satisfied. First the feature vector formation for the early ranking function is cheaper and second the early feature vector and ranking function in combination does generate higher relevant hits. These conditions can be satisfied simultaneously if some metadata is chosen as the feature for the early steps. The inverted index for those specific chosen metadata such as title reference text etc. can be of small size and therefore can be cached in memory for fast access. Documents that match query terms in those metadata are more relevant than in other metadata or body.

According to yet another aspect of the present invention a training item pair in ranking SVM can be represented by two feature vectors e.g. xand x. To introduce non linear kernels in Ranking SVM a generic mapping F x is applied to the feature vectors. When F x x the problem is reduced to a linear kernel case. The training process is the process to learn a ranking function in the form of wF x where w is the weight factor to be learned and is multiplied by each instance of F x as in w F x . In the linear kernel case w can be computed explicitly but in a non linear kernel case w normally is written into a linear combination of training vectors F x in order for the kernel trick to be applied. The classification problem is formed by the Ranking SVM as an optimization problem with some constraints.

By applying weighted factors to learn a ranking function a machine learning application is formed where the combination of training vectors F x allow data to be optimized with constraints. As a result query document pairs are assigned a classification score where a higher score for a document means a higher ranked document. The user may specify how good of a fit exists between a given query and document. User feedback is collected by clicking on any document and noting how good of a fit exists measured by a relevancy score. The resulting ranking SVM application requires less user time than scoring each individual document because only the most relevant documents are selected from each returned results list.

In one embodiment the conventional binary SVM classification problem differs from the Ranking SVM system in that the single vector is replaced with a pair of vectors F x F x . The solution weight vector can be written in the form of training pairs. The ranking function w F x can also be written in the form of kernel k x x F x F x .

According to another aspect different groups of features are formed to apply Ranking SVM to query relaxation steps wherein each group of features corresponds to one relaxation step. Ranking function in each step is then trained separately according to different feature vectors formed by different feature groups.

In one embodiment a user issues a query on metadata only rather than on document contents. If enough hits are returned from the metadata the user may stop resulting in much faster query results returned. One benefit to this methodology is a dramatically improved response time. A user will input the feedback machine learning training of each ranking algorithm into each step. Further a different ranking SVM algorithm will be assigned for each relaxation step by splitting an early function vector from the feature input vector in each step.

According to another aspect new document query pairs may be weighted more heavily than old document query pairs. As a result a user may develop a method to tune learning algorithms more quickly by using feedback gathered in machine learning feature vector steps. The resulting learning heuristic allows a user to more efficiently collect feedback decreasing time between training and ranking learning by adjusting ranking algorithms in a different way.

The machine learning system processing engine includes a series of feature set sub queries and is in communication with a database repository . The feature set sub query and correspond to learning function steps and query relaxation steps. Overall the learning function steps feature set sub queries and training ranking algorithms comprise a machine learning system and related user feedback system described in greater detail below to allow a user to execute a new query which is shown to come separately but could come directly from the interface of the client . One important feature is the ability to separate a query relaxation component from a training ranking algorithm in order to improve efficiency by designing an early function step comprising metadata in each corresponding user defined attribute.

In one embodiment an extensible enterprise search mechanism provides for a method useful for crawling and searching of a variety of sources across an enterprise regardless of whether any of these sources conform to a conventional user role model. In a heterogeneous enterprise wide environment sources may represent the same document in differing ways to highlight a plurality of attributes leading to difficulties to rank results. Method begins at start . The system can first perform a document crawl . A user then may generate a search query to be executed the query being generated from user inputs. If end user QRRS is not to be applied to the query then the unranked search results can be displayed . If necessary the search parameters can be revised in a trial and error approach whereby the new results can be displayed and if the results are not what the user desired the parameters can be revised again .

If the end user QRRS is to be applied to the query then the revised customer setting learning system ranking algorithm can be displayed that can transform the user query to provide for dynamic querying whereby global setting learning system algorithms can be applied as well as single instance learning system algorithms as appropriate. These ranking SVM query relaxative algorithms provide for a more current and personalized result list to be displayed to the user than can be obtained for static queries.

When default ranking algorithms are utilized such as those found in a standard web browser unranked search results are presented to an end user. Unranked search results are further complicated when the same document may yield different results when the same document is searched in different applications a common problem in a heterogeneous enterprise environment. As a result the end user is forced to adjust keywords multiple times or search through long lists of unranked results to find the desired query search results. The resulting trial and error search methodology is inefficient costly and slow. However when the end user utilizes a ranking SVM query relaxative algorithms including a series of sub query combination step functions a result based on end user preferences is obtained from a heterogeneous enterprise environment. Further such results can be tuned and optimized by continually updating the learning system combination function to more accurately reflect user preferences. Also ranking SVM query relaxative algorithms results can be tuned and optimized for each single instance of query results displayed or via an administrator or user s global settings preferences.

In one aspect a client interface comprises a set of one or more pairs of document and queries is communicatively coupled to a data repository via a machine learning system processing engine. The machine learning system processing engine comprises a series of one or more learning function steps representing sub queries corresponding to each step necessary to create training algorithms for each step. A machine learning system processing engine may be tuned according to a set of end user preferences by splitting a set of document query pairs into sub queries for carefully defined feature sets. A new query may be defined based on the machine learning processing system feedback based on a correlation of a series of different algorithms for each step. Each step function comprises both a query relaxative component and a feature set sub query content ranking algorithm. In each step a query relaxation process is performed on the sub query related metadata prior to performing a sub query ranking algorithm on the document query pair data. In one method of retrieving search results from a corpus training data gathered from user defined feedback is utilized to revise document candidate pair lists. Each document candidate pair comprises a first and second data element term. Each data element has a label that classifies that data element at least a portion of such label which is metadata. A machine learning ranking model is developed to rank data elements candidate pair lists and revised candidate pair lists based on a computed relevancy score.

As discussed above in a binary classification training problem the input to the learning process includes ranked item pairs. In a ranked pair if the first item is ranked higher than the other this pair belongs to one class. If the first item is ranked lower this pair belongs to a second class. The output is a classification function that minimizes classification errors with a large margin to produce a revised document query pairs tuned list. The classification function can be treated as a ranking function which evaluates the relevancy of a single item. In a search engine ranking system a ranked item is a pair consisting of a query and a hit document. Only items that have the same query are ranked. Each item is represented by a feature vector which lists features and corresponding feature weights. A feature can be any evidence that is used to determine the relevance of a document related to a given query. In general a feature can be an occurrence of query terms in document metadata such as title keyword description reference text. Also a feature can be an occurrence of query terms in a document body or document static ranks. A ranking function accepts an item feature vector and produces a relevancy score for the item. The higher the score the higher this item will be ranked. As illustrated in the process of end user QRRS can be applied to a query such as by applying pure ranking functions or other modifications or by defining steps with individual learned ranking functions . Feature vectors can be extracted and formed for each sub query step item and a relevancy score computed based on the corresponding input feature vector . An evaluation can be done as to whether the operations complete in memory . Also an inverted index can be searched to evaluate whether the results are too large for memory and if so a new feature vector step can be performed . If properly sized for memory the process can finish.

When a ranked item is modeled as a pair consisting of a query and a hit document only items that have the same query are ranked in one embodiment. Each item is represented by a feature vector which lists features and corresponding feature weights to allow an end user to tune a ranking function based on coupling a query relaxation method with a ranking SVM application discussed above. The end user can determine the best fit between the initial list of document query hits and a revised list produced from a trained learning system machine learning function. A feature itself can be any attribute of a document or evidence that is used to determine the relevance of a document related to a given query. More specifically a feature can be an occurrence of query terms in document metadata such as title keyword description reference text etc. Also a feature can be an occurrence of query terms in the document body or in the document static ranks such as page rank human generated document static ranks etc. A ranking function accepts an item feature vector and produces relevancy scores for the item. The higher the score the higher this item will be ranked. As a result of revised rankings a revised pairs list will be stored in the data repository and displayed to an end user upon request.

In accordance with one embodiment to apply Ranking SVM to query relaxation steps different groups of features are formed that each correspond to one relaxation step. The ranking function in each step is then trained separately according to different feature vectors formed by different feature groups. As shown in where metadata is chosen for the early feature vectors and performed prior to the content ranking functions query efficiency is improved and response time is lowered.

In the process of the learning system query efficiency improvement conditions are determined and the learning system combined steps are performed wherein a set of relaxation steps can be performed each utilizing a metadata early function feature vector step and a ranking function step after the metadata steps. As illustrated in the exemplary process of a query efficient design improvement is implemented wherein an evaluation is made as to whether the early metadata function is cheaper than the ranking functions as well as whether the combination function is more relevant . Depending upon the evaluation the metadata can be assigned as a feature step for the early steps and if the inverted index is of a small size an evaluation is made as to whether documents matching query terms in the metadata are more relevant .

A feature set can be used to search content. However the content will not be searched if enough hits to fill the first page occur on the basis of the metadata search. As a result the cost and query response time is dramatically improved. Based on the attribute weights of the defined steps and query a single instance combination machine learning algorithm function executed by an appropriate engine communicatively coupled to a query relaxation and execution engines will produce the relevant value for each document in accordance with the end user preferences and personalization configurations using template interpreter and query constructor to be delivered via a server computer communicatively coupled to a heterogeneous enterprise environment. An end user of the search system may subscribe to a template in the query application interface by providing their own personalized feedback and preferences to the returned document query pairs for the single instance of the query communicated to the enterprise environment.

A database server search mechanism and client interface thus comprise a search system including a query relaxation engine a learning system engine and a query execution engine. The query relaxation engine further comprises a template interpreter and a query constructor wherein the query constructor executes a series of sub query steps including a first step and one or more subsequent content steps. The first step will search only document query pairs including metadata. In an exemplary embodiment a user of client specifies a search term value or query pair values referred to as search criteria in the form of rules which are interpreted by a rule interpreter and translated into another format. For example a user might provide a set of search rules such as search terms query pairs AND OR which specifies search criteria and an order in which to execute related sub queries. Upon receiving a set of rules rule interpreter constructs a query template based on the set of rules. According to one embodiment the query template is in the form of a template. According to one embodiment the query template is in the form of a rewrite template described below. The query template represents search criteria and an order in which sub queries associated with the search criteria are to be executed. In another embodiment rule interpreter generates a relaxation query based on the rules received for submission to the database server. The relaxation query includes search criteria and an order in which constituent sub queries associated with the search criteria to be executed. Rule interpreter or other modules within search mechanism may be configured to provide other functionality to make users interaction with the database server user friendly.

According to another aspect the inverted index will become effective only when the inverted index size is small enough fast access memory storage in cache. For example the inverted index metadata is produced after a user selects an attribute field corresponding to the first step in a content training ranking factor. By searching the inverted index metadata for all user defined sub queries corresponding to a particular sub query step document attribute query response time is significantly improved because the search mechanism may not need to actually search the content training ranking SVM data.

According to another aspect of the present invention the training ranking function output is a classification function that minimizes classification errors with a large margin. The classification function is treated as a training ranking function which evaluates the relevancy of a single sub query item.

As discussed above such functionality can be used advantageously with a secure enterprise search SES system. An exemplary SES system can utilize a query layer and Java component to drive a crawler component to crawl enterprise applications documents and objects as illustrated in . A text index can then be stored in a database with results of the crawl. In one embodiment a database application accepts documents and generates the lists and other elements useful for text searching. An API allows a user to submit queries such as text queries to search documents based on for example keywords.

A query layer can be configured to receive queries from users applications entities etc. These can be any appropriate queries such as simple text queries entered through a search box or advanced queries. The query layer can convert a user query into the appropriate text queries making sure security authorization authentication and other aspects are addressed such that the results are returned to the user based on what the user is allowed to access across the enterprise. This approach can be referred to as secure enterprise search as an Internet search or other such searches typically are done only for public documents using more rigid queries. SES can also allow for searching of public documents but when accessing secure content SES can ensure that only authorized persons are able to retrieve that content.

In most embodiments the system includes some type of network . The network can be any type of network familiar to those skilled in the art that can support data communications using any of a variety of commercially available protocols including without limitation TCP IP SNA IPX AppleTalk and the like. Merely by way of example the network can be a local area network LAN such as an Ethernet network a Token Ring network and or the like a wide area network a virtual network including without limitation a virtual private network VPN the Internet an intranet an extranet a public switched telephone network PSTN an infra red network a wireless network e.g. a network operating under any of the IEEE 802.11 suite of protocols GRPS GSM UMTS EDGE 2G 2.5G 3G 4G Wimax WiFi CDMA 2000 WCDMA the Bluetooth protocol known in the art and or any other wireless protocol and or any combination of these and or other networks.

The system may also include one or more server computers which can be general purpose computers specialized server computers including merely by way of example PC servers UNIX servers mid range servers mainframe computers rack mounted servers etc. server farms server clusters or any other appropriate arrangement and or combination. One or more of the servers e.g. may be dedicated to running applications such as a business application a Web server application server etc. Such servers may be used to process requests from user computers . The applications can also include any number of applications for controlling access to resources of the servers .

The Web server can be running an operating system including any of those discussed above as well as any commercially available server operating systems. The Web server can also run any of a variety of server applications and or mid tier applications including HTTP servers FTP servers CGI servers database servers Java servers business applications and the like. The server s also may be one or more computers which can be capable of executing programs or scripts in response to the user computers . As one example a server may execute one or more Web applications. The Web application may be implemented as one or more scripts or programs written in any programming language such as Java C C or C and or any scripting language such as Perl Python or TCL as well as combinations of any programming scripting languages. The server s may also include database servers including without limitation those commercially available from Oracle Microsoft Sybase IBM and the like which can process requests from database clients running on a user computer .

The system may also include one or more databases . The database s may reside in a variety of locations. By way of example a database may reside on a storage medium local to and or resident in one or more of the computers . Alternatively it may be remote from any or all of the computers and or in communication e.g. via the network with one or more of these. In a particular set of embodiments the database may reside in a storage area network SAN familiar to those skilled in the art. Similarly any necessary files for performing the functions attributed to the computers may be stored locally on the respective computer and or remotely as appropriate. In one set of embodiments the database may be a relational database such as Oracle 10g that is adapted to store update and retrieve data in response to SQL formatted commands.

The computer system may additionally include a computer readable storage media reader a communications system e.g. a modem a network card wireless or wired an infra red communication device etc. and working memory which may include RAM and ROM devices as described above. In some embodiments the computer system may also include a processing acceleration unit which can include a digital signal processor DSP a special purpose processor and or the like.

The computer readable storage media reader can further be connected to a computer readable storage medium together and optionally in combination with storage device s comprehensively representing remote local fixed and or removable storage devices plus storage media for temporarily and or more permanently containing storing transmitting and retrieving computer readable information. The communications system may permit data to be exchanged with the network and or any other computer described above with respect to the system .

The computer system may also comprise software elements shown as being currently located within a working memory including an operating system and or other code such as an application program which may be a client application Web browser mid tier application RDBMS etc. . It should be appreciated that alternate embodiments of a computer system may have numerous variations from that described above. For example customized hardware might also be used and or particular elements might be implemented in hardware software including portable software such as applets or both. Further connection to other computing devices such as network input output devices may be employed.

Storage media and computer readable media for containing code or portions of code can include any appropriate media known or used in the art including storage media and communication media such as but not limited to volatile and non volatile removable and non removable media implemented in any method or technology for storage and or transmission of information such as computer readable instructions data structures program modules or other data including RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disk DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices data signals data transmissions or any other medium which can be used to store or transmit the desired information and which can be accessed by the computer. Based on the disclosure and teachings provided herein a person of ordinary skill in the art will appreciate other ways and or methods to implement the various embodiments.

While the invention has been described by way of example and in terms of the specific embodiments it is to be understood that the invention is not limited to the disclosed embodiments. To the contrary it is intended to cover various modifications and similar arrangements as would be apparent to those skilled in the art. Therefore the scope of the appended claims should be accorded the broadest interpretation so as to encompass all such modifications and similar arrangements.

