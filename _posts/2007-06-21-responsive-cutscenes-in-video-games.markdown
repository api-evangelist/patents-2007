---

title: Responsive cutscenes in video games
abstract: A determination is made that a player's avatar has performed an action while an audio signal representing a narrative of a non-player character is being produced. The action is mapped to an impression, which is mapped to a response. The audio signal is stopped before it is completed and the response is played by providing audio for the non-player character and/or animating the non-player character. After the response is played, steps ensure that critical information in the narrative has been provided to the player.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08622831&OS=08622831&RS=08622831
owner: 
number: 08622831
owner_city: 
owner_country: 
publication_date: 20070621
---
Video games typically include an avatar which is a character or object in the game that is controlled by a player and non player characters which are controlled by the game. In many games the player s avatar is able to interact with non player characters such that the non player characters will respond to actions taken by the player s avatar. For example if a player s avatar attacks a non character player the non character player may counter attack or run away.

Within video games it is common for developers to include audio and video segments known as cutscenes that provide narrative information such as a story line for the game contextual information for playing the game or instructions for proceeding forward in the game. Traditionally such cut scenes interrupted the game and took away the player s control of their avatar. Such cut scenes provide a movie like experience where the player simply watches the action in the cut scene. Some video games have allowed the player to continue to control their avatar during the cut scene. However actions taken by the avatar during such cut scenes are ignored by the non player characters in the cut scene. Thus the non player characters do not interact with the player s avatar during the cut scene and seem to become robotic.

The discussion above is merely provided for general background information and is not intended to be used as an aid in determining the scope of the claimed subject matter.

A determination is made that a player s avatar has performed an action while an audio signal representing a narrative of a non player character is being produced. The action is mapped to an impression which is mapped to a response. The audio signal is stopped before it is completed and the response is played by providing audio for the non player character and or animating the non player character. After the response is played steps ensure that critical information in the narrative has been provided to the player.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. The claimed subject matter is not limited to implementations that solve any or all disadvantages noted in the background.

As shown in gaming and media system includes a game and media console hereinafter console . Console is configured to accommodate one or more wireless controllers as represented by controllers and . A command button on console is used create a new wireless connection between on of the controllers and the console . Console is equipped with an internal hard disk drive not shown and a media drive that supports various forms of portable storage media as represented by optical storage disc . Examples of suitable portable storage media include DVD CD ROM game discs and so forth. Console also includes two memory unit card receptacles and for receiving removable flash type memory units .

Console also includes an optical port for communicating wirelessly with one or more devices and two USB Universal Serial Bus ports and to support a wired connection for additional controllers or other peripherals. In some implementations the number and arrangement of additional ports may be modified. A power button and an eject button are also positioned on the front face of game console . Power button is selected to apply power to the game console and can also provide access to other features and controls and eject button alternately opens and closes the tray of a portable media drive to enable insertion and extraction of a storage disc .

Console connects to a television or other display not shown via A V interfacing cables . In one implementation console is equipped with a dedicated A V port not shown configured for content secured digital communication using A V cables e.g. A V cables suitable for coupling to a High Definition Multimedia Interface HDMI port on a high definition monitor or other display device . A power cable provides power to the game console. Console may be further configured with broadband capabilities as represented by a cable or modem connector to facilitate access to a network such as the Internet.

Each controller is coupled to console via a wired or wireless interface. In the illustrated implementation the controllers are USB compatible and are coupled to console via a wireless or USB port . Console may be equipped with any of a wide variety of user interaction mechanisms. In an example illustrated in each controller is equipped with two thumbsticks and a D pad buttons User Guide button and two triggers . By pressing and holding User Guide button a user is able to power up or power down console . By pressing and releasing User Guide button a user is able to cause a User Guide Heads Up Display HUD user interface to appear over the current graphics displayed on monitor . The controllers described above are merely representative and other known gaming controllers may be substituted for or added to those shown in .

Controllers each provide a socket for a plug of a headset . Audio data is sent through the controller to a speaker in headset to allow sound to be played for a specific player wearing headset . Headset also includes a microphone that detects speech from the player and conveys an electrical signal to the controller representative of the speech. Controller then transmits a digital signal representative of the speech to console . Audio signals may also be provided to a speaker in monitor or to separate speakers connected to console .

In one implementation not shown a memory unit MU may also be inserted into one of controllers and to provide additional and portable storage. Portable MUs enable users to store game parameters and entire games for use when playing on other consoles. In this implementation each console is configured to accommodate two MUs although more or less than two MUs may also be employed.

Gaming and media system is generally configured for playing games stored on a memory medium as well as for downloading and playing games and reproducing pre recorded music and videos from both electronic and hard media sources. With the different storage offerings titles can be played from the hard disk drive from optical disk media e.g. from an online source from a peripheral storage device connected to USB connections or from MU .

CPU memory controller and various memory devices are interconnected via one or more buses not shown . The details of the bus that is used in this implementation are not particularly relevant to understanding the subject matter of interest being discussed herein. However it will be understood that such a bus might include one or more of serial and parallel buses a memory bus a peripheral bus and a processor or local bus using any of a variety of bus architectures. By way of example such architectures can include an Industry Standard Architecture ISA bus a Micro Channel Architecture MCA bus an Enhanced ISA EISA bus a Video Electronics Standards Association VESA local bus and a Peripheral Component Interconnects PCI bus also known as a Mezzanine bus.

In one implementation CPU memory controller ROM and RAM are integrated onto a common module . In this implementation ROM is configured as a flash ROM that is connected to memory controller via a Peripheral Component Interconnect PCI bus and a ROM bus neither of which are shown . RAM is configured as multiple Double Data Rate Synchronous Dynamic RAM DDR SDRAM modules that are independently controlled by memory controller via separate buses not shown . Hard disk drive and media drive are shown connected to the memory controller via the PCI bus and an AT Attachment ATA bus . However in other implementations dedicated data bus structures of different types can also be applied in the alternative.

In some embodiments ROM contains an operating system kernel that controls the basic operations of the console and that exposes a collection of Application Programming Interfaces that can be called by games and other applications to perform certain functions and to obtain certain data.

A three dimensional graphics processing unit and a video encoder form a video processing pipeline for high speed and high resolution e.g. High Definition graphics processing. Data are carried from graphics processing unit to video encoder via a digital video bus not shown . An audio processing unit and an audio codec coder decoder form a corresponding audio processing pipeline for multi channel audio processing of various digital audio formats. Audio data are carried between audio processing unit and audio codec via a communication link not shown . The video and audio processing pipelines output data to an A V audio video port for transmission to a television or other display containing one or more speakers. Some audio data formed by audio processing unit and audio codec is also directed to one or more headsets through controllers . In the illustrated implementation video and audio processing components are mounted on module .

In the implementation depicted in console includes a controller support subassembly for supporting up to four controllers . The controller support subassembly includes any hardware and software components needed to support wired and wireless operation with an external control device such as for example a media and game controller. A front panel I O subassembly supports the multiple functionalities of power button the eject button as well as any LEDs light emitting diodes or other indicators exposed on the outer surface of console . Subassemblies and are in communication with module via one or more cable assemblies . In other implementations console can include additional controller subassemblies. The illustrated implementation also shows an optical I O interface that is configured to send and receive signals that can be communicated to module .

MUs and are illustrated as being connectable to MU ports A and B respectively. Additional MUs e.g. MUs are illustrated as being connectable to controller i.e. two MUs for each controller. Each MU offers additional storage on which games game parameters and other data may be stored. In some implementations the other data can include any of a digital game component an executable gaming application an instruction set for expanding a gaming application and a media file. When inserted into console or a controller MU can be accessed by memory controller .

A system power supply module provides power to the components of gaming system . A fan cools the circuitry within console .

Under some embodiments an application comprising machine instructions is stored on hard disk drive . Application provides a collection of user interfaces that are associated with console instead of with an individual game. The user interfaces allow the user to select system settings for console access media attached to console view information about games and utilize services provided by a server that is connected to console through a network connection. When console is powered on various portions of application are loaded into RAM and or caches and for execution on CPU . Although application is shown as being stored on hard disk drive in alternative embodiments application is stored in ROM with the operating system kernel.

Gaming system may be operated as a standalone system by simply connecting the system to monitor a television a video projector or other display device. In this standalone mode gaming system enables one or more players to play games or enjoy digital media e.g. by watching movies or listening to music. However with the integration of broadband connectivity made available through network interface gaming system may further be operated as a participant in a larger network gaming community allowing among other things multi player gaming.

The console described in is just one example of a gaming machine that can be used with various embodiments described herein. Other gaming machines such as personal computers may be used instead of the gaming console of .

At step of a player triggers the cutscene. As shown in the top perspective view of a gaming environment in a player can trigger a cutscene under some embodiments by placing their avatar within a circumference of a non player character . In other embodiments the player can trigger the cutscene by placing the player s avatar within a same room as a non player character as shown in the top perspective view of a gaming environment in . Other techniques for triggering a cutscene include a player completing one or more tasks or selecting to initiate a cutscene using one or more control buttons.

After the player triggers the cutscene cutscene control of is started and retrieves a first clip of the cutscene at step of .

Under one embodiment each cutscene is divided into a plurality of clips. Each clip includes an audio signal representing speech from a non player character as well as animation descriptors that describe how the non player character should be animated during the playing of the clip. Under one embodiment each clip is a WAV file with a header that describes the animation for the non player character.

In a plurality of cutscenes is shown including cutscene and cutscene . Each of the cutscenes includes a plurality of clips. For example cutscene includes clips and and cutscene includes clips and . In addition each cutscene includes a summary clip such as summary clip of cutscene and summary clip of cutscene . These summary clips are described further below.

As noted below dividing each cutscene into clips allows the cutscene to be broken into natural breakpoints where the cutscene can be restarted if a cutscene clip is interrupted by an action by the player s avatar. By restarting the cutscene at the beginning of the clip that was interrupted a more natural restart of the cutscene is provided and helps to make the non player character appear more realistic.

At step of an audio signal and non player character animation are produced based on the selected cutscene clip. Under one embodiment to produce the animation cut scene control provides the animation information for the non player character to a vertex data generation unit . Vertex data generation unit uses the animation information and a graphical model of the non player character to generate a set of vertices that describe polygons. The vertices are provided to 3D graphics processing unit which uses the vertices to render polygons representing the non player character in the graphical three dimensional gaming environment. The rendered polygons are transmitted through video encoder and A V port of to be displayed on an attached display screen. The audio signal for the non player character is provided to audio processing unit which then generates an audio signal through audio code and A V port of .

At step cutscene control examines player state data to determine if the player s avatar has performed an action. Examples of actions include attacking the non player character moving a threshold distance away from the non player character or performing other actions supported by the game. Under one embodiment these other actions include things such as belching performing a silly dance flexing an arm performing a rude hand gesture and faking an attack on the non player character. Such actions are referred to herein as expressions.

Under one embodiment a player may select an action from a list of actions listed in a menu. provides an example of a screen shot showing a possible menu of actions that the player s avatar may perform. The player causes the menu to be displayed by either selecting an icon on the display or using one or more controls on the controller. Once the menu has been displayed the player may select one of the actions from the menu using the controller. In other embodiments actions may be mapped to one or more controls on the controller so that the player does not have to access the menu.

Under some embodiments the action may include the player s avatar moving more than a threshold distance away from the non player character. For example in the player s avatar may move outside of circumference and in the player s avatar may move outside of room . In both situations such movement will be interpreted as an action by cut scene control .

If cut scene control determines that the player s avatar has not performed an action at step it determines if the end of the current cutscene clip has been reached at step . If the end of the current cutscene clip has not been reached cutscene control continues producing the audio signal and non player character animation by returning to step . Steps and continue in a loop until an avatar action is received at step or the end of a cutscene clip is received at step . If the end of the cut scene clip is reached at step the process continues at step where cutscene control determines if there is another clip for the cutscene. If there is another clip for the cutscene the next clip is retrieved at step and the audio signal and non player character animation found in the clip is used to animate the non player character and produce an audio signal for the non player character.

If cut scene control determines that the player s avatar has performed an action at step it maps the action to an impression at step using an action to impression mapping in an action to response database . An impression is the way that a non player character will interpret the action. For example a non player character may interpret an action as being scary insulting impolite funny friendly aggressive inattentive or impatient each of which would be a possible impression. At step cutscene control maps the impression to a response using impression to response mapping of action to response database . By performing two mapping functions one from an action to an impression and another from an impression to a response embodiments described herein allow cutscene responses to be designed without needing to know all possible actions that may be performed. Instead a limited number of impressions can be specified and cutscene responses can be produced for those impressions. This also allows actions to be added later without affecting the currently produced responses. Multiple actions may be mapped to a single impression in action to impression mapping and multiple impressions may be mapped to a single response in impression to response mapping .

At step cutscene control determines if a response has been identified through the impression to response mapping in step . Under some embodiments an impression may map to no response so that the non player character will ignore the action taken by the player s avatar. If no response is to be provided at step the process returns to step where the audio signal and non player character animation continues for the cutscene clip. Note that although steps and appear to occur after step in the flow diagram of during steps and the audio signal and animation of the current cutscene clip continues to be output by cutscene control . Thus there is no interruption in the cutscene while these steps are being performed.

If the mapping of step identifies a response the response is retrieved from a set of stored responses which include cut scene responses and for example. The cut scene responses include animation information for movement of the non player character and or an audio signal containing dialog that represent the non player characters response to the action of the player s avatar. In some embodiments the cut scene responses also include scripting hooks that indicate directorial types of information such as directions to the non player character to move to a particular location movement of the camera lighting effects background music and sounds and the like.

At step the response is examined to determine if the response is a microreaction. Such information can be stored in a header of the response or can be stored in action to response database . A microreaction is a small animation or small change in tone of the audio signal that does not interrupt the audio signal and non player character animation of the cutscene clip but instead slightly modifies it as it continues. If the response is a microreaction at step the microreaction is combined or integrated with the cut scene clip at step . This can involve changing the tone of the audio signal of the cut scene by either raising or lowering the pitch or by adding additional animation features to the cutscene animation. If an animation is added the audio signal of the cut scene continues without interruption as the microreaction animation is integrated with the cut scene animation.

For example in the cutscene clip includes an animation in which the non player character points to his left using his left arm . Normally during this animation the non player character s eyebrows would remain unchanged. However based on a microreaction response to an avatar action the right eyebrow of the non player character is raised relative to the left eyebrow to convey that the non player character has detected the action taken by the avatar and that the impression left with the non player character is that the avatar is doing something slightly insulting.

If the response found during mapping step is more than a microreaction at step cutscene control interrupts the cut scene clip and plays the cut scene response. Under one embodiment the cut scene response is played by providing the animation information to vertex data generation unit which uses the animation information and NPC graphics model to generate sets of vertices representing the movement of the non player character. Each set of vertices is provided to 3D graphics processing unit which uses the vertices to render an animated image of the non player character. The audio data associated with the response is provided to audio processing unit .

Under some embodiments a player is able to activate a summary clip of the cut scene by taking an action that conveys an impression of impatience. For example the player may select an action in which their avatar requests just the facts and this action will be mapped to an impatience impression. The impression to response mapping will in turn map the impatience impression to a summary response. Under one embodiment such summary clips are stored together with the other clips of the cut scene. In other embodiments the summary clips may be stored with the cut scene responses . The summary clip contains audio data and animation information that causes the non player character to summarize the critical information that was to be conveyed by the cutscene. In general cutscenes contain both critical information and stylistic information wherein the critical information is required for the player to advance through the game and the stylistic information is provided to convey an emotional or stylistic attribute to the game. Under one embodiment the summary clip strips out most of the stylistic information to provide just the critical information.

Since playing the summary clip ensures that the player has been given all of the critical information of the cut scene narrative once the summary clip has been played there is no need to continue with the cut scene.

As such at step cut scene control determines if the response is a summary response and ends the cutscene procedure at step if the response was a summary response.

If the response was not a summary response cut scene control examines player state to determine if the player is ready to continue with the cut scene clip at step . For example if the player s avatar has not returned to the non player character after moving away from the non player character cut scene control will determine that the player is not ready to continue with the cut scene clip. Under one embodiment cut scene control will set a timer if the player is not ready to continue with the cut scene. Cut scene control will then loop at step until the player is ready to continue with the cut scene or until the timer expires. If the timer expires cut scene control will unload the current cut scene such that the player will have to trigger the cut scene from the beginning again.

When the avatar is ready to continue with the cut scene clip for example by coming back to the non player character cut scene control retrieves and plays an audio stitch from a collection of audio stitches at step . Audio stitches include a collection of audio stitch files such as audio stitch files and . Each audio stitch file includes audio and animation data for the non player character that provides an audio and visual segue between the response and restarting the cut scene clip that was interrupted at step . Examples of audio stitches include as I was saying if you are finished and now then . Such audio stitches provide a smooth transition between a response and the resumption of the cut scene clip.

At step the cut scene clip that was interrupted at step is restarted from the beginning of the cut scene clip. By restarting the cut scene clip cut scene control ensures that the critical information of the cut scene narrative is provided to the player. In most cases restarting the cut scene clip will involve reproducing the audio signal and animations that were played when the cut scene clip was initially started. The process then returns to step to continue playing of the cutscene clip and to await further avatar actions.

In other embodiments instead of playing an audio stitch file and restarting the cut scene clip that was interrupted cut scene control will select an alternate cut scene clip to play instead of the interrupted cut scene clip. After playing the alternate cut scene clip the process continues at step by selecting a next cut scene clip of the cut scene to play. In such embodiments the alternate cut scene clip and the next cut scene clip are selected to insure that the critical information of the cut scene is still provided to the player.

The process of continues until a summary response is played there are no more cutscene clips at step or a timeout occurs during step .

In the discussion above the detection of an avatar action was shown as only occurring at step . However in other embodiments cutscene control is event driven such that at any point in the flow diagram of cut scene control may receive an indication from player state that the avatar has taken an action. Based on that action cutscene control may map the action to an impression map the impression to a cutscene response as shown at steps and and produce an animation and audio signal based on the new response. Thus in the process of playing one response cutscene control may interrupt that response to play a different response based on a new avatar action.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

