---

title: Handling of extra contexts for shader constants
abstract: The present invention provides a system for handling extra contexts for shader constants, and applications thereof. In an embodiment there is provided a computer-based method for executing a series of compute packets in an execution pipeline. The execution pipeline includes a first plurality of registers configured to store state-updates of a first type and a second plurality of registers configured to store state-updates of a second type. A first number of state-updates of the first type and a second number of state-updates of the second type are respectively identified and stored in the first and second plurality of registers. A compute packet is sent to the execution pipeline responsive to the first number and the second number. Then, the compute packet is executed by the execution pipeline.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08593465&OS=08593465&RS=08593465
owner: Advanced Micro Devices, Inc.
number: 08593465
owner_city: Sunnyvale
owner_country: US
publication_date: 20070613
---
A graphics processing unit GPU is a complex integrated circuit that is specially designed to perform graphics processing tasks. A GPU may for example execute graphics processing tasks required by an end user application such as a video game application. In such an example there are several layers of software between the end user application and the GPU. The end user application communicates with an application programming interface API . An API allows the end user application to output graphics data and commands in a standardized format rather than in a format that is dependent on the GPU. Several types of APIs are commercially available including DirectX developed by Microsoft Corp. and OpenGL developed by Silicon Graphics Inc. The API communicates with a driver. The driver translates standard code received from the API into a native format of instructions understood by the GPU. The driver is typically written by the manufacturer of the GPU. The GPU then executes the instructions from the driver.

Many GPUs use a technique known as pipelining to execute the instructions. Pipelining enables a GPU to work on different steps of an instruction at the same time and thereby take advantage of parallelism that exists among the steps needed to execute the instruction. As a result a GPU can execute more instructions in a shorter period of time. The video data output by the graphics pipeline are dependent on state packages i.e. context specific constants such as texture handles shader constants transform matrices etc. that are locally stored by the graphics pipeline. Because the context specific constants are locally maintained they can be quickly accessed by the graphics pipeline.

The number of state packages maintained by the graphics pipeline depends on the API to which the GPU is coupled. The state packages associated with conventional APIs can be stored in a relatively small number of registers such as eight registers. Unlike conventional APIs newer APIs such as DirectX 10 require a relatively large number of frequent context switches with respect to certain aspects of the pipeline. The number of state packages associated with these frequent context switches cannot be supported by the relatively small number of registers maintained by conventional graphics pipelines.

An obvious solution for handling the larger number of state packages associated with newer APIs is to simply increase the number of state packages supported by the graphics pipeline. However this solution would significantly increase die area because additional registers would be required to handle the additional state packages. In addition this solution could create timing issues because the graphics pipeline would stall if the number of state packages exceeds the storage capacity of the pipeline. Another obvious solution would be to attempt to compensate for the increased number of state packages using software. For example the driver or the end user application could attempt to re order work sent to the GPU to reduce the number of state changes increase work sent per state change . This solution however has at least two drawbacks. First this solution will only work with some workloads some inherently have too many state changes . Second it significantly increases the workload of the CPU to search and sort input transactions.

Given the foregoing what is needed is a system and applications thereof that efficiently handle extra contexts for shader constants.

The present invention provides a system for handling extra contexts for shader constants and applications thereof. In an embodiment there is provided a computer based method for executing a series of compute packets in an execution pipeline. The execution pipeline includes a first plurality of registers configured to store state updates of a first type and a second plurality of registers configured to store state updates of a second type. A first number of state updates of the first type and a second number of state updates of the second type are respectively identified and stored in the first and second plurality of registers. A compute packet is sent to the execution pipeline responsive to the first number and the second number. Then the compute packet is executed by the execution pipeline.

In accordance with another embodiment of the present invention there is provided a computer readable medium containing instructions for generating a processor which when executed are adapted to create the processor. The processor comprises an execution pipeline that includes a first plurality of registers configured to store state updates of a first type and a second plurality of registers configured to store state updates of a second type. The processor is adapted to identify a first number of state updates of the first type and a second number of state updates of the second type respectively stored in the first and second plurality of registers. Responsive to the first number and the second number a compute packet is sent to the execution pipeline. Then the compute packet is executed by the execution pipeline.

In accordance with a further embodiment of the present invention there is provided a processor for executing a series of compute packets. The processor comprises an execution pipeline and a scheduler. The execution pipeline includes a first plurality of registers configured to store state updates of a first type and a second plurality of registers configured to store state updates of a second type. Based on the state updates stored in the first and second plurality of registers the execution pipeline is configured to execute compute packets. The scheduler is configured i to identify a first number of state updates of the first type and a second number of state updates of the second type respectively stored in the first plurality of registers and the second plurality of registers and ii to send compute packets to the execution pipeline responsive to the first and second numbers.

Further features and advantages of the invention as well as the structure and operation of various embodiments of the invention are described in detail below with reference to the accompanying drawings. It is noted that the invention is not limited to the specific embodiments described herein. Such embodiments are presented herein for illustrative purposes only. Additional embodiments will be apparent to persons skilled in the relevant art s based on the teachings contained herein.

The features and advantages of the present invention will become more apparent from the detailed description set forth below when taken in conjunction with the drawings in which like reference characters identify corresponding elements throughout. In the drawings like reference numbers generally indicate identical functionally similar and or structurally similar elements. The drawing in which an element first appears is indicated by the leftmost digit s in the corresponding reference number.

The present invention provides a system for handling extra contexts for shader constants and applications thereof. In the detailed description that follows references to one embodiment an embodiment an example embodiment etc. indicate that the embodiment described may include a particular feature structure or characteristic but every embodiment may not necessarily include the particular feature structure or characteristic. Moreover such phrases are not necessarily referring to the same embodiment. Further when a particular feature structure or characteristic is described in connection with an embodiment it is submitted that it is within the knowledge of one skilled in the art to affect such feature structure or characteristic in connection with other embodiments whether or not explicitly described.

In accordance with an embodiment of the present invention a scheduler is configured to support state packages of a first type mini packages and state packages of a second type standard packages . Mini packages are stored in registers of an execution pipeline that hold a relatively small amount of data. These mini packages comprise frequently accessed or updated data such as shader constants and texture handles. In an embodiment the execution pipeline includes sixty four registers that store mini packages. The standard packages are stored in registers of the execution pipeline that hold a relatively large amount of data. These standard packages comprise infrequently accessed data. In an embodiment the execution pipeline includes eight registers that store standard packages. The scheduler decides whether to use a mini package or a standard package for each context switch. In an embodiment the scheduler identifies a state package as a mini package or a standard package based on a register address of the state package.

For illustrative purposes only and not limitation the present invention will be described herein in terms of a GPU. A person skill in the relevant art s will appreciate however that the present invention may be applied to other types of processors such as central processing units and coprocessors that divide input into alternating streams of state updates and compute packets. These other types of processors are contemplated within the spirit and scope of the present invention.

The streams of state updates to a graphics pipeline are stored in state registers of a GPU. Of the hundreds of state registers in the GPU a select few are updated much more often than any others. In accordance with an embodiment of the present invention the scheduler which receives this input maintains two sets of state pointers one for mini states which are stored in mini state registers and one for standard states which are stored in standard state registers . Whenever the update state package writes a mini state register the mini state pointer is incremented and a new mini state is allocated. The standard state pointer is only incremented if a standard state register is touched. When a draw call is received it is tagged with the two state pointers. Throughout the pipe these two pointers indicate which standard and or mini state registers should be used for this draw. In an embodiment there are sixty four mini state registers and eight standard state registers allowing mini states to be updated eight times as often as the standard states with little extra area and trivial extra bookkeeping.

When the draw completes the state packages allocated to that draw are deallocated from the registers standard mini or both . If an update state arrives at the scheduler and there are no more standard or mini state registers free the scheduler stalls until earlier draw calls finish and deallocate a state register.

A person skilled in the relevant art will appreciate that the embodiments described herein can be extended to more than two classes of state updates.

System further includes local memory and local memory . Local memory is coupled to GPU and also coupled to bus . Local memory is coupled to coprocessor and also coupled to bus . Local memories and are available to GPU and coprocessor respectively in order to provide faster access to certain data such as data that is frequently used than would be possible if the data were stored in system memory .

In an embodiment GPU and coprocessor decode instructions in parallel with CPU and execute only those instructions intended for them. In another embodiment CPU sends instructions intended for GPU and coprocessor to respective command buffers.

For example depicts a block diagram illustrating an embodiment in which CPU sends instructions intended for GPU to a command buffer . Command buffer may be located for example in system memory or may be a separate memory coupled to bus . As illustrated in GPU includes a scheduler and a graphics pipeline . Scheduler retrieves instructions from command buffer . Scheduler forwards the instructions to graphics pipeline responsive to the number of state registers available to be written as described in more detail below.

The execution of a draw call is dependent on all the state updates that were retrieved since a previous draw call. For example illustrates five commands that are included in the command stream 1 a first draw call 2 a first update state 3 a second update state 4 a second draw call and 5 a third update state. The second draw call is dependent on the first and second state updates because these are the state updates that were retrieved since the first draw call. As described in more detail below the state update packets are identified as belonging to one of two different classes such as mini updates packets and standard updates packets.

Scheduler includes logic a mini counter and a standard counter . Logic is configured to identify the state update packets as either mini update packets or standard update packets. In an embodiment the update packets comprise a register address that is to be written. In this embodiment logic identifies whether a state update packet is a mini update packet or a standard update packet based on whether the register address of the state update packet is within a given address range. For example if the register address of a state update is less than a first predetermined address A and greater than or equal to a second predetermined address B then the state update is identified as a mini state update whereas if the register address is not within the address range specified by A and B then the state update is identified as a standard update. This example is summarized as follows IF register address mini state update IF register address standard state update. It is to be appreciated however that other schemes for parsing state updates can be used without deviating from the spirit and scope of the present invention.

Mini counter keeps track of the number of mini state updates and standard counter keeps track of the number of standard updates respectively written to graphics pipeline . As described in more detail below the number of mini state updates written cannot exceed a first predetermined number such as sixty four and the number of standard updates cannot exceed a second predetermined number such as eight .

Graphics pipeline includes a plurality of stages such as stage A through stage N that execute varies aspects of a draw call as is well known to a person skilled in the relevant art s . The execution of the draw call is dependent on the mini states and standard states respectively stored in mini registers and standard registers . In accordance with an embodiment of the present invention the number of mini registers is greater than the number of standard registers . As a result mini states can be updated more frequently than standard states. In an embodiment there are sixty four mini registers and eight standard registers thereby allowing mini states to be updated eight times as often as standard states.

As mentioned above scheduler retrieves state updates and draw commands from command buffer and then sends them to graphics processor . An example manner in which state updates and draw commands are processed is described below with reference to respectively.

In a step logic determines whether the state update is a mini state or a standard state. As mentioned above this determination may be based on whether the register address of the state update is within a given address range.

If logic determines that the state update is not a mini state then method proceeds to a step . In step scheduler determines whether standard counter is less than the number of standard registers max included in graphics pipeline . If it is standard counter is incremented as illustrated in step and the state update is written to one of standard registers as illustrated in step .

If however scheduler determines that standard counter is not less than the number of standard registers in step then method stalls as illustrated in step . If method stalls scheduler must wait until an earlier issued draw command finishes and deallocates a standard state as described in more detail with reference to .

If in step logic determines that the state update is a mini state then method proceeds to a step . In step scheduler determines whether mini counter is less than the number of mini registers max included in graphics pipeline . If it is mini counter is incremented as illustrated in step and the state update is written to one of mini registers as illustrated in step .

If however scheduler determines that mini counter is not less than the number of mini registers in step then method stalls as illustrated in step . If method stalls scheduler must wait until an earlier issued draw command finishes and deallocates a mini state as described in more detail with reference to .

In a step the draw call is tagged with state pointers corresponding to all state updates both mini updates and standard updates that were retrieved since the previous draw call was retrieved. Then in a step the draw call is sent through graphics pipeline . Throughout stages of graphics pipeline the state pointers indicate which mini registers and or standard registers should be used during the execution of the draw call.

Upon completion of the draw call the state packages allocated to the draw call are deallocated as illustrated in . In addition mini counter and or standard counter are decremented in accordance with the number of mini state packages and standard state packages that are deallocated.

In addition to hardware implementations of GPU such GPUs may also be embodied in software disposed for example in a computer usable e.g. readable medium configured to store the software e.g. a computer readable program code . The program code causes the enablement of embodiments of the present invention including the following embodiments i the functions of the systems and techniques disclosed herein such as writing state updates as described with reference to and or executing draw commands as described with reference to ii the fabrication of the systems and techniques disclosed herein such as the fabrication of GPU or iii a combination of the functions and fabrication of the systems and techniques disclosed herein.

For example this can be accomplished through the use of general programming languages such as C or C hardware description languages HDL including Verilog HDL VHDL Altera HDL AHDL and so on or other available programming and or schematic capture tools such as circuit capture tools . The program code can be disposed in any known computer usable medium including semiconductor magnetic disk optical disk such as CD ROM DVD ROM and as a computer data signal embodied in a computer usable e.g. readable transmission medium such as a carrier wave or any other medium including digital optical or analog based medium . As such the code can be transmitted over communication networks including the Internet and internets. It is understood that the functions accomplished and or structure provided by the systems and techniques described above can be represented in a core such as a GPU core that is embodied in program code and may be transformed to hardware as part of the production of integrated circuits.

It is to be appreciated that the Detailed Description section and not the Summary and Abstract sections is intended to be used to interpret the claims. The Summary and Abstract sections may set forth one or more but not all exemplary embodiments of the present invention as contemplated by the inventor s and thus are not intended to limit the present invention and the appended claims in any way.

