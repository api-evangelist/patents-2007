---

title: Method, network and computer program for processing a content request
abstract: The embodiments described herein provide a method, program and computing network for processing a content request received via a computing network. The method comprises the steps of receiving an incoming request for content from a remote computing device, determining the content type requested by the incoming request and delivering the request to one of a plurality of servers according to the determined content request type.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08898331&OS=08898331&RS=08898331
owner: Hewlett-Packard Development Company, L.P.
number: 08898331
owner_city: Houston
owner_country: US
publication_date: 20070913
---
There is an increasing need to deliver large amounts of data across both private and public networks. This is particularly the case for delivery of data over the Internet the largest single network in the world. Systems which are arranged to serve a large amount of data to a large amount of users require high availability high scalability and robust load management in order to meet high user demands. For example one data protocol commonly used to send data between computing systems is the Hypertext Transfer Protocol HTTP . Systems utilising HTTP are generally termed web class systems as HTTP is one of the principal protocols utilised to deliver a number of services colloquially known as web services. Other protocols are also used to deliver data between computing systems. Examples of data transfer i.e. application layer protocols include File Transfer Protocol FTP Real time Streaming Protocol RTSP and Stream Control Transmission Protocol SCTP .

While web scale systems vary greatly in functionality with applications ranging from search engines to media sites many content hosting web sites such as online stock trading news sites movie booking sites etc. exhibit similar fundamental characteristics. That is all of these systems are required to service a large amount of users. Moreover the working set of content on a web server e.g. the results of common searches frequently accessed videos frequently accessed web pages commonly fits within the collective memory cache of the servers which house and host the content. Therefore the traditional bottleneck of a web based system is not the disk access speed or CPU processing ability of the system but the ability of the system to handle and process web server requests.

There is described herein a system method and computer program for processing a content request received via a computing network.

In one embodiment there is provided a method for processing a content request received via a computing network comprising the steps of receiving an incoming request for content from a remote computing device determining the content type requested by the incoming request and delivering the request to one of a plurality of servers according to the determined content request type.

In another embodiment there is provided a computing network comprising a plurality of servers wherein each of the plurality of servers is arranged to receive an incoming request for content from a remote computing device and a processing arrangement configured to determine the content type requested and deliver the request to one of plurality of servers according to the content type request.

In another embodiment there is provided a program for processing incoming content requests in a programmable device and comprising at least one instruction which when implemented on a readable medium of the programmable device causes the programmable device to implement the steps of receiving an incoming request for content from a remote computing device determining the content type requested by the incoming request and delivering the request to one of a plurality of servers according to the determined content request type.

In more detail the embodiment described herein describes a content based Ethernet switching method and software application where the decision to switch a request to a particular server in a plurality of inter related servers is based on the content being sought by the request.

A system in accordance with an embodiment of the invention may be a computing network such as the exemplary network illustrated in . In one embodiment the computing network comprises a server farm including a plurality of servers etc. connected through a switching infrastructure including a plurality of switches arranged in a tree like structure etc. such that the switching infrastructure may switch incoming requests to a relevant server in the server farm . Incoming requests are received from clients via a network in the form of the Internet. Clients are in the form of personal computing devices comprising standard hardware and software for communicating with the server farm . The clients communicate with the server farm through the switching infrastructure using the Transmission Control Protocol Internet Protocol TCP IP suite of protocols which are used in the embodiment described herein to send HTTP requests from the clients to the server farm . The switching infrastructure is capable of Media Access Control MAC address look ups and Virtual Local Area Network VLAN based switching.

With reference to there is shown a block diagram of the hardware and software of an example server in the server farm which in the embodiment disclosed herein is a HP UX rx5670 server available from the Hewlett Packard Company. The server runs an operating system in the form of a Linux operating system . It should be noted that although in this embodiment the server implements a Linux operating system other embodiments can include different operating systems such as for example the UNIX operating system. The Linux operating system includes a file system having software for controlling the transfer of data between the network Internet and hard disk . A buffer cache composed of part of memory is used as a buffer for data transfer. The buffer cache is also arranged to hold the contents of disk blocks for the purpose of reducing frequent high latency disk I Os.

The server further includes a number of processors in the form of two Intel Itanium 2 processors available from Intel Corporation of The United States of America coupled to a system bus . A memory controller cache is also coupled to the system bus and is arranged to interface the memory which is in the form of double data rate DDR SDRAM. Also provided is a graphics adapter for handling high speed graphic addressing and an ATA gigabyte hard disk which are connected to an I O bus bridge by way of an I O bus . The memory controller and I O bus bridge may be interconnected as shown in . The memory and hard disk are examples of processor readable storage media.

Connected to the I O bus are PCI bus bridges which provide an interface to devices connected to the server via PCI buses . A modem and network adapter are coupled to PCI bus . The network adapter is configured to allow the server to exchange data with clients using the TCP IP protocol. The server can interact with clients through a switch infrastructure . As will be appreciated by a person skilled in the art additional I O devices such as a CD ROM may be coupled to the server via I O busses . The example HP server utilizes the Linux Operating system including Linux Kernel v2.6 .

A series of HP ProCurve Series 2500 Networking switches are utilized for the switches which form switching infrastructure . The switches are arranged in a tree like structure such that requests received via the network can be switched to the correct server in the server farm . In the example of switch is termed the front end switch as it is the switch which initially receives a request from the network .

It will be understood that the network server farm switching infrastructure clients and network described above are exemplary only and variations and modifications to the network server farm switching infrastructure client devices and network are within the purview of a skilled addressee.

In the embodiment described herein clients use the HTTP protocol for retrieving documents files of interest. Prior to the HTTP request packet arriving at a server in the server farm a TCP connection needs to be established between the client and a website hosted on one of the servers etc. . In a situation where a large number of concurrent TCP connections are required a layer 7 content router not shown may be inserted into the front end of the network i.e. between the front end switch and the network . It will be understood that the use of TCP accelerator based layer 7 switches can be utilised to improve overall system throughput by providing wire speed TCP connection handling and optimized connection hand over.

Upon the receipt of HTTP packets which in turn are embedded into Ethernet packets from the client the front end switch i.e. the switch or switches that interface directly with the network applies a hash function on the URL portion of the HTTP packet. The application of a hash function transforms the URL portion of the HTTP packet into a 60 bit hash value that serves as an Object Identifier OID . The Object Identifier field includes two parts 

Based on the object identifier derived from the incoming URL the TCP connection is handed off by the switching infrastructure to one of the servers in the server farm . In other words the unique OID generated by a front end switch is embedded into the existing Ethernet header of the incoming packet and is used to switch the packet through the switching infrastructure to a relevant server.

The manner in which the hash identifier is used to switch the packet is now described in more detail. The Ethernet frame which propagates the request through the switching infrastructure is modified such that the destination MAC address field of the Ethernet frame is populated with the 48 bit C MAC identifier while the 12 bit VLAN identifier field is populated with the C VID identifier. As the object identifiers are not unique the packet is encapsulated into the Ethernet frame. This allows the Ethernet frame to be switched as it is passed from one switch to another.

For the C MAC and C VID identifiers to be meaningful each server etc. in the server farm must be allocated or identified by a unique C VID which equals the 12 bit prefix of the OID range. The manner in which C VID are allocated is arbitrary as chosen by a system administrator or by an algorithm. For example each C VID may be allocated equally amongst each server in the server farm or weighting factors may also be used.

Moreover on each switch of the network the ports of each switch are tagged with all server C VIDs that can be reached from that port. This is achieved through a protocol where each server propagates its C VID by sending a packet through the network. Each switch tags the port on which it receives the packet to that particular VLAN. Given that the network is organized as a tree with servers in the leaf nodes the requests are switched from the front end switch using a VLAN tag switching scheme where packets are switched on the C VID portion of the 60 bit hash value generated by the front end switch.

By iteratively broadcasting the packets on the output port tagged to the C VID at each switch from the root to the server the destination server is reached. This obviates the need for MAC look up based switching. However if such a scheme is used exclusively the identifiers of content objects are statically associated with particular servers and data cannot be moved dynamically between servers. This interferes with the ability of the server farm to load balance as servers with a lower load cannot receive and serve content which is not ascribed to them.

However dynamic load sharing is possible where each of the switches utilize MAC tables. Whenever a switch receives a packet with a source MAC address that is not recognised it maps that MAC address to the input port on which the packet was received. Subsequent packets destined to that particular MAC address are automatically sent out on that port alone thus preventing broadcasts.

Therefore MAC tables can be utilised to perform load balancing in the network. Combining VLAN tag switching with MAC table look ups allows for opportunistic tag switching . That is when content is moved to another server or the surrogate server for that content intends to serve requests the MAC tables of all switches in the path from the common ancestor of the default server all the way down to the surrogate server are populated with the C MAC object identifier and the MAC table entry can be used to switch the packet to the correct server. This allows a limited number of files to be served by surrogate servers in the system with the limit being a function of the MAC table size of the switches.

The protocol for content switching based on an example 60 bit object identifier is shown in . At step the URL encapsulated in a HTTP packet for example is received by the front end switch. The front end switch converts the URL to a 60 bit hash step containing 002 as the C VID and F2 34 56 AB CD EF as the C MAC. At step the hash is converted into binary and is compared to the MAC table at step to determine whether a match can be found. If at step a match is found the packet is switched step according to the C MAC in the MAC table. If however at step no match is found the packet is switched and according to the C VID value.

However in another example the file is switched to a new surrogate server which is on VLAN ID equal to 005 as shown in the . Thus all MAC tables of all switches in the path from the common ancestor of the default server to the surrogate server are populated with the C MAC entry F2 34 56 AB CD EF as shown in . This is achieved using a protocol that reprograms the MAC tables of all switches from the common ancestor down to the surrogate switch with the OID to port mappings.

In the example the surrogate server sends a packet through the network the packet having a VLAN ID equal to 005 and a MAC address equal to the value F2 34 56 AB CD EF. As the packet passes through the switch infrastructure the MAC address is filled into the MAC tables of each switch until the front end switch is reached. The algorithm that is implemented on each switch is given below.

Each switch repeats the switch side protocol thus populating the new mapping of the content to all switches on the path from the common ancestor switch to the new owner.

Since the fast path switching does not distinguish between content Ethernet frames and normal Ethernet frames conventional Ethernet packets destined to the host MAC address can be used to copy the contents of files to the new server. These conventional packets are tag switched to the new server and the receiver side stack determines whether the destination MAC was an object identifier or a MAC address. Object identifiers that conflict with server MAC addresses cannot be relocated to other servers and are pinned to the server with MAC address that match their object ID.

The server that hosts content consists of a full fledged networking stack that operates in promiscuous mode as the network ensures that all packets that reach the server are indeed destined to that server. Where requests arrive over TCP a kernel hook module in the server inspects incoming content Ethernet frames extracts the TCP session parameter and subsequently creates a TCP connection to handle the content flow. The packet is then delivered to the front end switch which can include acceleration hardware to translate the IP address of the server to that of the front end switch thus anonymizing the IP address of the server. The packet is subsequently routed out of the network and to the client.

Although not required the embodiments described with reference to can be implemented via an application programming interface API for use by a developer or can be implemented as code within another software application. Generally as software applications include routines programs objects components and data files that perform or assist in the performance of particular functions it will be understood that a software application may be distributed across a number of routines objects and components but achieve the same functionality as the embodiment and the broader invention claimed herein. Such variations and modifications would be within the purview of those skilled in the art.

The foregoing description of the exemplary embodiments is provided to enable any person skilled in the art to make or use the present invention. While the invention has been described with respect to particular illustrated embodiments various modifications to these embodiments will be readily apparent to those skilled in the art and the generic principles defined herein may be applied to other embodiments without departing from the spirit or scope of the invention. For example the embodiment described herein may be implemented in any one of a variety of web class systems that have significantly different business models business flow patterns and may be utilised with any suitable protocol.

It is therefore desired that the present embodiments be considered in all respects as illustrative and not restrictive. Accordingly the present invention is not intended to be limited to the embodiments described above but is accorded the wider scope consistent with the principles and novel features disclosed herein.

