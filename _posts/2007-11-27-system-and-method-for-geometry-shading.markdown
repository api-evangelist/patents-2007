---

title: System and method for geometry shading
abstract: One embodiment of the present invention sets forth a technique for more effectively utilizing graphics hardware by allowing the developer to exploit parallelism at the primitive-level. In this technique, an algorithm is analyzed to break the total work associated with processing one primitive into discrete portions of work. The results of this analysis are used to program a geometry shader group that includes multiple geometry shaders. Upon receiving a single input primitive, the geometry shader group launches multiple parallel threads, one thread in each geometry shader in the group corresponding to each discrete portion of work. As each thread completes, the output of the thread is stored in on-chip GPU memory for processing by the next stage in the graphics pipeline. Since the overall work associated with a given input primitive is distributed across multiple threads, the output of each thread is smaller and, thus, the total memory required to implement the algorithm is reduced.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08212825&OS=08212825&RS=08212825
owner: NVIDIA Corporation
number: 08212825
owner_city: Santa Clara
owner_country: US
publication_date: 20071127
---
The present invention relates generally to the field of graphics processing and more specifically to a system and method for geometry shading.

A typical computing system includes a central processing unit CPU a system memory a graphics processing unit GPU a GPU local memory a GPU on chip memory one or more display devices and one or more input devices. The CPU usually executes the overall structure of the software application and configures the GPU to perform specific tasks in the graphics pipeline the collection of processing steps performed to transform 3 D images into 2 D images . Some GPUs are capable of very high performance using a relatively large number of small parallel execution threads on dedicated programmable hardware processing units.

To fully realize the processing capabilities of advanced GPUs GPU functionality may be exposed to graphics application developers through an application programming interface API of calls and libraries. Among other things doing so enables graphics application developers to tailor their shading programs to optimize the way GPUs process graphics scenes and images. In some GPUs the API may allow the hardware processing units to be configured as geometry shading engines that include multiple geometry shaders operating in parallel.

Typically each geometry shader within a geometry shading engine is programmed to perform image rendering operations on a single input primitive group of vertices such as a point line or triangle to produce zero or more output primitives. Upon receiving an input primitive each geometry shader launches one execution thread. Since multiple geometry shaders may be executing in parallel the inputs and the outputs of the geometry shaders are stored in memory buffers to preserve the processing order of the primitives throughout the graphics pipeline. Typically at least part of the geometry shader data buffers is stored in GPU on chip memory. After all of the geometry shader threads across the different geometry shaders have completed the output buffers of the geometry shaders are drained serially to transmit the geometry data to the next stage in the graphics pipeline.

For example for use in cube map rendering a streaming multiprocessor that includes 32 streaming processors may be configured as a geometry shading engine that includes 32 parallel geometry shaders. If each of these geometry shaders receives an input triangle then each of these geometry shaders executes one thread that processes the 6 cube faces and emits up to 6 output triangles one for each face of the cube. In this case the memory allocated to buffer the inputs of the geometry shaders must be able to store 96 vertices 

The functionality of programmable geometry shaders allows the GPU to implement shading programs that might otherwise be mapped to the CPU. One drawback to using geometry shaders however is that the memory required to store both the input primitives and the output primitives of the geometry shaders is expensive because the on chip memories take up valuable die area. Another drawback is that the latency of the geometry shaders may be large. One way to reduce the cost of the memory is to use less expensive off chip memory such as the GPU local memory. However since accessing off chip memory is slower than accessing on chip memory such a solution will further increase the latency of the geometry shaders and thus may cause the geometry shaders to become a bottleneck in the graphics pipeline. Another approach to storing the primitives associated with the geometry shaders is to use a combination of on chip memory and off chip memory. Again the on chip memory will be expensive and accessing the off chip memory may cause the geometry shaders to become a bottleneck in the graphics pipeline.

As the foregoing illustrates what is needed in the art is a more effective technique for parallel geometry shader processing.

One embodiment of the present invention sets forth a method for parallel geometry shading. The method includes the steps of defining a geometry shader group that includes a plurality of geometry shaders where an execution thread that is an instance of a geometry shading program executes on each one of the geometry shaders executing the geometry shading program such that the geometry shader group receives an input primitive and transmitting an instance of the input primitive to each geometry shader in the geometry shader group for processing.

One advantage of the disclosed method is that since the overall work associated with a given input primitive is distributed across multiple geometry shaders the output of each geometry shader is smaller and thus the total memory required to implement the algorithm is reduced. Another advantage is that since both the time required for the geometry shaders to execute and the time required to sequentially drain the resulting output buffers are reduced the latency of the geometry shaders are also reduced.

As shown the system data bus connects the CPU the input devices the system memory and the graphics processing subsystem . In alternate embodiments the system memory may connect directly to the CPU . The CPU receives user input from the input devices executes programming instructions stored in the system memory operates on data stored in the system memory and configures the graphics processing subsystem to perform specific tasks in the graphics pipeline. The system memory typically includes dynamic random access memory DRAM used to store programming instructions and data for processing by the CPU and the graphics processing subsystem . The graphics processing subsystem receives instructions transmitted by the CPU and processes the instructions in order to render and display graphics images on the display devices .

As also shown the system memory includes an application program an application programming interface API and a graphics processing unit GPU driver . The application program generates calls to the API in order to produce a desired set of results typically in the form of a sequence of graphics images. The application program also transmits zero or more high level shading programs to the API for processing within the GPU driver . The high level shading programs are typically source code text of high level programming instructions that are designed to operate on one or more shading engines within the graphics processing subsystem . The API functionality is typically implemented within the GPU driver . The GPU driver is configured to translate the high level shading programs into machine code shading programs that are typically optimized for a specific type of shading engine e.g. vertex geometry or fragment .

The graphics processing subsystem includes a graphics processing unit GPU an on chip GPU memory an on chip GPU data bus a GPU local memory and a GPU data bus . The GPU is configured to communicate with the on chip GPU memory via the on chip GPU data bus and with the GPU local memory via the GPU data bus . The GPU may receive instructions transmitted by the CPU process the instructions in order to render graphics data and images and store these images in the GPU local memory . Subsequently the GPU may display certain graphics images stored in the GPU local memory on the display devices .

The GPU includes one or more streaming multiprocessors . Each of the streaming multiprocessors is capable of executing a relatively large number of threads concurrently. Advantageously each of the streaming multiprocessors can be programmed to execute processing tasks relating to a wide variety of applications including but not limited to linear and nonlinear data transforms filtering of video and or audio data modeling operations e.g. applying of physics to determine position velocity and other attributes of objects and so on. Furthermore each of the streaming multiprocessors may be configured as a shading engine that includes one or more programmable shaders each executing a machine code shading program i.e. a thread to perform image rendering operations. The GPU may be provided with any amount of on chip GPU memory and GPU local memory including none and may use on chip GPU memory GPU local memory and system memory in any combination for memory operations.

The on chip GPU memory is configured to include GPU programming code and on chip buffers . The GPU programming may be transmitted from the GPU driver to the on chip GPU memory via the system data bus . The GPU programming may include a machine code vertex shading program a machine code geometry shading program a machine code fragment shading program or any number of variations of each. The on chip buffers are typically used to store shading data that requires fast access in order to reduce the latency of the shading engines in the graphics pipeline. Since the on chip GPU memory takes up valuable die area it is relatively expensive.

The GPU local memory typically includes less expensive off chip dynamic random access memory DRAM and is also used to store data and programming used by the GPU . As shown the GPU local memory includes a frame buffer . The frame buffer stores data for at least one two dimensional surface that may be used to drive the display devices . Furthermore the frame buffer may include more than one two dimensional surface so that the GPU can render to one two dimensional surface while a second two dimensional surface is used to drive the display devices .

The display devices are one or more output devices capable of emitting a visual image corresponding to an input data signal. For example a display device may be built using a cathode ray tube CRT monitor a liquid crystal display or any other suitable display system. The input data signals to the display devices are typically generated by scanning out the contents of one or more frames of image data that is stored in the frame buffer .

The data assembler is a fixed function unit that collects vertex data for high order surfaces primitives and the like and outputs the vertex data to the vertex shading engine . The data assembler may gather data from buffers stored within system memory the GPU local memory and the on chip GPU memory as well as from API calls from the application program used to specify vertex attributes. The vertex shading engine is a programmable execution unit such as the streaming multiprocessor that is configured to execute a machine code vertex shading program processing vertex data as specified by the vertex shading program. For example vertex shading engine may be programmed to transform the vertex data from an object based coordinate representation object space to an alternatively based coordinate system such as world space or normalized device coordinates NDC space. The vertex processing unit may read and write data that is stored in GPU local memory and the on chip GPU memory .

The primitive assembler is a fixed function unit that receives processed vertex data from vertex shading engine and constructs graphics primitives e.g. points lines triangles or the like for processing by the geometry shading engine . In alternative embodiments a second primitive assembler not shown may be included subsequent to the geometry shading engine in the data flow through the GPU . The geometry shading engine is a programmable execution unit such as the streaming multiprocessor that is configured to execute a machine code geometry shading program processing graphics primitives received from the primitive assembler as specified by the geometry shading program. The geometry shading engine may be programmed to generate zero or more new graphics primitives and calculate parameters such as plane equation coefficients that are used to rasterize the new graphics primitives. For example for use in cube map rendering the geometry shading engine may be configured to process input primitives sextuple the input primitives and emit up to 6 sets of output primitives one for each face of a cube. The geometry shading engine may read and write data that is stored in the GPU local memory and the on chip GPU memory . The geometry shading engine outputs the parameters and new graphics primitives to the rasterizer . The rasterizer is a fixed function unit that scans the new graphics primitives and outputs fragments and coverage data to the fragment shading engine .

The fragment shading engine is a programmable execution unit such as the streaming multiprocessor that is configured to execute a machine code fragment shading program processing fragments received from rasterizer as specified by the machine code fragment shading program. For example the fragment shading engine may be programmed to perform operations such as perspective correction texture mapping shading blending and the like to produce shaded fragments that are output to the raster operations unit . The fragment shading engine may read and write data that is stored in the GPU local memory and the on chip GPU memory . The raster operations unit optionally performs fixed function computations such as near and far plane clipping and raster operations such as stencil z test and the like and outputs pixel data as processed graphics data for storage in a buffer in the GPU local memory such as the frame buffer .

In prior art geometry shading engines each input primitive is processed by a single geometry shader using a single thread. However some geometry shading algorithms are amenable to partitioning the work associated with processing an input primitive into discrete portions of work that may be executed in parallel across multiple threads. To efficiently execute a geometry shading program that is structured to expose this parallelism the geometry shading engine may be configured to include one or more geometry shader groups executing in parallel. Each geometry shader group includes two or more geometry shaders operating in parallel to process the same input primitive thereby processing the input primitive using multiple threads. As a result each geometry shader in a geometry shader group performs a fraction of the work in a fraction of the time that would be required to process a single input primitive using a single geometry shader. Furthermore as shown in detail for geometry shader each geometry shader within a particular geometry shader group includes a work identifier which is configured to specify the portion of work that each individual geometry shader performs. In this fashion the geometry shaders in a particular geometry shader group may be coordinated.

Distributing the work associated with processing an input primitive across multiple geometry shaders in a geometry shader group also distributes the emitted output primitives across the geometry shaders . By doing so the number of input primitives processed simultaneously and the number of output primitives produced may be reduced. Since input primitives are stored in on chip GPU memory to allow parallel processing by the geometry shading engine and output primitives are stored in on chip GPU memory to allow sequential processing by the rasterizer distributing the work associated with processing an input primitive across a geometry shader group reduces the amount of data stored in on chip GPU memory . More specifically the amount of on chip GPU memory used by the geometry shading engine tends to be inversely proportional to the number of geometry shaders in each geometry shader group . Furthermore as shown in detail for geometry shader each geometry shader is configured to include an output limit . The output limit is a hardware imposed upper limit on the number of output primitives that a single geometry shader may generate during each invocation.

As shown the method begins at step where the geometry shading engine executes a machine level geometry shading program designed to perform geometry shading operations associated with cube map rendering. The geometry shading program configures the geometry shading engine to concurrently process five input triangles onto each of the six faces of a cube. Since each input triangle generates six output triangles one output triangle for each face of the cube a total of thirty output triangles are generated. Furthermore the geometry shading program configures the geometry shading engine to distribute the work associated with processing each input triangle into six distinct portions of work one portion of work for each of the six output triangles generated for the input triangle .

To ensure that each of the five input triangles are available to be processed in parallel in step the five input triangles are stored in the on chip buffers of . This requires the on chip buffers to allocate fifteen vertices of storage for the input triangles used by the geometry shading engine 

In step each of the five geometry shader groups within the geometry shading engine concurrently receives an input triangle . Thus the geometry shader group receives the input triangle the geometry shader group receives the input triangle the geometry shader group receives the input triangle the geometry shader group receives the input triangle and the geometry shader group simultaneously receives the input triangle .

In step logic within the geometry shading engine causes the input triangle associated with a particular geometry shader group to be passed to each of the six geometry shaders included in the geometry shader group . Thus the geometry shaders through receive the input triangle the geometry shaders through receive the input triangle the geometry shaders through receive the input triangle the geometry shaders through receive the input triangle and the geometry shaders through receive the input triangle .

In step each of the thirty geometry shaders in the geometry shading engine launches one thread that emits one output triangle . These thirty threads may execute in parallel. The work identifier in each of the geometry shaders may identify the face of the cube for which the geometry shader generates an output triangle. For example in one implementation the work identifier for the geometry shaders and is one indicating that each of these geometry shaders may generate an output triangle for face one of the cube.

Since in step each of the thirty geometry shaders may execute in parallel the thirty output triangles may be stored in the on chip buffers to preserve the processing order of the output triangles throughout the graphics pipeline. The on chip buffers allocate ninety vertices of storage for the thirty output triangles generated by the geometry shading engine 

In step each of the thirty parallel threads launched in step concludes by storing the output triangle generated by the thread in the on chip buffers . The method then terminates. Once the output triangles generated by the geometry shading engine have been passed to the rasterizer the method may repeat with another set of five input triangles .

As shown the method begins at step where logic within the GPU sets a thread index N to 1 and the rasterizer is set to an initial state to begin processing the primitives generated by the geometry shading engine . If in step logic within the GPU determines that the execution thread N in this case 1 spawned by the shading engine has not completed the method proceeds to step and logic within the GPU waits for the execution thread N to complete. The method then continues at step where logic within the GPU compares the thread index N to the total number of threads launched within the geometry shading engine here thirty to determine whether all of the launched threads have completed. Since the method has thus far only determined that thread 1 has completed the method proceeds to step where logic within the GPU increments the thread index N to 2.

The method continues in this fashion looping through steps a total of thirty times thus ensuring that all thirty threads launched by the geometry shading engine have completed. Ascertaining if a thread has completed in step and waiting in step may be accomplished in any technically feasible way. Once all of the launched threads have completed in step logic within the GPU transmits the thirty output triangles generated by the thirty threads to the rasterizer in sequential order thereby maintaining the order of the output triangles within the overall graphics pipeline . Again after the method completes the memory allocated in the on chip buffers for the output triangles may be released and the geometry shading engine may process the next five input triangles .

The overall latency of the geometry shading engine includes both the time required to execute method where geometry shading is performed and the time required to execute method where the output buffers are drained . If M cycles are required for a geometry shader to process an input triangle and store the resulting output triangle in the output buffer and each geometry shader within the geometry shading engine executes substantially in parallel then the geometry shading engine takes M cycles to process all of the input triangles . Furthermore if D cycles are required to drain each output buffer then 30 D cycles are required to drain the output buffers. Since as described above the output buffers drain serially to maintain the order of the output triangles within the overall graphics pipeline . Thus the overall latency of the geometry shading engine is M 30 D cycles. Advantageously this latency is approximately one sixth the latency of a conventional geometry shading engine that is configured to process 32 input triangles and generate 192 output triangles.

Although embodiments of the present invention have been described in the context of geometry shading for cube map rendering persons skilled in the art will appreciate that the principles of the present invention are applicable to any algorithm where the work associated with processing a single input primitive may be allocated across two or more geometry shaders defining a geometry shader group.

In sum improved utilization of graphics hardware may be achieved by explicitly expressing additional primitive level parallelism using geometry shader groups. In one embodiment of the invention a geometry shading algorithm is analyzed to determine whether the algorithm is amenable to distributing the processing of each input primitive across two or more geometry shaders defining a geometry shader group. In such cases upon receiving an input primitive logic within the geometry shading engine routes the input primitive to each of the geometry shaders in the geometry shader group thereby causing the geometry shaders to execute in parallel. Each geometry shader launches a single execution thread to process the input primitive according to the specific portion of work the geometry shader has been programmed to perform. As each thread completes the output primitive generated by the thread is stored in on chip GPU memory.

Further parallel processing may be achieved if the geometry shading engine is configured as multiple parallel geometry shader groups where each shader group is responsible for processing one or more input primitives. After all of the geometry shader threads across the different geometry shader groups have completed the output primitives are processed in sequential order by the rasterizer.

Advantageously when a geometry shading engine is configured to include geometry shader groups instead of individual geometry shaders the number of both input primitives and output primitives that are simultaneously stored in on chip GPU memory is divided by the number of geometry shaders in the geometry shader group. Thus the amount of on chip GPU memory used by the geometry shading engine may be significantly reduced. Furthermore since both the time required for the geometry shading engine to execute and the time required to sequentially drain the resulting output buffers are reduced the latency of the geometry shading engine is also reduced. Yet another advantage is that since the use of geometry shader groups reduces the number of output primitives emitted by each geometry shader using geometry shader groups may avoid the output limit restriction of conventional geometry shaders. Consequently embodiments of the present invention enable geometry shading engines to execute geometry shading algorithms that would be prohibited in prior art approaches.

While the forgoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored. Such computer readable storage media when carrying computer readable instructions that direct the functions of the present invention are embodiments of the present invention. Therefore the scope of the present invention is determined by the claims that follow.

