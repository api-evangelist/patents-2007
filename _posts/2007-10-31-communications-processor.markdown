---

title: Communications processor
abstract: A communication processor of a class, such as an Internet tuner, provides such desirable features (FIG. ) as LAN support, an SPI interface (), a dedicated port (), and ADPCM () for audio applications. The invention provides a low-cost, low-power, easily manufactured, small form-actor network access module which has a low memory demand and provides a highly efficient protocol decode. The invention comprises a hardware-integrated system that both decodes multiple network protocols in a streaming manner concurrently and processes packet data in one pass, thereby reducing system memory and form factor requirements, while also eliminating software CPU overhead.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07646790&OS=07646790&RS=07646790
owner: NVIDIA Corporation
number: 07646790
owner_city: Santa Clara
owner_country: US
publication_date: 20071031
---
The present application is a continuation of U.S. application Ser. No. 10 470 365 filed Jul. 25 2003 now U.S. Pat. No. 7 379 475 which in turn is a 371 filing of PCT US02 02293 filed Jan. 1 2002 which claims priority from U.S. provisional application 60 264 381 filed Jan. 26 2001 which are all incorporated herein by reference.

The invention relates to telecommunications. More particularly the invention relates to an apparatus and method for processing data in connection with protocols that are used in order to send and receive data for example email web documents digital files audio video or other data in digital format.

This section describes the prior art and defines the terms communications network network device protocol layer data frame data packet host computer CPU ISO OSI protocol processing software stack .

Communications networks use protocols to transmit and receive data. Typically a communications network comprises a collection of network devices also called nodes such as computers printers storage devices and other computer peripherals communicatively connected together. Data is transferred between each of these network devices using data packets that are transmitted through the communications network using a protocol. Many different protocols are in current use today. Examples of popular protocols include the Internet Protocol IP Internetwork Packet Exchange IPX protocol Sequenced Packet Exchange SPX protocol Transmission Control Protocol TCP Point to Point Protocol PPP and other similar new protocols that are under development. A network device contains a combination at hardware and software that processes protocols and data packets.

In 1978 the International Standards Organization ISO a standards setting body created a network reference model known as the Open System Interconnection OSI model. The OSI model includes seven conceptual layers 1 The Physical PHY layer that defines the physical components connecting the network device to the network 2 The Data Link layer that controls the movement of data in discrete forms known as frames that contain data packets 3 The Network layer that builds data packets following a specific protocol 4 The Transport layer that ensures reliable delivery of data packets 5 The Session layer that allows for two way communications between network devices 6 The Presentation layer that controls the manner of representing the data and ensures that the data is in correct form and 7 The Application layer that provides file sharing message handling printing and so on. Sometimes the Session and Presentation layers are omitted from this model. For an explanation of how modern communications networks and the Internet relate to the ISO seven layer model see for example chapter 11 of the text Internetworking with TCP IP by Douglas E. Comer volume 1 fourth edition ISBN 0201633469 and Chapter 1 of the text TCP IP Illustrated by W. Richard Stevens volume 1 ISBN 0130183806 .

An example of a network device is a computer attached to a Local Area Network LAN wherein the network device uses hardware in a host computer to handle the Physical and Data Link layers and uses software running on the host computer to handle the Network Transport Session Presentation and Application layers. The Network Transport Session and Presentation layers are implemented using protocol processing software also called protocol stacks. The Application layer is implemented using application software that process the data once the data is passed through the network device hardware and protocol processing software. The advantage to this software based protocol processing implementation is that it allows a general purpose computer to be used in many different types of communications networks and supports any applications that may be needed. The result of this software based protocol processing implementation however is that the overhead of the protocol processing software running on the Central Processing Unit CPU of the host computer to process the Network Transport Session and Presentation layers is very high. A software based protocol processing implementation also requires a large amount of memory on the host computer because data must be copied and moved as the software processes it. The high overhead required by protocol processing software is demonstrated in U.S. Pat. No. 5 485 460 issued to Schrier et al. on Jan. 16 1996 which teaches a method of operating multiple software protocol stacks. This type of software based protocol processing implementation is used for example in computers running Microsoft Windows.

During normal operation of a network device the network device hardware extracts the data packets that are then sent to the protocol processing software in the host computer. The protocol processing software runs on the host computer and this host computer is not optimized for the tasks to be performed by the protocol processing software. The combination of protocol processing software and a general purpose host computer is not optimized for protocol processing and this leads to performance limitations. Performance limitations in protocol processing such as the time lag created by the execution of protocol processing software is deleterious and may prevent for example audio and video transmissions from being processed in real time or prevent the full speed and capacity of the communications network from being used. It is evident that the amount of host computer CPU overhead required to process a protocol is very high and extremely cumbersome and requires the use of the CPU and a large amount of memory in the host computer.

New consumer and industrial products that do not fit in the traditional models of a network device are entering the market and at the same time network speed continues to increase. Examples of these consumer products include Internet enabled cell phones Internet enabled TVs and Internet appliances. Examples of industrial products include network interface cards NICs Internet routers Internet switches and Internet storage servers. Software based protocol processing implementations are too inefficient to meet the requirements of these new consumer and industrial products. Software based protocol processing implementations are difficult to incorporate into consumer products in a cost effective way because of their complexity. Software based protocol processing implementations are difficult to implement in high speed industrial products because of the processing power required. It protocol processing can be simplified and optimized such that it may be easily manufactured on a low cost low power high performance integrated and small form factor device these consumer and industrial products can read and write data on any communications network such as the Internet.

A hardware based as opposed to software based protocol processing implementation an Internet tuner is described in J. Minami R. Koyama M. Johnson M. Shinohara T. Poff D. Burkes U.S. Pat. No. 6 034 963 Mar. 7 2000 the 963 patent . This Internet tuner provides a core technology for processing protocols.

It would be advantageous to provide a communications processor of a class such as the Internet tuner discussed above that provides basic desirable features as LAN support and additional features such as compression for audio applications.

The invention comprises a communications processor of a class such as the Internet tuner discussed above which provides such basic desirable features as protocol processing to provide LAN support and additional protocol processing and data processing features such as compression for audio applications. The invention provides a low cost low power high performance easily manufactured integrated small form factor communications processor that greatly reduces or eliminates demand on the memory and the CPU of a host computer and provides highly efficient protocol and data processing. The invention comprises a hardware integrated system that both processes multiple protocols in a streaming manner and processes packet data in one pass. The invention thereby reduces or eliminates the use of host computer memory and CPU overhead.

The 963 patent discloses an Internet tuner for processing decoding and encoding protocols and packet data comprising a network protocol layer module for receiving and transmitting packets and for encoding and decoding network packets which comprise data a data handler module for exchanging said data with said network protocol layer module and at least one state machine module that is optimized for a single selected protocol said state machine module in communication with said data handler module and providing resource control and system and user interfaces wherein said network protocol layer module said data handler module and said state machine module comprise corresponding hardware structures that are implemented in gate level circuitry and wherein such hardware structures are dedicated solely to performing the respective functions of their corresponding modules.

The preferred embodiment of the invention comprises an auxiliary microprocessor or equivalent that acts as a protocol engine and provides any of LAN support external interfaces to peripherals and memory and additional protocol and data processing such as compression for audio applications for example to the Internet tuner of the 963 patent. The presently preferred communications processor incorporates a protocol engine a set of peripherals for the protocol engine an Internet tuner core or other network stack an external controller interface and a memory interface. The communications processor thus provides network e.g. Internet connectivity to a wide range of consumer network devices and industrial network devices.

The following sections describe an inventive communications processor. The discussion herein defines the architecture of the presently preferred embodiment of the communications processor describes the various diagrams that accompany this document and discusses various features of the invention. When combined with a PHY or modem or both the herein disclosed communications processor provides industrial and consumer products with the protocol processing needed to connect to the Internet send and receive for example data email web documents digital files audio video or other data in digital format.

The presently preferred communications processor is based in part on the Internet tuner described in J. Minami R. Koyama M. Johnson M. Shinohara T. Poff D. Burkes U.S. Pat. No. 6 034 963 Mar. 7 2000 the 963 patent . The preferred embodiment of the invention adds any of LAN support external interfaces to peripherals and memory and additional protocol and data processing features such as compression for audio applications.

Examples but not for purposes of limitation of applications in which the invention may be used include 

The invention provides a low cost low power easily manufactured integrated small form factor network access module that has a low memory demand and provides a highly efficient protocol decode. The invention comprises a hardware integrated system that both decodes and encodes multiple network protocols in a streaming manner concurrently and processes packet data in one pass thereby reducing system memory power consumption and form factor requirements while also eliminating software CPU overhead.

The 963 patent discloses an Internet tuner for decoding and encoding network protocols and data comprising a network protocol layer module for receiving and transmitting network packets and for encoding and decoding network packet bytes which comprise packet data a data handler module for exchanging said packet data with said network protocol layer module and at least one state machine module that is optimized for a single selected network protocol said state machine module in communication with said data handler module and providing resource control and system and user interfaces wherein said network protocol layer module said data handler module and said state machine module comprise corresponding hardware structures that are implemented in gate level circuitry and wherein such hardware structures are dedicated solely to performing the respective functions of their corresponding modules. The preferred embodiment of the invention comprises an auxiliary processor or protocol engine that adds any of LAN support external interfaces to peripherals and memory and additional protocol and data processing such as compression for audio applications for example to the Internet tuner of the 963 patent. The presently preferred communications processor incorporates a protocol engine a set of peripherals for the protocol engine an Internet tuner core an external controller interface a memory interface and two auxiliary serial ports. The communications processor thus provides network e.g. Internet connectivity to a wide range of devices.

The present communications processor uses a master clock that may be set in frequency from 8 MHz to 70 MHz. The clock frequency chosen depends upon the application and the protocol engine that is used. The presently preferred communications processor uses a Zilog Z80 core a popular 8 bit microprocessor as the protocol engine but any microprocessor such as ARM ARC PowerPC or MIPS could be used. A Z80 microprocessor is most suited to low cost consumer applications that do not require high speed communications. A more powerful microprocessor or combination of microprocessors could be used as the protocol engine for industrial and high performance applications.

The following discussion describes the interface between the communications processor and an optional external CPU microprocessor or microcontroller . The interface pins can be configured as either a parallel or serial SPI interface described in more detail later or If no external CPU microprocessor or microcontroller is attached these interface pins may be used as general purpose I O pins. A register set is provided as a communication channel between the external CPU microprocessor or microcontroller and the communications processor . The communications processor operates in one of two modes normal mode and CPU bypass mode. Mode selection is performed using configuration pins. When configured for CPU bypass mode the protocol engine is disabled and the external CPU microprocessor or microcontroller can communicate directly with the network stack using an application programming interface API register set. When configured for normal mode the protocol engine is enabled and the external CPU microprocessor or microcontroller communicates via a set of registers described that are described in the next section.

In normal mode the external CPU microprocessor or microcontroller can access the network stack memory using two methods. The first method involves cooperation with the protocol engine . In this first method the protocol engine must set up one of two sets of address registers depending on whether the external CPU microprocessor or microcontroller is reading or writing to the network stack memory . In the second method the external CPU microprocessor or microcontroller sets up the read address or write address to access the network stack memory . If the external CPU microprocessor or microcontroller wants to write to the network stack memory then it writes the starting memory address to a set of registers. The external CPU microprocessor or microcontroller can then start to write data. The address registers increment with each write. If the external CPU microprocessor or microcontroller wants to read the network stack memory it initializes a set of registers to the starting address of the network stack memory that is to be read. The address registers increments with each read. There is also a subset of the CPU bypass mode called the test index mode used primarily for test and diagnostic purposes. The test index mode effectively allows the external CPU microprocessor or microcontroller to control the network stack while keeping the protocol engine enabled. The protocol engine may also be kept in reset in an inactive state so that the protocol engine and the external CPU microprocessor or microcontroller do not simultaneously access the network stack . If simultaneous access to the network stack from the protocol engine and the external CPU microprocessor or microcontroller does occur the results are unpredictable. However if the protocol engine is not programmed to access the network stack then the external CPU microprocessor or microcontroller need not be kept in reset.

The protocol engine uses an internal integrated or on chip 32 KB RAM and optional external RAM and external ROM . The external RAM and external ROM is not needed when all of the code and data of the protocol engine is less than the size of the internal RAM or when the communications processor is operated in CPU bypass mode. The internal 32 KB RAM may be made substantially larger for high performance applications without affecting the architecture. The protocol engine internal RAM is capable of being battery operated via I O pins to allow nonvolatile storage of code when no external ROM is used.

This section describes the external memory connections used in normal operation. The present version of the communications processor provides programmable wait states for the optional external ROM so that a variety of ROM speeds may be used. However slower ROMs may have an impact on overall performance. The optimum ROM speed is application dependent but in general 70 ns ROMs provide adequate performance for consumer applications and are currently readily available and inexpensive. The present version of the communications processor uses 8 bit ROM for the external ROM and uses 8 bit RAM for the external RAM . Programmable wait states are provided for the external RAM . The optimum speed of the external RAM is dependent on the application but 70 ns parts offer adequate performance for most consumer product applications. The present version of the communications processor is designed to use 8 bit SRAM for the external RAM but other RAM sizes organizations and types such as SDRAM or DDR SDRAM may also be used that require changes to the bus controller but without significant changes to the rest of the architecture.

The present version of the communications processor contains a powerful IP filter engine to support such features as for example network address translation NAT and IP masquerading. The first function of the IP filter is to parse the information in the incoming data packet for example the type of packet the source and destination IP addresses the source and destination port numbers and so on . The information from the data packet is made available to the protocol engine so that the protocol engine can decide what to do with the data packet. The protocol engine may intercept the data packet pass the data packet up the network stack discard the data packet or re transmit forward the data packet. Prior to receiving or forwarding the packet the protocol engine may modify any packet parameter including but not limited to the source IP address destination IP address source port destination port and the time to live TTL . The IP filter engine will then recalculate the appropriate checksums and send the packet as directed by the protocol engine . The protocol engine controls these and other functions of the network stack via the protocol engine interface . The second function of the IP filter is to inject data packets back into the network stack . Injected data packets can come from either the IP filter engine or the protocol engine . The IP filter engine may be enabled under control of the protocol engine using a range of settings. For example the IP filter may be enabled to filter on the basis of specific ports IP addresses or on the basis of specific protocols. These IP filter criteria are set using registers. The following sections describe the theory of the operation of the IP filter for supporting NAT and IP masquerading. is a block schematic diagram of an exemplary network according to the invention.

In the example network of the base unit or base node or base network device contains a communications processor for both Ethernet LAN and telephone line links thus supporting two data links i.e. Ethernet link and a telephone line or dialup link . The base unit has an IP address associated with each data link. The IP address associated with the Ethernet link 10.10.150.1 is a local IP address and is not recognized external to the Ethernet LAN. The IP address associated with the telephone line link 204.192.4.5 is recognized external to the Ethernet LAN and may for example be a floating IP address that was assigned to the base unit by an Internet service provide ISP during PPP negotiations or it may be a permanent IP address. Although not shown or discussed explicitly in the example network described here the client units and may also contain a communications processor for both Ethernet link and telephone line link. As another example the communications processor may contain multiple Ethernet links or telephone line links and thus multiple client units and may be part of a single network device. The combination of the IP filter functions and support for multiple data links in a single integrated communications processor enables such sophisticated features as for example failover or load balancing to be performed.

In this section we describe the connections between client units and and the Internet for the example network shown in . Assume client unit wants to access www.iready.com on the Internet . In this case client unit sends a packet with its IP address 10.10.150.51 as the source IP address and the IP address of www.iready.com 123.45.6.78 as the destination IP address. Client unit detects that the destination IP address is not on the local network and sends the packet to the base unit assuming that the base unit is set up as the default gateway. Once the base unit receives the packet it is passed from the Ethernet MAC interface to the ARP engine . The ARP engine examines the packet to see if it is an ARP packet an IP packet or an unknown packet. In this case because the received packet is an IP packet it is passed to the IP router engine bottom . The IP router engine bottom arbitrates between incoming packets coming from the Ethernet path and PPP module . If no PPP traffic is currently being received then the received IP packet is sent to the IP filter engine . In the IP filter engine the packet is parsed and stored in the IP filter buffer part of the network stack internal memory . The protocol engine is then notified via an interrupt that a packet has arrived.

When the protocol engine receives the interrupt notification it uses registers to read the port and IP address information of the received packet to determine what to do with the received IP packet. In this example the protocol engine operates on the received IP packet and replaces the source IP address 10.10.150.51 of client unit with the base unit global IP address 204.192.4.5 and replaces the client unit source port number with a port number that the base unit associates with this socket. When these values are written to the appropriate IP filter registers a SND command is issued. Upon receiving the SND command the IP filter engine replaces the port and IP address information recalculates the IP and TCP header checksums and transmits the packet over the telephone line link in this example network . The protocol engine also logs a socket connection between a port on client unit and a port on www.iready.com .

When the base unit receives the return packet from www.iready.com via the dialup link in the example network shown in the incoming return packet is handled by the PPP module . The PPP module stores the incoming return packet into the PPP memory buffer part of the network stack internal memory . When the entire incoming return packet is received and the frame checksum FCS is validated the PPP buffer notifies the IP router engine bottom . If no Ethernet packet is currently being received via the Ethernet data link then the incoming return packet is sent from the PPP module to the IP filter engine via the IP Router Bottom . The IP filter engine parses the received packet and stores it in the IP filter buffer part of the network stack internal memory and notifies the protocol engine via an interrupt that a packet has arrived. The protocol engine examines the packet s port and IP address information and recognizes that the destination port number contained in the packet is the port number that is associated with a socket connection for client . The protocol engine replaces the destination port with the original source port from client unit and replaces the destination IP address with the IP address of client unit . When this is complete the protocol engine issues a SND command. This SND command causes the IP filter engine to replace the port number and IP address recalculate the checksums and then send the packet out via the Ethernet link . Determination of which physical link the packet should use is handled by the IP router bottom engine .

The sequence of events just described corresponds to the functions required by network address translation NAT and IP masquerading. The process of receiving and transmitting packets then continues in this manner until the connection is closed. The protocol engine can determine the closing of a connection by snooping viewing the TCP header flags of the transmitted and received packets. When the protocol engine recognizes that a connection has been closed the protocol engine removes that connection log from its active connection table stored in internal memory or external memory . Using this method the number of simultaneous connections that can be maintained is only limited by the amount of memory available to the protocol engine in the base unit . Consumer network devices that only require a few 1 10 connections may use a small memory such as the internal memory and industrial devices that may require thousands of connections can employ external memory .

For UDP connections the communications processor uses a timeout mechanism because unlike TCP UDP does not have any notion of opening or closing a connection. A timer resets every time a UDP packet for a connection is received. The timer may be set under external control with a presently preferred default timeout value of 15 minutes.

In this section we discuss how the connections between the client units and and the base unit are handled for the example network shown in . Assume a data packet is sent from a client unit to the base unit . When the received packet reaches the IP filter engine of the base unit it notifies the protocol engine that a packet has arrived. The protocol engine examines the received data packet and determines if the received data packet is intended for the base unit . If the received data packet is intended for the base unit the protocol engine issues a command the REC command to the IP filter engine . The REC command causes the received data packet to be passed up the network stack via the IP router top engine the IP engine the TCP IP engine and the sockets module . The data from the received data packet is passed through a network stack socket interface. When the base unit needs to send data back to the client unit it uses the network stack socket interface. The packets are then generated by the TCP UDP engine . The TCP UDP engine will query the IP router top engine for the next hop IP address and the appropriate source IP address. Both of these parameters are determined by the IP router top engine based on the destination IP address for the packet. The packet is then passed through the IP engine . The IP engine prepends the IP header and sends a transmission request to the IP router top engine . The packet is then sent through the IP filter without modification to the IP router bottom engine . At this point based on the next hop IP address the IP router bottom engine will route the packet to the appropriate physical data link. In this case it will send the packet to the ARP engine . The ARP engine will then use the next hop IP address to look up the corresponding MAC address. With this information the ARP engine generates the Ethernet header and prepends it to the packet. The complete packet is then sent to the MAC interface . In the MAC interface the packet is first queued in the MAC transmit buffer by the MAC buffer controller . The packet is then copied from the MAC transmit buffer to the internal MAC and finally out via the MII interface to the external PHY and on to the client units and .

In this section we describe how the connections between the base unit and the Internet are handled for the example network shown in . When data packets are generated by the TCP UDP engine the flow follows the same path as described in the previous section up to the point where it reaches the IP router bottom engine . The IP router bottom engine in this case wilt pass the packet to the PPP engine which will prepend the PPP header perform any data escaping necessary and calculate and append the PPP cyclic redundancy check CRC . The complete packet is then transmitted via the modem interface module and the modem interface to external modem and the Internet over the telephone line link in the case of this example network .

When the PPP engine receives reply data packets it sends the data packets up through the IP router bottom engine and then to the IP filter engine . The IP filter engine parses and stores the data packet in IP filter memory part of the network stack internal memory and notifies the application that an IP packet has been received. The application then examines the port and IP address information of the data packet and determines if the data packet is destined for the base unit . The application then issues the REC command to the IP filter engine which causes the IP filter to retrieve the packet from the IP filter memory part of the network stack internal memory and send it to the IP engine . The application then processes the data through the network socket interface.

In this section we discuss how ping requests from a client unit to the Internet are handled for the example network shown in . This situation is a special case of the connection between client units and and the Internet . The ping requests are entered into a special ping table in the base unit communication processor in part of the protocol engine internal memory . These ping table entries have a timeout e.g. approximately 10 seconds. If no ping response is received before a time equal to the timeout the ping table entry is deleted. If a ping response is received before a time equal to the timeout the sequence number of the ping reply is checked against entries in the ping table for the ping request. If the reply sequence number is correct the IP address for the client unit that sent the ping request is copied to the ping reply packet. The ping reply packet is then sent to the client unit on the LAN using the Ethernet link . The ping table entry is also deleted when the ping reply is received.

In this section we describe how raw IP packets are sent from the base unit for the example network shown in . A raw IP packet is any arbitrary network packet. When the network stack sends raw IP packets the raw IP packet is copied to the raw IP buffer part of the network stack internal memory by using commands and special purpose registers. Based upon the destination IP address for the raw IP packet the IP router bottom engine routes the raw IP packet to the proper data link. A register is then cleared to indicate that the raw IP packet has been completely transmitted.

In this section we describe how the base unit receives IP multicast and broadcast IP packets from the Internet for the example network shown in . When the base unit receives a broadcast or multicast IP packet from the Internet the packet is stored in the IP filter buffer part of the network stack internal memory and the protocol engine is notified that a packet has arrived. The protocol engine examines the packet and should it decide to forward the packet it may modify any appropriate packet parameter and then issue a SND command. This SND command causes the IP filter engine to recalculate the packet checksums and send the packet out via the Ethernet link .

In this section we describe how the base unit transmits IP multicast and broadcast IP packets for the example network shown in . The base unit can use the network stack socket interface when it sends multicast or broadcast packets. The destination IP address is set appropriately and the network stack handles the multicast or broadcast packet as a normal IP packet. Alternatively the protocol engine can send a multicast or broadcast packet out as a raw IP packet.

In this section we describe how the client units handle incoming packets from the Internet for the example network shown in . The base unit uses a port network address translation NAT table. This table matches port numbers with the client units on the LAN. For example if client unit with IP address 10.10.150.151 is designated as an HTTP server using port and client unit with IP address 10.10.150.152 is designated as a POP server using port a port NAT table would appear as shown in Table 1.

As packets arrive at the IP filter engine they are parsed and stored in the IP filter buffer part of the network stack internal memory and the protocol engine is notified via an interrupt using the protocol engine interface . The protocol engine examines the header parameter registers via the protocol engine interface to determine it the destination port in the incoming data packet matches any ports in the port NAT table. If the destination port does match a port NAT table entry then the destination IP address in the incoming data packet is changed to the IP address specified in the table corresponding to that port and a SND command is issued. The IP filter engine then changes the header parameter registers recalculates the checksums and transmits the modified data packet via the Ethernet link. When client unit sends a response data packet back to the base unit the protocol engine again attempts to match the port specified in the response data packet with the port NAT table. If there is a match between ports the protocol engine via the protocol engine interface changes the source IP address in the packet from the IP address of client unit to the IP address of the base unit prior to transmitting the packet to the Internet on the telephone line link in this example network .

This section describes the IP filter engine direct memory access DMA transfer. The IP filter engine uses 6 KB of the network stack internal memory . The 6 KB is split between the IP filter receive buffer the IP filter send buffer and the raw IP buffer. The partitioning and size of the buffers may be adjusted in different embodiments. For example both the IP filter receive send buffer and the raw IP buffer may be 3 KB in length or one may be 2 KB and the other 4 KB or each may be considerably larger for long latency or high bandwidth networks. Incoming IP packets are first stored in the IP filter receive send memory buffer part of the network stack internal memory . The application is notified when the packet is received. If the application wishes to move the packet to the raw IP buffer part of the network stack internal memory it writes the target memory location in the raw IP memory buffer part of the network stack internal memory to the DMA address registers. When the write to the DMA address registers is complete a DMA command is issued to start the DMA transfer. When the DMA transfer is complete a bit in a status register is set. If interrupts are enabled this status register bit condition triggers an interrupt to the application.

The following sections describe how the network stack handles ICMP echo request packets or ping packets . The network stack includes specialized and optimized hardware support for ICMP echo reply packet generation. That is if the IP engine receives an ICMP echo request packet the IP engine can automatically generate the appropriate ICMP echo reply packet. The IP engine uses part of the network stack internal memory as a temporary store for the data section of the echo request and echo reply packets.

There are two cases to consider for ICMP echo request and reply packet support in the network stack . The two cases correspond to the IP filter engine being enabled or disabled.

If the IP filter engine is disabled ICMP echo request packets pass directly through the IP filter engine and are processed by the IP engine . In this first case ICMP echo reply packets are automatically generated by the IP engine using network stack internal memory as a temporary store. The echo reply packet is then transmitted.

When the IP filter engine is enabled it uses the network stack internal memory . This prevents the IP engine from using network stack internal memory as a temporary store to generate the ICMP echo reply packets. In this second case the ICMP echo reply is generated under control of the protocol engine via the protocol engine interface . The protocol engine via the protocol engine interface changes the ICMP type in the ICMP echo request packet from 0x08 hex 08 to 0x00 and then swaps the source and destination addresses in the original echo request packet in order to form the echo reply packet. The protocol engine then issues a SEND command to the IP filter via the protocol engine interface in order to transmit the echo reply packet.

The following sections provide an overview of the IP router functions in the network stack including the IP router top engine and IP router bottom engine . These two IP router engines serve as an extension to the IP engine .

The IP router bottom engine serves as a switch between the Ethernet and PPP transmit and receive data link paths. In the receive direction the IP router bottom engine checks that two packets are not being received at the same time from the PPP engine the PPP data link receive path and the IP raw mux on the Ethernet data link receive path . All PPP packets are first buffered in part of the network stack memory . This is done because the PPP link is often much slower then the Ethernet LAN link. By first buffering the packet the network stack is able to process PPP packets at the same rate as packets from the Ethernet LAN link. Without packet buffering packets from the Ethernet LAN link may be held up for long periods while the network stack is processing a slowly arriving PPP packet. In the transmit direction the IP router bottom engine routes the transmitted packets between the PPP engine on the PPP data link transmit path and the IP raw mux on the Ethernet data link transmit path based upon the next hop IP address.

When a TCP packet or an IP raw packet is sent the IP router top engine checks the destination IP address. If the destination IP address corresponds to the local network the IP router top engine transmits the packet directly to network device at the specified IP address using either the Ethernet data link or the PPP data link. However if the destination IP address does not belong to any directly connected networks the IP router top engine searches to find the best gateway and the appropriate data link to which to send the packet. The mechanism for this search is described next.

The IP router top engine uses an n entry table for routing information which is described more completely in the following sections. All entries are programmable from the protocol engine . Of the n entries most of the entries are general purpose routing entries and one of them is a default routing entry. The IP router top engine is designed to support one or more of both PPP data links and Ethernet data links.

The IP router top engine sits below the TCP UDP engine and IP engine and above the PPP engine on the PPP data link path and IP raw mux and ARP engine on the Ethernet data link path in the network stack See . The IP router top engine interfaces directly to the IP engine and the protocol engine via the protocol engine interface . The IP router top engine monitors all outgoing packets and provides the next hop IP addresses as well as the appropriate source IP address for the packets.

The following sections describe the operation of the IP router top engine . When a data packet is sent from the application layer the IP router top engine and IP router bottom engine cooperate to direct the data packet to the appropriate data link. The IP route table is essential for maintaining IP routing information. The table is implemented in the IP router top engine and contains n entries there are several general purpose routing entries and one default routing entry. The general purpose entries may be programmed to be either static entries or dynamic entries and the default entry is always a static entry see Table 2 .

The routing decision made by the IP router top engine is biased on the information contained in the routing table. The IP router top engine searches the route table by performing three steps 

After the search is complete the IP router top engine determines which data link should be used to transmit a data packet. It passes the next hop IP address as well as the appropriate source IP address to use for the packet back to the calling engine. The routing is now complete.

The IP route table must be configured before any IP packets are sent. To configure the IP route table the protocol engine or external CPU microprocessor or microcontroller writes to a set of application programming interface registers. The following sequence of steps is required to configure the route table before any packets may be sent 

After the registers and the route table are configured the protocol engine maintains the route table by programming the appropriate routes using the protocol engine interface . Typically routes in the route table can change for any of the following reasons 

After the route table entries are set up the route table permits the data packets to be routed without the further intervention of the protocol engine . The IP router top engine monitors whether data links are up working or active or down broken or inactive and chooses the data links appropriately. The route table includes the following information destination IP address and gateway IP address. The route table information may be retrieved from the route table by the protocol engine by executing a read command.

The following sections describe the operation of ARP and the ARP engine . The ARP engine resolves an Ethernet hardware address from any given IP address. When IP packets are sent the destination IP address is not sufficient in an Ethernet network. In order to send a packet the 48 bit hardware address must also be found. In an Ethernet network a 48 bit hardware address is used to uniquely identify network devices. In order to map or resolve an IP address to the 48 bit hardware address the following sequence of steps occurs. The ARP engine sends a broadcast ARP request containing the IP address to be resolved to the network. The destination network device having recognized its IP address in the ARP request then sends back an ARP reply packet which includes the 48 bit hardware address of the destination network device to the ARP engine . The ARP engine saves the resolved 48 bit hardware address together with the original destination IP address as an associated pair in the ARP cache. Now when the application sends another packet to the same destination IP address the ARP engine knows by using the ARP cache where it may find the correct 48 bit hardware address and where to send the packet without performing another ARP request.

The preferred ARP cache contains four entries. A Least Recently Used scheme is applied to update and retire the cache entries. The ARP engine listens to any ARP request that it receives and generates all ARP replies that match its IP address. The ARP cache may contain substantially more entries for higher performance applications without affecting the architecture.

The ARP engine sits below the IP raw mux and IP router bottom engine in the network stack and interfaces directly to the Ethernet MAC interface . The ARP engine has access to the internal network stack memory through the memory arbitrator . The ARP engine operates very closely with the IP router bottom engine . In most applications the ARP engine and the IP router bottom engine are configured together especially when there are multiple data links that need to be supported e.g. PPP and Ethernet.

The following sections provide a more detailed description with an example of the ARP support features in the network stack . ARP provides a dynamic mapping from a 32 bit IP address to the corresponding 48 bit hardware or Ethernet address e.g. the Ethernet address 11 12 13 AA B0 C1 which corresponds to 48 bits . For example if an email application sends a message the TCP engine forms an IP packet with a specified destination IP address destined for the IP engine and the IP router top engine . The ARP engine provides a mapping between the IP address and the 48 bit hardware address so that the IP packet can be correctly sent to its destination.

The reverse of ARP known as the reverse address resolution protocol RARP is not supported by the present version of the ARP engine but RARP could be implemented using the same structures and design as the ARP engine with minor modifications.

The ARP cache is essential to maintain the ARP operation. The present cache table implemented in the ARP engine consists of four entries but the number of table entries may be increased in alternative embodiments. Each cache entry consists of the destination IP address destination hardware address and the ARP down counter the down counter serves as an expiration timeout counter .

The ARP engine is configured by writing to the corresponding application programming interface API registers. Configuration is achieved by completing the following two steps 

After the ARP engine is set up and an application is running an ARP cache entry is read by writing the ARP cache entry index to the ARP cache select register. The following ARP cache entry information may then be read from registers the resolved destination IP address the resolved 48 bit hardware address and the ARP cache down counter.

This section describes the handling of unsupported packet types. An unsupported packet is any frame that is received from the MAC interface that has an Ethernet frame type other than x0806 corresponding to an ARP packet or x0800 corresponding to an IP packet . The unsupported packet is stored and retrieved by the protocol engine if this store and retrieval feature is enabled by setting a bit in the ARP configuration register. The maximum size of an unsupported packet that may be stored by the ARP engine is 2 KB in the dedicated ARP buffer memory which is attached to the ARP engine but not shown explicitly in . Any unsupported packet that is longer than 2 KB triggers an overflow condition and the excess bytes are dropped. If the protocol engine intends to read any unsupported packet received it must read the packet from the ARP buffer memory as soon as the unsupported packet interrupt is detected to avoid any overflow condition. The number of bytes that are available in the ARP buffer memory can be read from a register. The protocol engine should only read those bytes that have been stored in the buffer memory to avoid any under run conditions.

The following sections describe the internal media access controller MAC interface . The MAC implementation integrated into the network stack enables Ethernet access for network devices that use the communications processor . The MAC interface may be configured to operate in two modes normal and test. During normal mode the MAC interface transmits data packets created by the network stack . The MAC interface also receives data packets filters the appropriate addresses and passes the data packets to the network stack for further processing. The MAC interface may also be configured in a test mode where the protocol engine has direct control over the MAC interface bypassing the network stack . In this test mode the protocol engine may send and receive Ethernet frames directly through the MAC send and receive buffers . In test mode the protocol engine is responsible for generating packets including the destination address source address Ethernet frame type and length fields and the packet data payload. When a valid Ethernet data packet is received the MAC interface passes the entire packet to the protocol engine .

The preferred MAC interface currently supports 10 100 Mbps Ethernet and requires a system clock running at a minimum frequency of 8 MHz for 10 Mbps operation. Using the minimum system clock frequency allows the network stack to sustain a throughput equal to the full 10 Mbps Ethernet bandwidth. When the PPP data link path is present a higher minimum system clock frequency may be required. The minimum system clock frequency is then dependent upon the speed of the PPP data link. Alternative embodiments may include higher speed Ethernet and PPP data links.

The MAC interface supports both full duplex and half duplex modes of operation. The default mode is fault duplex and the MAC interface can process and generate pause frames to perform flow control with its data link partner. The flow control mechanism is designed to avoid a receive FIFO over run condition. When the MAC buffer management receives Ethernet packets from the internal MAC or the external MAC it monitors the memory usage in the second level memory receive FIFO. When there are 64 or less bytes left in the FIFO the buffer management logic asserts the start pause signal to the pause frame generator module. The pause frame generator module begins to send a pause frame with a maximum pause size to either the internal MAC or the external MAC . The buffer management continues to keep track of the memory usage until there are 128 or more bytes available in the FIFO. It then sends an end pause signal to the pause frame generator module. The pause frame generator logic sends a pause frame of zero pause size to end the flow control mechanism. Upon receiving pause frames the transmit engine in the internal MAC halts any further transmission if there is one after the completion of the current frame. In half duplex mode the internal MAC issues jam sequences if the first level receive FIFO has one byte open indicating a close to full condition during receive.

The internal MAC provides an AutoPHY feature to start auto negotiation with the data link partner. The protocol engine first programs the desired link capabilities to registers before enabling the AutoPHY feature. The internal MAC attempts to negotiate capabilities with the PHY chip connected to the other end of the data link through the management data input output MDIO registers on the PHY chip connected to the internal MAC . MDIO is an IEEE standard two wire bus that allows for communications with physical layer PHY devices. The negotiation involves reading and writing to MDIO registers and is implemented in hardware. When auto negotiation is completed and the data link status signal is asserted the internal MAC interrupts the protocol engine . The data link capabilities that were negotiated are reported in registers. If the protocol engine does not use the AutoPHY feature it first examines the PHY connected to the internal MAC by accessing the MDIO registers in the PHY. The protocol engine then programs the capabilities accepted by the PHY to the MAC configuration registers.

The protocol engine sets up desired capabilities through the AutoPHY feature or by manually examining the PHY chip before the internal MAC can be enabled. The other required setup is to program the local Ethernet 48 bit hardware address. If multicast packets are supported the multicast mask and address should also be programmed into the appropriate registers. If all other default configuration parameters in the registers are acceptable the protocol engine can enable the MAC interface by setting the MAC configuration registers

This section describes how the MAC interface may be reset. To minimize any packet loss due to reset during both hard and soft resets the MAC interface is first disabled by clearing bits in the MAC configuration register. A soft reset available for the MAC interface resets all state machines and buffer memory pointers maintained by the MAC buffer management block. However almost all configurations are preserved by the internal MAC upon soft reset. The protocol engine preferably waits until the soft reset done interrupt status sets before re enabling either transmit or receive. Once the soft reset done interrupt is generated the protocol engine programs any unicast and multicast addresses through registers. Transmit and receive are now ready to be enabled by setting the MAC configuration register. Both hard resets and global soft resets perform a reset for the whole of the MAC interface including all the configuration bits.

This section describes the network stack memory architecture. The network stack uses a network stack internal memory for its buffers and work area. is a diagram that shows a network stack internal memory map according to the invention. In the present implementation the network stack internal memory is divided into two main sections of 2 KB and 8 KB. Both sections of the network stack internal memory use single port SRAM although the sizes of the memory and the sections and their uses may be varied greatly and the network stack internal memory may use different types of memory in different embodiments for different applications. In the present implementation the IP filter engine uses two different areas of the network stack internal memory . These two different areas are kept in different sections. The lower 4 KB of the IP filter memory is the area into which packet data is streamed for both transmit and receive . From this lower 4 KB IP filter memory data packets may be copied to or from internal memory or to or from external memory . Alternatively data packets may be copied to and from the lower 4 KB IP filter memory to the upper 2 KB IP filter memory under control of the IP filter. This feature is useful for unsupported packet types for example which are put aside in the upper 2 KB memory for the protocol engine to handle. The upper 2 KB IP filter memory buffer is also used as a raw IP buffer. The rest of the network stack internal memory is used for TCP header assembly PAP and CHAP authentication and a shared buffer for PPP or ARP.

The following sections provide an overview of the protocol engine . The communications processor uses a protocol engine for programmability. This protocol engine is also attached to a variety of peripherals including a standard memory management unit MMU which expands the addressable memory space of the protocol engine to 1 MB. In addition the protocol engine has access to all of the registers of the communication processor .

With the addition of the MMU the protocol engine has access to 1 MB of memory space. This memory space is divided into RAM and ROM memory types. A register within the MMU specifies the boundary between RAM and ROM memory types. Providing there is no other memory activity and the attached memory is fast enough the protocol engine can completes a memory accesses without added wait states.

The protocol engine uses a set of registers and interrupts to interface to an optional external CPU microprocessor or microcontroller . Eight interface registers are provided for any mutually agreed upon use by the protocol engine and external CPU microprocessor or microcontroller . When the external CPU microprocessor or microcontroller reads or writes data to any of the registers an access interrupt may be made to trigger indicating to the protocol engine that an interface register has been accessed by the external CPU microprocessor or microcontroller .

In addition to this access interrupt the external CPU microprocessor or microcontroller may also interrupt the protocol engine by asserting a bit in a control register. This action causes an interrupt back to the protocol engine assuming the protocol engine has enabled the external interrupt. The protocol engine can then clear this interrupt by writing to the control register.

In a similar fashion the protocol engine can send an interrupt back to the external CPU microprocessor or microcontroller by asserting an interrupt bit in the control register. This action causes the external controller interrupt to trigger assuming that the external CPU microprocessor or microcontroller has enabled the interrupt. The external CPU microprocessor or microcontroller can clear the interrupt by writing to the control register.

This section describes a direct data access mode that optimizes data transfers between the network stack and an external CPU microprocessor or microcontroller . When receiving data without the direct data access mode enabled the protocol engine must read data from the socket receive buffer manage a temporary buffer in its memory space and have the external CPU microprocessor or microcontroller read the data from the memory space of the protocol engine . Using the direct data access mode the external CPU microprocessor or microcontroller can read data directly from the socket receive buffer avoiding a data copy. The direct data access mode also applies for data writes. In the case of writes the external CPU microprocessor or microcontroller can write data directly to the socket transmit buffer .

To enable the direct data access mode the protocol engine asserts the direct data mode bit in the miscellaneous control register. The protocol engine then writes the appropriate memory address to a register. This is the address of the register that the external CPU microprocessor or microcontroller is attempting to access. The protocol engine then informs the external CPU microprocessor or microcontroller how much data there is to be read or how much room there is to write. Once the external CPU microprocessor or microcontroller has this information and is granted permission to use the direct data access mode the external CPU microprocessor or microcontroller begins reading data or writing data.

When using an external CPU microprocessor or microcontroller the protocol engine has a mechanism via the direct data access mode to temporarily block the external CPU microprocessor or microcontroller from accessing the network stack . To block access the protocol engine first set a bit in the miscellaneous control register. The protocol engine then polls the idle bit in the same register and waits until that bit is asserted. The protocol engine then de asserts the direct data access mode bit in the miscellaneous control register. At this point the protocol engine may again access the network stack . When protocol engine is finished with an access to the network stack the protocol engine de asserts the block external CPU bit and re asserts the direct data access mode bit. This is done in one write cycle to the miscellaneous control register. While the block external CPU bit is asserted the external CPU microprocessor or microcontroller is waited when it tries to access the network stack . Therefore it is critical that the protocol engine remember to de assert the block external CPU bit when it is done accessing the network stack .

This section describes the peripheral support for the protocol engine . The following peripherals are included in the preferred embodiment 

This section describes the memory management unit MMU . The protocol engine in the present version can only access 64 KB of memory by itself. With the addition of the MMU the protocol engine memory is extended to 1 MB of physical memory. The protocol engine memory is banked in such a way that at any given time the protocol engine is still only accessing 64 KB of logical memory.

This section describes the direct memory access DMA engine and DMA controller DMAC . The DMAC moves data from one memory or I O location to another in an automatic fashion thus allowing the protocol engine to continue to perform other functions. All DMA transfers are performed in bytes.

This section describes the general purpose timers and watchdog timer used by the protocol engine and communications processor . The present version of the communications processor supports four general purpose 32 bit timers that may either be used independently or joined together in a cascaded fashion. All timers provide a single programmable counter that triggers either a one time interrupt or continuously triggers a repeating loop interrupt that repeats at a programmed periodic rate.

The following sections describe the specialized data processing engines and specialized protocol processing engines that may be added to the communications processor . Although particular examples of engines that perform specific operations on data or perform specific assist functions or offload specific protocols are described here it is to be understood that the approach is a general one and that other data processing engines or other protocol processing engines may easily be added using the same basic architecture. In general the specialized data processing engines operate at or near the Presentation or Application layer. In general the specialized protocol processing engines operate at the Network Transport or Presentation layers often called upper level protocols those that are layered above TCP or IP for example .

This section describes a Base encoder and decoder . Base is used as an encoding scheme for transmitting binary data over Internet connections. It takes three characters in and transforms them into four characters within a 64 character mapping. The preferred Base encoder and decoder implements the Base algorithm as specified and described in the Internet Engineering Task Force IETF RFC1341. Base is an encoding scheme and not a compression scheme in that Base takes three bytes of data and transforms the three bytes of data into four bytes of data. Therefore the transformed data takes up more space then the original data. When encoding data a CR LF carriage return and linefeed character pair is inserted every 64 characters. These CR LF character pairs are ignored when decoding data. Also if the original data set does not contain an even multiple of three bytes then padding bytes consisting of 0x00 are used to fill up the missing bytes. If a six bit Base code contains nothing but padding bits then the resulting Base data byte is . The resulting Base data set always contains a multiple of tour bytes. When decoding data and the padding byte is detected the resulting six bit Base code is 0x00. Any resulting data byte that contains nothing but padding bits is not output.

This section describes the hardware assisted text rasterization engine . Text rasterization converts incoming packet data that is in ASCII format to a bitmap format. This bitmap format is then used for printing to specialized devices such as an LCD screen or a printer. The text rasterization engine has two different rasterization modes 8 bit ASCII and 16 bit character mode. A different font memory is supplied depending on which rasterization mode is used. If the hardware assisted text rasterization engine is used in conjunction with the G engine then the G engine must be enabled prior to enabling the hardware assisted text rasterization engine .

This section describes the G encoder . The G encoder takes output from the hardware assisted text rasterization engine and Huffman encodes the data to put it in the proper format for fax transmission. A source memory address which contains the rasterized data and a target memory address where the encoded data is stored is programmed into the G encoder prior to the stan of each session.

This section describes the Mime string search engine . The Mime string search engine searches a buffer for specified character strings. It reports back the starting and ending offsets for the string and is also capable of searching across multiple buffers. The Mime string search engine can also automatically search a data buffer for the POP termination string CR LF . CR LF . This type of specialized data processing engine might equally well be used for example to insert or detect tags markers or perform framing in a streaming protocol such as TCP in order to convert such a streaming protocol into a block based protocol.

This section describes the ADPCM accelerator engine . The ADPCM accelerator engine provides 2 1 and 4 1 compression and decompression functions. The ADPCM accelerator engine operates on a buffer of data in memory and puts the compressed or decompressed data back to memory. For compression the source and destination memory addresses can be the same because the compressed data take less room than the original data.

This section describes the IP only mode of operation of the network stack . is a block schematic diagram showing an IP only mode data path according to the invention. The IP only mode is provided so that non Ethernet or non PPP data links can be used. By default the IP only mode comes up disabled after resets. When the IP only mode is enabled both the Ethernet data link and the PPP data link are disabled. The data packets are tapped off at the IP raw mux . Therefore the IP router bottom engine is configured to send all data out the Ethernet data link. The IP only data still uses the MAC transmit and receive buffers . This prevents under run conditions and allows for retransmission on bad packets. To set the source IP address for this mode the system programs the local IP Address registers in the ARP engine . The IP only transmit interface works through the data link SPI interface. The data format used for the IP packet starts with the IP header and goes through the data field. No extra checksum or padding bytes are appended

This section describes the data link SPI interface of the communications processor . The data link SPI interface is used when communicating using the IP only mode or when using an external MAC. When the internal MAC is enabled then the data link SPI interface is disabled. When receiving packets only one data packet is stored in the receive buffer at a time. This only applies to packets that are made available to the protocol engine because all data packets go to the network stack . If another non data packet is received but the previous packet is still in the data link SPI receive buffer then the second packet is discarded.

This section describes the integrated test and debug features of the communications processor . Combined with an external CPU microprocessor or microcontroller the debug features allow breaking on an address and single stepping. The address comparison is made with the protocol engine physical 20 bit address 1 MB memory space . Breaks can be triggered on either reads or writes with each type of operation individually controlled. Two separate break point addresses are provided for flexibility. All registers associated with the protocol engine debugger are located in the protocol engine miscellaneous index registers. The communications processor uses built in self test BIST to test the internal RAMs scan testing for general fault coverage and NAND tree logic for parametric I O testing. Four dedicated test pins are provided for the communications processor .

This section describes the clocking features of the communications processor . The communications processor features a clocking mechanism that allows it to run the MAC buffers at a higher clock frequency then the rest of the communications processor . In addition the network stack logic can be made to operate at a different clock frequency then the protocol engine . The protocol engine may also slow itself down in order to conserve power during idle periods. The clocking logic also provides for a programmable clock output that can be used to drive system logic . 

Although the invention is described herein with reference to the preferred embodiment one skilled in the art will readily appreciate that other applications may be substituted for those set forth herein without departing from the spirit and scope of the present invention. Accordingly the invention should only be limited by the Claims included below.

