---

title: Using a WIKI editor to create speech-enabled applications
abstract: The present invention discloses a system and a method for creating and editing speech-enabled WIKIs. A WIKI editor can be served to client-side Web browsers so that end-users can utilize WIKI editor functions, which include functions to create and edit speech-enabled WIKI applications. A WIKI server can serve speech-enabled WIKI applications created via the WIKI editor. Each of the speech-enabled WIKI applications can include a link to at least one speech processing engine located in a speech processing system remote from the WIKI server. The speech processing engine can provide a speech processing capability for the speech-enabled WIKI application when served by the WIKI server. In one embodiment, the speech-enabled applications can include an introspection document, an entry collection of documents, and a resource collection of documents in accordance with standards specified by an ATOM PUBLISHING PROTOCOL (APP).
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07890333&OS=07890333&RS=07890333
owner: International Business Machines Corporation
number: 07890333
owner_city: Armonk
owner_country: US
publication_date: 20070620
---
This continuation in part application claims the benefit of U.S. patent application Ser. No. 11 765 900 filed Jun. 20 2007 the benefit of U.S. patent application Ser. No. 11 765 928 filed Jun. 20 2007 and the benefit of U.S. patent application Ser. No. 11 765 962 filed Jun. 20 2007 which are incorporated by reference herein.

The present invention relates to the field of WIKI creation and editing and more particularly to using a WIKI editor to create speech enabled applications.

A WIKI is a collaborative web application that allows end users to add and edit content. A WIKI application refers to a collection of WIKI pages written in a markup language that are interconnected via hyperlinks. WIKIs are served by a WIKI server to standard Web browsers which function as WIKI clients. A WIKI server can also serve a special Web page that is a WIKI editor where users add and edit content. Some WIKI sites permit WIKI content to be written in accordance with a WIKI syntax such as having special characters to indicate hyperlinked content bulleted content and the like. WIKI syntax is generally designed to be more intuitive for end users to utilize than standard markup languages.

Conventional WIKIs do not incorporate speech processing technologies. Such technologies can require a WIKI server or WIKI pages to be integrated with a server side speech processing system. Traditional interface mechanisms to these speech processing systems rely upon specialized voice toolkits such as IBM s WEBSPHERE VOICE SERVER WVS voice toolkit. Use of these toolkits requires some knowledge of speech processing technologies that is beyond a proficiency of most end users and even many programmers. Since end users are content providers of WIKI applications this effectively prevents WIKI applications from utilizing speech processing technologies.

The present invention discloses a WIKI editor for building speech enabled applications. The WIKI editor can be served as Web pages to clients that include Web browsers which render the WIKI editor for users of the client. In one embodiment an extended WIKI syntax for voice can be used to specify speech processing elements. Standard buttons and functions of the WIKI editor can be overloaded for speech processing capabilities. For example a preview button of the WIKI editor can be overloaded to render voice markup and or voice syntax so that users can test their speech enabled applications directly from their Web browser. In another embodiment standard WIKI syntax can dynamically transform normal WIKI syntax for HTML into VoiceXML at runtime using associated transformation style sheets. In still another embodiment the WIKI editor can include a graphical user interface GUI development tool for voice capable of creating graphical call flows using visual development tools.

A number of advantages are inherent in utilizing the Web 2.0 WIKI editor approach to build speech enabled applications over using standard development tools and approaches. The disclosed WIKI editor for example automatically facilitates concurrent development in the same application a speech enabled application includes multiple linked WIKI entries pages . Different people potentially located remotely from each other can edit the same speech enabled application at the same time. The speech enabled application being edited developed using the disclosed WIKI editor can be live applications where a developer can be permitted to preview changes on line before saving them. Further the disclosed WIKI editor can have a standard WIKI editor look feel which minimizes developer training time and which makes it easy for developers to intuitively construct speech enabled applications using different WIKI editors associated with different WIKI servers.

The present invention can be implemented in accordance with numerous aspects consistent with the material presented herein. For example one aspect of the present invention can include a system for creating and editing speech enabled WIKIs including a WIKI editor and a WIKI server. The WIKI editor can be served to client side Web browsers so that end users can utilize WIKI editor functions which include functions to create and edit speech enabled WIKI applications. The WIKI server can serve speech enabled WIKI applications created via the WIKI editor. Each of the speech enabled WIKI applications can include a link to at least one speech processing engine located in a speech processing system remote from the WIKI server. The speech processing engine can provide a speech processing capability for the speech enabled WIKI application when served by the WIKI server. In one embodiment the speech enabled applications can include an introspection document an entry collection of documents and a resource collection of documents in accordance with standards specified by an ATOM PUBLISHING PROTOCOL APP .

Another aspect of the present invention can include a method of creating and editing speech enabled WIKIs. In the method a WIKI editor can be accessed from a client interface. Input can be accepted via the client interface. This input can be processed to create content for a speech enabled WIKI entry which can be saved in a data store accessible by a WIKI server. The WIKI entry can establish a link with at least one speech processing engine located in a speech processing system remote from the WIKI server. The speech processing engine can provide a speech processing capability for the WIKI entry when served by the WIKI server.

Still another aspect of the present invention can include a method for developing speech enabled applications. The method can include a step of presenting a WIKI editor to an end user via a Web browser. WIKI syntax can be received from the end user through the WIKI editor. The WIKI syntax can be transformed into a voice markup language format such as VoiceXML to create a speech enabled application. The speech enabled application can be served to at least one WIKI client.

It should be noted that various aspects of the invention can be implemented as a program for controlling computing equipment to implement the functions described herein or as a program for enabling computing equipment to perform processes corresponding to the steps disclosed herein. This program may be provided by storing the program in a magnetic disk an optical disk a semiconductor memory or any other recording medium. The program can also be provided as a digitally encoded signal conveyed via a carrier wave. The described program can be a single program or can be implemented as multiple subprograms each of which interact within a single computing device or interact in a distributed fashion across a network space.

It should also be noted that the methods detailed herein can also be methods performed at least in part by a service agent and or a machine manipulated by a service agent in response to a service request.

In one embodiment a syntax transformer can utilize a set of style sheets to convert normal WIKI syntax to a speech enabled syntax such as a VoiceXML syntax. In another embodiment a sandbox can exist that permits the user to work on the application in a non live computing space which others are unable to access. There are no assumptions regarding the clients that access applications served by server other than an ability to communicate with the WIKI server using standard WIKI protocols.

The speech system can be a network accessible system of speech processing resources. The system can be a turn based speech system which provides speech recognition speech synthesis speaker identification and verification and other speech processing services. In one embodiment the speech system can be an implementation of IBM s WEBSPHERE VOICE SERVER although the invention is not limited in this regard. The speech processing engines of system can be accessed through a set of RESTful commands such as GET PUT POST and or DELETE.

The method of which includes steps can be performed in the context of environment . The method can begin in step where a user of a Web browser can connect to the WIKI editor . Step shows that the method selectively branches based upon WIKI editor implementation details. In different embodiments the WIKI editor can dynamically convert normal WIKI syntax to a speech enabled syntax can include an enhanced WIKI syntax that has been extended for voice and can include a software development tool for graphically creating speech enabled applications. These implementation mechanisms are used to illustrate that speech enabled applications can be constructed from a server side WIKI editor in various ways. The disclosed invention is not to be limited in this regard.

When the WIKI editor dynamically converts normal WIKI syntax to voice syntax the method can proceed from step to steps . In step a user can create modify a standard WIKI application . In step an associated transformation style sheet can be identified created and or modified by the user. In step a runtime transformer can convert the WIKI application into a WIKI for voice application in accordance with details specified by the style sheet. In step the user can optionally test edit or otherwise configure the style sheet the standard WIKI application and or the generated WIKI application for voice. In step the WIKI for voice application can be stored in a WIKI data store accessible by a WIKI server . In subsequent step the WIKI server can serve the stored WIKI application for voice to clients.

When the WIKI editor supports an extended WIKI syntax that has been extended for voice the method can proceed from step to steps . In step the user can create or modify a WIKI application using WIKI syntax that has been extended for voice. In step a created WIKI application for voice can be optionally tested edited and or tuned using a WIKI editor. In step the WIKI application can be stored. The stored application can be served by a WIKI server in step .

When the WIKI editor includes a GUI software development tool for visually constructing speech enabled applications the method can proceed from step to steps . In step a user can access a graphical development tool. In step the user can visually model a speech enabled WIKI using the graphical development tool. In step the tool can generate WIKI syntax extended for voice WIKI for voice markup VoiceXML markup and the like. In optional step the user can optionally edit test and or tune application specifics. In step the WIKI application for voice can be stored where it is served by a WIKI server in subsequent step .

More specifically shows a WIKI page in GUI that is constructed with a WIKI editor using WIKI syntax. The WIKI page is visually presented responsive to a user selecting a preview tab of the associated WIKI editor which is rendered in a Web browser. The content presented in the home page corresponds to content specified by WIKI syntax as shown in GUI . For example WIKI syntax h1. WebSphere Voice Server Homepage shown in GUI corresponds to the title WebSphere Voice Server Homepage shown in GUI .

GUI includes a number of different tabs such as a rich text tab a WIKI markup tab a preview tab a style sheet tab a generated voice markup tab and a configure speech resources tab . It should be appreciated that the WIKI markup shown in GUI is written in a normal WIKI syntax. This normal syntax can be dynamically converted into a voice format such as shown by the steps of . The style sheet tab can permit a user to specify details of a style sheet used to transform the normal WIKI syntax into a voice markup format. Selection of the generated voice markup tab can cause voice markup such as VoiceXML markup to be automatically generated from the WIKI markup in accordance with a style sheet specified by tab .

Additionally the configure speech resources tab can present a set of user configurable options relating to speech processing operations. The options displayed responsive to a selection of tab can permit a user to customize which speech resources are available to the WIKI entry speech processing characteristics e.g. language grammar voice attributes such as name or gender result characteristics e.g. results synchronous or asynchronous real time or batch processed results a media location and type for input output and other such settings.

The GUI can provide a number of visual software development tools to the user which can be arranged on a development canvas. The tools can include dialog construction components including but not limited to components for start statements prompts comments configuration decision processing transfer to an agent end goto global commands and the like. The canvas can be used to create and link multiple WIKI entries and . Each entry and can be a speech enabled WIKI page. For example the entry can include a dialog prompt for selecting a vehicle and a speech recognition grammar including entries for shuttle rocket enterprise and teleporter.

The builder tool of GUI can be a full featured voice development environment served by a WIKI server and presented within a Web browser. The builder tool can include for example a graphical call building component a VoiceXML development and debugging component a grammar development and debugging component a pronunciation builder component a Call Control Extensible Markup Language CCXML development component a speech resource configuration tool and the like.

It should be appreciated that the GUIs and are provided for illustrative purposes only and that the interface of the disclosed WIKI editor is not to be limited to precise arrangements shown therein. That is the GUIs and represent contemplated embodiments of general concepts of a WIKI editor for creating editing speech enabled applications which can be situationally adapted as desired. That is graphical elements menu options toolbars tabs pop up windows configuration options and the like of a WIKI editor for voice can be implemented in any sensible manner and not necessarily in accordance with specific elements illustrated in the sample GUIs and .

In system a browser can communicate with Web 2.0 server via Representational State Transfer REST architecture ATOM based protocol. The Web 2.0 server can communicate with a speech for Web 2.0 system via a REST ATOM based protocol. Protocols can include HTTP and similar protocols that are RESTful by nature as well as an Atom Publishing Protocol APP or other protocol that is specifically designed to conform to REST principles.

The Web 2.0 server can include a data store in which applications which can be speech enabled are stored. In one embodiment the applications can be written in a WIKI or other Web 2.0 syntax and can be stored in an APP format.

The speech enabled application can be accessed via an introspection document per the APP protocol. The application can contain a collection of entries and resources . The entries can specify a set of WIKI pages. Each WIKI page entry can be further decomposed into collections having a lower level of granularity such as WIKI page sections. The resources can include speech processing resources and their particulars such as ASR resources TTS resources SIV resources VXML interpreter resources and the like. Each resource can be further decomposed into configurable resource specifics such as a speech recognition grammar for a related WIKI page a recognition language and the like. The speech application elements can be introspected customized replaced added re ordered or removed by an end user utilizing browser using editor . The editor can be a standard WIKI editor having a voice plug in or extensions .

The transformer can convert WIKI or other Web 2.0 syntax into standard markup for browsers. In one embodiment the transformer can be an extension of a conventional transformer that supports HTML and XML. The extended transformer can be enhanced to handle JAVA SCRIPT such as AJAX. For example resource links of application can be converted into AJAX functions by the transformer having an AJAX plug in . The transformer can also include a VoiceXML plug in which generates VoiceXML markup for voice only clients.

In system Web 2.0 clients can communicate with WIKI server utilizing a REST ATOM protocol. The WIKI server can serve one or more speech enabled applications where speech resources are provided by a Web 2.0 for Voice system . One or more of the applications can include AJAX or other JavaScript code. In one embodiment the AJAX code can be automatically converted from WIKI or other syntax by a transformer of server .

Communications between the WIKI server and system can be in accordance with REST ATOM protocols. Each speech enabled application can be associated with an ATOM container which specifies Web 2.0 items resources and media . One or more resource can correspond to a speech engine .

The Web 2.0 clients can be any client capable of interfacing with WIKI server . For example the clients can include a Web or voice browser as well as any other type of interface which executes upon a computing device. The computing device can include a mobile telephone a mobile computer a laptop a media player a desktop computer a two way radio a line based phone and the like. Unlike conventional speech clients the clients need not have a speech specific interface and instead only require a standard Web 2.0 interface. That is there are no assumptions regarding the client other than an ability to communicate with a WIKI 2.0 server using WIKI conventions.

The Web 2.0 for voice system can utilize Web 2.0 concepts to provide speech capabilities. A server side interface is established between the voice system and a WIKI server . Available speech resources can be introspected and discovered via introspection documents which are one of the Web 2.0 items . Introspection can be in accordance with the APP specification or a similar protocol. The ability for dynamic configuration and installation is exposed to the server via the introspection document.

That is access to Web 2.0 for voice system can be through a Web 2.0 server that lets users e.g. clients provide their own customizations personalizations. Appreciably use of the APP opens up the application interface to speech resources using Web 2.0 JAVA 2 ENTERPRISE EDITION J2EE WEBSPHERE APPLICATION SERVER WAS and other conventions rather than being restricted to protocols such as media resource control protocol MRCP real time streaming protocol RTSP or real time protocol RTP .

A constrained set of RESTful commands can be used to interface with the Web 2.0 for voice system . RESTful commands can include a GET command a POST command a PUT command and a DELETE command each of which is able to be implemented as an HTTP command. As applied to speech GET e.g. HTTP GET can return capabilities and elements that are modifiable. The GET command can also be used for submitting simplistic speech queries and for receiving query results.

The POST command can create media related resources using speech engines . For example the POST command can create an audio file from input text using a text to speech TTS resource which is linked to a TTS engine . The POST command can create a text representation given an audio input using an automatic speech recognition ASR resource which is linked to an ASR engine . The POST command can create a score given an audio input using a Speaker Identification and Verification SIV resource which is linked to a SIV engine . Any type of speech processing resource can be similarly accessed using the POST command.

The PUT command can be used to update configuration of speech resources e.g. default voice name ASR or TTS language TTS voice media destination media delivery type etc. The PUT command can also be used to add a resource or capability to a WIKI server e.g. installing an SIV component . The DELETE command can remove a speech resource from a configuration. For example the DELETE command can be used to uninstall a previously installed speech component.

The Web 2.0 for Voice system is an extremely flexible solution that permits users of clients to customize numerous speech processing elements. Customizable speech processing elements can include speech resource availability request characteristics result characteristics media characteristics and the like. Speech resource availability can indicate whether a specific type of resource e.g. ASR TTS SIV Voice XML interpreter is available. Request characteristics can refer to characteristics such as language grammar voice attributes gender rate of speech and the like. The result characteristics can specify whether results are to be delivered synchronously or asynchronously. Result characteristics can alternatively indicate whether a listener for callback is to be supplied with results. Media characteristics can include input and output characteristics which can vary from a URI reference to an RTP stream. The media characteristics can specify a codec e.g. G711 a sample rate e.g. 8 KHz to 22 KHz and the like. In one configuration the speech engines can be provided from a J2EE environment such as a WAS environment. This environment can conform to a J2EE Connector Architecture JCA .

In one embodiment a set of additional facades can be utilized on top of Web 2.0 protocols to provide additional interface and protocol options e.g. MRCP RTSP RTP Session Initiation Protocol SIP etc. to the Web 2.0 for voice system . Use of facades can enable legacy access use of the Web 2.0 for voice system . The facades can be designed to segment the protocol from underlying details so that characteristics of the facade do not bleed through to speech implementation details. Functions such as the WAS . channel framework or a JCA container can be used to plug in a protocol which is not native to the J2EE environment . The media component of the container can be used to handle media storage delivery and format conversions as necessary. Facades can be used for asynchronous or synchronous protocols .

The present invention may be realized in hardware software or a combination of hardware and software. The present invention may be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software may be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention also may be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program in the present context means any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation b reproduction in a different material form.

This invention may be embodied in other forms without departing from the spirit or essential attributes thereof. Accordingly reference should be made to the following claims rather than to the foregoing specification as indicating the scope of the invention.

