---

title: Audio file interface
abstract: Methods, systems, and computer-readable medium for providing an audio file interface. In one implementation, a method is provided. The method includes, while playing an audio file on a mobile device and displaying a current view in a user interface of the mobile device, receiving first user input requesting that an audio interface be displayed, and displaying the audio interface as an overlay in the user interface, where the audio interface includes information associated with the audio file.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09477395&OS=09477395&RS=09477395
owner: APPLE INC.
number: 09477395
owner_city: Cupertino
owner_country: US
publication_date: 20070904
---
Conventional mobile devices often include an interactive user interface. Typically a user can input information into the user interface to manipulate configure operate the mobile device. For example the user may enter input such as text motions uploads voice commands or other information to perform tasks on the mobile device. In some implementations the user interface can be configured to output or present information related to the user input to the user. The device may produce as output an effect based on the user input. For example a user input can cause the mobile device to turn on or off.

Whether providing input or receiving output users generally want to be able to control the system and assess the state of the system at some point in time. As such the design of a user interface can affect the amount of effort expended by a user in providing input to and interpreting output from the system. In addition the design may dictate how much effort is spent to learn how to input entries and interpret output. Accordingly usability and aesthetics can be considered in designing user interfaces for mobile devices.

A technique method apparatus and system are described to provide an audio file interface. In general in one aspect a method is provided. The method includes while playing an audio file on a mobile device and displaying a current view in a user interface of the mobile device receiving first user input requesting that an audio interface be displayed and displaying the audio interface as an overlay in the user interface where the audio interface includes information associated with the audio file.

Implementations can include one or more of the following features. The overlay can be partially transparent. The audio interface can be displayed as an overlay over the current view displayed in the user interface. In response to the first user input a new view can be displayed in the user interface where the new view includes an image associated with the audio file and the audio interface is displayed as an overlay over the new view displayed in the user interface.

Implementations can include one or more of the following features. The transition from displaying the current view in the user interface to displaying the new view in the user interface can be animated. In one transition animation a shrinking of the current view in the user interface can be followed by an expanding of the new view in the user interface. In another transition animation the current view can slide off a vertical edge of the user interface and the new view can slide on from another vertical edge of the user interface. In yet another animation a wiping away of the current view from a horizontal edge of the user interface to reveal the new view as it appears from a same horizontal edge of the user interface is animated. A radial wiping away of the current view in the user interface to reveal the new view in the user interface can be animated. An enlarging burning hole in the current view in the user interface can be animated with an increasing portion of the new view being displayed inside the enlarging burning hole. In another animation transition an expanding ripple can be animated with the current view fading out and the new view fading in as the ripple expands.

Implementations can include one or more of the following features. The information associated with the audio file included in the audio interface can include one or more of a performer a song an album a track number an elapsed time or a remaining time. The information associated with the audio file included in the audio interface can include a link to a resource where the audio file is accessible such that selection of the link displays content from the resource. The audio interface can include one or more user interface elements for changing the playing of the audio file. The one or more user interface elements can allow one or more of changing a volume level pausing stopping skipping to a point in the audio file or skipping to another audio file. The method can include while the audio interface is displayed in the user interface receiving second user input requesting that the audio interface not be displayed and in response to the second user input displaying the current view in the user interface without the audio interface. The mobile device can include a multi touch sensitive display.

In one aspect a method is provided. The method includes receiving input at a mobile device where the mobile device includes a user interface with an interface element determining a state of the interface element or a context of the mobile device and in response to the received input performing a predetermined action based on the determination.

Implementations can include one or more of the following features. The predetermined action can be displaying a particular interface on the mobile device. The input can be received at a single hardware button for navigating the user interface of the mobile device.

In one aspect a mobile device is provided. The mobile device includes a multi touch sensitive display a user interface with an interface element and a hardware button where selection of the hardware button causes the mobile device to display a particular interface and the particular interface is based on a determination of a state of the interface element or a context of the mobile device. Implementations can include the following feature. The hardware button can be for navigating the user interface of the mobile device.

In one aspect a computer readable medium is provided. The computer readable medium has instructions stored thereon which when executed by a processor causes the processor to perform operations including receiving input at a mobile device including a user interface with an interface element determining a state of the interface element or a context of the mobile device and in response to the received input performing a predetermined action based on the determination.

Implementations can include one or more of the following features. The predetermined action can be displaying a particular interface on the mobile device. The input can be received at a single hardware button for navigating the user interface of the mobile device.

In some implementations the mobile device includes a touch sensitive display . The touch sensitive display can implement liquid crystal display LCD technology light emitting polymer display LPD technology or some other display technology. The touch sensitive display can be sensitive to haptic and or tactile contact with a user.

In some implementations the touch sensitive display can comprise a multi touch sensitive display . A multi touch sensitive display can for example process multiple simultaneous touch points including processing data related to the pressure degree and or position of each touch point. Such processing facilitates gestures and interactions with multiple fingers chording and other interactions. Other touch sensitive display technologies can also be used e.g. a display in which contact is made using a stylus or other pointing device. Some examples of multi touch sensitive display technology are described in U.S. Pat. Nos. 6 323 846 6 570 557 6 677 932 and 6 888 536 each of which is incorporated by reference herein in its entirety.

In some implementations the mobile device can display one or more graphical user interfaces on the touch sensitive display for providing the user access to various system objects and for conveying information to the user. In some implementations the graphical user interface can include one or more display objects . In the example shown the display objects are graphic representations of system objects. Some examples of system objects include device functions applications windows files alerts events or other identifiable system objects.

In some implementations the mobile device can implement multiple device functionalities such as a telephony device as indicated by a phone object an e mail device as indicated by the e mail object a network data communication device as indicated by the Web object a Wi Fi base station device not shown and a media processing device as indicated by the media player object . In some implementations particular display objects e.g. the phone object the e mail object the Web object and the media player object can be displayed in a menu bar . In some implementations device functionalities can be accessed from a top level graphical user interface such as the graphical user interface illustrated in . Touching one of the objects or can for example invoke corresponding functionality.

In some implementations the mobile device can implement network distribution functionality. For example the functionality can enable the user to take the mobile device and provide access to its associated network while traveling. In particular the mobile device can extend Internet access e.g. Wi Fi to other wireless devices in the vicinity. For example mobile device can be configured as a base station for one or more devices. As such mobile device can grant or deny network access to other wireless devices.

In some implementations upon invocation of device functionality the graphical user interface of the mobile device changes or is augmented or replaced with another user interface or user interface elements to facilitate user access to particular functions associated with the corresponding device functionality. For example in response to a user touching the phone object the graphical user interface of the touch sensitive display may present display objects related to various phone functions likewise touching of the email object may cause the graphical user interface to present display objects related to various e mail functions touching the Web object may cause the graphical user interface to present display objects related to various Web surfing functions and touching the media player object may cause the graphical user interface to present display objects related to various media processing functions.

In some implementations the top level graphical user interface environment or state of can be restored by pressing a button located near the bottom of the mobile device . In some implementations each corresponding device functionality may have corresponding home display objects displayed on the touch sensitive display and the graphical user interface environment of can be restored by pressing the home display object.

In some implementations the top level graphical user interface can include additional display objects such as a short messaging service SMS object a calendar object a photos object a camera object a calculator object a stocks object a weather object a maps object a notes object a clock object an address book object and a settings object . Touching the SMS display object can for example invoke an SMS messaging environment and supporting functionality likewise each selection of a display object and can invoke a corresponding object environment and functionality.

Additional and or different display objects can also be displayed in the graphical user interface of . For example if the device is functioning as a base station for other devices one or more connection objects may appear in the graphical user interface to indicate the connection. In some implementations the display objects can be configured by a user e.g. a user may specify which display objects are displayed and or may download additional applications or other software that provides other functionalities and corresponding display objects.

In some implementations the mobile device can include one or more input output I O devices and or sensor devices. For example a speaker and a microphone can be included to facilitate voice enabled functionalities such as phone and voice mail functions. In some implementations an up down button for volume control of the speaker and the microphone can be included. The mobile device can also include an on off button for a ring indicator of incoming phone calls. In some implementations a loud speaker can be included to facilitate hands free voice functionalities such as speaker phone functions. An audio jack can also be included for use of headphones and or a microphone.

In some implementations a proximity sensor can be included to facilitate the detection of the user positioning the mobile device proximate to the user s ear and in response to disengage the touch sensitive display to prevent accidental function invocations. In some implementations the touch sensitive display can be turned off to conserve additional power when the mobile device is proximate to the user s ear.

Other sensors can also be used. For example in some implementations an ambient light sensor can be utilized to facilitate adjusting the brightness of the touch sensitive display . In some implementations an accelerometer can be utilized to detect movement of the mobile device as indicated by the directional arrow . Accordingly display objects and or media can be presented according to a detected orientation e.g. portrait or landscape. In some implementations the mobile device may include circuitry and sensors for supporting a location determining capability such as that provided by the global positioning system GPS or other positioning systems e.g. systems using Wi Fi access points television signals cellular grids Uniform Resource Locators URLs . In some implementations a positioning system e.g. a GPS receiver can be integrated into the mobile device or provided as a separate device that can be coupled to the mobile device through an interface e.g. port device to provide access to location based services.

In some implementations a port device e.g. a Universal Serial Bus USB port or a docking port or some other wired port connection can be included. The port device can for example be utilized to establish a wired connection to other computing devices such as other communication devices network access devices a personal computer a printer a display screen or other processing devices capable of receiving and or transmitting data. In some implementations the port device allows the mobile device to synchronize with a host device using one or more protocols such as for example the TCP IP HTTP UDP and any other known protocol. In some implementations a TCP IP over USB protocol can be used as described in U.S. Provisional Patent Application No. 60 945 904 filed Jun. 22 2007 for Multiplexed Data Stream Protocol which provisional patent application is incorporated by reference herein in its entirety.

The mobile device can also include a camera lens and sensor . In some implementations the camera lens and sensor can be located on the back surface of the mobile device . The camera can capture still images and or video.

The mobile device can also include one or more wireless communication subsystems such as an 802.11b g communication device and or a Bluetooth communication device . Other communication protocols can also be supported including other 802.x communication protocols e.g. WiMax Wi Fi 3G code division multiple access CDMA global system for mobile communications GSM Enhanced Data GSM Environment EDGE etc.

In some implementations the mobile device includes a touch sensitive display which can be sensitive to haptic and or tactile contact with a user. In some implementations the mobile device can display one or more graphical user interfaces on the touch sensitive display for providing the user access to various system objects and for conveying information to the user.

In some implementations the mobile device can implement multiple device functionalities such as a music processing device as indicated by the music player object a video processing device as indicated by the video player object a digital photo album device as indicated by the photos object and a network data communication device for online shopping as indicated by the store object . In some implementations particular display objects e.g. the music player object the video player object the photos object and store object can be displayed in a menu bar . In some implementations device functionalities can be accessed from a top level graphical user interface such as the graphical user interface illustrated in . Touching one of the objects or can for example invoke corresponding functionality.

In some implementations the top level graphical user interface of mobile device can include additional display objects such as the Web object the calendar object the address book object the clock object the calculator object and the settings object described above with reference to mobile device of . In some implementations the top level graphical user interface can include other display objects such as a Web video object that provides functionality for uploading and playing videos on the Web. Each selection of a display object and can invoke a corresponding object environment and functionality.

Additional and or different display objects can also be displayed in the graphical user interface of . In some implementations the display objects can be configured by a user. In some implementations upon invocation of device functionality the graphical user interface of the mobile device changes or is augmented or replaced with another user interface or user interface elements to facilitate user access to particular functions associated with the corresponding device functionality.

In some implementations the mobile device can include one or more input output I O devices and a volume control device sensor devices and wireless communication subsystems and and a port device or some other wired port connection described above with reference to mobile device of .

The mobile devices and can also establish communications by other means. For example the wireless device can communicate with other wireless devices e.g. other mobile devices or cell phones etc. over the wireless network . Likewise the mobile devices and can establish peer to peer communications e.g. a personal area network by use of one or more communication subsystems such as the Bluetooth communication devices shown in . Other communication protocols and topologies can also be implemented.

The mobile device or can for example communicate with one or more services and over the one or more wired and or wireless networks . For example a navigation service can provide navigation information e.g. map information location information route information and other information to the mobile device or . A user of the mobile device can invoke a map functionality e.g. by pressing the maps object on the top level graphical user interface shown in and can request and receive a map for a particular location.

A messaging service can for example provide e mail and or other messaging services. A media service can for example provide access to media files such as song files audio books movie files video clips and other media data. In some implementations separate audio and video services not shown can provide access to the respective types of media files. A syncing service can for example perform syncing services e.g. sync files . An activation service can for example perform an activation process for activating the mobile device or . Other services can also be provided including a software update service that automatically determines whether software updates exist for software on the mobile device or then downloads the software updates to the mobile device or where the software updates can be manually or automatically unpacked and or installed.

The mobile device or can also access other data and content over the one or more wired and or wireless networks . For example content publishers such as news sites RSS feeds web sites blogs social networking sites developer networks etc. can be accessed by the mobile device or . Such access can be provided by invocation of a web browsing function or application e.g. a browser in response to a user touching the Web object .

Sensors devices and subsystems can be coupled to the peripherals interface to facilitate multiple functionalities. For example a motion sensor a light sensor and a proximity sensor can be coupled to the peripherals interface to facilitate the orientation lighting and proximity functions described with respect to . Other sensors can also be connected to the peripherals interface such as a positioning system e.g. GPS receiver a temperature sensor a biometric sensor or other sensing device to facilitate related functionalities.

A camera subsystem and an optical sensor e.g. a charged coupled device CCD or a complementary metal oxide semiconductor CMOS optical sensor can be utilized to facilitate camera functions such as recording photographs and video clips.

Communication functions can be facilitated through one or more wireless communication subsystems which can include radio frequency receivers and transmitters and or optical e.g. infrared receivers and transmitters. The specific design and implementation of the communication subsystem can depend on the communication network s over which the mobile device or is intended to operate. For example a mobile device or may include communication subsystems designed to operate over a GSM network a GPRS network an EDGE network a Wi Fi or WiMax network and a Bluetooth network. In particular the wireless communication subsystems may include hosting protocols such that the device or may be configured as a base station for other wireless devices.

An audio subsystem can be coupled to a speaker and a microphone to facilitate voice enabled functions such as voice recognition voice replication digital recording and telephony functions.

The I O subsystem can include a touch screen controller and or other input controller s . The touch screen controller can be coupled to a touch screen . The touch screen and touch screen controller can for example detect contact and movement or break thereof using any of a plurality of touch sensitivity technologies including but not limited to capacitive resistive infrared and surface acoustic wave technologies as well as other proximity sensor arrays or other elements for determining one or more points of contact with the touch screen .

The other input controller s can be coupled to other input control devices such as one or more buttons rocker switches thumb wheel infrared port USB port and or a pointer device such as a stylus. The one or more buttons not shown can include an up down button for volume control of the speaker and or the microphone .

In one implementation a pressing of the button for a first duration may disengage a lock of the touch screen and a pressing of the button for a second duration that is longer than the first duration may turn power to the mobile device or on or off. The user may be able to customize a functionality of one or more of the buttons. The touch screen can for example also be used to implement virtual or soft buttons and or a keyboard.

In some implementations the mobile device or can present recorded audio and or video files such as MP3 AAC and MPEG files. In some implementations the mobile device or can include the functionality of an MP3 player such as an iPod . The mobile device or may therefore include a 36 pin connector that is compatible with the iPod. Other input output and control devices can also be used.

The memory interface can be coupled to memory . The memory can include high speed random access memory and or non volatile memory such as one or more magnetic disk storage devices one or more optical storage devices and or flash memory e.g. NAND NOR . The memory can store an operating system such as Darwin RTXC LINUX UNIX OS X WINDOWS or an embedded operating system such as VxWorks. The operating system may include instructions for handling basic system services and for performing hardware dependent tasks. In some implementations the operating system can be a kernel e.g. UNIX kernel as described in reference to .

The memory may also store communication instructions to facilitate communicating with one or more additional devices one or more computers and or one or more servers. The memory may include graphical user interface instructions to facilitate graphic user interface processing sensor processing instructions to facilitate sensor related processing and functions phone instructions to facilitate phone related processes and functions electronic messaging instructions to facilitate electronic messaging related processes and functions web browsing instructions to facilitate web browsing related processes and functions media processing instructions to facilitate media processing related processes and functions GPS Navigation instructions to facilitate GPS and navigation related processes and instructions camera instructions to facilitate camera related processes and functions and or other software instructions to facilitate other processes and functions e.g. security processes and functions as described in reference to . The memory may also store other software instructions not shown such as web video instructions to facilitate web video related processes and functions and or web shopping instructions to facilitate web shopping related processes and functions. In some implementations the media processing instructions are divided into audio processing instructions and video processing instructions to facilitate audio processing related processes and functions and video processing related processes and functions respectively. An activation record and International Mobile Equipment Identity IMEI or similar hardware identifier can also be stored in memory .

Each of the above identified instructions and applications can correspond to a set of instructions for performing one or more functions described above. These instructions need not be implemented as separate software programs procedures or modules. The memory can include additional instructions or fewer instructions. Furthermore various functions of the mobile device or may be implemented in hardware and or in software including in one or more signal processing and or application specific integrated circuits.

The OS kernel manages the resources of the mobile device or and allows other programs to run and use these resources. Some examples of resources include a processor memory and I O. For example the kernel can determine which running processes should be allocated to a processor processors or processor cores allocates memory to the processes and allocates requests from applications and remote services to perform I O operations. In some implementations the kernel provides methods for synchronization and inter process communications with other devices.

In some implementations the kernel can be stored in non volatile memory of the mobile device or . When the mobile device or is turned on a boot loader starts executing the kernel in supervisor mode. The kernel then initializes itself and starts one or more processes for the mobile device or including a security process for remote access management.

The library system provides various services for applications running in the application layer . Such services can include audio services video services database services image processing services graphics services etc.

The application framework provides an object oriented application environment including classes and Application Programming Interfaces APIs that can be used by developers to build applications using well known programming languages e.g. Objective C Java .

The applications layer is where various applications exist in the software stack . Developers can use the APIs and environment provided by the application framework to build applications such as the applications represented by the display objects shown in e.g. email media player Web browser phone music player video player photos and store .

The user interface can display a view of an audio application which can generally execute e.g. play back audio files such as songs movies podcasts or other media stored in the memory of or accessed by device or . In particular the user interface can display a heads up display HUD audio interface overlaid on a background image . In some implementations the background image can correspond to an audio track on the mobile device such as an album graphic or music video. In other implementations the background image can correspond to an application running on the device such as a browser application an email application or a phone application to name a few examples.

The HUD audio interface can be a transparent or partially transparent display that presents data without obstructing the user s view of background image . For example the interface can be an audio interface displayed as an overlay to a user s current view displayed in interface . As such the HUD audio interface can be used to simultaneously present various user interface elements in the display of device or for example. The user interface elements can include controls images or information for example time date program information text or other device information. As shown the HUD audio interface includes the following user interface elements a volume slide control a reverse track control a forward track control and a pause play control . In general the user can use any or all of the user interface elements for changing the playing of one or more audio files.

In an example operational mode the user can select and slide an indicator of the volume slide control to change the volume level of the device or for a particular audio file playing on the device e.g. from a playlist. A playlist can generally include a list of audio files a user has configured to play consecutively or randomly. As such when a user selects a playlist the audio files can be queued for play in device or .

The user can also select the reverse track control to skip backward to a different point in an audio file. Similarly the user can select the forward track control to skip forward to a different point in an audio file. In some implementations the reverse track control and the forward track control can be used to skip backward or forward respectively in an audio file playlist artist list song list or other audio related list stored in device memory. The user can also select the pause play control to pause or play a selected audio file. In some implementations a stop button not shown can also be selected to stop playing a particular audio file. In some implementations the objects in the interface may not be selectable until the user unlocks a locking control for example.

As shown the touch sensitive display includes the locking control . As shown the control is in a locked position and the device or can be locked until the user slides the control to unlock or alternatively uses another unlocking mechanism e.g. hardware buttons reboot etc. . In some implementations the user can choose to lock or unlock the touch sensitive display during use. For example the user can slide locking control into lock mode e.g. when listening to audio on the device while jogging or when placing the device in a bag to avoid unintentionally providing input to the touch sensitive display . In some implementations when the device is in lock mode the user can trigger the display of the HUD audio interface by selecting e.g. double tapping a hardware control for example button on device or . If the elements of the HUD audio interface are disabled when the lock control is engaged the user can slide the locking control to an unlock state to modify volume or change a song for example. In some implementations the locking control can display directions for the user. For example the locking control shown in interface includes a slide to unlock instruction that visually instructs the user on how to use the control . In some implementations fewer interface elements are provided by the HUD audio interface when the locking control is engaged than the number of interface elements provided by a HUD audio interface when the locking control is disengaged.

As shown in interface the HUD audio interface includes a time display that can display the current time of day for example. The HUD audio interface can also include now playing information shown here as a song named Baba O Riley next playing information not shown previously played audio not shown audio track lengths not shown and other audio information for example.

In some implementations upon invocation of particular device functionality the graphical user interface can be changed or replaced with another user interface or user interface elements to facilitate user access to functions associated with the corresponding invoked device functionality. As an example in response to a user sliding the locking control the touch sensitive display can be unlocked and a new view can be presented in the user interface. The new view may include a different interface for example interface . The interface depicts a HUD audio interface with display elements related to various audio functions. Similar to HUD audio interface the HUD audio interface includes audio controls for volume fast forward rewind and play pause. Additional information can be shown in the HUD audio interface such as a current song generally in play . In this example the current song is displayed as Grace Finds Beauty In Everything from the band U2 on the album Beautiful Day. In some implementations more or less information can be shown about the current song. In addition the HUD audio interface provides the user with the option to enter iPod mode by selecting an iPod button to select other albums songs or media. For example if the user selects iPod button the user interface can present an MP3 video library or other audio related selection within the device. The user interface may include various artists songs videos and other media selectable for play or view in the user interface . In addition the unlocked user interface can allow the user to interact with any or all device options.

In some implementations while the device in an unlocked mode the user can select a close button on the HUD audio interface . Selection of the close button can trigger the device or to exit the HUD audio interface and return the user to a home screen or a previous screen . For example the previous screen can include an email application as shown in shadowed behind HUD audio interface . In some implementations the previous screen may represent the screen that was displayed in the device before the HUD audio interface was invoked for example. Here the user may have been reading or composing email when deciding to invoke the audio interface. In another scenario the user may have been composing email while listening to audio on the device and may wish to change or switch to the audio interface at some point. The user can then change the audio output by performing a preset action e.g. double tapping a hardware or software control selecting an audio icon etc. . In some implementations the user action can trigger the display of a new user interface overlaid on the current interface or replacing the current interface.

In some implementations the new user interface can include an audio application view e.g. the example view in user interface . For example in response to a user entered action the device can display the audio application view of interface . The audio application view can include images or other information associated with a particular audio file including but not limited to a performer a song an album a track number an elapsed time a remaining time album art text menus or other graphics and controls. In some implementations the audio file information shown in an audio application view or in a HUD audio interface can include a link to a resource where the audio file is accessible. For example the link can be a URL for an internet radio website and selection of the link can direct the user to the website e.g. in a browser application on the device. The link may point to more information about the audio file such as album data album reviews performer interviews and more. Selecting such a link can display content about the audio file and other information available from the resource.

In some implementations the user may invoke the display of interface interface or another interface upon performing a similar action. For example if the user double taps hardware button for example he or she may be presented with a user interface such as interface interface or another interface. In particular the same action can bring the user to a number of different user interfaces based on the context of the device or or the state of the current user interface for example.

In some implementations the user interface presented upon user selection of an object or button may depend upon the context of the device or . For example if the user is using the phone application and double taps button an address book user interface may be presented for example to assist the user with finding a phone number. Similarly if the user is using the camera functionality a double tap to button can present a user interface for directing the user to a storage location for a captured photograph for example. In yet another alternative if the user is using the audio player a double tap to button can open or close an audio interface such as the HUD audio interface of interface or interface . For example the user may be composing email and can double tap button to be presented with an audio interface. In this example the interface can display the HUD audio interface over the view of the email application. Using the HUD audio interface the user can change the state of the audio player e.g. change a song volume or other setting .

In some implementations the user interface presented upon user selection of an object or button may depend upon the current state of one or more user interface elements e.g. a slider a button or a dial. For example when the locking control is engaged the HUD audio interface is presented upon user selection of e.g. double tapping button . In another scenario if the locking control is disengaged user selection of button may trigger the display of a different interface for example an interface with additional interface elements not provided with the HUD audio interface . In the locked state of the touch sensitive display may have been set by the user and may remain until a user interaction changes the state. As such the user may unlock the touch sensitive display and then use the HUD audio interface to change one or more settings of the audio player.

In some implementations the user can specify the result of selecting e.g. doubled tapping a button or control through a preference menu. For example the user can specify which user interface is displayed when selecting button while using various applications. More specifically the user can use a preference menu to configure software and hardware control behavior while using each application including the presentation of one or more types of user interfaces. For example a transparent user interface overlay can be presented if the user selects button while composing text in an email for example. In some implementations a new user interface can replace a presently displayed user interface upon selection of the same button . For example a new user interface can be displayed if the user selects button after completing a phone call.

The process begins when input is received at a mobile device where the mobile device includes a user interface with an interface element . Generally a user interface includes multiple interface elements. In some implementations the input is received from a user as a selection of an object or icon displayed on the mobile device. In other implementations the input is a double tap motion on a menu control or a hardware button. In other implementations the input is gesture input provided to a multi touch sensitive display of the mobile device.

The state of the interface element or a context of the mobile device is determined . Interface element states can include for example an engaged locking control a checked check box or a selected menu button. The context of a mobile device can include for example a currently active application a sleep mode a lock mode or an update mode.

In response to the received input a predetermined action is performed based on the determination of the device context or the interface element state . In some implementations the predetermined action can be the display of a particular interface e.g. a HUD audio interface on the mobile device. In other implementations the predetermined action is the invocation of a particular application or feature. The particular interface displayed can be previously specified by a user selection e.g. in a preference menu.

The process begins when a user of a mobile device selects a media or an audio object e.g. the media player object of device or the music player object of device to execute an audio function for example to play an audio file . Alternatively the user can invoke playback of one or more audio files through another icon or pre programmed hardware control. During playback of the audio files the user can use other interfaces on device or . For example the user can use other interfaces to compose email schedule events view photos or websites or other tasks selectable on the mobile device. In some implementations the user can interrupt audio play to use phone features or other messaging features and return to audio play upon completion of a phone call message. Although the audio interface may be running in the background the user is generally using a current view to perform other tasks. As such the current view is displayed in the user interface .

While playing an audio file on the mobile device and displaying an unrelated view in the user interface the user can send a request to display the audio interface. The audio interface can generally include a now playing interface related to the audio track currently in playback. In some implementations the user request may be a selection of an audio icon. In other implementations the user request may be in the form of a double tap motion on a particular menu control or a hardware button. In yet other implementations the request may be in the form of a touch or gesture predetermined by the user to invoke particular device functionality e.g. switch user interface functionality .

In some implementations the mobile device can detect or perform a query to determine whether a user request to display an audio interface is received . If the user request is not received the current view can remain in the user interface e.g. user interface . However if the request to display the audio interface is received in the system the mobile device can display the audio interface as an overlay in the user interface where the audio interface includes information associated with one or more audio files . For example in response to the user double tapping a hardware control button a now playing interface e.g. HUD audio interface can be displayed as an overlay in the user interface e.g. the graphical user interface . Further the now playing interface can include information associated with the audio file such as the name of a file or song song length album title or album length and audio controls such as play rewind or forward.

While displaying the audio interface the mobile device can detect or perform a query to determine whether a user request is received to hide or exit the audio interface. For example the mobile device or can determine whether the user requested to minimize hide exit or otherwise mask the audio interface. If the request is not received the mobile device can continue to display the audio interface. If the request to not display the audio interface is received the mobile device can return to displaying the current view in the user interface without the audio interface . For example the audio interface may be hidden or minimized such that the user does not see the audio interface but the audio player continues to function i.e. the audio file is still in playback . In some implementations the audio file may be paused rather than in playback when the audio interface is minimized hidden or closed.

In some implementations the device or can be transitioned from one user interface to another according to user input or device programming. For example when a user invokes an email application on device an email user interface can be displayed on the device and interfaces for other applications can be minimized closed or otherwise reduced in the display. As such transition screens or interfaces can be presented between the changing of interfaces or applications. For example device or can include animated transitions from displaying the current view in the user interface to displaying a new view in the user interface.

Various animation transition techniques can be used to present a change in the user interface. In general the techniques can include gradual transitions from one image to another in the device display i.e. one view to another view in the user interface . For example one image can be replaced by another image with a distinct or blurry edge. The images described in this disclosure can be actual application content e.g. email audio website controls or text still images text and banners for example. In some implementations the transition shown between images can also include a transition between one application and another application. For example device or can use one or more animated transitions to move from an email application view to an audio playback application view. In some implementations the display of audio interfaces can also be animated along with any image application text etc. The audio interface can remain transparent or partially transparent over any or all animated content and the interface elements of the audio interface can be enabled when animation completes. In some implementations the audio interface can be transitioned before a background image is transitioned.

In some implementations the transition animations occur gradually over a period of time. In other implementations the transition animations occur immediately upon receiving a user request. For example the image in the user interface can be faded wiped dissolved cut away or otherwise morphed into another image over time or instantaneously. In some implementations one or more animation effects can be user configured for each application through a preference menu for example.

The shrink and expand animation can include effects such as the shrinking of a current view in a user interface followed by an expanding of a new view in the user interface. In some implementations the shrink and expand animation can occur upon user request. For example the user can touch or provide input gesture to the device that a change in the user interface is desired. The user touch or gesture can include a double tap of a control button to indicate that a change is desired in the user interface of screen shot for example. In some implementations the user touch or gesture can include selection of a hardware button an icon or other menu item.

In an example operational mode the user indicated change can occur for example when the user is viewing application data such as a webpage . In this example the webpage is shown in screen shot and represents a news story accessed by the user. The user can generally utilize the webpage or another application on the device until the user wishes to switch the content displayed in the user interface. For example the user may use the webpage and can decide at some point to switch to view an audio application view. The user can then invoke the audio application view with an audio interface by touching or providing gesture input to the screen to trigger the desired screen change e.g. double tapping a control button on the device . In response to the user touch or gesture the display of the webpage image can be transitioned through animation to display the requested audio application view. In some implementations the animated transition can include gradually shrinking the webpage image shown in screen shot over time until the image fades away. For example the webpage image is shown smaller in screen shot smaller yet in screen shot still smaller in screen shot and finally barely visible in screen shot .

Upon reaching a certain image dissolution the device can begin to present and expand a new interface image . The new image is shown in screen shot as a small view of an audio application. The animation continues by gradually expanding the new image in screen shot and finishes as a full sized image in screen shot . In some implementations an audio interface can be animated in the user interface along with the audio application content. In this example the audio interface is present in screen shot with interface elements selectable by the user. After the animated transition completes the user can begin using the presented audio interface. In some implementations the animated transition can incrementally fade while shrinking or brighten while expanding over time. In some implementations the audio interface may be visible and usable before the animation effect is complete. In some implementations the audio interface is an overlay over the view of the audio application. In other implementations the audio interface is part of the audio application view.

In an example operational mode a user may be viewing content in the user interface of screen shot . The content in this example is a webpage image . At some point the user can request to view different content in the interface such as an audio application view. As such the user request can invoke the mobile device to switch to a display of the new user interface. For example upon receiving the user request the mobile device may begin the slide animation by shifting the webpage image upward and eventually off the screen of the device.

As shown in screen shot the slide animation begins to appear. For example the webpage image is shown sliding upward as a first portion of a new image is presented in the device for example. Over time the webpage image can slide further upward while a new image slides upward below image to replace image . More particularly the new image can slide upward at a similar rate to the rate the image slides upward and thereby can replace the webpage image . In some implementations the slide transition can be completed in less than a second.

As shown in screen shot approximately half of each image and is displayed in the user interface of the device. In this animation image slides upward while image slides to replace image in a portion of the screen. A screen shot displays a last portion of image and a nearly full portion of image . A screen shot displays the fully transitioned image triggered by the user entered request to change content. After the slide animation effect is completed the interface of screen shot depicts the image as a view of an audio application selectable and usable by the user of the device. In some implementations an audio interface e.g. audio interface appears as an overlay over the view of the audio application. In some implementations the user may switch to the audio image briefly to change a song in play and switch back to the initial webpage image upon completion of the change song task. In a similar fashion the user can switch to another task and back to the audio image as desired.

In some implementations the slide animation can occur horizontally or diagonally across the screen of the device. In certain implementations the sliding animation effect can occur from left to right right to left upward or downward. In a similar fashion the diagonal slide effect may occur corner to corner from any one of the corners of the device display.

In some implementations the wipe away animation effect can occur upon user request. For example the user can touch or provide input gesture to the device that a change in the user interface is desired. As described above the user touch or gesture can include a double tap of a control button to indicate that a change is desired in a user interface of screen shot for example. Other user applied motions are possible.

In an example operational mode a user may be viewing content in the user interface of screen shot . The content in this example is a webpage image . At some point the user can request to view different content in the interface such as an audio application view. Accordingly and upon user request the mobile device may begin the wipe away transition by beginning to scroll a horizontal edge . As shown in screen shot the wipe away animation is beginning to change the view in the user interface of screen shot . The horizontal edge is shown in screen shot as a line of demarcation as the two images scroll across the user interface. At this point the first image is shown in the right portion of the interface of screen shot while a second image begins to wipe onto the left portion of the interface of screen shot . In effect the transition can also be viewed as a wiping away of the first image along the line of demarcation to reveal the second image which appears to lie beneath the first image in the user interface of screen shot .

As shown in screen shot the line of demarcation has progressed across the screen to approximately half way between image and image . An audio interface appears as in overlay over a lower portion of image . In some implementations the user can select a control element in the audio interface as soon as the selectable control element is displayed in the user interface. For example the user can select and use the audio interface controls before the image animation is complete. In this example the audio interface may temporarily disassociate with the animation if the user selects the controls before a particular animation transition completes.

The wipe away animation continues in screen shot and can complete in screen shot . Here the new image has completely replaced previous image and the user can begin using the audio application including the controls of the audio interface as requested. In some implementations the wipe away animation effect can be performed in a clock pattern. In some implementations the wipe away animation can occur vertically or diagonally across the screen of the device.

As an example a user may be viewing content in the user interface of screen shot . The content in this example is again a webpage image . At some point the user can request to view different content in the interface such as an audio application view and the mobile device may begin the clock wipe animation by sweeping a radius around a center point of the user interface. The screen shot depicts a new image revealed below or replacing the current image in a radial pattern about center point . As shown in screen shot the radial sweep begins at the center point pointing upward to the 12 00 position on a standard analog clock. In some implementations the clock wipe animation can be configured to begin anywhere on the screen.

In screen shots and the clock wipe animation continues in a clockwise direction as more of the image is shown and less of the image is shown. In some implementations the clock wipe can be performed in a counterclockwise direction.

A screen shot displays the fully transitioned image resulting from the user entered request to change content. After the clock wipe animation effect is completed the interface of screen shot depicts the image as a view of an audio application usable by the user of the device. In some implementations an audio interface e.g. audio interface appears as an overlay over the view of the audio application.

Turning to screen shot a user may be viewing a webpage image and wish to switch the view to an audio application view with a now playing audio interface on the mobile device. As such the user may request to view an audio application view such as the example view in user interface for an audio application on the mobile device. As shown in screen shot the device can begin to animate the ripple upon receiving the user s request. The ripple shows a new image partially superimposed on the surrounding webpage image .

Now turning to screen shot the ripple animation effect is affecting a larger portion of the images and . Similarly the screen shots and show blends between the images and . In some implementations over time the effect can begin to dampen as the ripple resonates through the user interface. At some point the webpage image may become out of focus and semi transparent as it fades away and image ripples into view in the user interface. The screen shots and show the fading of image and the emerging of image respectively. A screen shot shows the new image and the user can begin using the newly displayed audio application in the user interface of screen shot . In some implementations an audio interface e.g. audio interface appears as an overlay over the view of the audio application.

Similar to the above described examples while viewing the user interface of screen shot containing a webpage image the user of the device can request a user interface change. For example the user may request to view an audio application view with a now playing interface such as the example view in user interface for an audio application on the device. As shown in screen shot the device can begin to animate a burning hole upon receiving the user s request. The burning hole shows a new image while the surrounding image is that of webpage image .

Referring to screen shot a larger portion of the image is displayed through the enlarging opening of the burning hole . The user interface of screen shot still contains portions of webpage image but less so than in screen shot . Similarly the burning hole is larger in screen shot and larger yet in screen shot . Finally the burning hole animation is shown completed in screen shot . Here the new image is fully visible in the user interface whereas image has burned away. In some implementations an audio interface e.g. audio interface appears as an overlay over the view of the audio application as represented by image . In this example the burning hole is shown beginning from the center outward. However in some implementations the burning hole may begin anywhere on the user interface.

In some implementations a dissolve animation effect can be used to transition from one image to another. For example an image in a user interface can gradually transition to another image by interpolation. In particular the device can gradually interpolate between the red green and blue RGB values of each pixel of the first image and the RGB values of each corresponding pixel of the second image. The dissolve animation can soften the first image while sharpening the second image. At some point the two images may appear blurred together until the first image is dissolved and the second image is brought in focus.

In some implementations a matrix wipe animation can be used to transition from one view to another view in the user interface of the device. For example a patterned transition can be programmed to wipe from one view to another. The matrix wipe can use various patterns such as a grid stars boxes pixels etc.

In some implementations the user can configure the device or with the desired animation effects. In some implementations one animation effect can be assigned to any or all user interface changes. For example the user can configure the device or to display a particular wipe effect when switching from any application view to an audio application view such as the example view in user interface . In other implementations the user can configure separate animation effects for each transition in the user interface of the mobile device.

The described features can be implemented advantageously in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. A computer program is a set of instructions that can be used directly or indirectly in a computer to perform a certain activity or bring about a certain result. A computer program can be written in any form of programming language e.g. Objective C Java including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment.

Suitable processors for the execution of a program of instructions include by way of example both general and special purpose microprocessors and the sole processor or one of multiple processors or cores of any kind of computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memories for storing instructions and data. Generally a computer will also include or be operatively coupled to communicate with one or more mass storage devices for storing data files such devices include magnetic disks such as internal hard disks and removable disks magneto optical disks and optical disks. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices such as EPROM EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in ASICs application specific integrated circuits .

To provide for interaction with a user the features can be implemented on a computer having a display device such as a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device such as a mouse or a trackball by which the user can provide input to the computer.

The features can be implemented in a computer system that includes a back end component such as a data server or that includes a middleware component such as an application server or an Internet server or that includes a front end component such as a client computer having a graphical user interface or an Internet browser or any combination of them. The components of the system can be connected by any form or medium of digital data communication such as a communication network. Examples of communication networks include e.g. a LAN a WAN and the computers and networks forming the Internet.

The computer system can include clients and servers. A client and server are generally remote from each other and typically interact through a network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made. For example elements of one or more implementations may be combined deleted modified or supplemented to form further implementations. As yet another example the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other implementations are within the scope of the following claims.

