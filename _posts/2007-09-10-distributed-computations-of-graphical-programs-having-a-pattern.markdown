---

title: Distributed computations of graphical programs having a pattern
abstract: In one embodiment, a computer-implemented method for concurrently processing at least a portion of a graphical model is provided. The method may include obtaining the graphical model; recognizing a pattern in the graphical model, the pattern suitable for concurrent processing; and employing concurrent processing using multi-thread, multi-core, or multi-processor computing device when executing the pattern in the graphical model.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09262141&OS=09262141&RS=09262141
owner: The MathWorks, Inc.
number: 09262141
owner_city: Natick
owner_country: US
publication_date: 20070910
---
The present application claims the benefit of U.S. Provisional Patent Application No. 60 843 095 filed on Sep. 8 2006 the content of which is incorporated by reference in its entirety.

Techniques such as graphical analysis and simulation may be used in modeling design analysis and or synthesis of engineered systems. These techniques may provide various classes of graphical models to describe computations that can be performed on application specific or general purpose computational hardware such as a computer microcontroller field programmable gate array FPGA or custom hardware. Classes of such graphical models may include time based block diagrams state based and flow diagrams entity flow network diagrams and or data flow diagrams. A common characteristic among these various classes of graphical models is that they can define semantics that determine how a diagram is executed.

Graphical modeling has spawned a variety of software products that cater to various aspects of dynamic system analysis and design. Such products allow users to perform various types of tasks including constructing system models through a user interface that allows drafting graphical models allowing augmentation of a pre defined set of blocks used in block diagrams with users custom built blocks using the graphical model to compute and trace the temporal evolution of the dynamic system s outputs executing the graphical model and automatically producing either deployable software systems or descriptions of hardware systems that mimic the behavior of either the entire model or portions of it.

In one embodiment a computer implemented method for concurrently processing at least a portion of a graphical model is provided. The method may include obtaining the graphical model recognizing a pattern in the graphical model that is suitable for concurrent processing and employing concurrent processing using a multi threaded multi core or multi processor computing device when executing the pattern in the graphical model.

In another embodiment a system for concurrently processing at least a portion of a graphical model is provided. The system includes a pattern recognizer that recognizes a pattern in the graphical model. The pattern is suitable for concurrent processing. The system also includes a pattern partitioner that partitions the recognized pattern into a specified number of partitions for concurrent processing. Each partition is executed by a different thread a different core or a different computing resource.

In still another embodiment a medium storing computer executable instructions for causing concurrent processing at least a portion of a graphical model is provided. The instructions include instructions for obtaining the graphical model instructions for recognizing a pattern in the graphical model wherein the pattern is suitable for concurrent processing and instructions for employing concurrent processing using a multi threaded multi core multi processor or a combination thereof in executing the pattern in the graphical model.

In yet another embodiment a computer implemented method for concurrent processing at least a portion of a graphical model is provided. The method includes obtaining the graphical model recognizing a pattern in the graphical model wherein the pattern is suitable for concurrent processing and designating the pattern for concurrent execution.

The complexity of systems modeled in a modeling environment may necessitate the deployment of the automatically produced software and hardware descriptions onto hardware platforms that contain more than one resource capable of performing computational processing. Such resources can range from multiple threads running on a single processor to multiprocessor platforms. A multiprocessor system is one in which two or more central processing units CPUs are installed in a single package such as within a single integrated circuit package or a single printed circuit board PCB . A multiprocessor system is capable of allocating computing tasks amongst the multiple CPUs in the system. The term multiprocessing is used to mean that a multiprocessing system is capable of processing multiple tasks in a concurrent fashion. Multiprocessor systems are further classified as tightly coupled or loosely coupled depending on the bandwidth of the communication which is supported amongst the CPUs in the system. For example tightly coupled processors are those which are connected through a high bandwidth bus. For example a loosely couple multiprocessing system is a system of N processors which are connected through a lower bandwidth Ethernet network connection. A multicore platform is a tightly coupled multiprocessor system in which the CPUs in the system are packaged into a single integrated circuit.

The multiple computational resources on the hardware platform may allow the deployment of complex systems in which computations can be performed in a concurrent manner on these resources.

Additionally with many engineering and scientific problems requiring larger and more complex modeling computations become more resource intensive and time consuming. However a single computational processor can be limiting to the size of the problem that can be solved in a reasonable amount of time because of the relationship of the computing power of the workstation to the computing power necessary to execute computing intensive iterative processing of complex problems in a reasonable amount of time. For example a simulation of a large complex aircraft model may take a reasonable amount of time to run with a single workstation with a specified set of parameters. However the analysis of the problem may also require the model to be executed multiple times with a different set of parameters e.g. for an aeronautical model the model may need to be executed at one hundred different altitude levels and fifty different aircraft weights to understand the behavior of the model under varied conditions. This example requires five thousand computations of the model to analyze the problem and the single workstation takes an unreasonable amount of time to perform these computations. Therefore it may be desirable to perform executions using multiple computing resources when the computation becomes so large and complex that it cannot be completed in a reasonable amount of time on a single workstation. In addition it may be desirable to perform executions using multiple computing resources when executing a single model on a single workstation would take too long.

Exemplary embodiments may provide devices and or techniques for deploying portions of a graphical model on a hardware platform that supports concurrent processing. Exemplary embodiments may also concurrently simulate at least a portion of a graphical model. A portion of a graphical model may be identified and compared to predetermined patterns that are suitable for concurrent simulation or deployment. If the portion matches one of the patterns the portion may be concurrently processed. Concurrent is used herein to mean simultaneous execution of two or more computations partly or fully overlapped in time. Concurrently processed is used herein to mean that the portion may simulated concurrently or software and or hardware module is generated for deployment on a hardware platform that supports concurrent processing.

Exemplary embodiments can be applied to a time based graphical model a state based graphical model an entity based graphical model or a combination thereof. Exemplary embodiments can also be applied to other types of graphical models such as a dataflow graphical model.

Exemplary embodiments may partition patterns present in a model and perform concurrent processing using a multi threaded multi core or multi processor system.

Selected embodiments may provide concurrent processing of at least a portion of a graphical model where the portion includes a pattern among a set of patterns. Concurrent processing may be efficient when the graphical model has components that fit one of the identified patterns. The greater the number of patterns that can be identified in a model the greater the number of opportunities to execute portions of the model concurrently and thus the greater performance improvement that may be achieved.

In this way a time based simulation environment such as SIMULINK can participate in the aforementioned identification of certain patterns and may lead to a concurrent implementation of the time based model.

In one embodiment an intermediate representation IR of a graphical model may be used to recognize a pattern in the graphical model that is suitable for concurrent processing. One IR useful for this task is an in memory graph based representation of the block diagram. Nodes of the graph may be symbolic representations of activities such as computations to be performed on data and may correspond to the blocks in the diagram. Edges of the graph that is interconnections among graph nodes may represent input output or intermediate data results utilized or produced by the nodes in the graph and may represent lines connecting blocks in the original graphical model. Recognition of connectivity patterns in the graphical block diagram may be complicated by the presence of irrelevant attributes such as color shape position size etc. of the blocks. In contrast recognition of patterns in the IR is greatly simplified since irrelevant attributes are discarded or made to be easily ignored in the graph nodes. Traversal of graph nodes is also generally simplified in the IR as compared to traversing a direct representation of an original graphical model. Also the graph may be particularly tailored for use with another program that may assess collections of connected nodes to identify patterns of interest and may permit simpler removal replacement extension or transformation of the graph or subgraphs within the graph to yield a new graph.

Pattern templates may be produced and retained in memory as small independent graphs of connected nodes and in this way a library of pattern templates motifs may be stored in a compact form to be used during identification. As the IR corresponding to a model is compiled each node of the IR is visited. At this time each graph template in the library may be compared at the correct node to test for a match. Different nodes of the template graph can be selected for alignment to the current IR node for robust identification.

Techniques for matching a template graph to a larger graph are well known and include heuristic search.

Graphical portions and can be concurrently processed. In this scatter gather pattern each of the portions and may be assigned to be executed on different computing elements. The implementation of the different computing elements to which the portions and may be assigned will be described below in more detail with reference to .

The distribution node and aggregation node may perform their operations on the same computing element or separate computing elements. Likewise the three graphical nodes and may operate on three separate computing elements or may share fewer resources.

Although illustrate a pipelining pattern using three graphical portions a pipelining pattern with any number of graphical portions more than one may be used.

The term multi core is used herein to refer to a computing resource that has multiple cores where each core is a distinct and separably operable processing node.

The term multi processor is used herein to refer to multiple computing resources that are used to perform processing operations such as processing operations related to a graphical model. For example computing device has both processor and computing resource s that can be used to process a graphical model built using application . The computing resources in a multi processor environment do not need to be the same. In other words computing device may have a multi processor environment even if computing resource is not a processor.

The term multi thread is used herein to refer to an environment that supports multiple parallel paths of execution.

The memory may include a computer system memory or random access memory such as dynamic random access memory DRAM static random access memory SRAM extended data output random access memory EDO RAM etc. The memory may include other types of memory as well or combinations thereof. A user may interact with the computing device through a visual display device such as a computer monitor which may include a user interface . The computing device may include other I O devices such a keyboard a pointing device such as a mouse for receiving input from a user. Optionally the keyboard and the pointing device may be connected to the visual display device . The computing device may include other suitable conventional I O peripherals. The computing device may further comprise a storage device such as a hard drive CD ROM or other computer readable media for storing an operating system and other related software and for storing application .

A graphical model implemented using application can be executed using multi thread multi core or multi processor computing techniques and or devices. Application can include a pattern recognizer for detecting a pattern in the graphical model that is suitable for concurrent processing. Application can also include pattern partitioner for partitioning the pattern in the graphical model that is recognized by pattern recognizer . One of ordinary skill in the art will appreciate that pattern recognizer and pattern partitioner can be adapted to be included as part of the application or they can each be a stand alone application module script program that responds to calls from the application .

Additionally the operating system and application can be run from a computer readable media such as for example KNOPPIX a bootable CD for GNU Linux.

The computing device may include a network interface to interface to a Local Area Network LAN Wide Area Network WAN or the Internet through a variety of connections including but not limited to standard telephone lines LAN or WAN links e.g. 802.11 T1 T3 56 kb X.25 broadband connections e.g. ISDN Frame Relay ATM wireless connections controller area network CAN or some combination of any or all of the above. The network interface may comprise a built in network adapter network interface card personal computer memory card international association PCMCIA network card card bus network adapter wireless network adapter USB network adapter modem or any other device suitable for interfacing the computing device to any type of network capable of communication and performing the operations described herein. Moreover the computing device may be any computer system such as a workstation desktop computer server laptop handheld computer or other form of computing or telecommunications device that is capable of communication and that has sufficient processor power and memory capacity to perform the operations described herein.

The computing device can run substantially any operating system such as any of the versions of the Microsoft Windows operating systems the different versions of the Unix and Linux operating systems any version of the MacOS for Macintosh computers any embedded operating system any real time operating system any open source operating system any proprietary operating system any operating systems for mobile computing devices or any other operating system capable of running on the computing device and performing the operations described herein. The operating system may be running in native mode or emulated mode.

Virtualization can be employed in computing device so that infrastructure and resources in the computing device can be shared dynamically. Virtualized processors may also be used with application and other software in storage . A virtual machine can be provided to handle a process running on multiple processors so that the process appears to be using only one computing resource rather than multiple. Multiple virtual machines can also be used with one processor. Other computing resources such as Field Programming Gate Array FPGA Application Specific Integrated Circuit ASIC Application Specific Instruction Processor ASIP Digital Signal Processor DSP and General Purpose Processor GPP may also be used for executing code and or software. A hardware accelerator such as implemented in an ASIC FPGA or the like can additionally be used to speed up the general processing rate of the computing device .

A concurrent computing lab is a process such as an instance of an application executing on a computing resource where the process performs distributed computing or parallel computing.

A computing resource can be but not limited to a processor a computer system GPP DSP FPGA ASIC or other hardware with computational capabilities such as instruments for data acquisition oscilloscopes waveform generators etc. . Each computing resource may have a single core or multiple core. For a multi core computing resource it can further be a homogeneous multi core such as Intel Centrino Duo dual core processor or a heterogeneous multi core such as a TI OMAP processor that has an ARM core and a C5000 DSP core or a Silinx Virtex 2 FPGA with 1 to 4 PowerPC processor cores.

More than one concurrent computing lab can be run on a single computing resource and each concurrent computing lab can be on a different thread or a different core. More than one concurrent computing lab can also be run on a single core of a computing resource where each concurrent computing lab can be on a different thread. The concurrent computing client is in communication with the concurrent computing labs A N and server through network communication channels over a network . One of ordinary skill in the art will appreciate that workstations A N server and client may have one or more concurrent computing lab. Each of the concurrent computing labs A N is an instance of the application .

The concurrent computing client can be a technical or non technical computing software application. Concurrent computing client may provide a technical computing and or graphical modeling environment for generating block diagram models and to define mathematical algorithms for simulating models. The concurrent computing client may include all or a portion of the functionality provided by the application . Furthermore the concurrent computing client can be a custom software program or other software that accesses functionalities of application via an interface such as an application programming interface API or by other means. One of ordinary skill in the art will appreciate the various combinations of client types that may access the functionalities of the system.

In one embodiment of the present invention concurrent computing client is also a concurrent computing lab. In such a configuration communication channels are set up among the concurrent computing labs concurrent computing client and concurrent computing labs A N . Each of the concurrent computing labs including the concurrent computing client has its local copy of a computer program that is executed in the corresponding concurrent computing labs so there is no main concurrent computing lab that distributes executions to the other concurrent computing labs.

Alternatively a copy of the computer program can be accessed through a network connection. The local copy of the program for each lab may or may not be identical. The concurrent computing client can additionally have the functionality to accept inputs and or commands from a user related to the computer program using a tool such as an Integrated Development Environment IDE . The concurrent computing client and concurrent computing labs A N can be configured to perform distributed computing or parallel computing.

In one embodiment of the present invention functions can be defined by the concurrent computing client with an application programming interface API and or programming language representing a technical computing task to be executed by either a technical computing environment local to the client or remote on the workstations A N. Tasks can be declared on a concurrent computing client and additionally organized into jobs. A job is a logical unit of activities or tasks that are processed and or managed collectively. A task defines a technical modeling computing command to be executed and the number of arguments and any input data to the arguments. Each job can include one or more tasks.

In one aspect of the present invention a task can be directly distributed by the concurrent computing client to one or more computing resources such as workstations A N. A computing resource performs technical computing on a task and may return a result to the concurrent computing client .

In another aspect of the present invention the system may include a server on which a scheduler runs. The scheduler can be a scheduler provided with application a generic scheduler or a third party scheduler that is designed and provided by a company or individual that may not provide application .

For example if application is parallel computing with MATLAB by The MathWorks Inc. of Natick Mass. a third party scheduler can be MPI Exec LSF Condor Microsoft Compute Cluster Server or PBS. The server communicates over a network communication channel on the network to the workstations A N. One of ordinary skill in the art will appreciate that any of the workstations A N may include more than one technical computing lab to practice the present invention. Additionally client and server may also include one or more concurrent computing labs.

The scheduler comprises one or more application software components to provide for the automatic distribution of tasks from the concurrent computing client to one or more of the concurrent computing labs A N. The scheduler allows the concurrent computing client to delegate the management of task distribution to the scheduler . The scheduler may also set up for concurrent computing client the concurrent computing labs A N by using the information received from the concurrent computing client regarding the number of concurrent computing labs needed and other configuration information.

Hence the concurrent computing client may not need to know the specifics of the concurrent computing labs A N. The concurrent computing client can define a function to submit the task to the scheduler and get a result of the execution of the task. As such the scheduler provides a level of indirection between the concurrent computing client and the concurrent computing labs A N.

The use of a scheduler eases the distributed programming and integration burden on the concurrent computing client . The concurrent computing client may not need to have prior knowledge of the availability of the workstations A N. For multiple task submissions from the concurrent computing client the scheduler can manage and handle the delegations of the tasks to the concurrent computing labs A N and hold the results of the tasks on behalf of the concurrent computing client for retrieval after the completion of technical computing of all the tasks distributed by concurrent computing client or at desired intermediate points.

In an alternative implementation the concurrent computing labs A N may provide concurrent computing client directly the results of the tasks assigned to concurrent computing labs A N by the scheduler . The scheduler can further include an object oriented interface to provide control of delegating tasks and obtaining results in the system . The scheduler also provides an interface for managing a group of tasks collectively as a single unit called a job and on behalf of a concurrent computing client submitting those tasks making up the job and obtaining the results of each of the tasks until the job is completed.

One of ordinary skill in the art will recognize that the functions and operations of the scheduler can be separated into various software components applications and interfaces. Additionally the functions and operations of the scheduler may reside on either the concurrent computing client or one of the concurrent computing labs A N instead of the server .

Additionally each of the client the server and the workstations A N can be running the same or different operating systems with the same or different processors. For example the client can be running Microsoft Windows the server can be running a version of Unix and the workstations A N a version of Linux. Alternatively each of the client the server and the workstations A N can be running Microsoft Windows .

One of ordinarily skill in the art will recognize the various combinations of operating systems and processors that can be running on any of the computing devices client server workstations A N . One or ordinary skill in the art will also appreciate that some computing devices may not have or require an operating system. For example an FPGA that may operate without an operating system can be configured to perform computations synchronously and or asynchronously and may place the data on a communication bus and or other type of device and or interface.

In other embodiments the concurrent computing labs A B and C can interface via socket based communications over TCP IP implementing a custom message specification. In further embodiments the concurrent computing labs A B and C may communicate using any available messaging communications products and or custom solutions that allow the sending and receiving of messages among the concurrent computing labs A B and C.

In certain embodiments the communication channel may include a file interfacing mechanism such as reading and writing to files on a network accessible directory or common file system. Furthermore the concurrent computing labs A B and C can each be waiting or listening for messages from other concurrent computing labs A B and C.

One of ordinary skill in the art will recognize the various types of interfaces to communicate messages among the concurrent computing labs A B and C. The communication among the concurrent labs A C may be done over a bus using interfaces such as PCMCI Flexray Firewire RS 232.

In one embodiment of the present invention the collaboration is dynamic. In other words a user can modify or change the size of the collaboration by adding another computing resource. The user may be provided on the client with a user interface to modify or change the size of the collaboration or designate a specific resource to add or remove from the collaboration. In another embodiment of the present invention the client can forward the information to the scheduler which will determine a concurrent computing lab to be added or removed from the collaboration.

Dataflow may refer to a programming method where the execution of a particular program is triggered by the availability of data to all inputs of the particular program. For example in a graphical programming language that implements a dataflow the program and or model may include boxes with inputs and or outputs. The program model may further include arrows between the boxes where the arrows indicate a flow of the input and output data. The boxes may run when inputs used by a box become valid and not having to wait for the program to encounter the boxes.

Dataflow components can be used to model a dataflow program as a directed graph of data flowing between operations. When all inputs are available in a dataflow component execution of the dataflow component may begin and may continue until a termination signal is encountered. Unlike other programs such as a time based program or an event based program execution of all elements in a dataflow component does not stop or pause somewhere in the middle of the execution before resuming execution.

LabVIEW is an example of a software program that utilizes a dataflow environment however it is an asynchronous dataflow program. In an asynchronous dataflow program inputs are not available at the same time hence one cannot predict when execution of the dataflow components will start. In an exemplary embodiment the dataflow components are synchronous dataflow components. In a synchronous dataflow component data flow is scheduled so that the flow of control is completely predictable at compile time. In other words inputs would be available at the time when the synchronous dataflow component is scheduled to be executed.

Referring still to in step the pattern recognizer may inspect the graphical model and recognize a pattern in the graphical model where the pattern is suitable for concurrent processing. In an exemplary embodiment one or more elements in the dataflow components form the recognized pattern. The pattern can be a scatter and gather pattern a pipelining pattern an iteration pattern or a combination thereof. illustrates different patterns that are suitable for concurrent processing. The pattern recognizer may optionally recognize the pattern at compile time of the graphical model. The pattern recognizer may also optionally use an intermediate representation of the graphical model to find the recognized pattern in step .

In step user instructions may be optionally obtained regarding how to partition the recognized pattern. In step pattern partitioner may partition the recognized pattern automatically or may partition based on user instructions where each partition may be executed by a different thread a different core or a different computing resource.

In one aspect the pattern partitioner partitions the recognized pattern based on computational power of one or more computing resources used in concurrent processing of the pattern in the graphical model. Pattern partitioner can partitions the recognized pattern into a determined number of partitions.

In another aspect pattern partitioner may partition the recognized pattern based on user instructions. A user may specify a number of partitions or the pattern partitioner may partition the pattern based on available resources computational requirements of each graphical portion in the pattern and or other information.

For example given a scatter and gather pattern like that in that is recognized by the pattern recognizer and given two threads that can be used to perform concurrent processing pattern partitioner may decide to use one thread to execute graphical portions and and another thread to execute graphical portion given that graphical portion takes the longest to process among the three graphical portions and .

In another example if three computing resources are available and a scatter and gather pattern like that in is recognized the pattern partitioner may assign each computing resource with a graphical portion. Alternatively the pattern partitioner may partition graphical portions and into one partition and assign them to one computing resource. The other two computing resources are assigned to share the processing of graphical portion since graphical portion may take the longest to process among the three graphical portions.

Referring still to user instructions optionally may be obtained regarding one or more computing resources that can be used to employ concurrent processing of the graphical model in step . User instructions can include which partition should be assigned to which computing resource or what type of concurrent processing would be employed either multi thread multi core multi processor or a combination thereof. For each partition code is generated to fit the corresponding computing resource. The right I O input output driver the right API application programming interface the memory needed and other materials need to be prepared for each computing resource so that concurrent processing can be realized.

Although concurrent processing has overhead in obtaining the proper driver the interface or in performing other preparation work a lot of time can still be save if the graphical model is complex and or large enough for execution. Finally in step concurrent processing is employed using multi thread multi core multi processor or a combination thereof in executing the pattern part of the graphical model.

Exemplary embodiments are described for illustrative purposes relative to a Simulink compatible modeling environment that enables a graphical model to be built and or executed. A SIMULINK compatible modeling environment provides means e.g. via hardware or software based logic to use a SIMULINK model and or features in the SIMULINK compatible modeling environment. For example a SIMULINK compatible modeling environment may provide means to interface with a SIMULINK model means for importing or exporting a SIMULINK model means for translating a SIMULINK model means for integrating a SIMULINK model etc. Although exemplary embodiments may be described relative to a SIMULINK compatible modeling environment the present invention is not limited to these embodiments and may be applied to graphical modeling and or computing tasks via other graphical modeling environments.

Further examples of graphical modeling environments that may be used to develop and or execute a graphical model in accordance with exemplary embodiments include but are not limited to LabVIEW or MATRIXx from National Instruments Inc. SoftWIRE by Measurement Computing VisSim by Visual Solutions WiT by DALSA Coreco VEE Pro by Agilent Dymola from Dynasim AB Extend from Imagine That Inc. Scicos from The French National Institution for Research in Computer Science and Control INRIA MSC.Adams from MSC.Software Corporation Rhapsody from iLogix Inc. Rational from International Business Machines Corporation ARTiSAN Studio from ARTiSAN Software Tools Inc. SCADE from Esterel Technologies Inc. and a Unified Modeling Language UML environment among others.

The foregoing description of exemplary embodiments of the invention provides illustration and description but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention. For example while a series of acts has been described with regard to the order of the acts may be modified in other implementations consistent with the principles of the invention. Further non dependent acts may be performed in parallel.

In addition implementations consistent with principles of the invention can be implemented using devices and configurations other than those illustrated in the figures and described in the specification without departing from the spirit of the invention. Devices and or components may be added and or removed from the implementations of depending on specific deployments and or applications. Further disclosed implementations may not be limited to any specific combination of hardware and or software.

Further certain portions of the invention may be implemented as logic that performs one or more functions. This logic may include hardware such as hardwired logic an application specific integrated circuit a field programmable gate array a microprocessor software wetware or a combination of hardware and software.

No element act or instruction used in the description of the invention should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items. Further the phrase based on as used herein is intended to mean based at least in part on unless explicitly stated otherwise.

